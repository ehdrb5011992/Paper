{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"03.GoogLeNet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [GoogLeNet]"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original GoogLeNet\n","```\n","1) Support Functions\n","2) Almost Original GoogLeNet\n","3) GoogLeNet Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606277552908,"user_tz":-540,"elapsed":119775,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"849c05f3-1d1f-4e0f-f79c-275d6ad24648"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606277552909,"user_tz":-540,"elapsed":119761,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"96c120aa-f949-4de1-9504-839082f084d2"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HxNdfTtNwd9J","executionInfo":{"status":"ok","timestamp":1606277556936,"user_tz":-540,"elapsed":123783,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["from f1score import macro_f1score,weighted_f1score\n","from pool_helper import PoolHelper\n","from lrn import LRN"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1606277556950,"user_tz":-540,"elapsed":123794,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D\n","from tensorflow.keras.layers import add\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606277556954,"user_tz":-540,"elapsed":123782,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"571ff9ea-7bfb-40b8-b03d-e8711aeb7173"},"source":["os.getcwd()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"aeqQ6tagEcQi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606277560555,"user_tz":-540,"elapsed":127371,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"bfe6f467-d64c-4317-d01a-e13dd05b00eb"},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dskXxmkc_-fK","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606277560938,"user_tz":-540,"elapsed":127744,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"245e789b-a872-4d26-8904-56933b9552e1"},"source":["tf.test.gpu_device_name()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"joOrR4FOMkja","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606277560941,"user_tz":-540,"elapsed":127737,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"5368f48f-7cd4-47e8-d646-36b4e188c7b0"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 12954268794818763326\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 10371663052467458468\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 7514750248482351377\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15473714176\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 16513206466039624170\n","physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"UJMl9X9C3H1h","executionInfo":{"status":"ok","timestamp":1606277560944,"user_tz":-540,"elapsed":127738,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'MIT'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 224\n","super_size = 256\n","input_sizes = (size,size,3)\n","batch_sizes = 128\n","weight_decay = 1e-4\n","epochs = 70"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1606277560945,"user_tz":-540,"elapsed":127737,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"tW0qQsvKnGTG","executionInfo":{"status":"ok","timestamp":1606277560945,"user_tz":-540,"elapsed":127734,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1606277560946,"user_tz":-540,"elapsed":127731,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g_JGvoqtnGTM"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"a6Ht6oZinGTM","executionInfo":{"status":"ok","timestamp":1606277560947,"user_tz":-540,"elapsed":127730,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1606277560948,"user_tz":-540,"elapsed":127729,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"kRUFnlHG8dQ0","executionInfo":{"status":"ok","timestamp":1606277560948,"user_tz":-540,"elapsed":127727,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"FBTMwbyuJq1A","executionInfo":{"status":"ok","timestamp":1606277560949,"user_tz":-540,"elapsed":127726,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 매우 간단하다.\n","\n","#1. train data\n","\n","def generate_train_for_three(crop_length=size, batch_sizes = batch_sizes, super_size=super_size):\n","\n","      batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical')\n","\n","      while True:\n","          batch_x, batch_y = next(batches)\n","          batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","          for i in range(batch_x.shape[0]):\n","              batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","          yield batch_crops, [batch_y,batch_y,batch_y]\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oh3RCAUaJq1E","executionInfo":{"status":"ok","timestamp":1606277560950,"user_tz":-540,"elapsed":127725,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 2. valid data\n","\n","def generate_valid_for_three(size=size, batch_sizes = batch_sizes):\n","\n","      batches_xy = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical')\n","\n","      while True:\n","\n","          batch_xy = batches_xy.next()\n","          yield  batch_xy[0], [ batch_xy[1],batch_xy[1],batch_xy[1] ]"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"5IuLwjb-Jq1H","executionInfo":{"status":"ok","timestamp":1606277560951,"user_tz":-540,"elapsed":127724,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 3. test data\n","\n","def generate_test_for_three(size=size, batch_sizes = batch_sizes):\n","\n","      batches_xy = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical')\n","\n","      while True:\n","\n","          batch_xy = batches_xy.next()\n","          yield  batch_xy[0], [ batch_xy[1],batch_xy[1],batch_xy[1] ] "],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"QLPktMPZJq1J","executionInfo":{"status":"ok","timestamp":1606277560952,"user_tz":-540,"elapsed":127723,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 위에서 쓰임\n","# train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","# train_generator= crop_generator(train_batches, size)\n","\n","# valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","# test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original GoogLeNet\n","---"]},{"cell_type":"markdown","metadata":{"id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 3e-4\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JcsJNpFIEPSR"},"source":["### 3) Almost Original GoogLeNet"]},{"cell_type":"code","metadata":{"id":"RQQSvuzfUBlZ"},"source":["# GoogLeNet를 최대한 논문에 가깝게 맞춰 모형작성.\n","\n","def googlenet(input_shape=(224,224,3), classes=1000, weight_decay = weight_decay, weights_path = None,name='Inception_v1'):\n","\n","    input = Input(input_shape)\n","\n","    conv1_7x7_s2 = Conv2D(64, (7,7), strides=(2,2), padding='same', activation='relu', name='conv1/7x7_s2', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(input)\n","    pool1_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same', name='pool1/3x3_s2')(conv1_7x7_s2)\n","    pool1_norm1 = LRN(name='pool1/norm1')(pool1_3x3_s2)\n","\n","    conv2_3x3_reduce = Conv2D(64, (1,1), padding='same', activation='relu', name='conv2/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool1_norm1)\n","    conv2_3x3 = Conv2D(192, (3,3), padding='same', activation='relu', name='conv2/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(conv2_3x3_reduce)\n","    conv2_norm2 = LRN(name='conv2/norm2')(conv2_3x3)\n","    pool2_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same', name='pool2/3x3_s2')(conv2_norm2)\n","\n","    inception_3a_1x1 = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_3a/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool2_3x3_s2)\n","    inception_3a_3x3_reduce = Conv2D(96, (1,1), padding='same', activation='relu', name='inception_3a/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool2_3x3_s2)\n","    inception_3a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3_reduce)\n","    inception_3a_3x3 = Conv2D(128, (3,3), padding='valid', activation='relu', name='inception_3a/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_3x3_pad)\n","    inception_3a_5x5_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_3a/5x5_reduce', kernel_regularizer=l2(weight_decay))(pool2_3x3_s2)\n","    inception_3a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5_reduce)\n","    inception_3a_5x5 = Conv2D(32, (5,5), padding='valid', activation='relu', name='inception_3a/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_5x5_pad)\n","    inception_3a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3a/pool')(pool2_3x3_s2)\n","    inception_3a_pool_proj = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_3a/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_pool)\n","    inception_3a_output = Concatenate(axis=-1, name='inception_3a/output')([inception_3a_1x1,inception_3a_3x3,inception_3a_5x5,inception_3a_pool_proj])\n","    # Concatenate axis 수정.\n","\n","    inception_3b_1x1 = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_3b/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_output)\n","    inception_3b_3x3_reduce = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_3b/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_output)\n","    inception_3b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3_reduce)\n","    inception_3b_3x3 = Conv2D(192, (3,3), padding='valid', activation='relu', name='inception_3b/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3b_3x3_pad)\n","    inception_3b_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_3b/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_output)\n","    inception_3b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5_reduce)\n","    inception_3b_5x5 = Conv2D(96, (5,5), padding='valid', activation='relu', name='inception_3b/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3b_5x5_pad)\n","    inception_3b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3b/pool')(inception_3a_output)\n","    inception_3b_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_3b/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3b_pool)\n","    inception_3b_output = Concatenate(axis=-1, name='inception_3b/output')([inception_3b_1x1,inception_3b_3x3,inception_3b_5x5,inception_3b_pool_proj])\n","\n","    pool3_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same', name='pool3/3x3_s2')(inception_3b_output)\n","\n","    inception_4a_1x1 = Conv2D(192, (1,1), padding='same', activation='relu', name='inception_4a/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool3_3x3_s2)\n","    inception_4a_3x3_reduce = Conv2D(96, (1,1), padding='same', activation='relu', name='inception_4a/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool3_3x3_s2)\n","    inception_4a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4a_3x3_reduce)\n","    inception_4a_3x3 = Conv2D(208, (3,3), padding='valid', activation='relu', name='inception_4a/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_3x3_pad)\n","    inception_4a_5x5_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4a/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool3_3x3_s2)\n","    inception_4a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4a_5x5_reduce)\n","    inception_4a_5x5 = Conv2D(48, (5,5), padding='valid', activation='relu', name='inception_4a/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_5x5_pad)\n","    inception_4a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4a/pool')(pool3_3x3_s2)\n","    inception_4a_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4a/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_pool)\n","    inception_4a_output = Concatenate(axis=-1, name='inception_4a/output')([inception_4a_1x1,inception_4a_3x3,inception_4a_5x5,inception_4a_pool_proj])\n","\n","    loss1_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss1/ave_pool')(inception_4a_output)\n","    loss1_conv = Conv2D(128, (1,1), padding='same', activation='relu', name='loss1/conv', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(loss1_ave_pool)\n","    loss1_flat = Flatten()(loss1_conv)\n","    loss1_fc = Dense(1024, activation='relu', name='loss1/fc', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(loss1_flat)\n","    loss1_drop_fc = Dropout(rate=0.7)(loss1_fc)\n","    loss1_classifier = Dense(classes, activation='softmax', kernel_regularizer=l2(weight_decay), name='loss1/classifier')(loss1_drop_fc)\n","\n","    inception_4b_1x1 = Conv2D(160, (1,1), padding='same', activation='relu', name='inception_4b/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_output)\n","    inception_4b_3x3_reduce = Conv2D(112, (1,1), padding='same', activation='relu', name='inception_4b/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_output)\n","    inception_4b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4b_3x3_reduce)\n","    inception_4b_3x3 = Conv2D(224, (3,3), padding='valid', activation='relu', name='inception_4b/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_3x3_pad)\n","    inception_4b_5x5_reduce = Conv2D(24, (1,1), padding='same', activation='relu', name='inception_4b/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_output)\n","    inception_4b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4b_5x5_reduce)\n","    inception_4b_5x5 = Conv2D(64, (5,5), padding='valid', activation='relu', name='inception_4b/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_5x5_pad)\n","    inception_4b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4b/pool')(inception_4a_output)\n","    inception_4b_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4b/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_pool)\n","    inception_4b_output = Concatenate(axis=-1, name='inception_4b/output')([inception_4b_1x1,inception_4b_3x3,inception_4b_5x5,inception_4b_pool_proj])\n","\n","    inception_4c_1x1 = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_4c/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_output)\n","    inception_4c_3x3_reduce = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_4c/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_output)\n","    inception_4c_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4c_3x3_reduce)\n","    inception_4c_3x3 = Conv2D(256, (3,3), padding='valid', activation='relu', name='inception_4c/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_3x3_pad)\n","    inception_4c_5x5_reduce = Conv2D(24, (1,1), padding='same', activation='relu', name='inception_4c/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_output)\n","    inception_4c_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4c_5x5_reduce)\n","    inception_4c_5x5 = Conv2D(64, (5,5), padding='valid', activation='relu', name='inception_4c/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_5x5_pad)\n","    inception_4c_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4c/pool')(inception_4b_output)\n","    inception_4c_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4c/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_pool)\n","    inception_4c_output = Concatenate(axis=-1, name='inception_4c/output')([inception_4c_1x1,inception_4c_3x3,inception_4c_5x5,inception_4c_pool_proj])\n","\n","    inception_4d_1x1 = Conv2D(112, (1,1), padding='same', activation='relu', name='inception_4d/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_output)\n","    inception_4d_3x3_reduce = Conv2D(144, (1,1), padding='same', activation='relu', name='inception_4d/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_output)\n","    inception_4d_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4d_3x3_reduce)\n","    inception_4d_3x3 = Conv2D(288, (3,3), padding='valid', activation='relu', name='inception_4d/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_3x3_pad)\n","    inception_4d_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_4d/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_output)\n","    inception_4d_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4d_5x5_reduce)\n","    inception_4d_5x5 = Conv2D(64, (5,5), padding='valid', activation='relu', name='inception_4d/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_5x5_pad)\n","    inception_4d_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4d/pool')(inception_4c_output)\n","    inception_4d_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4d/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_pool)\n","    inception_4d_output = Concatenate(axis=-1, name='inception_4d/output')([inception_4d_1x1,inception_4d_3x3,inception_4d_5x5,inception_4d_pool_proj])\n","\n","    loss2_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss2/ave_pool')(inception_4d_output)\n","    loss2_conv = Conv2D(128, (1,1), padding='same', activation='relu', name='loss2/conv', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(loss2_ave_pool)\n","    loss2_flat = Flatten()(loss2_conv)\n","    loss2_fc = Dense(1024, activation='relu', name='loss2/fc', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(loss2_flat)\n","    loss2_drop_fc = Dropout(rate=0.7)(loss2_fc)\n","    loss2_classifier = Dense(classes, activation='softmax', kernel_regularizer=l2(weight_decay), name='loss2/classifier')(loss2_drop_fc)\n","\n","    inception_4e_1x1 = Conv2D(256, (1,1), padding='same', activation='relu', name='inception_4e/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_output)\n","    inception_4e_3x3_reduce = Conv2D(160, (1,1), padding='same', activation='relu', name='inception_4e/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_output)\n","    inception_4e_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_3x3_reduce)\n","    inception_4e_3x3 = Conv2D(320, (3,3), padding='valid', activation='relu', name='inception_4e/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4e_3x3_pad)\n","    inception_4e_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_4e/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_output)\n","    inception_4e_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4e_5x5_reduce)\n","    inception_4e_5x5 = Conv2D(128, (5,5), padding='valid', activation='relu', name='inception_4e/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4e_5x5_pad)\n","    inception_4e_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4e/pool')(inception_4d_output)\n","    inception_4e_pool_proj = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_4e/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4e_pool)\n","    inception_4e_output = Concatenate(axis=-1, name='inception_4e/output')([inception_4e_1x1,inception_4e_3x3,inception_4e_5x5,inception_4e_pool_proj])\n","\n","    pool4_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same', name='pool4/3x3_s2')(inception_4e_output)\n","\n","    inception_5a_1x1 = Conv2D(256, (1,1), padding='same', activation='relu', name='inception_5a/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool4_3x3_s2)\n","    inception_5a_3x3_reduce = Conv2D(160, (1,1), padding='same', activation='relu', name='inception_5a/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool4_3x3_s2)\n","    inception_5a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5a_3x3_reduce)\n","    inception_5a_3x3 = Conv2D(320, (3,3), padding='valid', activation='relu', name='inception_5a/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_3x3_pad)\n","    inception_5a_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_5a/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool4_3x3_s2)\n","    inception_5a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5a_5x5_reduce)\n","    inception_5a_5x5 = Conv2D(128, (5,5), padding='valid', activation='relu', name='inception_5a/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_5x5_pad)\n","    inception_5a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5a/pool')(pool4_3x3_s2)\n","    inception_5a_pool_proj = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_5a/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_pool)\n","    inception_5a_output = Concatenate(axis=-1, name='inception_5a/output')([inception_5a_1x1,inception_5a_3x3,inception_5a_5x5,inception_5a_pool_proj])\n","\n","    inception_5b_1x1 = Conv2D(384, (1,1), padding='same', activation='relu', name='inception_5b/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_output)\n","    inception_5b_3x3_reduce = Conv2D(192, (1,1), padding='same', activation='relu', name='inception_5b/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_output)\n","    inception_5b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5b_3x3_reduce)\n","    inception_5b_3x3 = Conv2D(384, (3,3), padding='valid', activation='relu', name='inception_5b/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5b_3x3_pad)\n","    inception_5b_5x5_reduce = Conv2D(48, (1,1), padding='same', activation='relu', name='inception_5b/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_output)\n","    inception_5b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5b_5x5_reduce)\n","    inception_5b_5x5 = Conv2D(128, (5,5), padding='valid', activation='relu', name='inception_5b/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5b_5x5_pad)\n","    inception_5b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5b/pool')(inception_5a_output)\n","    inception_5b_pool_proj = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_5b/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5b_pool)\n","    inception_5b_output = Concatenate(axis=-1, name='inception_5b/output')([inception_5b_1x1,inception_5b_3x3,inception_5b_5x5,inception_5b_pool_proj])\n","\n","    pool5_7x7_s1 = AveragePooling2D(pool_size=(7,7), strides=(1,1), name='pool5/7x7_s2')(inception_5b_output)\n","\n","    loss3_flat = Flatten()(pool5_7x7_s1)\n","    pool5_drop_7x7_s1 = Dropout(rate=0.4)(loss3_flat)\n","    loss3_classifier = Dense(classes, activation='softmax', kernel_regularizer=l2(weight_decay), name='loss3/classifier')(pool5_drop_7x7_s1)\n","\n","    googlenet = Model(inputs=input, outputs=[loss1_classifier,loss2_classifier,loss3_classifier],name=name)\n","\n","    if weights_path:\n","        googlenet.load_weights(weights_path)\n","\n","    return googlenet\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"te4pinumUBle","scrolled":true},"source":["model = googlenet(input_shape=input_sizes, classes=classes, name='GoogleNet')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vmeG8i1uwd-I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606132043561,"user_tz":-540,"elapsed":76301,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"61826644-bfb1-4964-ef0e-9e8d31821221"},"source":["# auxiliary classifier 2개를 포함하기 때문에, 모수의 개수는 1000만개쯤 된다.\n","# 메인은 670만개 가량의 모수.\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"GoogleNet\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9472        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","pool1/3x3_s2 (MaxPooling2D)     (None, 56, 56, 64)   0           conv1/7x7_s2[0][0]               \n","__________________________________________________________________________________________________\n","pool1/norm1 (LRN)               (None, 56, 56, 64)   0           pool1/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","conv2/3x3_reduce (Conv2D)       (None, 56, 56, 64)   4160        pool1/norm1[0][0]                \n","__________________________________________________________________________________________________\n","conv2/3x3 (Conv2D)              (None, 56, 56, 192)  110784      conv2/3x3_reduce[0][0]           \n","__________________________________________________________________________________________________\n","conv2/norm2 (LRN)               (None, 56, 56, 192)  0           conv2/3x3[0][0]                  \n","__________________________________________________________________________________________________\n","pool2/3x3_s2 (MaxPooling2D)     (None, 28, 28, 192)  0           conv2/norm2[0][0]                \n","__________________________________________________________________________________________________\n","inception_3a/3x3_reduce (Conv2D (None, 28, 28, 96)   18528       pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_3a/5x5_reduce (Conv2D (None, 28, 28, 16)   3088        pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","zero_padding2d (ZeroPadding2D)  (None, 30, 30, 96)   0           inception_3a/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, 32, 32, 16)   0           inception_3a/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_3a/pool (MaxPooling2D (None, 28, 28, 192)  0           pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_3a/1x1 (Conv2D)       (None, 28, 28, 64)   12352       pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_3a/3x3 (Conv2D)       (None, 28, 28, 128)  110720      zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","inception_3a/5x5 (Conv2D)       (None, 28, 28, 32)   12832       zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","inception_3a/pool_proj (Conv2D) (None, 28, 28, 32)   6176        inception_3a/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_3a/output (Concatenat (None, 28, 28, 256)  0           inception_3a/1x1[0][0]           \n","                                                                 inception_3a/3x3[0][0]           \n","                                                                 inception_3a/5x5[0][0]           \n","                                                                 inception_3a/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_3b/3x3_reduce (Conv2D (None, 28, 28, 128)  32896       inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_3b/5x5_reduce (Conv2D (None, 28, 28, 32)   8224        inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_2 (ZeroPadding2D (None, 30, 30, 128)  0           inception_3b/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_3 (ZeroPadding2D (None, 32, 32, 32)   0           inception_3b/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_3b/pool (MaxPooling2D (None, 28, 28, 256)  0           inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_3b/1x1 (Conv2D)       (None, 28, 28, 128)  32896       inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_3b/3x3 (Conv2D)       (None, 28, 28, 192)  221376      zero_padding2d_2[0][0]           \n","__________________________________________________________________________________________________\n","inception_3b/5x5 (Conv2D)       (None, 28, 28, 96)   76896       zero_padding2d_3[0][0]           \n","__________________________________________________________________________________________________\n","inception_3b/pool_proj (Conv2D) (None, 28, 28, 64)   16448       inception_3b/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_3b/output (Concatenat (None, 28, 28, 480)  0           inception_3b/1x1[0][0]           \n","                                                                 inception_3b/3x3[0][0]           \n","                                                                 inception_3b/5x5[0][0]           \n","                                                                 inception_3b/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","pool3/3x3_s2 (MaxPooling2D)     (None, 14, 14, 480)  0           inception_3b/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4a/3x3_reduce (Conv2D (None, 14, 14, 96)   46176       pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_4a/5x5_reduce (Conv2D (None, 14, 14, 16)   7696        pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","zero_padding2d_4 (ZeroPadding2D (None, 16, 16, 96)   0           inception_4a/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_5 (ZeroPadding2D (None, 18, 18, 16)   0           inception_4a/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4a/pool (MaxPooling2D (None, 14, 14, 480)  0           pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_4a/1x1 (Conv2D)       (None, 14, 14, 192)  92352       pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_4a/3x3 (Conv2D)       (None, 14, 14, 208)  179920      zero_padding2d_4[0][0]           \n","__________________________________________________________________________________________________\n","inception_4a/5x5 (Conv2D)       (None, 14, 14, 48)   19248       zero_padding2d_5[0][0]           \n","__________________________________________________________________________________________________\n","inception_4a/pool_proj (Conv2D) (None, 14, 14, 64)   30784       inception_4a/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4a/output (Concatenat (None, 14, 14, 512)  0           inception_4a/1x1[0][0]           \n","                                                                 inception_4a/3x3[0][0]           \n","                                                                 inception_4a/5x5[0][0]           \n","                                                                 inception_4a/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4b/3x3_reduce (Conv2D (None, 14, 14, 112)  57456       inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4b/5x5_reduce (Conv2D (None, 14, 14, 24)   12312       inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_6 (ZeroPadding2D (None, 16, 16, 112)  0           inception_4b/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_7 (ZeroPadding2D (None, 18, 18, 24)   0           inception_4b/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4b/pool (MaxPooling2D (None, 14, 14, 512)  0           inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4b/1x1 (Conv2D)       (None, 14, 14, 160)  82080       inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4b/3x3 (Conv2D)       (None, 14, 14, 224)  226016      zero_padding2d_6[0][0]           \n","__________________________________________________________________________________________________\n","inception_4b/5x5 (Conv2D)       (None, 14, 14, 64)   38464       zero_padding2d_7[0][0]           \n","__________________________________________________________________________________________________\n","inception_4b/pool_proj (Conv2D) (None, 14, 14, 64)   32832       inception_4b/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4b/output (Concatenat (None, 14, 14, 512)  0           inception_4b/1x1[0][0]           \n","                                                                 inception_4b/3x3[0][0]           \n","                                                                 inception_4b/5x5[0][0]           \n","                                                                 inception_4b/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4c/3x3_reduce (Conv2D (None, 14, 14, 128)  65664       inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4c/5x5_reduce (Conv2D (None, 14, 14, 24)   12312       inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_8 (ZeroPadding2D (None, 16, 16, 128)  0           inception_4c/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_9 (ZeroPadding2D (None, 18, 18, 24)   0           inception_4c/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4c/pool (MaxPooling2D (None, 14, 14, 512)  0           inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4c/1x1 (Conv2D)       (None, 14, 14, 128)  65664       inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4c/3x3 (Conv2D)       (None, 14, 14, 256)  295168      zero_padding2d_8[0][0]           \n","__________________________________________________________________________________________________\n","inception_4c/5x5 (Conv2D)       (None, 14, 14, 64)   38464       zero_padding2d_9[0][0]           \n","__________________________________________________________________________________________________\n","inception_4c/pool_proj (Conv2D) (None, 14, 14, 64)   32832       inception_4c/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4c/output (Concatenat (None, 14, 14, 512)  0           inception_4c/1x1[0][0]           \n","                                                                 inception_4c/3x3[0][0]           \n","                                                                 inception_4c/5x5[0][0]           \n","                                                                 inception_4c/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4d/3x3_reduce (Conv2D (None, 14, 14, 144)  73872       inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4d/5x5_reduce (Conv2D (None, 14, 14, 32)   16416       inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_10 (ZeroPadding2 (None, 16, 16, 144)  0           inception_4d/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 32)   0           inception_4d/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4d/pool (MaxPooling2D (None, 14, 14, 512)  0           inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4d/1x1 (Conv2D)       (None, 14, 14, 112)  57456       inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4d/3x3 (Conv2D)       (None, 14, 14, 288)  373536      zero_padding2d_10[0][0]          \n","__________________________________________________________________________________________________\n","inception_4d/5x5 (Conv2D)       (None, 14, 14, 64)   51264       zero_padding2d_11[0][0]          \n","__________________________________________________________________________________________________\n","inception_4d/pool_proj (Conv2D) (None, 14, 14, 64)   32832       inception_4d/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4d/output (Concatenat (None, 14, 14, 528)  0           inception_4d/1x1[0][0]           \n","                                                                 inception_4d/3x3[0][0]           \n","                                                                 inception_4d/5x5[0][0]           \n","                                                                 inception_4d/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4e/3x3_reduce (Conv2D (None, 14, 14, 160)  84640       inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4e/5x5_reduce (Conv2D (None, 14, 14, 32)   16928       inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_12 (ZeroPadding2 (None, 16, 16, 160)  0           inception_4e/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 32)   0           inception_4e/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4e/pool (MaxPooling2D (None, 14, 14, 528)  0           inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4e/1x1 (Conv2D)       (None, 14, 14, 256)  135424      inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4e/3x3 (Conv2D)       (None, 14, 14, 320)  461120      zero_padding2d_12[0][0]          \n","__________________________________________________________________________________________________\n","inception_4e/5x5 (Conv2D)       (None, 14, 14, 128)  102528      zero_padding2d_13[0][0]          \n","__________________________________________________________________________________________________\n","inception_4e/pool_proj (Conv2D) (None, 14, 14, 128)  67712       inception_4e/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4e/output (Concatenat (None, 14, 14, 832)  0           inception_4e/1x1[0][0]           \n","                                                                 inception_4e/3x3[0][0]           \n","                                                                 inception_4e/5x5[0][0]           \n","                                                                 inception_4e/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","pool4/3x3_s2 (MaxPooling2D)     (None, 7, 7, 832)    0           inception_4e/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_5a/3x3_reduce (Conv2D (None, 7, 7, 160)    133280      pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_5a/5x5_reduce (Conv2D (None, 7, 7, 32)     26656       pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","zero_padding2d_14 (ZeroPadding2 (None, 9, 9, 160)    0           inception_5a/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_15 (ZeroPadding2 (None, 11, 11, 32)   0           inception_5a/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_5a/pool (MaxPooling2D (None, 7, 7, 832)    0           pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_5a/1x1 (Conv2D)       (None, 7, 7, 256)    213248      pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_5a/3x3 (Conv2D)       (None, 7, 7, 320)    461120      zero_padding2d_14[0][0]          \n","__________________________________________________________________________________________________\n","inception_5a/5x5 (Conv2D)       (None, 7, 7, 128)    102528      zero_padding2d_15[0][0]          \n","__________________________________________________________________________________________________\n","inception_5a/pool_proj (Conv2D) (None, 7, 7, 128)    106624      inception_5a/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_5a/output (Concatenat (None, 7, 7, 832)    0           inception_5a/1x1[0][0]           \n","                                                                 inception_5a/3x3[0][0]           \n","                                                                 inception_5a/5x5[0][0]           \n","                                                                 inception_5a/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_5b/3x3_reduce (Conv2D (None, 7, 7, 192)    159936      inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_5b/5x5_reduce (Conv2D (None, 7, 7, 48)     39984       inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_16 (ZeroPadding2 (None, 9, 9, 192)    0           inception_5b/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_17 (ZeroPadding2 (None, 11, 11, 48)   0           inception_5b/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_5b/pool (MaxPooling2D (None, 7, 7, 832)    0           inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","loss1/ave_pool (AveragePooling2 (None, 4, 4, 512)    0           inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","loss2/ave_pool (AveragePooling2 (None, 4, 4, 528)    0           inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_5b/1x1 (Conv2D)       (None, 7, 7, 384)    319872      inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_5b/3x3 (Conv2D)       (None, 7, 7, 384)    663936      zero_padding2d_16[0][0]          \n","__________________________________________________________________________________________________\n","inception_5b/5x5 (Conv2D)       (None, 7, 7, 128)    153728      zero_padding2d_17[0][0]          \n","__________________________________________________________________________________________________\n","inception_5b/pool_proj (Conv2D) (None, 7, 7, 128)    106624      inception_5b/pool[0][0]          \n","__________________________________________________________________________________________________\n","loss1/conv (Conv2D)             (None, 4, 4, 128)    65664       loss1/ave_pool[0][0]             \n","__________________________________________________________________________________________________\n","loss2/conv (Conv2D)             (None, 4, 4, 128)    67712       loss2/ave_pool[0][0]             \n","__________________________________________________________________________________________________\n","inception_5b/output (Concatenat (None, 7, 7, 1024)   0           inception_5b/1x1[0][0]           \n","                                                                 inception_5b/3x3[0][0]           \n","                                                                 inception_5b/5x5[0][0]           \n","                                                                 inception_5b/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 2048)         0           loss1/conv[0][0]                 \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 2048)         0           loss2/conv[0][0]                 \n","__________________________________________________________________________________________________\n","pool5/7x7_s2 (AveragePooling2D) (None, 1, 1, 1024)   0           inception_5b/output[0][0]        \n","__________________________________________________________________________________________________\n","loss1/fc (Dense)                (None, 1024)         2098176     flatten[0][0]                    \n","__________________________________________________________________________________________________\n","loss2/fc (Dense)                (None, 1024)         2098176     flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 1024)         0           pool5/7x7_s2[0][0]               \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 1024)         0           loss1/fc[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           loss2/fc[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","loss1/classifier (Dense)        (None, 67)           68675       dropout[0][0]                    \n","__________________________________________________________________________________________________\n","loss2/classifier (Dense)        (None, 67)           68675       dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","loss3/classifier (Dense)        (None, 67)           68675       dropout_2[0][0]                  \n","==================================================================================================\n","Total params: 10,509,305\n","Trainable params: 10,509,305\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8_zZtvSY4KCo"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nqg2fSkrdIMr"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2AsMQKJXUfy"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3FCbpFOcmHd"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_loss3/classifier_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]                    \t\n","\n","model.compile(optimizer, loss={'loss1/classifier' : 'categorical_crossentropy', 'loss2/classifier' : 'categorical_crossentropy', 'loss3/classifier' : 'categorical_crossentropy'},\n","              loss_weights={'loss1/classifier' : 0.3, 'loss2/classifier' : 0.3, 'loss3/classifier' : 1.0}, \n","              metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDj1YFknYC-S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606155525633,"user_tz":-540,"elapsed":23558294,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"98d0d12c-5b90-427d-8d35-00addf8ceb59"},"source":["######## flow_from_directory\n","#history = model.fit_generator(generate_train_for_three(), steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = generate_valid_for_three(), epochs=epochs , verbose=1 , callbacks = callbacks_list,validation_steps=int(len(x_valid)/batch_sizes))\n","history = model.fit(generate_train_for_three(), steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = generate_valid_for_three(), epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 12466 images belonging to 67 classes.\n","Learning rate:  0.0003\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 1/70\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for conv1/7x7_s2/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for conv2/3x3_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for conv2/3x3/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3a/3x3_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3a/5x5_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3a/1x1/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3a/3x3/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3a/5x5/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3a/pool_proj/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3b/3x3_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3b/5x5_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3b/1x1/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3b/3x3/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3b/5x5/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_3b/pool_proj/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4a/3x3_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4a/5x5_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4a/1x1/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4a/3x3/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4a/5x5/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4a/pool_proj/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4b/3x3_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4b/5x5_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4b/1x1/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4b/3x3/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4b/5x5/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4b/pool_proj/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4c/3x3_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4c/5x5_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4c/1x1/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4c/3x3/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4c/5x5/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4c/pool_proj/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4d/3x3_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4d/5x5_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4d/1x1/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4d/3x3/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4d/5x5/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4d/pool_proj/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4e/3x3_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4e/5x5_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4e/1x1/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4e/3x3/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4e/5x5/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_4e/pool_proj/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5a/3x3_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5a/5x5_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5a/1x1/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5a/3x3/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5a/5x5/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5a/pool_proj/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5b/3x3_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5b/5x5_reduce/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5b/1x1/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5b/3x3/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5b/5x5/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for inception_5b/pool_proj/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for loss1/conv/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for loss2/conv/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for loss1/fc/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for loss2/fc/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for loss1/classifier/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for loss2/classifier/kernel:0\n","0.0(L1), 1.0153461394838174e-05(L2) weight decay set for loss3/classifier/kernel:0\n","97/97 [==============================] - ETA: 0s - loss: 6.3963 - loss1/classifier_loss: 4.0089 - loss2/classifier_loss: 4.0307 - loss3/classifier_loss: 3.9844 - loss1/classifier_accuracy: 0.0584 - loss1/classifier_top5_acc: 0.2241 - loss1/classifier_macro_f1score: 1.3335e-04 - loss2/classifier_accuracy: 0.0525 - loss2/classifier_top5_acc: 0.2121 - loss2/classifier_macro_f1score: 1.5387e-04 - loss3/classifier_accuracy: 0.0570 - loss3/classifier_top5_acc: 0.2283 - loss3/classifier_macro_f1score: 1.7182e-04  Found 1564 images belonging to 67 classes.\n","\n","Epoch 00001: val_loss improved from inf to 6.02899, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/001.h5\n","\n","Epoch 00001: val_loss3/classifier_accuracy improved from -inf to 0.10547, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/001.h5\n","97/97 [==============================] - 6815s 70s/step - loss: 6.3963 - loss1/classifier_loss: 4.0089 - loss2/classifier_loss: 4.0307 - loss3/classifier_loss: 3.9844 - loss1/classifier_accuracy: 0.0584 - loss1/classifier_top5_acc: 0.2241 - loss1/classifier_macro_f1score: 1.3335e-04 - loss2/classifier_accuracy: 0.0525 - loss2/classifier_top5_acc: 0.2121 - loss2/classifier_macro_f1score: 1.5387e-04 - loss3/classifier_accuracy: 0.0570 - loss3/classifier_top5_acc: 0.2283 - loss3/classifier_macro_f1score: 1.7182e-04 - val_loss: 6.0290 - val_loss1/classifier_loss: 3.7385 - val_loss2/classifier_loss: 3.7788 - val_loss3/classifier_loss: 3.7738 - val_loss1/classifier_accuracy: 0.1113 - val_loss1/classifier_top5_acc: 0.3268 - val_loss1/classifier_macro_f1score: 0.0019 - val_loss2/classifier_accuracy: 0.1068 - val_loss2/classifier_top5_acc: 0.3307 - val_loss2/classifier_macro_f1score: 0.0017 - val_loss3/classifier_accuracy: 0.1055 - val_loss3/classifier_top5_acc: 0.3242 - val_loss3/classifier_macro_f1score: 0.0013\n","Learning rate:  0.0003\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 2/70\n","97/97 [==============================] - ETA: 0s - loss: 5.9392 - loss1/classifier_loss: 3.7014 - loss2/classifier_loss: 3.7365 - loss3/classifier_loss: 3.7078 - loss1/classifier_accuracy: 0.0969 - loss1/classifier_top5_acc: 0.3429 - loss1/classifier_macro_f1score: 0.0015 - loss2/classifier_accuracy: 0.0993 - loss2/classifier_top5_acc: 0.3339 - loss2/classifier_macro_f1score: 7.0721e-04 - loss3/classifier_accuracy: 0.0973 - loss3/classifier_top5_acc: 0.3322 - loss3/classifier_macro_f1score: 4.4402e-04\n","Epoch 00002: val_loss improved from 6.02899 to 5.84530, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/002.h5\n","\n","Epoch 00002: val_loss3/classifier_accuracy did not improve from 0.10547\n","97/97 [==============================] - 250s 3s/step - loss: 5.9392 - loss1/classifier_loss: 3.7014 - loss2/classifier_loss: 3.7365 - loss3/classifier_loss: 3.7078 - loss1/classifier_accuracy: 0.0969 - loss1/classifier_top5_acc: 0.3429 - loss1/classifier_macro_f1score: 0.0015 - loss2/classifier_accuracy: 0.0993 - loss2/classifier_top5_acc: 0.3339 - loss2/classifier_macro_f1score: 7.0721e-04 - loss3/classifier_accuracy: 0.0973 - loss3/classifier_top5_acc: 0.3322 - loss3/classifier_macro_f1score: 4.4402e-04 - val_loss: 5.8453 - val_loss1/classifier_loss: 3.5182 - val_loss2/classifier_loss: 3.6248 - val_loss3/classifier_loss: 3.7024 - val_loss1/classifier_accuracy: 0.1348 - val_loss1/classifier_top5_acc: 0.4030 - val_loss1/classifier_macro_f1score: 0.0012 - val_loss2/classifier_accuracy: 0.1087 - val_loss2/classifier_top5_acc: 0.3594 - val_loss2/classifier_macro_f1score: 0.0012 - val_loss3/classifier_accuracy: 0.1022 - val_loss3/classifier_top5_acc: 0.3333 - val_loss3/classifier_macro_f1score: 0.0000e+00\n","Learning rate:  0.0003\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 3/70\n","97/97 [==============================] - ETA: 0s - loss: 5.6712 - loss1/classifier_loss: 3.5294 - loss2/classifier_loss: 3.5600 - loss3/classifier_loss: 3.5444 - loss1/classifier_accuracy: 0.1215 - loss1/classifier_top5_acc: 0.3982 - loss1/classifier_macro_f1score: 0.0045 - loss2/classifier_accuracy: 0.1230 - loss2/classifier_top5_acc: 0.3866 - loss2/classifier_macro_f1score: 0.0035 - loss3/classifier_accuracy: 0.1164 - loss3/classifier_top5_acc: 0.3877 - loss3/classifier_macro_f1score: 0.0013\n","Epoch 00003: val_loss improved from 5.84530 to 5.65664, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/003.h5\n","\n","Epoch 00003: val_loss3/classifier_accuracy improved from 0.10547 to 0.12240, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/003.h5\n","97/97 [==============================] - 251s 3s/step - loss: 5.6712 - loss1/classifier_loss: 3.5294 - loss2/classifier_loss: 3.5600 - loss3/classifier_loss: 3.5444 - loss1/classifier_accuracy: 0.1215 - loss1/classifier_top5_acc: 0.3982 - loss1/classifier_macro_f1score: 0.0045 - loss2/classifier_accuracy: 0.1230 - loss2/classifier_top5_acc: 0.3866 - loss2/classifier_macro_f1score: 0.0035 - loss3/classifier_accuracy: 0.1164 - loss3/classifier_top5_acc: 0.3877 - loss3/classifier_macro_f1score: 0.0013 - val_loss: 5.6566 - val_loss1/classifier_loss: 3.4643 - val_loss2/classifier_loss: 3.5106 - val_loss3/classifier_loss: 3.5642 - val_loss1/classifier_accuracy: 0.1458 - val_loss1/classifier_top5_acc: 0.4167 - val_loss1/classifier_macro_f1score: 0.0036 - val_loss2/classifier_accuracy: 0.1426 - val_loss2/classifier_top5_acc: 0.4062 - val_loss2/classifier_macro_f1score: 0.0039 - val_loss3/classifier_accuracy: 0.1224 - val_loss3/classifier_top5_acc: 0.3841 - val_loss3/classifier_macro_f1score: 0.0031\n","Learning rate:  0.0003\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 4/70\n","97/97 [==============================] - ETA: 0s - loss: 5.5083 - loss1/classifier_loss: 3.3981 - loss2/classifier_loss: 3.4500 - loss3/classifier_loss: 3.4539 - loss1/classifier_accuracy: 0.1486 - loss1/classifier_top5_acc: 0.4331 - loss1/classifier_macro_f1score: 0.0052 - loss2/classifier_accuracy: 0.1395 - loss2/classifier_top5_acc: 0.4202 - loss2/classifier_macro_f1score: 0.0052 - loss3/classifier_accuracy: 0.1292 - loss3/classifier_top5_acc: 0.4096 - loss3/classifier_macro_f1score: 0.0023\n","Epoch 00004: val_loss improved from 5.65664 to 5.25824, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/004.h5\n","\n","Epoch 00004: val_loss3/classifier_accuracy improved from 0.12240 to 0.15495, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/004.h5\n","97/97 [==============================] - 253s 3s/step - loss: 5.5083 - loss1/classifier_loss: 3.3981 - loss2/classifier_loss: 3.4500 - loss3/classifier_loss: 3.4539 - loss1/classifier_accuracy: 0.1486 - loss1/classifier_top5_acc: 0.4331 - loss1/classifier_macro_f1score: 0.0052 - loss2/classifier_accuracy: 0.1395 - loss2/classifier_top5_acc: 0.4202 - loss2/classifier_macro_f1score: 0.0052 - loss3/classifier_accuracy: 0.1292 - loss3/classifier_top5_acc: 0.4096 - loss3/classifier_macro_f1score: 0.0023 - val_loss: 5.2582 - val_loss1/classifier_loss: 3.2126 - val_loss2/classifier_loss: 3.2629 - val_loss3/classifier_loss: 3.3156 - val_loss1/classifier_accuracy: 0.1895 - val_loss1/classifier_top5_acc: 0.4980 - val_loss1/classifier_macro_f1score: 0.0021 - val_loss2/classifier_accuracy: 0.1745 - val_loss2/classifier_top5_acc: 0.4811 - val_loss2/classifier_macro_f1score: 0.0015 - val_loss3/classifier_accuracy: 0.1549 - val_loss3/classifier_top5_acc: 0.4635 - val_loss3/classifier_macro_f1score: 6.2189e-04\n","Learning rate:  0.0003\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 5/70\n","97/97 [==============================] - ETA: 0s - loss: 5.3480 - loss1/classifier_loss: 3.3080 - loss2/classifier_loss: 3.3569 - loss3/classifier_loss: 3.3486 - loss1/classifier_accuracy: 0.1700 - loss1/classifier_top5_acc: 0.4553 - loss1/classifier_macro_f1score: 0.0103 - loss2/classifier_accuracy: 0.1520 - loss2/classifier_top5_acc: 0.4423 - loss2/classifier_macro_f1score: 0.0087 - loss3/classifier_accuracy: 0.1497 - loss3/classifier_top5_acc: 0.4385 - loss3/classifier_macro_f1score: 0.0048\n","Epoch 00005: val_loss improved from 5.25824 to 5.13864, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/005.h5\n","\n","Epoch 00005: val_loss3/classifier_accuracy improved from 0.15495 to 0.17188, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/005.h5\n","97/97 [==============================] - 253s 3s/step - loss: 5.3480 - loss1/classifier_loss: 3.3080 - loss2/classifier_loss: 3.3569 - loss3/classifier_loss: 3.3486 - loss1/classifier_accuracy: 0.1700 - loss1/classifier_top5_acc: 0.4553 - loss1/classifier_macro_f1score: 0.0103 - loss2/classifier_accuracy: 0.1520 - loss2/classifier_top5_acc: 0.4423 - loss2/classifier_macro_f1score: 0.0087 - loss3/classifier_accuracy: 0.1497 - loss3/classifier_top5_acc: 0.4385 - loss3/classifier_macro_f1score: 0.0048 - val_loss: 5.1386 - val_loss1/classifier_loss: 3.1108 - val_loss2/classifier_loss: 3.1910 - val_loss3/classifier_loss: 3.2481 - val_loss1/classifier_accuracy: 0.2168 - val_loss1/classifier_top5_acc: 0.5156 - val_loss1/classifier_macro_f1score: 0.0100 - val_loss2/classifier_accuracy: 0.1966 - val_loss2/classifier_top5_acc: 0.4948 - val_loss2/classifier_macro_f1score: 0.0027 - val_loss3/classifier_accuracy: 0.1719 - val_loss3/classifier_top5_acc: 0.4753 - val_loss3/classifier_macro_f1score: 0.0029\n","Learning rate:  0.0003\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 6/70\n","97/97 [==============================] - ETA: 0s - loss: 5.1635 - loss1/classifier_loss: 3.1995 - loss2/classifier_loss: 3.2483 - loss3/classifier_loss: 3.2292 - loss1/classifier_accuracy: 0.1844 - loss1/classifier_top5_acc: 0.4895 - loss1/classifier_macro_f1score: 0.0139 - loss2/classifier_accuracy: 0.1727 - loss2/classifier_top5_acc: 0.4733 - loss2/classifier_macro_f1score: 0.0110 - loss3/classifier_accuracy: 0.1696 - loss3/classifier_top5_acc: 0.4780 - loss3/classifier_macro_f1score: 0.0085\n","Epoch 00006: val_loss did not improve from 5.13864\n","\n","Epoch 00006: val_loss3/classifier_accuracy improved from 0.17188 to 0.17513, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/006.h5\n","97/97 [==============================] - 251s 3s/step - loss: 5.1635 - loss1/classifier_loss: 3.1995 - loss2/classifier_loss: 3.2483 - loss3/classifier_loss: 3.2292 - loss1/classifier_accuracy: 0.1844 - loss1/classifier_top5_acc: 0.4895 - loss1/classifier_macro_f1score: 0.0139 - loss2/classifier_accuracy: 0.1727 - loss2/classifier_top5_acc: 0.4733 - loss2/classifier_macro_f1score: 0.0110 - loss3/classifier_accuracy: 0.1696 - loss3/classifier_top5_acc: 0.4780 - loss3/classifier_macro_f1score: 0.0085 - val_loss: 5.3005 - val_loss1/classifier_loss: 3.1648 - val_loss2/classifier_loss: 3.2716 - val_loss3/classifier_loss: 3.3696 - val_loss1/classifier_accuracy: 0.2064 - val_loss1/classifier_top5_acc: 0.5020 - val_loss1/classifier_macro_f1score: 0.0206 - val_loss2/classifier_accuracy: 0.1927 - val_loss2/classifier_top5_acc: 0.4655 - val_loss2/classifier_macro_f1score: 0.0165 - val_loss3/classifier_accuracy: 0.1751 - val_loss3/classifier_top5_acc: 0.4421 - val_loss3/classifier_macro_f1score: 0.0132\n","Learning rate:  0.0003\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 7/70\n","97/97 [==============================] - ETA: 0s - loss: 5.0511 - loss1/classifier_loss: 3.1226 - loss2/classifier_loss: 3.1767 - loss3/classifier_loss: 3.1613 - loss1/classifier_accuracy: 0.1978 - loss1/classifier_top5_acc: 0.5109 - loss1/classifier_macro_f1score: 0.0212 - loss2/classifier_accuracy: 0.1918 - loss2/classifier_top5_acc: 0.4972 - loss2/classifier_macro_f1score: 0.0184 - loss3/classifier_accuracy: 0.1843 - loss3/classifier_top5_acc: 0.4967 - loss3/classifier_macro_f1score: 0.0153\n","Epoch 00007: val_loss improved from 5.13864 to 4.92058, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/007.h5\n","\n","Epoch 00007: val_loss3/classifier_accuracy improved from 0.17513 to 0.20443, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/007.h5\n","97/97 [==============================] - 251s 3s/step - loss: 5.0511 - loss1/classifier_loss: 3.1226 - loss2/classifier_loss: 3.1767 - loss3/classifier_loss: 3.1613 - loss1/classifier_accuracy: 0.1978 - loss1/classifier_top5_acc: 0.5109 - loss1/classifier_macro_f1score: 0.0212 - loss2/classifier_accuracy: 0.1918 - loss2/classifier_top5_acc: 0.4972 - loss2/classifier_macro_f1score: 0.0184 - loss3/classifier_accuracy: 0.1843 - loss3/classifier_top5_acc: 0.4967 - loss3/classifier_macro_f1score: 0.0153 - val_loss: 4.9206 - val_loss1/classifier_loss: 2.9865 - val_loss2/classifier_loss: 3.0477 - val_loss3/classifier_loss: 3.1103 - val_loss1/classifier_accuracy: 0.2370 - val_loss1/classifier_top5_acc: 0.5423 - val_loss1/classifier_macro_f1score: 0.0238 - val_loss2/classifier_accuracy: 0.2246 - val_loss2/classifier_top5_acc: 0.5254 - val_loss2/classifier_macro_f1score: 0.0139 - val_loss3/classifier_accuracy: 0.2044 - val_loss3/classifier_top5_acc: 0.5052 - val_loss3/classifier_macro_f1score: 0.0148\n","Learning rate:  0.0003\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 8/70\n","97/97 [==============================] - ETA: 0s - loss: 4.9388 - loss1/classifier_loss: 3.0441 - loss2/classifier_loss: 3.1096 - loss3/classifier_loss: 3.0927 - loss1/classifier_accuracy: 0.2183 - loss1/classifier_top5_acc: 0.5279 - loss1/classifier_macro_f1score: 0.0281 - loss2/classifier_accuracy: 0.2030 - loss2/classifier_top5_acc: 0.5134 - loss2/classifier_macro_f1score: 0.0246 - loss3/classifier_accuracy: 0.2035 - loss3/classifier_top5_acc: 0.5125 - loss3/classifier_macro_f1score: 0.0227\n","Epoch 00008: val_loss did not improve from 4.92058\n","\n","Epoch 00008: val_loss3/classifier_accuracy improved from 0.20443 to 0.20833, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/008.h5\n","97/97 [==============================] - 245s 3s/step - loss: 4.9388 - loss1/classifier_loss: 3.0441 - loss2/classifier_loss: 3.1096 - loss3/classifier_loss: 3.0927 - loss1/classifier_accuracy: 0.2183 - loss1/classifier_top5_acc: 0.5279 - loss1/classifier_macro_f1score: 0.0281 - loss2/classifier_accuracy: 0.2030 - loss2/classifier_top5_acc: 0.5134 - loss2/classifier_macro_f1score: 0.0246 - loss3/classifier_accuracy: 0.2035 - loss3/classifier_top5_acc: 0.5125 - loss3/classifier_macro_f1score: 0.0227 - val_loss: 4.9893 - val_loss1/classifier_loss: 2.9854 - val_loss2/classifier_loss: 3.0778 - val_loss3/classifier_loss: 3.1703 - val_loss1/classifier_accuracy: 0.2389 - val_loss1/classifier_top5_acc: 0.5319 - val_loss1/classifier_macro_f1score: 0.0382 - val_loss2/classifier_accuracy: 0.2155 - val_loss2/classifier_top5_acc: 0.5124 - val_loss2/classifier_macro_f1score: 0.0399 - val_loss3/classifier_accuracy: 0.2083 - val_loss3/classifier_top5_acc: 0.5007 - val_loss3/classifier_macro_f1score: 0.0447\n","Learning rate:  0.0003\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 9/70\n","97/97 [==============================] - ETA: 0s - loss: 4.7573 - loss1/classifier_loss: 2.9498 - loss2/classifier_loss: 3.0142 - loss3/classifier_loss: 2.9681 - loss1/classifier_accuracy: 0.2333 - loss1/classifier_top5_acc: 0.5630 - loss1/classifier_macro_f1score: 0.0352 - loss2/classifier_accuracy: 0.2231 - loss2/classifier_top5_acc: 0.5405 - loss2/classifier_macro_f1score: 0.0286 - loss3/classifier_accuracy: 0.2276 - loss3/classifier_top5_acc: 0.5502 - loss3/classifier_macro_f1score: 0.0294\n","Epoch 00009: val_loss improved from 4.92058 to 4.82535, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/009.h5\n","\n","Epoch 00009: val_loss3/classifier_accuracy improved from 0.20833 to 0.22721, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/009.h5\n","97/97 [==============================] - 241s 2s/step - loss: 4.7573 - loss1/classifier_loss: 2.9498 - loss2/classifier_loss: 3.0142 - loss3/classifier_loss: 2.9681 - loss1/classifier_accuracy: 0.2333 - loss1/classifier_top5_acc: 0.5630 - loss1/classifier_macro_f1score: 0.0352 - loss2/classifier_accuracy: 0.2231 - loss2/classifier_top5_acc: 0.5405 - loss2/classifier_macro_f1score: 0.0286 - loss3/classifier_accuracy: 0.2276 - loss3/classifier_top5_acc: 0.5502 - loss3/classifier_macro_f1score: 0.0294 - val_loss: 4.8254 - val_loss1/classifier_loss: 2.8900 - val_loss2/classifier_loss: 2.9869 - val_loss3/classifier_loss: 3.0623 - val_loss1/classifier_accuracy: 0.2572 - val_loss1/classifier_top5_acc: 0.5807 - val_loss1/classifier_macro_f1score: 0.0475 - val_loss2/classifier_accuracy: 0.2441 - val_loss2/classifier_top5_acc: 0.5449 - val_loss2/classifier_macro_f1score: 0.0404 - val_loss3/classifier_accuracy: 0.2272 - val_loss3/classifier_top5_acc: 0.5260 - val_loss3/classifier_macro_f1score: 0.0410\n","Learning rate:  0.0003\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 10/70\n","97/97 [==============================] - ETA: 0s - loss: 4.5912 - loss1/classifier_loss: 2.8526 - loss2/classifier_loss: 2.9127 - loss3/classifier_loss: 2.8616 - loss1/classifier_accuracy: 0.2561 - loss1/classifier_top5_acc: 0.5847 - loss1/classifier_macro_f1score: 0.0435 - loss2/classifier_accuracy: 0.2420 - loss2/classifier_top5_acc: 0.5709 - loss2/classifier_macro_f1score: 0.0396 - loss3/classifier_accuracy: 0.2504 - loss3/classifier_top5_acc: 0.5817 - loss3/classifier_macro_f1score: 0.0407\n","Epoch 00010: val_loss improved from 4.82535 to 4.63635, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/010.h5\n","\n","Epoch 00010: val_loss3/classifier_accuracy improved from 0.22721 to 0.24089, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/010.h5\n","97/97 [==============================] - 242s 2s/step - loss: 4.5912 - loss1/classifier_loss: 2.8526 - loss2/classifier_loss: 2.9127 - loss3/classifier_loss: 2.8616 - loss1/classifier_accuracy: 0.2561 - loss1/classifier_top5_acc: 0.5847 - loss1/classifier_macro_f1score: 0.0435 - loss2/classifier_accuracy: 0.2420 - loss2/classifier_top5_acc: 0.5709 - loss2/classifier_macro_f1score: 0.0396 - loss3/classifier_accuracy: 0.2504 - loss3/classifier_top5_acc: 0.5817 - loss3/classifier_macro_f1score: 0.0407 - val_loss: 4.6364 - val_loss1/classifier_loss: 2.7612 - val_loss2/classifier_loss: 2.8590 - val_loss3/classifier_loss: 2.9503 - val_loss1/classifier_accuracy: 0.2676 - val_loss1/classifier_top5_acc: 0.6029 - val_loss1/classifier_macro_f1score: 0.0477 - val_loss2/classifier_accuracy: 0.2474 - val_loss2/classifier_top5_acc: 0.5892 - val_loss2/classifier_macro_f1score: 0.0422 - val_loss3/classifier_accuracy: 0.2409 - val_loss3/classifier_top5_acc: 0.5612 - val_loss3/classifier_macro_f1score: 0.0422\n","Learning rate:  0.0003\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 11/70\n","97/97 [==============================] - ETA: 0s - loss: 4.4258 - loss1/classifier_loss: 2.7744 - loss2/classifier_loss: 2.8138 - loss3/classifier_loss: 2.7493 - loss1/classifier_accuracy: 0.2736 - loss1/classifier_top5_acc: 0.6048 - loss1/classifier_macro_f1score: 0.0524 - loss2/classifier_accuracy: 0.2620 - loss2/classifier_top5_acc: 0.5943 - loss2/classifier_macro_f1score: 0.0495 - loss3/classifier_accuracy: 0.2736 - loss3/classifier_top5_acc: 0.6084 - loss3/classifier_macro_f1score: 0.0501\n","Epoch 00011: val_loss improved from 4.63635 to 4.41562, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/011.h5\n","\n","Epoch 00011: val_loss3/classifier_accuracy improved from 0.24089 to 0.26562, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/011.h5\n","97/97 [==============================] - 243s 3s/step - loss: 4.4258 - loss1/classifier_loss: 2.7744 - loss2/classifier_loss: 2.8138 - loss3/classifier_loss: 2.7493 - loss1/classifier_accuracy: 0.2736 - loss1/classifier_top5_acc: 0.6048 - loss1/classifier_macro_f1score: 0.0524 - loss2/classifier_accuracy: 0.2620 - loss2/classifier_top5_acc: 0.5943 - loss2/classifier_macro_f1score: 0.0495 - loss3/classifier_accuracy: 0.2736 - loss3/classifier_top5_acc: 0.6084 - loss3/classifier_macro_f1score: 0.0501 - val_loss: 4.4156 - val_loss1/classifier_loss: 2.6662 - val_loss2/classifier_loss: 2.7315 - val_loss3/classifier_loss: 2.7963 - val_loss1/classifier_accuracy: 0.2897 - val_loss1/classifier_top5_acc: 0.6289 - val_loss1/classifier_macro_f1score: 0.0605 - val_loss2/classifier_accuracy: 0.2760 - val_loss2/classifier_top5_acc: 0.6133 - val_loss2/classifier_macro_f1score: 0.0592 - val_loss3/classifier_accuracy: 0.2656 - val_loss3/classifier_top5_acc: 0.6035 - val_loss3/classifier_macro_f1score: 0.0513\n","Learning rate:  0.0003\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 12/70\n","97/97 [==============================] - ETA: 0s - loss: 4.3698 - loss1/classifier_loss: 2.7389 - loss2/classifier_loss: 2.7777 - loss3/classifier_loss: 2.7148 - loss1/classifier_accuracy: 0.2773 - loss1/classifier_top5_acc: 0.6139 - loss1/classifier_macro_f1score: 0.0562 - loss2/classifier_accuracy: 0.2709 - loss2/classifier_top5_acc: 0.6016 - loss2/classifier_macro_f1score: 0.0550 - loss3/classifier_accuracy: 0.2796 - loss3/classifier_top5_acc: 0.6200 - loss3/classifier_macro_f1score: 0.0583\n","Epoch 00012: val_loss did not improve from 4.41562\n","\n","Epoch 00012: val_loss3/classifier_accuracy did not improve from 0.26562\n","97/97 [==============================] - 242s 2s/step - loss: 4.3698 - loss1/classifier_loss: 2.7389 - loss2/classifier_loss: 2.7777 - loss3/classifier_loss: 2.7148 - loss1/classifier_accuracy: 0.2773 - loss1/classifier_top5_acc: 0.6139 - loss1/classifier_macro_f1score: 0.0562 - loss2/classifier_accuracy: 0.2709 - loss2/classifier_top5_acc: 0.6016 - loss2/classifier_macro_f1score: 0.0550 - loss3/classifier_accuracy: 0.2796 - loss3/classifier_top5_acc: 0.6200 - loss3/classifier_macro_f1score: 0.0583 - val_loss: 4.4522 - val_loss1/classifier_loss: 2.6324 - val_loss2/classifier_loss: 2.7581 - val_loss3/classifier_loss: 2.8351 - val_loss1/classifier_accuracy: 0.3040 - val_loss1/classifier_top5_acc: 0.6387 - val_loss1/classifier_macro_f1score: 0.0798 - val_loss2/classifier_accuracy: 0.2852 - val_loss2/classifier_top5_acc: 0.6165 - val_loss2/classifier_macro_f1score: 0.0776 - val_loss3/classifier_accuracy: 0.2650 - val_loss3/classifier_top5_acc: 0.5957 - val_loss3/classifier_macro_f1score: 0.0747\n","Learning rate:  0.0003\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 13/70\n","97/97 [==============================] - ETA: 0s - loss: 4.1531 - loss1/classifier_loss: 2.6422 - loss2/classifier_loss: 2.6502 - loss3/classifier_loss: 2.5653 - loss1/classifier_accuracy: 0.2990 - loss1/classifier_top5_acc: 0.6337 - loss1/classifier_macro_f1score: 0.0738 - loss2/classifier_accuracy: 0.2940 - loss2/classifier_top5_acc: 0.6337 - loss2/classifier_macro_f1score: 0.0744 - loss3/classifier_accuracy: 0.3173 - loss3/classifier_top5_acc: 0.6486 - loss3/classifier_macro_f1score: 0.0821\n","Epoch 00013: val_loss improved from 4.41562 to 4.16252, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/013.h5\n","\n","Epoch 00013: val_loss3/classifier_accuracy improved from 0.26562 to 0.32552, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/013.h5\n","97/97 [==============================] - 241s 2s/step - loss: 4.1531 - loss1/classifier_loss: 2.6422 - loss2/classifier_loss: 2.6502 - loss3/classifier_loss: 2.5653 - loss1/classifier_accuracy: 0.2990 - loss1/classifier_top5_acc: 0.6337 - loss1/classifier_macro_f1score: 0.0738 - loss2/classifier_accuracy: 0.2940 - loss2/classifier_top5_acc: 0.6337 - loss2/classifier_macro_f1score: 0.0744 - loss3/classifier_accuracy: 0.3173 - loss3/classifier_top5_acc: 0.6486 - loss3/classifier_macro_f1score: 0.0821 - val_loss: 4.1625 - val_loss1/classifier_loss: 2.5813 - val_loss2/classifier_loss: 2.5935 - val_loss3/classifier_loss: 2.6101 - val_loss1/classifier_accuracy: 0.3073 - val_loss1/classifier_top5_acc: 0.6374 - val_loss1/classifier_macro_f1score: 0.0904 - val_loss2/classifier_accuracy: 0.3294 - val_loss2/classifier_top5_acc: 0.6536 - val_loss2/classifier_macro_f1score: 0.0961 - val_loss3/classifier_accuracy: 0.3255 - val_loss3/classifier_top5_acc: 0.6354 - val_loss3/classifier_macro_f1score: 0.0954\n","Learning rate:  0.0003\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 14/70\n","97/97 [==============================] - ETA: 0s - loss: 4.0518 - loss1/classifier_loss: 2.5922 - loss2/classifier_loss: 2.5802 - loss3/classifier_loss: 2.5001 - loss1/classifier_accuracy: 0.3074 - loss1/classifier_top5_acc: 0.6480 - loss1/classifier_macro_f1score: 0.0710 - loss2/classifier_accuracy: 0.3098 - loss2/classifier_top5_acc: 0.6501 - loss2/classifier_macro_f1score: 0.0824 - loss3/classifier_accuracy: 0.3277 - loss3/classifier_top5_acc: 0.6683 - loss3/classifier_macro_f1score: 0.0909\n","Epoch 00014: val_loss improved from 4.16252 to 4.00973, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/014.h5\n","\n","Epoch 00014: val_loss3/classifier_accuracy did not improve from 0.32552\n","97/97 [==============================] - 240s 2s/step - loss: 4.0518 - loss1/classifier_loss: 2.5922 - loss2/classifier_loss: 2.5802 - loss3/classifier_loss: 2.5001 - loss1/classifier_accuracy: 0.3074 - loss1/classifier_top5_acc: 0.6480 - loss1/classifier_macro_f1score: 0.0710 - loss2/classifier_accuracy: 0.3098 - loss2/classifier_top5_acc: 0.6501 - loss2/classifier_macro_f1score: 0.0824 - loss3/classifier_accuracy: 0.3277 - loss3/classifier_top5_acc: 0.6683 - loss3/classifier_macro_f1score: 0.0909 - val_loss: 4.0097 - val_loss1/classifier_loss: 2.4958 - val_loss2/classifier_loss: 2.4905 - val_loss3/classifier_loss: 2.5138 - val_loss1/classifier_accuracy: 0.3268 - val_loss1/classifier_top5_acc: 0.6797 - val_loss1/classifier_macro_f1score: 0.0826 - val_loss2/classifier_accuracy: 0.3333 - val_loss2/classifier_top5_acc: 0.6738 - val_loss2/classifier_macro_f1score: 0.0924 - val_loss3/classifier_accuracy: 0.3223 - val_loss3/classifier_top5_acc: 0.6628 - val_loss3/classifier_macro_f1score: 0.0951\n","Learning rate:  0.0003\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 15/70\n","97/97 [==============================] - ETA: 0s - loss: 3.9116 - loss1/classifier_loss: 2.5262 - loss2/classifier_loss: 2.4992 - loss3/classifier_loss: 2.4039 - loss1/classifier_accuracy: 0.3207 - loss1/classifier_top5_acc: 0.6657 - loss1/classifier_macro_f1score: 0.0833 - loss2/classifier_accuracy: 0.3326 - loss2/classifier_top5_acc: 0.6718 - loss2/classifier_macro_f1score: 0.0934 - loss3/classifier_accuracy: 0.3463 - loss3/classifier_top5_acc: 0.6912 - loss3/classifier_macro_f1score: 0.1069\n","Epoch 00015: val_loss did not improve from 4.00973\n","\n","Epoch 00015: val_loss3/classifier_accuracy did not improve from 0.32552\n","97/97 [==============================] - 238s 2s/step - loss: 3.9116 - loss1/classifier_loss: 2.5262 - loss2/classifier_loss: 2.4992 - loss3/classifier_loss: 2.4039 - loss1/classifier_accuracy: 0.3207 - loss1/classifier_top5_acc: 0.6657 - loss1/classifier_macro_f1score: 0.0833 - loss2/classifier_accuracy: 0.3326 - loss2/classifier_top5_acc: 0.6718 - loss2/classifier_macro_f1score: 0.0934 - loss3/classifier_accuracy: 0.3463 - loss3/classifier_top5_acc: 0.6912 - loss3/classifier_macro_f1score: 0.1069 - val_loss: 4.1606 - val_loss1/classifier_loss: 2.5319 - val_loss2/classifier_loss: 2.6200 - val_loss3/classifier_loss: 2.6150 - val_loss1/classifier_accuracy: 0.3210 - val_loss1/classifier_top5_acc: 0.6549 - val_loss1/classifier_macro_f1score: 0.0924 - val_loss2/classifier_accuracy: 0.3210 - val_loss2/classifier_top5_acc: 0.6413 - val_loss2/classifier_macro_f1score: 0.0980 - val_loss3/classifier_accuracy: 0.3164 - val_loss3/classifier_top5_acc: 0.6465 - val_loss3/classifier_macro_f1score: 0.1059\n","Learning rate:  0.0003\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 16/70\n","97/97 [==============================] - ETA: 0s - loss: 3.8321 - loss1/classifier_loss: 2.4765 - loss2/classifier_loss: 2.4462 - loss3/classifier_loss: 2.3553 - loss1/classifier_accuracy: 0.3352 - loss1/classifier_top5_acc: 0.6811 - loss1/classifier_macro_f1score: 0.0967 - loss2/classifier_accuracy: 0.3406 - loss2/classifier_top5_acc: 0.6822 - loss2/classifier_macro_f1score: 0.1049 - loss3/classifier_accuracy: 0.3646 - loss3/classifier_top5_acc: 0.7030 - loss3/classifier_macro_f1score: 0.1193\n","Epoch 00016: val_loss improved from 4.00973 to 3.89507, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/016.h5\n","\n","Epoch 00016: val_loss3/classifier_accuracy improved from 0.32552 to 0.34115, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/016.h5\n","97/97 [==============================] - 241s 2s/step - loss: 3.8321 - loss1/classifier_loss: 2.4765 - loss2/classifier_loss: 2.4462 - loss3/classifier_loss: 2.3553 - loss1/classifier_accuracy: 0.3352 - loss1/classifier_top5_acc: 0.6811 - loss1/classifier_macro_f1score: 0.0967 - loss2/classifier_accuracy: 0.3406 - loss2/classifier_top5_acc: 0.6822 - loss2/classifier_macro_f1score: 0.1049 - loss3/classifier_accuracy: 0.3646 - loss3/classifier_top5_acc: 0.7030 - loss3/classifier_macro_f1score: 0.1193 - val_loss: 3.8951 - val_loss1/classifier_loss: 2.4353 - val_loss2/classifier_loss: 2.4114 - val_loss3/classifier_loss: 2.4411 - val_loss1/classifier_accuracy: 0.3451 - val_loss1/classifier_top5_acc: 0.6810 - val_loss1/classifier_macro_f1score: 0.1036 - val_loss2/classifier_accuracy: 0.3444 - val_loss2/classifier_top5_acc: 0.6992 - val_loss2/classifier_macro_f1score: 0.1172 - val_loss3/classifier_accuracy: 0.3411 - val_loss3/classifier_top5_acc: 0.6868 - val_loss3/classifier_macro_f1score: 0.1237\n","Learning rate:  0.0003\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 17/70\n","97/97 [==============================] - ETA: 0s - loss: 3.6806 - loss1/classifier_loss: 2.4195 - loss2/classifier_loss: 2.3673 - loss3/classifier_loss: 2.2446 - loss1/classifier_accuracy: 0.3484 - loss1/classifier_top5_acc: 0.6914 - loss1/classifier_macro_f1score: 0.1038 - loss2/classifier_accuracy: 0.3657 - loss2/classifier_top5_acc: 0.6970 - loss2/classifier_macro_f1score: 0.1209 - loss3/classifier_accuracy: 0.3866 - loss3/classifier_top5_acc: 0.7256 - loss3/classifier_macro_f1score: 0.1402\n","Epoch 00017: val_loss improved from 3.89507 to 3.82423, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/017.h5\n","\n","Epoch 00017: val_loss3/classifier_accuracy improved from 0.34115 to 0.35221, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/017.h5\n","97/97 [==============================] - 240s 2s/step - loss: 3.6806 - loss1/classifier_loss: 2.4195 - loss2/classifier_loss: 2.3673 - loss3/classifier_loss: 2.2446 - loss1/classifier_accuracy: 0.3484 - loss1/classifier_top5_acc: 0.6914 - loss1/classifier_macro_f1score: 0.1038 - loss2/classifier_accuracy: 0.3657 - loss2/classifier_top5_acc: 0.6970 - loss2/classifier_macro_f1score: 0.1209 - loss3/classifier_accuracy: 0.3866 - loss3/classifier_top5_acc: 0.7256 - loss3/classifier_macro_f1score: 0.1402 - val_loss: 3.8242 - val_loss1/classifier_loss: 2.3735 - val_loss2/classifier_loss: 2.3872 - val_loss3/classifier_loss: 2.3960 - val_loss1/classifier_accuracy: 0.3568 - val_loss1/classifier_top5_acc: 0.6927 - val_loss1/classifier_macro_f1score: 0.1050 - val_loss2/classifier_accuracy: 0.3424 - val_loss2/classifier_top5_acc: 0.6914 - val_loss2/classifier_macro_f1score: 0.1207 - val_loss3/classifier_accuracy: 0.3522 - val_loss3/classifier_top5_acc: 0.6914 - val_loss3/classifier_macro_f1score: 0.1223\n","Learning rate:  0.0003\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 18/70\n","97/97 [==============================] - ETA: 0s - loss: 3.6008 - loss1/classifier_loss: 2.3675 - loss2/classifier_loss: 2.3155 - loss3/classifier_loss: 2.1959 - loss1/classifier_accuracy: 0.3618 - loss1/classifier_top5_acc: 0.7016 - loss1/classifier_macro_f1score: 0.1123 - loss2/classifier_accuracy: 0.3725 - loss2/classifier_top5_acc: 0.7101 - loss2/classifier_macro_f1score: 0.1274 - loss3/classifier_accuracy: 0.4015 - loss3/classifier_top5_acc: 0.7346 - loss3/classifier_macro_f1score: 0.1494\n","Epoch 00018: val_loss improved from 3.82423 to 3.79127, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/018.h5\n","\n","Epoch 00018: val_loss3/classifier_accuracy improved from 0.35221 to 0.35807, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/018.h5\n","97/97 [==============================] - 240s 2s/step - loss: 3.6008 - loss1/classifier_loss: 2.3675 - loss2/classifier_loss: 2.3155 - loss3/classifier_loss: 2.1959 - loss1/classifier_accuracy: 0.3618 - loss1/classifier_top5_acc: 0.7016 - loss1/classifier_macro_f1score: 0.1123 - loss2/classifier_accuracy: 0.3725 - loss2/classifier_top5_acc: 0.7101 - loss2/classifier_macro_f1score: 0.1274 - loss3/classifier_accuracy: 0.4015 - loss3/classifier_top5_acc: 0.7346 - loss3/classifier_macro_f1score: 0.1494 - val_loss: 3.7913 - val_loss1/classifier_loss: 2.3359 - val_loss2/classifier_loss: 2.3513 - val_loss3/classifier_loss: 2.3851 - val_loss1/classifier_accuracy: 0.3717 - val_loss1/classifier_top5_acc: 0.7005 - val_loss1/classifier_macro_f1score: 0.1168 - val_loss2/classifier_accuracy: 0.3555 - val_loss2/classifier_top5_acc: 0.7129 - val_loss2/classifier_macro_f1score: 0.1163 - val_loss3/classifier_accuracy: 0.3581 - val_loss3/classifier_top5_acc: 0.6940 - val_loss3/classifier_macro_f1score: 0.1243\n","Learning rate:  0.0003\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 19/70\n","97/97 [==============================] - ETA: 0s - loss: 3.5023 - loss1/classifier_loss: 2.3284 - loss2/classifier_loss: 2.2507 - loss3/classifier_loss: 2.1286 - loss1/classifier_accuracy: 0.3705 - loss1/classifier_top5_acc: 0.7075 - loss1/classifier_macro_f1score: 0.1216 - loss2/classifier_accuracy: 0.3879 - loss2/classifier_top5_acc: 0.7263 - loss2/classifier_macro_f1score: 0.1418 - loss3/classifier_accuracy: 0.4126 - loss3/classifier_top5_acc: 0.7495 - loss3/classifier_macro_f1score: 0.1637\n","Epoch 00019: val_loss improved from 3.79127 to 3.64475, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/019.h5\n","\n","Epoch 00019: val_loss3/classifier_accuracy improved from 0.35807 to 0.39258, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/019.h5\n","97/97 [==============================] - 239s 2s/step - loss: 3.5023 - loss1/classifier_loss: 2.3284 - loss2/classifier_loss: 2.2507 - loss3/classifier_loss: 2.1286 - loss1/classifier_accuracy: 0.3705 - loss1/classifier_top5_acc: 0.7075 - loss1/classifier_macro_f1score: 0.1216 - loss2/classifier_accuracy: 0.3879 - loss2/classifier_top5_acc: 0.7263 - loss2/classifier_macro_f1score: 0.1418 - loss3/classifier_accuracy: 0.4126 - loss3/classifier_top5_acc: 0.7495 - loss3/classifier_macro_f1score: 0.1637 - val_loss: 3.6447 - val_loss1/classifier_loss: 2.3368 - val_loss2/classifier_loss: 2.2818 - val_loss3/classifier_loss: 2.2592 - val_loss1/classifier_accuracy: 0.3711 - val_loss1/classifier_top5_acc: 0.7064 - val_loss1/classifier_macro_f1score: 0.1329 - val_loss2/classifier_accuracy: 0.3802 - val_loss2/classifier_top5_acc: 0.7188 - val_loss2/classifier_macro_f1score: 0.1466 - val_loss3/classifier_accuracy: 0.3926 - val_loss3/classifier_top5_acc: 0.7181 - val_loss3/classifier_macro_f1score: 0.1536\n","Learning rate:  0.0003\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 20/70\n","97/97 [==============================] - ETA: 0s - loss: 3.4197 - loss1/classifier_loss: 2.2869 - loss2/classifier_loss: 2.1993 - loss3/classifier_loss: 2.0739 - loss1/classifier_accuracy: 0.3807 - loss1/classifier_top5_acc: 0.7128 - loss1/classifier_macro_f1score: 0.1288 - loss2/classifier_accuracy: 0.4063 - loss2/classifier_top5_acc: 0.7304 - loss2/classifier_macro_f1score: 0.1541 - loss3/classifier_accuracy: 0.4282 - loss3/classifier_top5_acc: 0.7578 - loss3/classifier_macro_f1score: 0.1761\n","Epoch 00020: val_loss did not improve from 3.64475\n","\n","Epoch 00020: val_loss3/classifier_accuracy did not improve from 0.39258\n","97/97 [==============================] - 239s 2s/step - loss: 3.4197 - loss1/classifier_loss: 2.2869 - loss2/classifier_loss: 2.1993 - loss3/classifier_loss: 2.0739 - loss1/classifier_accuracy: 0.3807 - loss1/classifier_top5_acc: 0.7128 - loss1/classifier_macro_f1score: 0.1288 - loss2/classifier_accuracy: 0.4063 - loss2/classifier_top5_acc: 0.7304 - loss2/classifier_macro_f1score: 0.1541 - loss3/classifier_accuracy: 0.4282 - loss3/classifier_top5_acc: 0.7578 - loss3/classifier_macro_f1score: 0.1761 - val_loss: 4.0305 - val_loss1/classifier_loss: 2.4392 - val_loss2/classifier_loss: 2.4809 - val_loss3/classifier_loss: 2.5545 - val_loss1/classifier_accuracy: 0.3503 - val_loss1/classifier_top5_acc: 0.6732 - val_loss1/classifier_macro_f1score: 0.1272 - val_loss2/classifier_accuracy: 0.3392 - val_loss2/classifier_top5_acc: 0.6855 - val_loss2/classifier_macro_f1score: 0.1225 - val_loss3/classifier_accuracy: 0.3411 - val_loss3/classifier_top5_acc: 0.6647 - val_loss3/classifier_macro_f1score: 0.1278\n","Learning rate:  0.0003\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 21/70\n","97/97 [==============================] - ETA: 0s - loss: 3.3451 - loss1/classifier_loss: 2.2537 - loss2/classifier_loss: 2.1535 - loss3/classifier_loss: 2.0229 - loss1/classifier_accuracy: 0.3857 - loss1/classifier_top5_acc: 0.7295 - loss1/classifier_macro_f1score: 0.1361 - loss2/classifier_accuracy: 0.4122 - loss2/classifier_top5_acc: 0.7451 - loss2/classifier_macro_f1score: 0.1570 - loss3/classifier_accuracy: 0.4434 - loss3/classifier_top5_acc: 0.7719 - loss3/classifier_macro_f1score: 0.1872\n","Epoch 00021: val_loss improved from 3.64475 to 3.60739, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/021.h5\n","\n","Epoch 00021: val_loss3/classifier_accuracy did not improve from 0.39258\n","97/97 [==============================] - 239s 2s/step - loss: 3.3451 - loss1/classifier_loss: 2.2537 - loss2/classifier_loss: 2.1535 - loss3/classifier_loss: 2.0229 - loss1/classifier_accuracy: 0.3857 - loss1/classifier_top5_acc: 0.7295 - loss1/classifier_macro_f1score: 0.1361 - loss2/classifier_accuracy: 0.4122 - loss2/classifier_top5_acc: 0.7451 - loss2/classifier_macro_f1score: 0.1570 - loss3/classifier_accuracy: 0.4434 - loss3/classifier_top5_acc: 0.7719 - loss3/classifier_macro_f1score: 0.1872 - val_loss: 3.6074 - val_loss1/classifier_loss: 2.2327 - val_loss2/classifier_loss: 2.2265 - val_loss3/classifier_loss: 2.2697 - val_loss1/classifier_accuracy: 0.3893 - val_loss1/classifier_top5_acc: 0.7148 - val_loss1/classifier_macro_f1score: 0.1408 - val_loss2/classifier_accuracy: 0.3958 - val_loss2/classifier_top5_acc: 0.7324 - val_loss2/classifier_macro_f1score: 0.1543 - val_loss3/classifier_accuracy: 0.3887 - val_loss3/classifier_top5_acc: 0.7279 - val_loss3/classifier_macro_f1score: 0.1686\n","Learning rate:  0.0003\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 22/70\n","97/97 [==============================] - ETA: 0s - loss: 3.2428 - loss1/classifier_loss: 2.2209 - loss2/classifier_loss: 2.0938 - loss3/classifier_loss: 1.9484 - loss1/classifier_accuracy: 0.3992 - loss1/classifier_top5_acc: 0.7319 - loss1/classifier_macro_f1score: 0.1390 - loss2/classifier_accuracy: 0.4233 - loss2/classifier_top5_acc: 0.7586 - loss2/classifier_macro_f1score: 0.1746 - loss3/classifier_accuracy: 0.4538 - loss3/classifier_top5_acc: 0.7852 - loss3/classifier_macro_f1score: 0.2018\n","Epoch 00022: val_loss improved from 3.60739 to 3.60350, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/022.h5\n","\n","Epoch 00022: val_loss3/classifier_accuracy improved from 0.39258 to 0.39453, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/022.h5\n","97/97 [==============================] - 239s 2s/step - loss: 3.2428 - loss1/classifier_loss: 2.2209 - loss2/classifier_loss: 2.0938 - loss3/classifier_loss: 1.9484 - loss1/classifier_accuracy: 0.3992 - loss1/classifier_top5_acc: 0.7319 - loss1/classifier_macro_f1score: 0.1390 - loss2/classifier_accuracy: 0.4233 - loss2/classifier_top5_acc: 0.7586 - loss2/classifier_macro_f1score: 0.1746 - loss3/classifier_accuracy: 0.4538 - loss3/classifier_top5_acc: 0.7852 - loss3/classifier_macro_f1score: 0.2018 - val_loss: 3.6035 - val_loss1/classifier_loss: 2.2937 - val_loss2/classifier_loss: 2.2602 - val_loss3/classifier_loss: 2.2373 - val_loss1/classifier_accuracy: 0.3848 - val_loss1/classifier_top5_acc: 0.7031 - val_loss1/classifier_macro_f1score: 0.1413 - val_loss2/classifier_accuracy: 0.3861 - val_loss2/classifier_top5_acc: 0.7240 - val_loss2/classifier_macro_f1score: 0.1542 - val_loss3/classifier_accuracy: 0.3945 - val_loss3/classifier_top5_acc: 0.7344 - val_loss3/classifier_macro_f1score: 0.1740\n","Learning rate:  0.0003\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 23/70\n","97/97 [==============================] - ETA: 0s - loss: 3.0797 - loss1/classifier_loss: 2.1353 - loss2/classifier_loss: 2.0024 - loss3/classifier_loss: 1.8384 - loss1/classifier_accuracy: 0.4125 - loss1/classifier_top5_acc: 0.7505 - loss1/classifier_macro_f1score: 0.1579 - loss2/classifier_accuracy: 0.4442 - loss2/classifier_top5_acc: 0.7752 - loss2/classifier_macro_f1score: 0.1938 - loss3/classifier_accuracy: 0.4822 - loss3/classifier_top5_acc: 0.8052 - loss3/classifier_macro_f1score: 0.2275\n","Epoch 00023: val_loss improved from 3.60350 to 3.45437, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/023.h5\n","\n","Epoch 00023: val_loss3/classifier_accuracy improved from 0.39453 to 0.39844, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/023.h5\n","97/97 [==============================] - 239s 2s/step - loss: 3.0797 - loss1/classifier_loss: 2.1353 - loss2/classifier_loss: 2.0024 - loss3/classifier_loss: 1.8384 - loss1/classifier_accuracy: 0.4125 - loss1/classifier_top5_acc: 0.7505 - loss1/classifier_macro_f1score: 0.1579 - loss2/classifier_accuracy: 0.4442 - loss2/classifier_top5_acc: 0.7752 - loss2/classifier_macro_f1score: 0.1938 - loss3/classifier_accuracy: 0.4822 - loss3/classifier_top5_acc: 0.8052 - loss3/classifier_macro_f1score: 0.2275 - val_loss: 3.4544 - val_loss1/classifier_loss: 2.2162 - val_loss2/classifier_loss: 2.1529 - val_loss3/classifier_loss: 2.1436 - val_loss1/classifier_accuracy: 0.4082 - val_loss1/classifier_top5_acc: 0.7383 - val_loss1/classifier_macro_f1score: 0.1368 - val_loss2/classifier_accuracy: 0.4089 - val_loss2/classifier_top5_acc: 0.7526 - val_loss2/classifier_macro_f1score: 0.1548 - val_loss3/classifier_accuracy: 0.3984 - val_loss3/classifier_top5_acc: 0.7500 - val_loss3/classifier_macro_f1score: 0.1726\n","Learning rate:  0.0003\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 24/70\n","97/97 [==============================] - ETA: 0s - loss: 3.0568 - loss1/classifier_loss: 2.1333 - loss2/classifier_loss: 1.9860 - loss3/classifier_loss: 1.8210 - loss1/classifier_accuracy: 0.4152 - loss1/classifier_top5_acc: 0.7477 - loss1/classifier_macro_f1score: 0.1568 - loss2/classifier_accuracy: 0.4584 - loss2/classifier_top5_acc: 0.7735 - loss2/classifier_macro_f1score: 0.1970 - loss3/classifier_accuracy: 0.4829 - loss3/classifier_top5_acc: 0.8077 - loss3/classifier_macro_f1score: 0.2274\n","Epoch 00024: val_loss did not improve from 3.45437\n","\n","Epoch 00024: val_loss3/classifier_accuracy did not improve from 0.39844\n","97/97 [==============================] - 237s 2s/step - loss: 3.0568 - loss1/classifier_loss: 2.1333 - loss2/classifier_loss: 1.9860 - loss3/classifier_loss: 1.8210 - loss1/classifier_accuracy: 0.4152 - loss1/classifier_top5_acc: 0.7477 - loss1/classifier_macro_f1score: 0.1568 - loss2/classifier_accuracy: 0.4584 - loss2/classifier_top5_acc: 0.7735 - loss2/classifier_macro_f1score: 0.1970 - loss3/classifier_accuracy: 0.4829 - loss3/classifier_top5_acc: 0.8077 - loss3/classifier_macro_f1score: 0.2274 - val_loss: 3.9161 - val_loss1/classifier_loss: 2.4304 - val_loss2/classifier_loss: 2.4115 - val_loss3/classifier_loss: 2.4635 - val_loss1/classifier_accuracy: 0.3568 - val_loss1/classifier_top5_acc: 0.6940 - val_loss1/classifier_macro_f1score: 0.1337 - val_loss2/classifier_accuracy: 0.3678 - val_loss2/classifier_top5_acc: 0.7077 - val_loss2/classifier_macro_f1score: 0.1562 - val_loss3/classifier_accuracy: 0.3757 - val_loss3/classifier_top5_acc: 0.6927 - val_loss3/classifier_macro_f1score: 0.1769\n","Learning rate:  0.0003\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 25/70\n","97/97 [==============================] - ETA: 0s - loss: 2.9275 - loss1/classifier_loss: 2.0704 - loss2/classifier_loss: 1.9151 - loss3/classifier_loss: 1.7319 - loss1/classifier_accuracy: 0.4278 - loss1/classifier_top5_acc: 0.7661 - loss1/classifier_macro_f1score: 0.1676 - loss2/classifier_accuracy: 0.4705 - loss2/classifier_top5_acc: 0.7893 - loss2/classifier_macro_f1score: 0.2062 - loss3/classifier_accuracy: 0.5062 - loss3/classifier_top5_acc: 0.8229 - loss3/classifier_macro_f1score: 0.2469\n","Epoch 00025: val_loss did not improve from 3.45437\n","\n","Epoch 00025: val_loss3/classifier_accuracy improved from 0.39844 to 0.40690, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/025.h5\n","97/97 [==============================] - 239s 2s/step - loss: 2.9275 - loss1/classifier_loss: 2.0704 - loss2/classifier_loss: 1.9151 - loss3/classifier_loss: 1.7319 - loss1/classifier_accuracy: 0.4278 - loss1/classifier_top5_acc: 0.7661 - loss1/classifier_macro_f1score: 0.1676 - loss2/classifier_accuracy: 0.4705 - loss2/classifier_top5_acc: 0.7893 - loss2/classifier_macro_f1score: 0.2062 - loss3/classifier_accuracy: 0.5062 - loss3/classifier_top5_acc: 0.8229 - loss3/classifier_macro_f1score: 0.2469 - val_loss: 3.5225 - val_loss1/classifier_loss: 2.2363 - val_loss2/classifier_loss: 2.1534 - val_loss3/classifier_loss: 2.2055 - val_loss1/classifier_accuracy: 0.4004 - val_loss1/classifier_top5_acc: 0.7240 - val_loss1/classifier_macro_f1score: 0.1627 - val_loss2/classifier_accuracy: 0.4121 - val_loss2/classifier_top5_acc: 0.7520 - val_loss2/classifier_macro_f1score: 0.1870 - val_loss3/classifier_accuracy: 0.4069 - val_loss3/classifier_top5_acc: 0.7513 - val_loss3/classifier_macro_f1score: 0.2075\n","Learning rate:  0.0003\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 26/70\n","97/97 [==============================] - ETA: 0s - loss: 2.8377 - loss1/classifier_loss: 2.0422 - loss2/classifier_loss: 1.8643 - loss3/classifier_loss: 1.6657 - loss1/classifier_accuracy: 0.4392 - loss1/classifier_top5_acc: 0.7680 - loss1/classifier_macro_f1score: 0.1776 - loss2/classifier_accuracy: 0.4805 - loss2/classifier_top5_acc: 0.8020 - loss2/classifier_macro_f1score: 0.2220 - loss3/classifier_accuracy: 0.5252 - loss3/classifier_top5_acc: 0.8308 - loss3/classifier_macro_f1score: 0.2686\n","Epoch 00026: val_loss did not improve from 3.45437\n","\n","Epoch 00026: val_loss3/classifier_accuracy improved from 0.40690 to 0.41602, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/026.h5\n","97/97 [==============================] - 240s 2s/step - loss: 2.8377 - loss1/classifier_loss: 2.0422 - loss2/classifier_loss: 1.8643 - loss3/classifier_loss: 1.6657 - loss1/classifier_accuracy: 0.4392 - loss1/classifier_top5_acc: 0.7680 - loss1/classifier_macro_f1score: 0.1776 - loss2/classifier_accuracy: 0.4805 - loss2/classifier_top5_acc: 0.8020 - loss2/classifier_macro_f1score: 0.2220 - loss3/classifier_accuracy: 0.5252 - loss3/classifier_top5_acc: 0.8308 - loss3/classifier_macro_f1score: 0.2686 - val_loss: 3.5522 - val_loss1/classifier_loss: 2.1766 - val_loss2/classifier_loss: 2.1974 - val_loss3/classifier_loss: 2.2400 - val_loss1/classifier_accuracy: 0.4180 - val_loss1/classifier_top5_acc: 0.7493 - val_loss1/classifier_macro_f1score: 0.1666 - val_loss2/classifier_accuracy: 0.4225 - val_loss2/classifier_top5_acc: 0.7435 - val_loss2/classifier_macro_f1score: 0.1910 - val_loss3/classifier_accuracy: 0.4160 - val_loss3/classifier_top5_acc: 0.7493 - val_loss3/classifier_macro_f1score: 0.2024\n","Learning rate:  0.0003\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 27/70\n","97/97 [==============================] - ETA: 0s - loss: 2.7557 - loss1/classifier_loss: 1.9817 - loss2/classifier_loss: 1.8154 - loss3/classifier_loss: 1.6165 - loss1/classifier_accuracy: 0.4523 - loss1/classifier_top5_acc: 0.7825 - loss1/classifier_macro_f1score: 0.1867 - loss2/classifier_accuracy: 0.4909 - loss2/classifier_top5_acc: 0.8069 - loss2/classifier_macro_f1score: 0.2321 - loss3/classifier_accuracy: 0.5405 - loss3/classifier_top5_acc: 0.8439 - loss3/classifier_macro_f1score: 0.2765\n","Epoch 00027: val_loss did not improve from 3.45437\n","\n","Epoch 00027: val_loss3/classifier_accuracy did not improve from 0.41602\n","97/97 [==============================] - 239s 2s/step - loss: 2.7557 - loss1/classifier_loss: 1.9817 - loss2/classifier_loss: 1.8154 - loss3/classifier_loss: 1.6165 - loss1/classifier_accuracy: 0.4523 - loss1/classifier_top5_acc: 0.7825 - loss1/classifier_macro_f1score: 0.1867 - loss2/classifier_accuracy: 0.4909 - loss2/classifier_top5_acc: 0.8069 - loss2/classifier_macro_f1score: 0.2321 - loss3/classifier_accuracy: 0.5405 - loss3/classifier_top5_acc: 0.8439 - loss3/classifier_macro_f1score: 0.2765 - val_loss: 3.6949 - val_loss1/classifier_loss: 2.2838 - val_loss2/classifier_loss: 2.2888 - val_loss3/classifier_loss: 2.3231 - val_loss1/classifier_accuracy: 0.3893 - val_loss1/classifier_top5_acc: 0.7253 - val_loss1/classifier_macro_f1score: 0.1611 - val_loss2/classifier_accuracy: 0.3952 - val_loss2/classifier_top5_acc: 0.7220 - val_loss2/classifier_macro_f1score: 0.1743 - val_loss3/classifier_accuracy: 0.4049 - val_loss3/classifier_top5_acc: 0.7350 - val_loss3/classifier_macro_f1score: 0.2004\n","Learning rate:  0.0003\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 28/70\n","97/97 [==============================] - ETA: 0s - loss: 2.6644 - loss1/classifier_loss: 1.9637 - loss2/classifier_loss: 1.7609 - loss3/classifier_loss: 1.5470 - loss1/classifier_accuracy: 0.4581 - loss1/classifier_top5_acc: 0.7834 - loss1/classifier_macro_f1score: 0.1961 - loss2/classifier_accuracy: 0.5063 - loss2/classifier_top5_acc: 0.8184 - loss2/classifier_macro_f1score: 0.2504 - loss3/classifier_accuracy: 0.5555 - loss3/classifier_top5_acc: 0.8526 - loss3/classifier_macro_f1score: 0.2997\n","Epoch 00028: val_loss did not improve from 3.45437\n","\n","Epoch 00028: val_loss3/classifier_accuracy improved from 0.41602 to 0.42383, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/028.h5\n","97/97 [==============================] - 238s 2s/step - loss: 2.6644 - loss1/classifier_loss: 1.9637 - loss2/classifier_loss: 1.7609 - loss3/classifier_loss: 1.5470 - loss1/classifier_accuracy: 0.4581 - loss1/classifier_top5_acc: 0.7834 - loss1/classifier_macro_f1score: 0.1961 - loss2/classifier_accuracy: 0.5063 - loss2/classifier_top5_acc: 0.8184 - loss2/classifier_macro_f1score: 0.2504 - loss3/classifier_accuracy: 0.5555 - loss3/classifier_top5_acc: 0.8526 - loss3/classifier_macro_f1score: 0.2997 - val_loss: 3.6322 - val_loss1/classifier_loss: 2.1820 - val_loss2/classifier_loss: 2.2384 - val_loss3/classifier_loss: 2.3061 - val_loss1/classifier_accuracy: 0.4212 - val_loss1/classifier_top5_acc: 0.7487 - val_loss1/classifier_macro_f1score: 0.1772 - val_loss2/classifier_accuracy: 0.4108 - val_loss2/classifier_top5_acc: 0.7480 - val_loss2/classifier_macro_f1score: 0.1964 - val_loss3/classifier_accuracy: 0.4238 - val_loss3/classifier_top5_acc: 0.7376 - val_loss3/classifier_macro_f1score: 0.2219\n","Learning rate:  0.0003\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 29/70\n","97/97 [==============================] - ETA: 0s - loss: 2.6096 - loss1/classifier_loss: 1.9259 - loss2/classifier_loss: 1.7261 - loss3/classifier_loss: 1.5140 - loss1/classifier_accuracy: 0.4632 - loss1/classifier_top5_acc: 0.7932 - loss1/classifier_macro_f1score: 0.2004 - loss2/classifier_accuracy: 0.5157 - loss2/classifier_top5_acc: 0.8227 - loss2/classifier_macro_f1score: 0.2517 - loss3/classifier_accuracy: 0.5620 - loss3/classifier_top5_acc: 0.8625 - loss3/classifier_macro_f1score: 0.2999\n","Epoch 00029: val_loss did not improve from 3.45437\n","\n","Epoch 00029: val_loss3/classifier_accuracy improved from 0.42383 to 0.43229, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/029.h5\n","97/97 [==============================] - 239s 2s/step - loss: 2.6096 - loss1/classifier_loss: 1.9259 - loss2/classifier_loss: 1.7261 - loss3/classifier_loss: 1.5140 - loss1/classifier_accuracy: 0.4632 - loss1/classifier_top5_acc: 0.7932 - loss1/classifier_macro_f1score: 0.2004 - loss2/classifier_accuracy: 0.5157 - loss2/classifier_top5_acc: 0.8227 - loss2/classifier_macro_f1score: 0.2517 - loss3/classifier_accuracy: 0.5620 - loss3/classifier_top5_acc: 0.8625 - loss3/classifier_macro_f1score: 0.2999 - val_loss: 3.5522 - val_loss1/classifier_loss: 2.2011 - val_loss2/classifier_loss: 2.1941 - val_loss3/classifier_loss: 2.2336 - val_loss1/classifier_accuracy: 0.4167 - val_loss1/classifier_top5_acc: 0.7467 - val_loss1/classifier_macro_f1score: 0.1948 - val_loss2/classifier_accuracy: 0.4277 - val_loss2/classifier_top5_acc: 0.7539 - val_loss2/classifier_macro_f1score: 0.2155 - val_loss3/classifier_accuracy: 0.4323 - val_loss3/classifier_top5_acc: 0.7604 - val_loss3/classifier_macro_f1score: 0.2428\n","Learning rate:  0.0003\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 30/70\n","97/97 [==============================] - ETA: 0s - loss: 2.5026 - loss1/classifier_loss: 1.8726 - loss2/classifier_loss: 1.6679 - loss3/classifier_loss: 1.4404 - loss1/classifier_accuracy: 0.4818 - loss1/classifier_top5_acc: 0.8031 - loss1/classifier_macro_f1score: 0.2083 - loss2/classifier_accuracy: 0.5264 - loss2/classifier_top5_acc: 0.8383 - loss2/classifier_macro_f1score: 0.2706 - loss3/classifier_accuracy: 0.5815 - loss3/classifier_top5_acc: 0.8738 - loss3/classifier_macro_f1score: 0.3255\n","Epoch 00030: val_loss did not improve from 3.45437\n","\n","Epoch 00030: val_loss3/classifier_accuracy did not improve from 0.43229\n","97/97 [==============================] - 237s 2s/step - loss: 2.5026 - loss1/classifier_loss: 1.8726 - loss2/classifier_loss: 1.6679 - loss3/classifier_loss: 1.4404 - loss1/classifier_accuracy: 0.4818 - loss1/classifier_top5_acc: 0.8031 - loss1/classifier_macro_f1score: 0.2083 - loss2/classifier_accuracy: 0.5264 - loss2/classifier_top5_acc: 0.8383 - loss2/classifier_macro_f1score: 0.2706 - loss3/classifier_accuracy: 0.5815 - loss3/classifier_top5_acc: 0.8738 - loss3/classifier_macro_f1score: 0.3255 - val_loss: 3.5354 - val_loss1/classifier_loss: 2.1507 - val_loss2/classifier_loss: 2.1341 - val_loss3/classifier_loss: 2.2500 - val_loss1/classifier_accuracy: 0.4251 - val_loss1/classifier_top5_acc: 0.7389 - val_loss1/classifier_macro_f1score: 0.1767 - val_loss2/classifier_accuracy: 0.4297 - val_loss2/classifier_top5_acc: 0.7487 - val_loss2/classifier_macro_f1score: 0.2046 - val_loss3/classifier_accuracy: 0.4297 - val_loss3/classifier_top5_acc: 0.7507 - val_loss3/classifier_macro_f1score: 0.2243\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 31/70\n","97/97 [==============================] - ETA: 0s - loss: 2.2023 - loss1/classifier_loss: 1.7785 - loss2/classifier_loss: 1.4868 - loss3/classifier_loss: 1.2227 - loss1/classifier_accuracy: 0.5013 - loss1/classifier_top5_acc: 0.8174 - loss1/classifier_macro_f1score: 0.2298 - loss2/classifier_accuracy: 0.5728 - loss2/classifier_top5_acc: 0.8581 - loss2/classifier_macro_f1score: 0.3053 - loss3/classifier_accuracy: 0.6437 - loss3/classifier_top5_acc: 0.9027 - loss3/classifier_macro_f1score: 0.3788\n","Epoch 00031: val_loss improved from 3.45437 to 3.26657, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/031.h5\n","\n","Epoch 00031: val_loss3/classifier_accuracy improved from 0.43229 to 0.49219, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/031.h5\n","97/97 [==============================] - 240s 2s/step - loss: 2.2023 - loss1/classifier_loss: 1.7785 - loss2/classifier_loss: 1.4868 - loss3/classifier_loss: 1.2227 - loss1/classifier_accuracy: 0.5013 - loss1/classifier_top5_acc: 0.8174 - loss1/classifier_macro_f1score: 0.2298 - loss2/classifier_accuracy: 0.5728 - loss2/classifier_top5_acc: 0.8581 - loss2/classifier_macro_f1score: 0.3053 - loss3/classifier_accuracy: 0.6437 - loss3/classifier_top5_acc: 0.9027 - loss3/classifier_macro_f1score: 0.3788 - val_loss: 3.2666 - val_loss1/classifier_loss: 2.0535 - val_loss2/classifier_loss: 2.0101 - val_loss3/classifier_loss: 2.0475 - val_loss1/classifier_accuracy: 0.4499 - val_loss1/classifier_top5_acc: 0.7747 - val_loss1/classifier_macro_f1score: 0.2093 - val_loss2/classifier_accuracy: 0.4707 - val_loss2/classifier_top5_acc: 0.7780 - val_loss2/classifier_macro_f1score: 0.2533 - val_loss3/classifier_accuracy: 0.4922 - val_loss3/classifier_top5_acc: 0.7995 - val_loss3/classifier_macro_f1score: 0.2836\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 32/70\n","97/97 [==============================] - ETA: 0s - loss: 2.0281 - loss1/classifier_loss: 1.7205 - loss2/classifier_loss: 1.3987 - loss3/classifier_loss: 1.0924 - loss1/classifier_accuracy: 0.5121 - loss1/classifier_top5_acc: 0.8284 - loss1/classifier_macro_f1score: 0.2452 - loss2/classifier_accuracy: 0.5957 - loss2/classifier_top5_acc: 0.8740 - loss2/classifier_macro_f1score: 0.3284 - loss3/classifier_accuracy: 0.6759 - loss3/classifier_top5_acc: 0.9165 - loss3/classifier_macro_f1score: 0.4166\n","Epoch 00032: val_loss did not improve from 3.26657\n","\n","Epoch 00032: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 237s 2s/step - loss: 2.0281 - loss1/classifier_loss: 1.7205 - loss2/classifier_loss: 1.3987 - loss3/classifier_loss: 1.0924 - loss1/classifier_accuracy: 0.5121 - loss1/classifier_top5_acc: 0.8284 - loss1/classifier_macro_f1score: 0.2452 - loss2/classifier_accuracy: 0.5957 - loss2/classifier_top5_acc: 0.8740 - loss2/classifier_macro_f1score: 0.3284 - loss3/classifier_accuracy: 0.6759 - loss3/classifier_top5_acc: 0.9165 - loss3/classifier_macro_f1score: 0.4166 - val_loss: 3.4409 - val_loss1/classifier_loss: 2.1086 - val_loss2/classifier_loss: 2.1271 - val_loss3/classifier_loss: 2.1702 - val_loss1/classifier_accuracy: 0.4434 - val_loss1/classifier_top5_acc: 0.7604 - val_loss1/classifier_macro_f1score: 0.2020 - val_loss2/classifier_accuracy: 0.4440 - val_loss2/classifier_top5_acc: 0.7721 - val_loss2/classifier_macro_f1score: 0.2346 - val_loss3/classifier_accuracy: 0.4701 - val_loss3/classifier_top5_acc: 0.7806 - val_loss3/classifier_macro_f1score: 0.2732\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 33/70\n","97/97 [==============================] - ETA: 0s - loss: 1.9981 - loss1/classifier_loss: 1.7058 - loss2/classifier_loss: 1.3780 - loss3/classifier_loss: 1.0729 - loss1/classifier_accuracy: 0.5182 - loss1/classifier_top5_acc: 0.8279 - loss1/classifier_macro_f1score: 0.2445 - loss2/classifier_accuracy: 0.6024 - loss2/classifier_top5_acc: 0.8779 - loss2/classifier_macro_f1score: 0.3393 - loss3/classifier_accuracy: 0.6824 - loss3/classifier_top5_acc: 0.9176 - loss3/classifier_macro_f1score: 0.4244\n","Epoch 00033: val_loss improved from 3.26657 to 3.24258, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/033.h5\n","\n","Epoch 00033: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 238s 2s/step - loss: 1.9981 - loss1/classifier_loss: 1.7058 - loss2/classifier_loss: 1.3780 - loss3/classifier_loss: 1.0729 - loss1/classifier_accuracy: 0.5182 - loss1/classifier_top5_acc: 0.8279 - loss1/classifier_macro_f1score: 0.2445 - loss2/classifier_accuracy: 0.6024 - loss2/classifier_top5_acc: 0.8779 - loss2/classifier_macro_f1score: 0.3393 - loss3/classifier_accuracy: 0.6824 - loss3/classifier_top5_acc: 0.9176 - loss3/classifier_macro_f1score: 0.4244 - val_loss: 3.2426 - val_loss1/classifier_loss: 2.0349 - val_loss2/classifier_loss: 1.9945 - val_loss3/classifier_loss: 2.0337 - val_loss1/classifier_accuracy: 0.4518 - val_loss1/classifier_top5_acc: 0.7780 - val_loss1/classifier_macro_f1score: 0.2129 - val_loss2/classifier_accuracy: 0.4740 - val_loss2/classifier_top5_acc: 0.7969 - val_loss2/classifier_macro_f1score: 0.2594 - val_loss3/classifier_accuracy: 0.4902 - val_loss3/classifier_top5_acc: 0.8047 - val_loss3/classifier_macro_f1score: 0.2856\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 34/70\n","97/97 [==============================] - ETA: 0s - loss: 1.9627 - loss1/classifier_loss: 1.6989 - loss2/classifier_loss: 1.3561 - loss3/classifier_loss: 1.0462 - loss1/classifier_accuracy: 0.5180 - loss1/classifier_top5_acc: 0.8331 - loss1/classifier_macro_f1score: 0.2517 - loss2/classifier_accuracy: 0.6059 - loss2/classifier_top5_acc: 0.8828 - loss2/classifier_macro_f1score: 0.3434 - loss3/classifier_accuracy: 0.6893 - loss3/classifier_top5_acc: 0.9187 - loss3/classifier_macro_f1score: 0.4339\n","Epoch 00034: val_loss did not improve from 3.24258\n","\n","Epoch 00034: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 238s 2s/step - loss: 1.9627 - loss1/classifier_loss: 1.6989 - loss2/classifier_loss: 1.3561 - loss3/classifier_loss: 1.0462 - loss1/classifier_accuracy: 0.5180 - loss1/classifier_top5_acc: 0.8331 - loss1/classifier_macro_f1score: 0.2517 - loss2/classifier_accuracy: 0.6059 - loss2/classifier_top5_acc: 0.8828 - loss2/classifier_macro_f1score: 0.3434 - loss3/classifier_accuracy: 0.6893 - loss3/classifier_top5_acc: 0.9187 - loss3/classifier_macro_f1score: 0.4339 - val_loss: 3.3015 - val_loss1/classifier_loss: 2.0512 - val_loss2/classifier_loss: 2.0239 - val_loss3/classifier_loss: 2.0790 - val_loss1/classifier_accuracy: 0.4466 - val_loss1/classifier_top5_acc: 0.7721 - val_loss1/classifier_macro_f1score: 0.2211 - val_loss2/classifier_accuracy: 0.4714 - val_loss2/classifier_top5_acc: 0.7897 - val_loss2/classifier_macro_f1score: 0.2558 - val_loss3/classifier_accuracy: 0.4883 - val_loss3/classifier_top5_acc: 0.8008 - val_loss3/classifier_macro_f1score: 0.2905\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 35/70\n","97/97 [==============================] - ETA: 0s - loss: 1.9638 - loss1/classifier_loss: 1.6932 - loss2/classifier_loss: 1.3661 - loss3/classifier_loss: 1.0459 - loss1/classifier_accuracy: 0.5229 - loss1/classifier_top5_acc: 0.8311 - loss1/classifier_macro_f1score: 0.2595 - loss2/classifier_accuracy: 0.5999 - loss2/classifier_top5_acc: 0.8755 - loss2/classifier_macro_f1score: 0.3433 - loss3/classifier_accuracy: 0.6872 - loss3/classifier_top5_acc: 0.9198 - loss3/classifier_macro_f1score: 0.4304\n","Epoch 00035: val_loss did not improve from 3.24258\n","\n","Epoch 00035: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 242s 2s/step - loss: 1.9638 - loss1/classifier_loss: 1.6932 - loss2/classifier_loss: 1.3661 - loss3/classifier_loss: 1.0459 - loss1/classifier_accuracy: 0.5229 - loss1/classifier_top5_acc: 0.8311 - loss1/classifier_macro_f1score: 0.2595 - loss2/classifier_accuracy: 0.5999 - loss2/classifier_top5_acc: 0.8755 - loss2/classifier_macro_f1score: 0.3433 - loss3/classifier_accuracy: 0.6872 - loss3/classifier_top5_acc: 0.9198 - loss3/classifier_macro_f1score: 0.4304 - val_loss: 3.3546 - val_loss1/classifier_loss: 2.0614 - val_loss2/classifier_loss: 2.0591 - val_loss3/classifier_loss: 2.1184 - val_loss1/classifier_accuracy: 0.4544 - val_loss1/classifier_top5_acc: 0.7702 - val_loss1/classifier_macro_f1score: 0.2106 - val_loss2/classifier_accuracy: 0.4642 - val_loss2/classifier_top5_acc: 0.7839 - val_loss2/classifier_macro_f1score: 0.2466 - val_loss3/classifier_accuracy: 0.4863 - val_loss3/classifier_top5_acc: 0.8001 - val_loss3/classifier_macro_f1score: 0.2757\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 36/70\n","97/97 [==============================] - ETA: 0s - loss: 1.9204 - loss1/classifier_loss: 1.6892 - loss2/classifier_loss: 1.3365 - loss3/classifier_loss: 1.0127 - loss1/classifier_accuracy: 0.5237 - loss1/classifier_top5_acc: 0.8327 - loss1/classifier_macro_f1score: 0.2505 - loss2/classifier_accuracy: 0.6088 - loss2/classifier_top5_acc: 0.8872 - loss2/classifier_macro_f1score: 0.3458 - loss3/classifier_accuracy: 0.6929 - loss3/classifier_top5_acc: 0.9269 - loss3/classifier_macro_f1score: 0.4341\n","Epoch 00036: val_loss did not improve from 3.24258\n","\n","Epoch 00036: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 239s 2s/step - loss: 1.9204 - loss1/classifier_loss: 1.6892 - loss2/classifier_loss: 1.3365 - loss3/classifier_loss: 1.0127 - loss1/classifier_accuracy: 0.5237 - loss1/classifier_top5_acc: 0.8327 - loss1/classifier_macro_f1score: 0.2505 - loss2/classifier_accuracy: 0.6088 - loss2/classifier_top5_acc: 0.8872 - loss2/classifier_macro_f1score: 0.3458 - loss3/classifier_accuracy: 0.6929 - loss3/classifier_top5_acc: 0.9269 - loss3/classifier_macro_f1score: 0.4341 - val_loss: 3.4098 - val_loss1/classifier_loss: 2.0762 - val_loss2/classifier_loss: 2.0653 - val_loss3/classifier_loss: 2.1674 - val_loss1/classifier_accuracy: 0.4473 - val_loss1/classifier_top5_acc: 0.7734 - val_loss1/classifier_macro_f1score: 0.2216 - val_loss2/classifier_accuracy: 0.4661 - val_loss2/classifier_top5_acc: 0.7943 - val_loss2/classifier_macro_f1score: 0.2675 - val_loss3/classifier_accuracy: 0.4837 - val_loss3/classifier_top5_acc: 0.7904 - val_loss3/classifier_macro_f1score: 0.2944\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 37/70\n","97/97 [==============================] - ETA: 0s - loss: 1.9005 - loss1/classifier_loss: 1.6667 - loss2/classifier_loss: 1.3277 - loss3/classifier_loss: 1.0021 - loss1/classifier_accuracy: 0.5285 - loss1/classifier_top5_acc: 0.8340 - loss1/classifier_macro_f1score: 0.2596 - loss2/classifier_accuracy: 0.6134 - loss2/classifier_top5_acc: 0.8842 - loss2/classifier_macro_f1score: 0.3533 - loss3/classifier_accuracy: 0.6987 - loss3/classifier_top5_acc: 0.9262 - loss3/classifier_macro_f1score: 0.4420\n","Epoch 00037: val_loss did not improve from 3.24258\n","\n","Epoch 00037: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 239s 2s/step - loss: 1.9005 - loss1/classifier_loss: 1.6667 - loss2/classifier_loss: 1.3277 - loss3/classifier_loss: 1.0021 - loss1/classifier_accuracy: 0.5285 - loss1/classifier_top5_acc: 0.8340 - loss1/classifier_macro_f1score: 0.2596 - loss2/classifier_accuracy: 0.6134 - loss2/classifier_top5_acc: 0.8842 - loss2/classifier_macro_f1score: 0.3533 - loss3/classifier_accuracy: 0.6987 - loss3/classifier_top5_acc: 0.9262 - loss3/classifier_macro_f1score: 0.4420 - val_loss: 3.3702 - val_loss1/classifier_loss: 2.0703 - val_loss2/classifier_loss: 2.0539 - val_loss3/classifier_loss: 2.1329 - val_loss1/classifier_accuracy: 0.4453 - val_loss1/classifier_top5_acc: 0.7715 - val_loss1/classifier_macro_f1score: 0.2075 - val_loss2/classifier_accuracy: 0.4681 - val_loss2/classifier_top5_acc: 0.7812 - val_loss2/classifier_macro_f1score: 0.2629 - val_loss3/classifier_accuracy: 0.4850 - val_loss3/classifier_top5_acc: 0.7917 - val_loss3/classifier_macro_f1score: 0.2893\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 38/70\n","97/97 [==============================] - ETA: 0s - loss: 1.8835 - loss1/classifier_loss: 1.6661 - loss2/classifier_loss: 1.3143 - loss3/classifier_loss: 0.9894 - loss1/classifier_accuracy: 0.5272 - loss1/classifier_top5_acc: 0.8351 - loss1/classifier_macro_f1score: 0.2626 - loss2/classifier_accuracy: 0.6158 - loss2/classifier_top5_acc: 0.8858 - loss2/classifier_macro_f1score: 0.3592 - loss3/classifier_accuracy: 0.6987 - loss3/classifier_top5_acc: 0.9272 - loss3/classifier_macro_f1score: 0.4518\n","Epoch 00038: val_loss did not improve from 3.24258\n","\n","Epoch 00038: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 238s 2s/step - loss: 1.8835 - loss1/classifier_loss: 1.6661 - loss2/classifier_loss: 1.3143 - loss3/classifier_loss: 0.9894 - loss1/classifier_accuracy: 0.5272 - loss1/classifier_top5_acc: 0.8351 - loss1/classifier_macro_f1score: 0.2626 - loss2/classifier_accuracy: 0.6158 - loss2/classifier_top5_acc: 0.8858 - loss2/classifier_macro_f1score: 0.3592 - loss3/classifier_accuracy: 0.6987 - loss3/classifier_top5_acc: 0.9272 - loss3/classifier_macro_f1score: 0.4518 - val_loss: 3.3380 - val_loss1/classifier_loss: 2.0448 - val_loss2/classifier_loss: 2.0274 - val_loss3/classifier_loss: 2.1163 - val_loss1/classifier_accuracy: 0.4544 - val_loss1/classifier_top5_acc: 0.7786 - val_loss1/classifier_macro_f1score: 0.2166 - val_loss2/classifier_accuracy: 0.4714 - val_loss2/classifier_top5_acc: 0.7904 - val_loss2/classifier_macro_f1score: 0.2622 - val_loss3/classifier_accuracy: 0.4889 - val_loss3/classifier_top5_acc: 0.7969 - val_loss3/classifier_macro_f1score: 0.2965\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 39/70\n","97/97 [==============================] - ETA: 0s - loss: 1.8460 - loss1/classifier_loss: 1.6509 - loss2/classifier_loss: 1.2874 - loss3/classifier_loss: 0.9645 - loss1/classifier_accuracy: 0.5370 - loss1/classifier_top5_acc: 0.8374 - loss1/classifier_macro_f1score: 0.2676 - loss2/classifier_accuracy: 0.6207 - loss2/classifier_top5_acc: 0.8887 - loss2/classifier_macro_f1score: 0.3688 - loss3/classifier_accuracy: 0.7079 - loss3/classifier_top5_acc: 0.9302 - loss3/classifier_macro_f1score: 0.4520\n","Epoch 00039: val_loss did not improve from 3.24258\n","\n","Epoch 00039: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 238s 2s/step - loss: 1.8460 - loss1/classifier_loss: 1.6509 - loss2/classifier_loss: 1.2874 - loss3/classifier_loss: 0.9645 - loss1/classifier_accuracy: 0.5370 - loss1/classifier_top5_acc: 0.8374 - loss1/classifier_macro_f1score: 0.2676 - loss2/classifier_accuracy: 0.6207 - loss2/classifier_top5_acc: 0.8887 - loss2/classifier_macro_f1score: 0.3688 - loss3/classifier_accuracy: 0.7079 - loss3/classifier_top5_acc: 0.9302 - loss3/classifier_macro_f1score: 0.4520 - val_loss: 3.4409 - val_loss1/classifier_loss: 2.0663 - val_loss2/classifier_loss: 2.0936 - val_loss3/classifier_loss: 2.1930 - val_loss1/classifier_accuracy: 0.4512 - val_loss1/classifier_top5_acc: 0.7754 - val_loss1/classifier_macro_f1score: 0.2141 - val_loss2/classifier_accuracy: 0.4635 - val_loss2/classifier_top5_acc: 0.7806 - val_loss2/classifier_macro_f1score: 0.2615 - val_loss3/classifier_accuracy: 0.4818 - val_loss3/classifier_top5_acc: 0.7936 - val_loss3/classifier_macro_f1score: 0.2804\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 40/70\n","97/97 [==============================] - ETA: 0s - loss: 1.8499 - loss1/classifier_loss: 1.6551 - loss2/classifier_loss: 1.3020 - loss3/classifier_loss: 0.9628 - loss1/classifier_accuracy: 0.5269 - loss1/classifier_top5_acc: 0.8395 - loss1/classifier_macro_f1score: 0.2637 - loss2/classifier_accuracy: 0.6213 - loss2/classifier_top5_acc: 0.8864 - loss2/classifier_macro_f1score: 0.3635 - loss3/classifier_accuracy: 0.7064 - loss3/classifier_top5_acc: 0.9307 - loss3/classifier_macro_f1score: 0.4574\n","Epoch 00040: val_loss did not improve from 3.24258\n","\n","Epoch 00040: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 238s 2s/step - loss: 1.8499 - loss1/classifier_loss: 1.6551 - loss2/classifier_loss: 1.3020 - loss3/classifier_loss: 0.9628 - loss1/classifier_accuracy: 0.5269 - loss1/classifier_top5_acc: 0.8395 - loss1/classifier_macro_f1score: 0.2637 - loss2/classifier_accuracy: 0.6213 - loss2/classifier_top5_acc: 0.8864 - loss2/classifier_macro_f1score: 0.3635 - loss3/classifier_accuracy: 0.7064 - loss3/classifier_top5_acc: 0.9307 - loss3/classifier_macro_f1score: 0.4574 - val_loss: 3.3876 - val_loss1/classifier_loss: 2.0650 - val_loss2/classifier_loss: 2.0493 - val_loss3/classifier_loss: 2.1533 - val_loss1/classifier_accuracy: 0.4453 - val_loss1/classifier_top5_acc: 0.7741 - val_loss1/classifier_macro_f1score: 0.2157 - val_loss2/classifier_accuracy: 0.4629 - val_loss2/classifier_top5_acc: 0.7871 - val_loss2/classifier_macro_f1score: 0.2616 - val_loss3/classifier_accuracy: 0.4850 - val_loss3/classifier_top5_acc: 0.7923 - val_loss3/classifier_macro_f1score: 0.2824\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 41/70\n","97/97 [==============================] - ETA: 0s - loss: 1.8239 - loss1/classifier_loss: 1.6444 - loss2/classifier_loss: 1.2893 - loss3/classifier_loss: 0.9438 - loss1/classifier_accuracy: 0.5283 - loss1/classifier_top5_acc: 0.8420 - loss1/classifier_macro_f1score: 0.2587 - loss2/classifier_accuracy: 0.6207 - loss2/classifier_top5_acc: 0.8887 - loss2/classifier_macro_f1score: 0.3605 - loss3/classifier_accuracy: 0.7173 - loss3/classifier_top5_acc: 0.9366 - loss3/classifier_macro_f1score: 0.4538\n","Epoch 00041: val_loss did not improve from 3.24258\n","\n","Epoch 00041: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 237s 2s/step - loss: 1.8239 - loss1/classifier_loss: 1.6444 - loss2/classifier_loss: 1.2893 - loss3/classifier_loss: 0.9438 - loss1/classifier_accuracy: 0.5283 - loss1/classifier_top5_acc: 0.8420 - loss1/classifier_macro_f1score: 0.2587 - loss2/classifier_accuracy: 0.6207 - loss2/classifier_top5_acc: 0.8887 - loss2/classifier_macro_f1score: 0.3605 - loss3/classifier_accuracy: 0.7173 - loss3/classifier_top5_acc: 0.9366 - loss3/classifier_macro_f1score: 0.4538 - val_loss: 3.3593 - val_loss1/classifier_loss: 2.0341 - val_loss2/classifier_loss: 2.0333 - val_loss3/classifier_loss: 2.1391 - val_loss1/classifier_accuracy: 0.4499 - val_loss1/classifier_top5_acc: 0.7767 - val_loss1/classifier_macro_f1score: 0.2237 - val_loss2/classifier_accuracy: 0.4753 - val_loss2/classifier_top5_acc: 0.7995 - val_loss2/classifier_macro_f1score: 0.2598 - val_loss3/classifier_accuracy: 0.4870 - val_loss3/classifier_top5_acc: 0.7969 - val_loss3/classifier_macro_f1score: 0.2869\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 42/70\n","97/97 [==============================] - ETA: 0s - loss: 1.7954 - loss1/classifier_loss: 1.6280 - loss2/classifier_loss: 1.2708 - loss3/classifier_loss: 0.9257 - loss1/classifier_accuracy: 0.5374 - loss1/classifier_top5_acc: 0.8467 - loss1/classifier_macro_f1score: 0.2698 - loss2/classifier_accuracy: 0.6246 - loss2/classifier_top5_acc: 0.8950 - loss2/classifier_macro_f1score: 0.3685 - loss3/classifier_accuracy: 0.7192 - loss3/classifier_top5_acc: 0.9379 - loss3/classifier_macro_f1score: 0.4669\n","Epoch 00042: val_loss did not improve from 3.24258\n","\n","Epoch 00042: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 237s 2s/step - loss: 1.7954 - loss1/classifier_loss: 1.6280 - loss2/classifier_loss: 1.2708 - loss3/classifier_loss: 0.9257 - loss1/classifier_accuracy: 0.5374 - loss1/classifier_top5_acc: 0.8467 - loss1/classifier_macro_f1score: 0.2698 - loss2/classifier_accuracy: 0.6246 - loss2/classifier_top5_acc: 0.8950 - loss2/classifier_macro_f1score: 0.3685 - loss3/classifier_accuracy: 0.7192 - loss3/classifier_top5_acc: 0.9379 - loss3/classifier_macro_f1score: 0.4669 - val_loss: 3.4342 - val_loss1/classifier_loss: 2.0623 - val_loss2/classifier_loss: 2.0859 - val_loss3/classifier_loss: 2.1898 - val_loss1/classifier_accuracy: 0.4518 - val_loss1/classifier_top5_acc: 0.7799 - val_loss1/classifier_macro_f1score: 0.2169 - val_loss2/classifier_accuracy: 0.4655 - val_loss2/classifier_top5_acc: 0.7812 - val_loss2/classifier_macro_f1score: 0.2583 - val_loss3/classifier_accuracy: 0.4850 - val_loss3/classifier_top5_acc: 0.7943 - val_loss3/classifier_macro_f1score: 0.2806\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 43/70\n","97/97 [==============================] - ETA: 0s - loss: 1.7864 - loss1/classifier_loss: 1.6282 - loss2/classifier_loss: 1.2635 - loss3/classifier_loss: 0.9189 - loss1/classifier_accuracy: 0.5365 - loss1/classifier_top5_acc: 0.8463 - loss1/classifier_macro_f1score: 0.2723 - loss2/classifier_accuracy: 0.6298 - loss2/classifier_top5_acc: 0.8937 - loss2/classifier_macro_f1score: 0.3751 - loss3/classifier_accuracy: 0.7197 - loss3/classifier_top5_acc: 0.9364 - loss3/classifier_macro_f1score: 0.4713\n","Epoch 00043: val_loss did not improve from 3.24258\n","\n","Epoch 00043: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 238s 2s/step - loss: 1.7864 - loss1/classifier_loss: 1.6282 - loss2/classifier_loss: 1.2635 - loss3/classifier_loss: 0.9189 - loss1/classifier_accuracy: 0.5365 - loss1/classifier_top5_acc: 0.8463 - loss1/classifier_macro_f1score: 0.2723 - loss2/classifier_accuracy: 0.6298 - loss2/classifier_top5_acc: 0.8937 - loss2/classifier_macro_f1score: 0.3751 - loss3/classifier_accuracy: 0.7197 - loss3/classifier_top5_acc: 0.9364 - loss3/classifier_macro_f1score: 0.4713 - val_loss: 3.4293 - val_loss1/classifier_loss: 2.0639 - val_loss2/classifier_loss: 2.0707 - val_loss3/classifier_loss: 2.1889 - val_loss1/classifier_accuracy: 0.4512 - val_loss1/classifier_top5_acc: 0.7754 - val_loss1/classifier_macro_f1score: 0.2170 - val_loss2/classifier_accuracy: 0.4701 - val_loss2/classifier_top5_acc: 0.7858 - val_loss2/classifier_macro_f1score: 0.2678 - val_loss3/classifier_accuracy: 0.4863 - val_loss3/classifier_top5_acc: 0.7878 - val_loss3/classifier_macro_f1score: 0.2962\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 44/70\n","97/97 [==============================] - ETA: 0s - loss: 1.7899 - loss1/classifier_loss: 1.6249 - loss2/classifier_loss: 1.2774 - loss3/classifier_loss: 0.9192 - loss1/classifier_accuracy: 0.5382 - loss1/classifier_top5_acc: 0.8436 - loss1/classifier_macro_f1score: 0.2729 - loss2/classifier_accuracy: 0.6287 - loss2/classifier_top5_acc: 0.8912 - loss2/classifier_macro_f1score: 0.3677 - loss3/classifier_accuracy: 0.7261 - loss3/classifier_top5_acc: 0.9367 - loss3/classifier_macro_f1score: 0.4733\n","Epoch 00044: val_loss did not improve from 3.24258\n","\n","Epoch 00044: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 238s 2s/step - loss: 1.7899 - loss1/classifier_loss: 1.6249 - loss2/classifier_loss: 1.2774 - loss3/classifier_loss: 0.9192 - loss1/classifier_accuracy: 0.5382 - loss1/classifier_top5_acc: 0.8436 - loss1/classifier_macro_f1score: 0.2729 - loss2/classifier_accuracy: 0.6287 - loss2/classifier_top5_acc: 0.8912 - loss2/classifier_macro_f1score: 0.3677 - loss3/classifier_accuracy: 0.7261 - loss3/classifier_top5_acc: 0.9367 - loss3/classifier_macro_f1score: 0.4733 - val_loss: 3.5563 - val_loss1/classifier_loss: 2.0916 - val_loss2/classifier_loss: 2.1511 - val_loss3/classifier_loss: 2.2835 - val_loss1/classifier_accuracy: 0.4486 - val_loss1/classifier_top5_acc: 0.7669 - val_loss1/classifier_macro_f1score: 0.2100 - val_loss2/classifier_accuracy: 0.4577 - val_loss2/classifier_top5_acc: 0.7708 - val_loss2/classifier_macro_f1score: 0.2492 - val_loss3/classifier_accuracy: 0.4688 - val_loss3/classifier_top5_acc: 0.7669 - val_loss3/classifier_macro_f1score: 0.2801\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 45/70\n","97/97 [==============================] - ETA: 0s - loss: 1.7571 - loss1/classifier_loss: 1.6286 - loss2/classifier_loss: 1.2473 - loss3/classifier_loss: 0.8944 - loss1/classifier_accuracy: 0.5345 - loss1/classifier_top5_acc: 0.8473 - loss1/classifier_macro_f1score: 0.2683 - loss2/classifier_accuracy: 0.6298 - loss2/classifier_top5_acc: 0.8954 - loss2/classifier_macro_f1score: 0.3706 - loss3/classifier_accuracy: 0.7294 - loss3/classifier_top5_acc: 0.9419 - loss3/classifier_macro_f1score: 0.4686\n","Epoch 00045: val_loss did not improve from 3.24258\n","\n","Epoch 00045: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 237s 2s/step - loss: 1.7571 - loss1/classifier_loss: 1.6286 - loss2/classifier_loss: 1.2473 - loss3/classifier_loss: 0.8944 - loss1/classifier_accuracy: 0.5345 - loss1/classifier_top5_acc: 0.8473 - loss1/classifier_macro_f1score: 0.2683 - loss2/classifier_accuracy: 0.6298 - loss2/classifier_top5_acc: 0.8954 - loss2/classifier_macro_f1score: 0.3706 - loss3/classifier_accuracy: 0.7294 - loss3/classifier_top5_acc: 0.9419 - loss3/classifier_macro_f1score: 0.4686 - val_loss: 3.3608 - val_loss1/classifier_loss: 2.0032 - val_loss2/classifier_loss: 2.0249 - val_loss3/classifier_loss: 2.1524 - val_loss1/classifier_accuracy: 0.4583 - val_loss1/classifier_top5_acc: 0.7858 - val_loss1/classifier_macro_f1score: 0.2233 - val_loss2/classifier_accuracy: 0.4746 - val_loss2/classifier_top5_acc: 0.7975 - val_loss2/classifier_macro_f1score: 0.2677 - val_loss3/classifier_accuracy: 0.4876 - val_loss3/classifier_top5_acc: 0.7943 - val_loss3/classifier_macro_f1score: 0.2988\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 46/70\n","97/97 [==============================] - ETA: 0s - loss: 1.7507 - loss1/classifier_loss: 1.6154 - loss2/classifier_loss: 1.2545 - loss3/classifier_loss: 0.8897 - loss1/classifier_accuracy: 0.5400 - loss1/classifier_top5_acc: 0.8431 - loss1/classifier_macro_f1score: 0.2752 - loss2/classifier_accuracy: 0.6240 - loss2/classifier_top5_acc: 0.8936 - loss2/classifier_macro_f1score: 0.3718 - loss3/classifier_accuracy: 0.7299 - loss3/classifier_top5_acc: 0.9392 - loss3/classifier_macro_f1score: 0.4820\n","Epoch 00046: val_loss did not improve from 3.24258\n","\n","Epoch 00046: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 239s 2s/step - loss: 1.7507 - loss1/classifier_loss: 1.6154 - loss2/classifier_loss: 1.2545 - loss3/classifier_loss: 0.8897 - loss1/classifier_accuracy: 0.5400 - loss1/classifier_top5_acc: 0.8431 - loss1/classifier_macro_f1score: 0.2752 - loss2/classifier_accuracy: 0.6240 - loss2/classifier_top5_acc: 0.8936 - loss2/classifier_macro_f1score: 0.3718 - loss3/classifier_accuracy: 0.7299 - loss3/classifier_top5_acc: 0.9392 - loss3/classifier_macro_f1score: 0.4820 - val_loss: 3.4818 - val_loss1/classifier_loss: 2.0741 - val_loss2/classifier_loss: 2.1068 - val_loss3/classifier_loss: 2.2276 - val_loss1/classifier_accuracy: 0.4499 - val_loss1/classifier_top5_acc: 0.7812 - val_loss1/classifier_macro_f1score: 0.2123 - val_loss2/classifier_accuracy: 0.4635 - val_loss2/classifier_top5_acc: 0.7865 - val_loss2/classifier_macro_f1score: 0.2569 - val_loss3/classifier_accuracy: 0.4896 - val_loss3/classifier_top5_acc: 0.7819 - val_loss3/classifier_macro_f1score: 0.2834\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 47/70\n","97/97 [==============================] - ETA: 0s - loss: 1.7549 - loss1/classifier_loss: 1.6160 - loss2/classifier_loss: 1.2471 - loss3/classifier_loss: 0.8960 - loss1/classifier_accuracy: 0.5416 - loss1/classifier_top5_acc: 0.8449 - loss1/classifier_macro_f1score: 0.2702 - loss2/classifier_accuracy: 0.6332 - loss2/classifier_top5_acc: 0.8969 - loss2/classifier_macro_f1score: 0.3706 - loss3/classifier_accuracy: 0.7254 - loss3/classifier_top5_acc: 0.9399 - loss3/classifier_macro_f1score: 0.4714\n","Epoch 00047: val_loss did not improve from 3.24258\n","\n","Epoch 00047: val_loss3/classifier_accuracy did not improve from 0.49219\n","97/97 [==============================] - 238s 2s/step - loss: 1.7549 - loss1/classifier_loss: 1.6160 - loss2/classifier_loss: 1.2471 - loss3/classifier_loss: 0.8960 - loss1/classifier_accuracy: 0.5416 - loss1/classifier_top5_acc: 0.8449 - loss1/classifier_macro_f1score: 0.2702 - loss2/classifier_accuracy: 0.6332 - loss2/classifier_top5_acc: 0.8969 - loss2/classifier_macro_f1score: 0.3706 - loss3/classifier_accuracy: 0.7254 - loss3/classifier_top5_acc: 0.9399 - loss3/classifier_macro_f1score: 0.4714 - val_loss: 3.3722 - val_loss1/classifier_loss: 2.0678 - val_loss2/classifier_loss: 2.0468 - val_loss3/classifier_loss: 2.1378 - val_loss1/classifier_accuracy: 0.4486 - val_loss1/classifier_top5_acc: 0.7773 - val_loss1/classifier_macro_f1score: 0.2116 - val_loss2/classifier_accuracy: 0.4746 - val_loss2/classifier_top5_acc: 0.7936 - val_loss2/classifier_macro_f1score: 0.2675 - val_loss3/classifier_accuracy: 0.4870 - val_loss3/classifier_top5_acc: 0.7943 - val_loss3/classifier_macro_f1score: 0.2884\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 48/70\n","97/97 [==============================] - ETA: 0s - loss: 1.6980 - loss1/classifier_loss: 1.5978 - loss2/classifier_loss: 1.2197 - loss3/classifier_loss: 0.8528 - loss1/classifier_accuracy: 0.5401 - loss1/classifier_top5_acc: 0.8493 - loss1/classifier_macro_f1score: 0.2821 - loss2/classifier_accuracy: 0.6441 - loss2/classifier_top5_acc: 0.9001 - loss2/classifier_macro_f1score: 0.3838 - loss3/classifier_accuracy: 0.7391 - loss3/classifier_top5_acc: 0.9448 - loss3/classifier_macro_f1score: 0.4903\n","Epoch 00048: val_loss did not improve from 3.24258\n","\n","Epoch 00048: val_loss3/classifier_accuracy improved from 0.49219 to 0.49609, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/048.h5\n","97/97 [==============================] - 238s 2s/step - loss: 1.6980 - loss1/classifier_loss: 1.5978 - loss2/classifier_loss: 1.2197 - loss3/classifier_loss: 0.8528 - loss1/classifier_accuracy: 0.5401 - loss1/classifier_top5_acc: 0.8493 - loss1/classifier_macro_f1score: 0.2821 - loss2/classifier_accuracy: 0.6441 - loss2/classifier_top5_acc: 0.9001 - loss2/classifier_macro_f1score: 0.3838 - loss3/classifier_accuracy: 0.7391 - loss3/classifier_top5_acc: 0.9448 - loss3/classifier_macro_f1score: 0.4903 - val_loss: 3.3875 - val_loss1/classifier_loss: 2.0358 - val_loss2/classifier_loss: 2.0302 - val_loss3/classifier_loss: 2.1677 - val_loss1/classifier_accuracy: 0.4544 - val_loss1/classifier_top5_acc: 0.7865 - val_loss1/classifier_macro_f1score: 0.2196 - val_loss2/classifier_accuracy: 0.4824 - val_loss2/classifier_top5_acc: 0.7956 - val_loss2/classifier_macro_f1score: 0.2708 - val_loss3/classifier_accuracy: 0.4961 - val_loss3/classifier_top5_acc: 0.7930 - val_loss3/classifier_macro_f1score: 0.2954\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 49/70\n","97/97 [==============================] - ETA: 0s - loss: 1.6889 - loss1/classifier_loss: 1.5912 - loss2/classifier_loss: 1.2060 - loss3/classifier_loss: 0.8498 - loss1/classifier_accuracy: 0.5473 - loss1/classifier_top5_acc: 0.8506 - loss1/classifier_macro_f1score: 0.2768 - loss2/classifier_accuracy: 0.6465 - loss2/classifier_top5_acc: 0.9026 - loss2/classifier_macro_f1score: 0.3850 - loss3/classifier_accuracy: 0.7414 - loss3/classifier_top5_acc: 0.9442 - loss3/classifier_macro_f1score: 0.4861\n","Epoch 00049: val_loss did not improve from 3.24258\n","\n","Epoch 00049: val_loss3/classifier_accuracy did not improve from 0.49609\n","97/97 [==============================] - 239s 2s/step - loss: 1.6889 - loss1/classifier_loss: 1.5912 - loss2/classifier_loss: 1.2060 - loss3/classifier_loss: 0.8498 - loss1/classifier_accuracy: 0.5473 - loss1/classifier_top5_acc: 0.8506 - loss1/classifier_macro_f1score: 0.2768 - loss2/classifier_accuracy: 0.6465 - loss2/classifier_top5_acc: 0.9026 - loss2/classifier_macro_f1score: 0.3850 - loss3/classifier_accuracy: 0.7414 - loss3/classifier_top5_acc: 0.9442 - loss3/classifier_macro_f1score: 0.4861 - val_loss: 3.4783 - val_loss1/classifier_loss: 2.0308 - val_loss2/classifier_loss: 2.0887 - val_loss3/classifier_loss: 2.2425 - val_loss1/classifier_accuracy: 0.4577 - val_loss1/classifier_top5_acc: 0.7891 - val_loss1/classifier_macro_f1score: 0.2330 - val_loss2/classifier_accuracy: 0.4668 - val_loss2/classifier_top5_acc: 0.7904 - val_loss2/classifier_macro_f1score: 0.2763 - val_loss3/classifier_accuracy: 0.4870 - val_loss3/classifier_top5_acc: 0.7930 - val_loss3/classifier_macro_f1score: 0.3067\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 50/70\n","97/97 [==============================] - ETA: 0s - loss: 1.6696 - loss1/classifier_loss: 1.5895 - loss2/classifier_loss: 1.2008 - loss3/classifier_loss: 0.8325 - loss1/classifier_accuracy: 0.5433 - loss1/classifier_top5_acc: 0.8535 - loss1/classifier_macro_f1score: 0.2792 - loss2/classifier_accuracy: 0.6461 - loss2/classifier_top5_acc: 0.9049 - loss2/classifier_macro_f1score: 0.3788 - loss3/classifier_accuracy: 0.7488 - loss3/classifier_top5_acc: 0.9483 - loss3/classifier_macro_f1score: 0.4848\n","Epoch 00050: val_loss did not improve from 3.24258\n","\n","Epoch 00050: val_loss3/classifier_accuracy did not improve from 0.49609\n","97/97 [==============================] - 238s 2s/step - loss: 1.6696 - loss1/classifier_loss: 1.5895 - loss2/classifier_loss: 1.2008 - loss3/classifier_loss: 0.8325 - loss1/classifier_accuracy: 0.5433 - loss1/classifier_top5_acc: 0.8535 - loss1/classifier_macro_f1score: 0.2792 - loss2/classifier_accuracy: 0.6461 - loss2/classifier_top5_acc: 0.9049 - loss2/classifier_macro_f1score: 0.3788 - loss3/classifier_accuracy: 0.7488 - loss3/classifier_top5_acc: 0.9483 - loss3/classifier_macro_f1score: 0.4848 - val_loss: 3.5426 - val_loss1/classifier_loss: 2.0501 - val_loss2/classifier_loss: 2.1170 - val_loss3/classifier_loss: 2.2925 - val_loss1/classifier_accuracy: 0.4531 - val_loss1/classifier_top5_acc: 0.7780 - val_loss1/classifier_macro_f1score: 0.2267 - val_loss2/classifier_accuracy: 0.4622 - val_loss2/classifier_top5_acc: 0.7845 - val_loss2/classifier_macro_f1score: 0.2737 - val_loss3/classifier_accuracy: 0.4870 - val_loss3/classifier_top5_acc: 0.7878 - val_loss3/classifier_macro_f1score: 0.2979\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 51/70\n","97/97 [==============================] - ETA: 0s - loss: 1.6981 - loss1/classifier_loss: 1.6120 - loss2/classifier_loss: 1.2059 - loss3/classifier_loss: 0.8528 - loss1/classifier_accuracy: 0.5430 - loss1/classifier_top5_acc: 0.8465 - loss1/classifier_macro_f1score: 0.2759 - loss2/classifier_accuracy: 0.6439 - loss2/classifier_top5_acc: 0.9019 - loss2/classifier_macro_f1score: 0.3853 - loss3/classifier_accuracy: 0.7377 - loss3/classifier_top5_acc: 0.9423 - loss3/classifier_macro_f1score: 0.4887\n","Epoch 00051: val_loss did not improve from 3.24258\n","\n","Epoch 00051: val_loss3/classifier_accuracy did not improve from 0.49609\n","97/97 [==============================] - 238s 2s/step - loss: 1.6981 - loss1/classifier_loss: 1.6120 - loss2/classifier_loss: 1.2059 - loss3/classifier_loss: 0.8528 - loss1/classifier_accuracy: 0.5430 - loss1/classifier_top5_acc: 0.8465 - loss1/classifier_macro_f1score: 0.2759 - loss2/classifier_accuracy: 0.6439 - loss2/classifier_top5_acc: 0.9019 - loss2/classifier_macro_f1score: 0.3853 - loss3/classifier_accuracy: 0.7377 - loss3/classifier_top5_acc: 0.9423 - loss3/classifier_macro_f1score: 0.4887 - val_loss: 3.5272 - val_loss1/classifier_loss: 2.0400 - val_loss2/classifier_loss: 2.1081 - val_loss3/classifier_loss: 2.2828 - val_loss1/classifier_accuracy: 0.4590 - val_loss1/classifier_top5_acc: 0.7839 - val_loss1/classifier_macro_f1score: 0.2239 - val_loss2/classifier_accuracy: 0.4622 - val_loss2/classifier_top5_acc: 0.7904 - val_loss2/classifier_macro_f1score: 0.2675 - val_loss3/classifier_accuracy: 0.4876 - val_loss3/classifier_top5_acc: 0.7943 - val_loss3/classifier_macro_f1score: 0.2957\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 52/70\n","97/97 [==============================] - ETA: 0s - loss: 1.6489 - loss1/classifier_loss: 1.5900 - loss2/classifier_loss: 1.1924 - loss3/classifier_loss: 0.8142 - loss1/classifier_accuracy: 0.5429 - loss1/classifier_top5_acc: 0.8543 - loss1/classifier_macro_f1score: 0.2788 - loss2/classifier_accuracy: 0.6464 - loss2/classifier_top5_acc: 0.9070 - loss2/classifier_macro_f1score: 0.3861 - loss3/classifier_accuracy: 0.7517 - loss3/classifier_top5_acc: 0.9479 - loss3/classifier_macro_f1score: 0.5043\n","Epoch 00052: val_loss did not improve from 3.24258\n","\n","Epoch 00052: val_loss3/classifier_accuracy did not improve from 0.49609\n","97/97 [==============================] - 237s 2s/step - loss: 1.6489 - loss1/classifier_loss: 1.5900 - loss2/classifier_loss: 1.1924 - loss3/classifier_loss: 0.8142 - loss1/classifier_accuracy: 0.5429 - loss1/classifier_top5_acc: 0.8543 - loss1/classifier_macro_f1score: 0.2788 - loss2/classifier_accuracy: 0.6464 - loss2/classifier_top5_acc: 0.9070 - loss2/classifier_macro_f1score: 0.3861 - loss3/classifier_accuracy: 0.7517 - loss3/classifier_top5_acc: 0.9479 - loss3/classifier_macro_f1score: 0.5043 - val_loss: 3.5889 - val_loss1/classifier_loss: 2.0583 - val_loss2/classifier_loss: 2.1365 - val_loss3/classifier_loss: 2.3305 - val_loss1/classifier_accuracy: 0.4583 - val_loss1/classifier_top5_acc: 0.7760 - val_loss1/classifier_macro_f1score: 0.2210 - val_loss2/classifier_accuracy: 0.4714 - val_loss2/classifier_top5_acc: 0.7858 - val_loss2/classifier_macro_f1score: 0.2744 - val_loss3/classifier_accuracy: 0.4811 - val_loss3/classifier_top5_acc: 0.7897 - val_loss3/classifier_macro_f1score: 0.3002\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 53/70\n","97/97 [==============================] - ETA: 0s - loss: 1.6313 - loss1/classifier_loss: 1.5798 - loss2/classifier_loss: 1.1776 - loss3/classifier_loss: 0.8041 - loss1/classifier_accuracy: 0.5466 - loss1/classifier_top5_acc: 0.8517 - loss1/classifier_macro_f1score: 0.2809 - loss2/classifier_accuracy: 0.6550 - loss2/classifier_top5_acc: 0.9063 - loss2/classifier_macro_f1score: 0.3953 - loss3/classifier_accuracy: 0.7524 - loss3/classifier_top5_acc: 0.9505 - loss3/classifier_macro_f1score: 0.4973\n","Epoch 00053: val_loss did not improve from 3.24258\n","\n","Epoch 00053: val_loss3/classifier_accuracy did not improve from 0.49609\n","97/97 [==============================] - 237s 2s/step - loss: 1.6313 - loss1/classifier_loss: 1.5798 - loss2/classifier_loss: 1.1776 - loss3/classifier_loss: 0.8041 - loss1/classifier_accuracy: 0.5466 - loss1/classifier_top5_acc: 0.8517 - loss1/classifier_macro_f1score: 0.2809 - loss2/classifier_accuracy: 0.6550 - loss2/classifier_top5_acc: 0.9063 - loss2/classifier_macro_f1score: 0.3953 - loss3/classifier_accuracy: 0.7524 - loss3/classifier_top5_acc: 0.9505 - loss3/classifier_macro_f1score: 0.4973 - val_loss: 3.6765 - val_loss1/classifier_loss: 2.1082 - val_loss2/classifier_loss: 2.1998 - val_loss3/classifier_loss: 2.3841 - val_loss1/classifier_accuracy: 0.4505 - val_loss1/classifier_top5_acc: 0.7721 - val_loss1/classifier_macro_f1score: 0.2195 - val_loss2/classifier_accuracy: 0.4603 - val_loss2/classifier_top5_acc: 0.7780 - val_loss2/classifier_macro_f1score: 0.2642 - val_loss3/classifier_accuracy: 0.4779 - val_loss3/classifier_top5_acc: 0.7845 - val_loss3/classifier_macro_f1score: 0.2856\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00054: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 54/70\n","97/97 [==============================] - ETA: 0s - loss: 1.6423 - loss1/classifier_loss: 1.5841 - loss2/classifier_loss: 1.1795 - loss3/classifier_loss: 0.8132 - loss1/classifier_accuracy: 0.5450 - loss1/classifier_top5_acc: 0.8490 - loss1/classifier_macro_f1score: 0.2798 - loss2/classifier_accuracy: 0.6493 - loss2/classifier_top5_acc: 0.9064 - loss2/classifier_macro_f1score: 0.3875 - loss3/classifier_accuracy: 0.7480 - loss3/classifier_top5_acc: 0.9486 - loss3/classifier_macro_f1score: 0.4914\n","Epoch 00054: val_loss did not improve from 3.24258\n","\n","Epoch 00054: val_loss3/classifier_accuracy did not improve from 0.49609\n","97/97 [==============================] - 236s 2s/step - loss: 1.6423 - loss1/classifier_loss: 1.5841 - loss2/classifier_loss: 1.1795 - loss3/classifier_loss: 0.8132 - loss1/classifier_accuracy: 0.5450 - loss1/classifier_top5_acc: 0.8490 - loss1/classifier_macro_f1score: 0.2798 - loss2/classifier_accuracy: 0.6493 - loss2/classifier_top5_acc: 0.9064 - loss2/classifier_macro_f1score: 0.3875 - loss3/classifier_accuracy: 0.7480 - loss3/classifier_top5_acc: 0.9486 - loss3/classifier_macro_f1score: 0.4914 - val_loss: 3.4112 - val_loss1/classifier_loss: 2.0029 - val_loss2/classifier_loss: 2.0469 - val_loss3/classifier_loss: 2.1962 - val_loss1/classifier_accuracy: 0.4557 - val_loss1/classifier_top5_acc: 0.7845 - val_loss1/classifier_macro_f1score: 0.2282 - val_loss2/classifier_accuracy: 0.4740 - val_loss2/classifier_top5_acc: 0.7995 - val_loss2/classifier_macro_f1score: 0.2681 - val_loss3/classifier_accuracy: 0.4922 - val_loss3/classifier_top5_acc: 0.8014 - val_loss3/classifier_macro_f1score: 0.2899\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00055: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 55/70\n","97/97 [==============================] - ETA: 0s - loss: 1.6099 - loss1/classifier_loss: 1.5742 - loss2/classifier_loss: 1.1552 - loss3/classifier_loss: 0.7910 - loss1/classifier_accuracy: 0.5470 - loss1/classifier_top5_acc: 0.8561 - loss1/classifier_macro_f1score: 0.2830 - loss2/classifier_accuracy: 0.6576 - loss2/classifier_top5_acc: 0.9122 - loss2/classifier_macro_f1score: 0.4002 - loss3/classifier_accuracy: 0.7595 - loss3/classifier_top5_acc: 0.9533 - loss3/classifier_macro_f1score: 0.5069\n","Epoch 00055: val_loss did not improve from 3.24258\n","\n","Epoch 00055: val_loss3/classifier_accuracy did not improve from 0.49609\n","97/97 [==============================] - 238s 2s/step - loss: 1.6099 - loss1/classifier_loss: 1.5742 - loss2/classifier_loss: 1.1552 - loss3/classifier_loss: 0.7910 - loss1/classifier_accuracy: 0.5470 - loss1/classifier_top5_acc: 0.8561 - loss1/classifier_macro_f1score: 0.2830 - loss2/classifier_accuracy: 0.6576 - loss2/classifier_top5_acc: 0.9122 - loss2/classifier_macro_f1score: 0.4002 - loss3/classifier_accuracy: 0.7595 - loss3/classifier_top5_acc: 0.9533 - loss3/classifier_macro_f1score: 0.5069 - val_loss: 3.5261 - val_loss1/classifier_loss: 2.0396 - val_loss2/classifier_loss: 2.1133 - val_loss3/classifier_loss: 2.2802 - val_loss1/classifier_accuracy: 0.4499 - val_loss1/classifier_top5_acc: 0.7806 - val_loss1/classifier_macro_f1score: 0.2328 - val_loss2/classifier_accuracy: 0.4688 - val_loss2/classifier_top5_acc: 0.7858 - val_loss2/classifier_macro_f1score: 0.2824 - val_loss3/classifier_accuracy: 0.4896 - val_loss3/classifier_top5_acc: 0.7904 - val_loss3/classifier_macro_f1score: 0.3078\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00056: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 56/70\n","97/97 [==============================] - ETA: 0s - loss: 1.5928 - loss1/classifier_loss: 1.5704 - loss2/classifier_loss: 1.1576 - loss3/classifier_loss: 0.7744 - loss1/classifier_accuracy: 0.5494 - loss1/classifier_top5_acc: 0.8535 - loss1/classifier_macro_f1score: 0.2866 - loss2/classifier_accuracy: 0.6580 - loss2/classifier_top5_acc: 0.9074 - loss2/classifier_macro_f1score: 0.3985 - loss3/classifier_accuracy: 0.7567 - loss3/classifier_top5_acc: 0.9532 - loss3/classifier_macro_f1score: 0.5082\n","Epoch 00056: val_loss did not improve from 3.24258\n","\n","Epoch 00056: val_loss3/classifier_accuracy improved from 0.49609 to 0.50000, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/056.h5\n","97/97 [==============================] - 238s 2s/step - loss: 1.5928 - loss1/classifier_loss: 1.5704 - loss2/classifier_loss: 1.1576 - loss3/classifier_loss: 0.7744 - loss1/classifier_accuracy: 0.5494 - loss1/classifier_top5_acc: 0.8535 - loss1/classifier_macro_f1score: 0.2866 - loss2/classifier_accuracy: 0.6580 - loss2/classifier_top5_acc: 0.9074 - loss2/classifier_macro_f1score: 0.3985 - loss3/classifier_accuracy: 0.7567 - loss3/classifier_top5_acc: 0.9532 - loss3/classifier_macro_f1score: 0.5082 - val_loss: 3.4751 - val_loss1/classifier_loss: 2.0148 - val_loss2/classifier_loss: 2.0773 - val_loss3/classifier_loss: 2.2475 - val_loss1/classifier_accuracy: 0.4629 - val_loss1/classifier_top5_acc: 0.7871 - val_loss1/classifier_macro_f1score: 0.2348 - val_loss2/classifier_accuracy: 0.4733 - val_loss2/classifier_top5_acc: 0.7988 - val_loss2/classifier_macro_f1score: 0.2893 - val_loss3/classifier_accuracy: 0.5000 - val_loss3/classifier_top5_acc: 0.7923 - val_loss3/classifier_macro_f1score: 0.3126\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00057: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 57/70\n","97/97 [==============================] - ETA: 0s - loss: 1.5822 - loss1/classifier_loss: 1.5638 - loss2/classifier_loss: 1.1467 - loss3/classifier_loss: 0.7691 - loss1/classifier_accuracy: 0.5503 - loss1/classifier_top5_acc: 0.8567 - loss1/classifier_macro_f1score: 0.2753 - loss2/classifier_accuracy: 0.6590 - loss2/classifier_top5_acc: 0.9119 - loss2/classifier_macro_f1score: 0.3957 - loss3/classifier_accuracy: 0.7647 - loss3/classifier_top5_acc: 0.9541 - loss3/classifier_macro_f1score: 0.5052\n","Epoch 00057: val_loss did not improve from 3.24258\n","\n","Epoch 00057: val_loss3/classifier_accuracy improved from 0.50000 to 0.50130, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/GoogleNet/057.h5\n","97/97 [==============================] - 238s 2s/step - loss: 1.5822 - loss1/classifier_loss: 1.5638 - loss2/classifier_loss: 1.1467 - loss3/classifier_loss: 0.7691 - loss1/classifier_accuracy: 0.5503 - loss1/classifier_top5_acc: 0.8567 - loss1/classifier_macro_f1score: 0.2753 - loss2/classifier_accuracy: 0.6590 - loss2/classifier_top5_acc: 0.9119 - loss2/classifier_macro_f1score: 0.3957 - loss3/classifier_accuracy: 0.7647 - loss3/classifier_top5_acc: 0.9541 - loss3/classifier_macro_f1score: 0.5052 - val_loss: 3.5176 - val_loss1/classifier_loss: 2.0242 - val_loss2/classifier_loss: 2.0714 - val_loss3/classifier_loss: 2.2889 - val_loss1/classifier_accuracy: 0.4583 - val_loss1/classifier_top5_acc: 0.7871 - val_loss1/classifier_macro_f1score: 0.2307 - val_loss2/classifier_accuracy: 0.4720 - val_loss2/classifier_top5_acc: 0.7956 - val_loss2/classifier_macro_f1score: 0.2775 - val_loss3/classifier_accuracy: 0.5013 - val_loss3/classifier_top5_acc: 0.8047 - val_loss3/classifier_macro_f1score: 0.2929\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00058: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 58/70\n","97/97 [==============================] - ETA: 0s - loss: 1.5736 - loss1/classifier_loss: 1.5716 - loss2/classifier_loss: 1.1443 - loss3/classifier_loss: 0.7588 - loss1/classifier_accuracy: 0.5502 - loss1/classifier_top5_acc: 0.8552 - loss1/classifier_macro_f1score: 0.2886 - loss2/classifier_accuracy: 0.6625 - loss2/classifier_top5_acc: 0.9093 - loss2/classifier_macro_f1score: 0.4065 - loss3/classifier_accuracy: 0.7658 - loss3/classifier_top5_acc: 0.9546 - loss3/classifier_macro_f1score: 0.5136\n","Epoch 00058: val_loss did not improve from 3.24258\n","\n","Epoch 00058: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 238s 2s/step - loss: 1.5736 - loss1/classifier_loss: 1.5716 - loss2/classifier_loss: 1.1443 - loss3/classifier_loss: 0.7588 - loss1/classifier_accuracy: 0.5502 - loss1/classifier_top5_acc: 0.8552 - loss1/classifier_macro_f1score: 0.2886 - loss2/classifier_accuracy: 0.6625 - loss2/classifier_top5_acc: 0.9093 - loss2/classifier_macro_f1score: 0.4065 - loss3/classifier_accuracy: 0.7658 - loss3/classifier_top5_acc: 0.9546 - loss3/classifier_macro_f1score: 0.5136 - val_loss: 3.6418 - val_loss1/classifier_loss: 2.0622 - val_loss2/classifier_loss: 2.1464 - val_loss3/classifier_loss: 2.3792 - val_loss1/classifier_accuracy: 0.4538 - val_loss1/classifier_top5_acc: 0.7799 - val_loss1/classifier_macro_f1score: 0.2309 - val_loss2/classifier_accuracy: 0.4655 - val_loss2/classifier_top5_acc: 0.7884 - val_loss2/classifier_macro_f1score: 0.2803 - val_loss3/classifier_accuracy: 0.4844 - val_loss3/classifier_top5_acc: 0.7852 - val_loss3/classifier_macro_f1score: 0.3059\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00059: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 59/70\n","97/97 [==============================] - ETA: 0s - loss: 1.5671 - loss1/classifier_loss: 1.5689 - loss2/classifier_loss: 1.1346 - loss3/classifier_loss: 0.7561 - loss1/classifier_accuracy: 0.5512 - loss1/classifier_top5_acc: 0.8543 - loss1/classifier_macro_f1score: 0.2793 - loss2/classifier_accuracy: 0.6674 - loss2/classifier_top5_acc: 0.9107 - loss2/classifier_macro_f1score: 0.4005 - loss3/classifier_accuracy: 0.7650 - loss3/classifier_top5_acc: 0.9545 - loss3/classifier_macro_f1score: 0.5107\n","Epoch 00059: val_loss did not improve from 3.24258\n","\n","Epoch 00059: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 238s 2s/step - loss: 1.5671 - loss1/classifier_loss: 1.5689 - loss2/classifier_loss: 1.1346 - loss3/classifier_loss: 0.7561 - loss1/classifier_accuracy: 0.5512 - loss1/classifier_top5_acc: 0.8543 - loss1/classifier_macro_f1score: 0.2793 - loss2/classifier_accuracy: 0.6674 - loss2/classifier_top5_acc: 0.9107 - loss2/classifier_macro_f1score: 0.4005 - loss3/classifier_accuracy: 0.7650 - loss3/classifier_top5_acc: 0.9545 - loss3/classifier_macro_f1score: 0.5107 - val_loss: 3.4671 - val_loss1/classifier_loss: 2.0088 - val_loss2/classifier_loss: 2.0649 - val_loss3/classifier_loss: 2.2450 - val_loss1/classifier_accuracy: 0.4557 - val_loss1/classifier_top5_acc: 0.7891 - val_loss1/classifier_macro_f1score: 0.2288 - val_loss2/classifier_accuracy: 0.4844 - val_loss2/classifier_top5_acc: 0.7897 - val_loss2/classifier_macro_f1score: 0.2777 - val_loss3/classifier_accuracy: 0.4974 - val_loss3/classifier_top5_acc: 0.7949 - val_loss3/classifier_macro_f1score: 0.3072\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00060: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 60/70\n","97/97 [==============================] - ETA: 0s - loss: 1.5345 - loss1/classifier_loss: 1.5525 - loss2/classifier_loss: 1.1260 - loss3/classifier_loss: 0.7309 - loss1/classifier_accuracy: 0.5518 - loss1/classifier_top5_acc: 0.8571 - loss1/classifier_macro_f1score: 0.2866 - loss2/classifier_accuracy: 0.6675 - loss2/classifier_top5_acc: 0.9130 - loss2/classifier_macro_f1score: 0.4049 - loss3/classifier_accuracy: 0.7746 - loss3/classifier_top5_acc: 0.9589 - loss3/classifier_macro_f1score: 0.5163\n","Epoch 00060: val_loss did not improve from 3.24258\n","\n","Epoch 00060: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 237s 2s/step - loss: 1.5345 - loss1/classifier_loss: 1.5525 - loss2/classifier_loss: 1.1260 - loss3/classifier_loss: 0.7309 - loss1/classifier_accuracy: 0.5518 - loss1/classifier_top5_acc: 0.8571 - loss1/classifier_macro_f1score: 0.2866 - loss2/classifier_accuracy: 0.6675 - loss2/classifier_top5_acc: 0.9130 - loss2/classifier_macro_f1score: 0.4049 - loss3/classifier_accuracy: 0.7746 - loss3/classifier_top5_acc: 0.9589 - loss3/classifier_macro_f1score: 0.5163 - val_loss: 3.6690 - val_loss1/classifier_loss: 2.0497 - val_loss2/classifier_loss: 2.1695 - val_loss3/classifier_loss: 2.4032 - val_loss1/classifier_accuracy: 0.4609 - val_loss1/classifier_top5_acc: 0.7845 - val_loss1/classifier_macro_f1score: 0.2251 - val_loss2/classifier_accuracy: 0.4590 - val_loss2/classifier_top5_acc: 0.7806 - val_loss2/classifier_macro_f1score: 0.2811 - val_loss3/classifier_accuracy: 0.4811 - val_loss3/classifier_top5_acc: 0.7891 - val_loss3/classifier_macro_f1score: 0.3071\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00061: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 61/70\n","97/97 [==============================] - ETA: 0s - loss: 1.5144 - loss1/classifier_loss: 1.5407 - loss2/classifier_loss: 1.1195 - loss3/classifier_loss: 0.7164 - loss1/classifier_accuracy: 0.5569 - loss1/classifier_top5_acc: 0.8585 - loss1/classifier_macro_f1score: 0.2898 - loss2/classifier_accuracy: 0.6653 - loss2/classifier_top5_acc: 0.9166 - loss2/classifier_macro_f1score: 0.4026 - loss3/classifier_accuracy: 0.7816 - loss3/classifier_top5_acc: 0.9596 - loss3/classifier_macro_f1score: 0.5265\n","Epoch 00061: val_loss did not improve from 3.24258\n","\n","Epoch 00061: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 238s 2s/step - loss: 1.5144 - loss1/classifier_loss: 1.5407 - loss2/classifier_loss: 1.1195 - loss3/classifier_loss: 0.7164 - loss1/classifier_accuracy: 0.5569 - loss1/classifier_top5_acc: 0.8585 - loss1/classifier_macro_f1score: 0.2898 - loss2/classifier_accuracy: 0.6653 - loss2/classifier_top5_acc: 0.9166 - loss2/classifier_macro_f1score: 0.4026 - loss3/classifier_accuracy: 0.7816 - loss3/classifier_top5_acc: 0.9596 - loss3/classifier_macro_f1score: 0.5265 - val_loss: 3.5237 - val_loss1/classifier_loss: 2.0087 - val_loss2/classifier_loss: 2.0850 - val_loss3/classifier_loss: 2.2956 - val_loss1/classifier_accuracy: 0.4603 - val_loss1/classifier_top5_acc: 0.7910 - val_loss1/classifier_macro_f1score: 0.2347 - val_loss2/classifier_accuracy: 0.4701 - val_loss2/classifier_top5_acc: 0.7904 - val_loss2/classifier_macro_f1score: 0.2824 - val_loss3/classifier_accuracy: 0.4987 - val_loss3/classifier_top5_acc: 0.7949 - val_loss3/classifier_macro_f1score: 0.3070\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00062: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 62/70\n","97/97 [==============================] - ETA: 0s - loss: 1.4771 - loss1/classifier_loss: 1.5290 - loss2/classifier_loss: 1.0950 - loss3/classifier_loss: 0.6899 - loss1/classifier_accuracy: 0.5622 - loss1/classifier_top5_acc: 0.8590 - loss1/classifier_macro_f1score: 0.2917 - loss2/classifier_accuracy: 0.6760 - loss2/classifier_top5_acc: 0.9155 - loss2/classifier_macro_f1score: 0.4122 - loss3/classifier_accuracy: 0.7893 - loss3/classifier_top5_acc: 0.9617 - loss3/classifier_macro_f1score: 0.5384\n","Epoch 00062: val_loss did not improve from 3.24258\n","\n","Epoch 00062: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 237s 2s/step - loss: 1.4771 - loss1/classifier_loss: 1.5290 - loss2/classifier_loss: 1.0950 - loss3/classifier_loss: 0.6899 - loss1/classifier_accuracy: 0.5622 - loss1/classifier_top5_acc: 0.8590 - loss1/classifier_macro_f1score: 0.2917 - loss2/classifier_accuracy: 0.6760 - loss2/classifier_top5_acc: 0.9155 - loss2/classifier_macro_f1score: 0.4122 - loss3/classifier_accuracy: 0.7893 - loss3/classifier_top5_acc: 0.9617 - loss3/classifier_macro_f1score: 0.5384 - val_loss: 3.5335 - val_loss1/classifier_loss: 2.0068 - val_loss2/classifier_loss: 2.0719 - val_loss3/classifier_loss: 2.3098 - val_loss1/classifier_accuracy: 0.4655 - val_loss1/classifier_top5_acc: 0.7897 - val_loss1/classifier_macro_f1score: 0.2279 - val_loss2/classifier_accuracy: 0.4753 - val_loss2/classifier_top5_acc: 0.7930 - val_loss2/classifier_macro_f1score: 0.2758 - val_loss3/classifier_accuracy: 0.4967 - val_loss3/classifier_top5_acc: 0.7910 - val_loss3/classifier_macro_f1score: 0.3014\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00063: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 63/70\n","97/97 [==============================] - ETA: 0s - loss: 1.4688 - loss1/classifier_loss: 1.5236 - loss2/classifier_loss: 1.0994 - loss3/classifier_loss: 0.6819 - loss1/classifier_accuracy: 0.5633 - loss1/classifier_top5_acc: 0.8623 - loss1/classifier_macro_f1score: 0.2893 - loss2/classifier_accuracy: 0.6756 - loss2/classifier_top5_acc: 0.9156 - loss2/classifier_macro_f1score: 0.4094 - loss3/classifier_accuracy: 0.7904 - loss3/classifier_top5_acc: 0.9647 - loss3/classifier_macro_f1score: 0.5305\n","Epoch 00063: val_loss did not improve from 3.24258\n","\n","Epoch 00063: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 237s 2s/step - loss: 1.4688 - loss1/classifier_loss: 1.5236 - loss2/classifier_loss: 1.0994 - loss3/classifier_loss: 0.6819 - loss1/classifier_accuracy: 0.5633 - loss1/classifier_top5_acc: 0.8623 - loss1/classifier_macro_f1score: 0.2893 - loss2/classifier_accuracy: 0.6756 - loss2/classifier_top5_acc: 0.9156 - loss2/classifier_macro_f1score: 0.4094 - loss3/classifier_accuracy: 0.7904 - loss3/classifier_top5_acc: 0.9647 - loss3/classifier_macro_f1score: 0.5305 - val_loss: 3.4779 - val_loss1/classifier_loss: 1.9970 - val_loss2/classifier_loss: 2.0555 - val_loss3/classifier_loss: 2.2621 - val_loss1/classifier_accuracy: 0.4668 - val_loss1/classifier_top5_acc: 0.7975 - val_loss1/classifier_macro_f1score: 0.2392 - val_loss2/classifier_accuracy: 0.4759 - val_loss2/classifier_top5_acc: 0.7988 - val_loss2/classifier_macro_f1score: 0.2858 - val_loss3/classifier_accuracy: 0.5007 - val_loss3/classifier_top5_acc: 0.7943 - val_loss3/classifier_macro_f1score: 0.3175\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00064: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 64/70\n","97/97 [==============================] - ETA: 0s - loss: 1.4653 - loss1/classifier_loss: 1.5221 - loss2/classifier_loss: 1.0792 - loss3/classifier_loss: 0.6849 - loss1/classifier_accuracy: 0.5659 - loss1/classifier_top5_acc: 0.8623 - loss1/classifier_macro_f1score: 0.2909 - loss2/classifier_accuracy: 0.6749 - loss2/classifier_top5_acc: 0.9232 - loss2/classifier_macro_f1score: 0.4090 - loss3/classifier_accuracy: 0.7906 - loss3/classifier_top5_acc: 0.9615 - loss3/classifier_macro_f1score: 0.5343\n","Epoch 00064: val_loss did not improve from 3.24258\n","\n","Epoch 00064: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 236s 2s/step - loss: 1.4653 - loss1/classifier_loss: 1.5221 - loss2/classifier_loss: 1.0792 - loss3/classifier_loss: 0.6849 - loss1/classifier_accuracy: 0.5659 - loss1/classifier_top5_acc: 0.8623 - loss1/classifier_macro_f1score: 0.2909 - loss2/classifier_accuracy: 0.6749 - loss2/classifier_top5_acc: 0.9232 - loss2/classifier_macro_f1score: 0.4090 - loss3/classifier_accuracy: 0.7906 - loss3/classifier_top5_acc: 0.9615 - loss3/classifier_macro_f1score: 0.5343 - val_loss: 3.5125 - val_loss1/classifier_loss: 1.9966 - val_loss2/classifier_loss: 2.0749 - val_loss3/classifier_loss: 2.2910 - val_loss1/classifier_accuracy: 0.4629 - val_loss1/classifier_top5_acc: 0.7956 - val_loss1/classifier_macro_f1score: 0.2305 - val_loss2/classifier_accuracy: 0.4766 - val_loss2/classifier_top5_acc: 0.7962 - val_loss2/classifier_macro_f1score: 0.2839 - val_loss3/classifier_accuracy: 0.4954 - val_loss3/classifier_top5_acc: 0.7936 - val_loss3/classifier_macro_f1score: 0.3097\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00065: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 65/70\n","97/97 [==============================] - ETA: 0s - loss: 1.4921 - loss1/classifier_loss: 1.5368 - loss2/classifier_loss: 1.1054 - loss3/classifier_loss: 0.6995 - loss1/classifier_accuracy: 0.5571 - loss1/classifier_top5_acc: 0.8586 - loss1/classifier_macro_f1score: 0.2933 - loss2/classifier_accuracy: 0.6698 - loss2/classifier_top5_acc: 0.9139 - loss2/classifier_macro_f1score: 0.4133 - loss3/classifier_accuracy: 0.7840 - loss3/classifier_top5_acc: 0.9596 - loss3/classifier_macro_f1score: 0.5339\n","Epoch 00065: val_loss did not improve from 3.24258\n","\n","Epoch 00065: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 239s 2s/step - loss: 1.4921 - loss1/classifier_loss: 1.5368 - loss2/classifier_loss: 1.1054 - loss3/classifier_loss: 0.6995 - loss1/classifier_accuracy: 0.5571 - loss1/classifier_top5_acc: 0.8586 - loss1/classifier_macro_f1score: 0.2933 - loss2/classifier_accuracy: 0.6698 - loss2/classifier_top5_acc: 0.9139 - loss2/classifier_macro_f1score: 0.4133 - loss3/classifier_accuracy: 0.7840 - loss3/classifier_top5_acc: 0.9596 - loss3/classifier_macro_f1score: 0.5339 - val_loss: 3.4962 - val_loss1/classifier_loss: 2.0009 - val_loss2/classifier_loss: 2.0641 - val_loss3/classifier_loss: 2.2767 - val_loss1/classifier_accuracy: 0.4648 - val_loss1/classifier_top5_acc: 0.7930 - val_loss1/classifier_macro_f1score: 0.2375 - val_loss2/classifier_accuracy: 0.4785 - val_loss2/classifier_top5_acc: 0.7930 - val_loss2/classifier_macro_f1score: 0.2949 - val_loss3/classifier_accuracy: 0.5000 - val_loss3/classifier_top5_acc: 0.7943 - val_loss3/classifier_macro_f1score: 0.3181\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00066: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 66/70\n","97/97 [==============================] - ETA: 0s - loss: 1.4896 - loss1/classifier_loss: 1.5414 - loss2/classifier_loss: 1.0991 - loss3/classifier_loss: 0.6974 - loss1/classifier_accuracy: 0.5588 - loss1/classifier_top5_acc: 0.8583 - loss1/classifier_macro_f1score: 0.2875 - loss2/classifier_accuracy: 0.6730 - loss2/classifier_top5_acc: 0.9164 - loss2/classifier_macro_f1score: 0.4114 - loss3/classifier_accuracy: 0.7845 - loss3/classifier_top5_acc: 0.9606 - loss3/classifier_macro_f1score: 0.5300\n","Epoch 00066: val_loss did not improve from 3.24258\n","\n","Epoch 00066: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 236s 2s/step - loss: 1.4896 - loss1/classifier_loss: 1.5414 - loss2/classifier_loss: 1.0991 - loss3/classifier_loss: 0.6974 - loss1/classifier_accuracy: 0.5588 - loss1/classifier_top5_acc: 0.8583 - loss1/classifier_macro_f1score: 0.2875 - loss2/classifier_accuracy: 0.6730 - loss2/classifier_top5_acc: 0.9164 - loss2/classifier_macro_f1score: 0.4114 - loss3/classifier_accuracy: 0.7845 - loss3/classifier_top5_acc: 0.9606 - loss3/classifier_macro_f1score: 0.5300 - val_loss: 3.4774 - val_loss1/classifier_loss: 1.9925 - val_loss2/classifier_loss: 2.0560 - val_loss3/classifier_loss: 2.2628 - val_loss1/classifier_accuracy: 0.4635 - val_loss1/classifier_top5_acc: 0.7943 - val_loss1/classifier_macro_f1score: 0.2347 - val_loss2/classifier_accuracy: 0.4727 - val_loss2/classifier_top5_acc: 0.7975 - val_loss2/classifier_macro_f1score: 0.2785 - val_loss3/classifier_accuracy: 0.4967 - val_loss3/classifier_top5_acc: 0.7975 - val_loss3/classifier_macro_f1score: 0.3124\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00067: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 67/70\n","97/97 [==============================] - ETA: 0s - loss: 1.4930 - loss1/classifier_loss: 1.5420 - loss2/classifier_loss: 1.1036 - loss3/classifier_loss: 0.6993 - loss1/classifier_accuracy: 0.5592 - loss1/classifier_top5_acc: 0.8617 - loss1/classifier_macro_f1score: 0.2892 - loss2/classifier_accuracy: 0.6683 - loss2/classifier_top5_acc: 0.9164 - loss2/classifier_macro_f1score: 0.4128 - loss3/classifier_accuracy: 0.7861 - loss3/classifier_top5_acc: 0.9604 - loss3/classifier_macro_f1score: 0.5360\n","Epoch 00067: val_loss did not improve from 3.24258\n","\n","Epoch 00067: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 235s 2s/step - loss: 1.4930 - loss1/classifier_loss: 1.5420 - loss2/classifier_loss: 1.1036 - loss3/classifier_loss: 0.6993 - loss1/classifier_accuracy: 0.5592 - loss1/classifier_top5_acc: 0.8617 - loss1/classifier_macro_f1score: 0.2892 - loss2/classifier_accuracy: 0.6683 - loss2/classifier_top5_acc: 0.9164 - loss2/classifier_macro_f1score: 0.4128 - loss3/classifier_accuracy: 0.7861 - loss3/classifier_top5_acc: 0.9604 - loss3/classifier_macro_f1score: 0.5360 - val_loss: 3.5039 - val_loss1/classifier_loss: 2.0125 - val_loss2/classifier_loss: 2.0751 - val_loss3/classifier_loss: 2.2776 - val_loss1/classifier_accuracy: 0.4616 - val_loss1/classifier_top5_acc: 0.7865 - val_loss1/classifier_macro_f1score: 0.2331 - val_loss2/classifier_accuracy: 0.4805 - val_loss2/classifier_top5_acc: 0.7910 - val_loss2/classifier_macro_f1score: 0.2825 - val_loss3/classifier_accuracy: 0.4974 - val_loss3/classifier_top5_acc: 0.7956 - val_loss3/classifier_macro_f1score: 0.3090\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00068: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 68/70\n","97/97 [==============================] - ETA: 0s - loss: 1.4820 - loss1/classifier_loss: 1.5392 - loss2/classifier_loss: 1.0948 - loss3/classifier_loss: 0.6918 - loss1/classifier_accuracy: 0.5551 - loss1/classifier_top5_acc: 0.8579 - loss1/classifier_macro_f1score: 0.2853 - loss2/classifier_accuracy: 0.6718 - loss2/classifier_top5_acc: 0.9203 - loss2/classifier_macro_f1score: 0.4059 - loss3/classifier_accuracy: 0.7888 - loss3/classifier_top5_acc: 0.9612 - loss3/classifier_macro_f1score: 0.5306\n","Epoch 00068: val_loss did not improve from 3.24258\n","\n","Epoch 00068: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 237s 2s/step - loss: 1.4820 - loss1/classifier_loss: 1.5392 - loss2/classifier_loss: 1.0948 - loss3/classifier_loss: 0.6918 - loss1/classifier_accuracy: 0.5551 - loss1/classifier_top5_acc: 0.8579 - loss1/classifier_macro_f1score: 0.2853 - loss2/classifier_accuracy: 0.6718 - loss2/classifier_top5_acc: 0.9203 - loss2/classifier_macro_f1score: 0.4059 - loss3/classifier_accuracy: 0.7888 - loss3/classifier_top5_acc: 0.9612 - loss3/classifier_macro_f1score: 0.5306 - val_loss: 3.5125 - val_loss1/classifier_loss: 2.0159 - val_loss2/classifier_loss: 2.0840 - val_loss3/classifier_loss: 2.2825 - val_loss1/classifier_accuracy: 0.4596 - val_loss1/classifier_top5_acc: 0.7858 - val_loss1/classifier_macro_f1score: 0.2264 - val_loss2/classifier_accuracy: 0.4733 - val_loss2/classifier_top5_acc: 0.7936 - val_loss2/classifier_macro_f1score: 0.2663 - val_loss3/classifier_accuracy: 0.4961 - val_loss3/classifier_top5_acc: 0.7910 - val_loss3/classifier_macro_f1score: 0.3058\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00069: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 69/70\n","97/97 [==============================] - ETA: 0s - loss: 1.4778 - loss1/classifier_loss: 1.5285 - loss2/classifier_loss: 1.0893 - loss3/classifier_loss: 0.6924 - loss1/classifier_accuracy: 0.5628 - loss1/classifier_top5_acc: 0.8584 - loss1/classifier_macro_f1score: 0.2871 - loss2/classifier_accuracy: 0.6754 - loss2/classifier_top5_acc: 0.9160 - loss2/classifier_macro_f1score: 0.4128 - loss3/classifier_accuracy: 0.7871 - loss3/classifier_top5_acc: 0.9627 - loss3/classifier_macro_f1score: 0.5299\n","Epoch 00069: val_loss did not improve from 3.24258\n","\n","Epoch 00069: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 238s 2s/step - loss: 1.4778 - loss1/classifier_loss: 1.5285 - loss2/classifier_loss: 1.0893 - loss3/classifier_loss: 0.6924 - loss1/classifier_accuracy: 0.5628 - loss1/classifier_top5_acc: 0.8584 - loss1/classifier_macro_f1score: 0.2871 - loss2/classifier_accuracy: 0.6754 - loss2/classifier_top5_acc: 0.9160 - loss2/classifier_macro_f1score: 0.4128 - loss3/classifier_accuracy: 0.7871 - loss3/classifier_top5_acc: 0.9627 - loss3/classifier_macro_f1score: 0.5299 - val_loss: 3.4707 - val_loss1/classifier_loss: 2.0018 - val_loss2/classifier_loss: 2.0548 - val_loss3/classifier_loss: 2.2537 - val_loss1/classifier_accuracy: 0.4616 - val_loss1/classifier_top5_acc: 0.7904 - val_loss1/classifier_macro_f1score: 0.2245 - val_loss2/classifier_accuracy: 0.4746 - val_loss2/classifier_top5_acc: 0.7969 - val_loss2/classifier_macro_f1score: 0.2735 - val_loss3/classifier_accuracy: 0.4967 - val_loss3/classifier_top5_acc: 0.7956 - val_loss3/classifier_macro_f1score: 0.3012\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00070: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 70/70\n","97/97 [==============================] - ETA: 0s - loss: 1.4824 - loss1/classifier_loss: 1.5379 - loss2/classifier_loss: 1.1014 - loss3/classifier_loss: 0.6906 - loss1/classifier_accuracy: 0.5572 - loss1/classifier_top5_acc: 0.8604 - loss1/classifier_macro_f1score: 0.2793 - loss2/classifier_accuracy: 0.6700 - loss2/classifier_top5_acc: 0.9191 - loss2/classifier_macro_f1score: 0.3974 - loss3/classifier_accuracy: 0.7915 - loss3/classifier_top5_acc: 0.9608 - loss3/classifier_macro_f1score: 0.5226\n","Epoch 00070: val_loss did not improve from 3.24258\n","\n","Epoch 00070: val_loss3/classifier_accuracy did not improve from 0.50130\n","97/97 [==============================] - 237s 2s/step - loss: 1.4824 - loss1/classifier_loss: 1.5379 - loss2/classifier_loss: 1.1014 - loss3/classifier_loss: 0.6906 - loss1/classifier_accuracy: 0.5572 - loss1/classifier_top5_acc: 0.8604 - loss1/classifier_macro_f1score: 0.2793 - loss2/classifier_accuracy: 0.6700 - loss2/classifier_top5_acc: 0.9191 - loss2/classifier_macro_f1score: 0.3974 - loss3/classifier_accuracy: 0.7915 - loss3/classifier_top5_acc: 0.9608 - loss3/classifier_macro_f1score: 0.5226 - val_loss: 3.5159 - val_loss1/classifier_loss: 2.0176 - val_loss2/classifier_loss: 2.0884 - val_loss3/classifier_loss: 2.2841 - val_loss1/classifier_accuracy: 0.4583 - val_loss1/classifier_top5_acc: 0.7884 - val_loss1/classifier_macro_f1score: 0.2234 - val_loss2/classifier_accuracy: 0.4714 - val_loss2/classifier_top5_acc: 0.7917 - val_loss2/classifier_macro_f1score: 0.2825 - val_loss3/classifier_accuracy: 0.4928 - val_loss3/classifier_top5_acc: 0.7917 - val_loss3/classifier_macro_f1score: 0.3010\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W3hAqJFKvqie"},"source":["### 3) GoogLeNet Evaluate\n"]},{"cell_type":"code","metadata":{"id":"UNop2cYdMkkH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606156403746,"user_tz":-540,"elapsed":24436393,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"24052ad4-4043-4d28-adc2-d4884e6289bc"},"source":["# 1. epoch=maximum\n","#var = model.evaluate_generator(generate_test_for_three(),steps=int(len(x_test)/batch_sizes))\n","var = model.evaluate(generate_test_for_three(),steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (var[0],var[-3],var[-2],var[-1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 1590 images belonging to 67 classes.\n","12/12 [==============================] - 778s 65s/step - loss: 3.4523 - loss1/classifier_loss: 1.9862 - loss2/classifier_loss: 2.0429 - loss3/classifier_loss: 2.2435 - loss1/classifier_accuracy: 0.4648 - loss1/classifier_top5_acc: 0.7826 - loss1/classifier_macro_f1score: 0.2171 - loss2/classifier_accuracy: 0.4844 - loss2/classifier_top5_acc: 0.8014 - loss2/classifier_macro_f1score: 0.2668 - loss3/classifier_accuracy: 0.4863 - loss3/classifier_top5_acc: 0.7943 - loss3/classifier_macro_f1score: 0.2958\n","[Test Loss: 3.4523 /  Test Top-1 Accuracy: 0.4863 / Test Top-5 Accuracy: 0.7943 / Test Macro f1: 0.2958]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gHMaAEJbMkkJ"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['loss3/classifier_accuracy']\n","val_acc=history.history['val_loss3/classifier_accuracy']\n","top5_acc=history.history['loss3/classifier_top5_acc']\n","val_top5_acc=history.history['val_loss3/classifier_top5_acc']\n","f1=history.history['loss3/classifier_macro_f1score']\n","val_f1=history.history['val_loss3/classifier_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_J63NZRjMkkM"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vE5-Vi6O4del"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pAQKONLzMkkP"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'GoogleNet.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RFy1r9jVMkkS"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTSL86SdMkkU","colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"status":"ok","timestamp":1606156404633,"user_tz":-540,"elapsed":24437242,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"f1543007-8401-4da9-9a37-7aab7b952fe5"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Ts4qdfNV4uOW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kigdcVl1aHFF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0z6BwcAulnw","executionInfo":{"status":"ok","timestamp":1606277569857,"user_tz":-540,"elapsed":1253,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / Inception-V1"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c","executionInfo":{"status":"ok","timestamp":1606277570606,"user_tz":-540,"elapsed":1988,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak","executionInfo":{"status":"ok","timestamp":1606277570608,"user_tz":-540,"elapsed":1981,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pFcw51AuDG4","executionInfo":{"status":"ok","timestamp":1606277581300,"user_tz":-540,"elapsed":12666,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["model=load_model(os.path.join(dir,'model_output',number,'GoogleNet','057.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc,\"LRN\":LRN,\"PoolHelper\":PoolHelper, \"AdamW\":AdamW})"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWlrnY9EuDG-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606278359770,"user_tz":-540,"elapsed":791127,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"82ad424e-86ed-4c77-823a-cfdc2da21c34"},"source":["# 2. epoch=?\n","var = model.evaluate(generate_test_for_three(),steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (var[0],var[-3],var[-2],var[-1]))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Found 1590 images belonging to 67 classes.\n","12/12 [==============================] - 673s 56s/step - loss: 3.4930 - loss1/classifier_loss: 2.0216 - loss2/classifier_loss: 2.0478 - loss3/classifier_loss: 2.2722 - loss1/classifier_accuracy: 0.4688 - loss1/classifier_top5_acc: 0.7773 - loss1/classifier_macro_f1score: 0.2330 - loss2/classifier_accuracy: 0.4954 - loss2/classifier_top5_acc: 0.8073 - loss2/classifier_macro_f1score: 0.2872 - loss3/classifier_accuracy: 0.5007 - loss3/classifier_top5_acc: 0.8021 - loss3/classifier_macro_f1score: 0.3113\n","[Test Loss: 3.4930 /  Test Top-1 Accuracy: 0.5007 / Test Top-5 Accuracy: 0.8021 / Test Macro f1: 0.3113]\n","\n"],"name":"stdout"}]}]}
