{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05.ResNet50.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"veB_9DzkobyH","executionInfo":{"status":"ok","timestamp":1606112049483,"user_tz":-540,"elapsed":680,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["#모형 출처 : https://github.com/titu1994/keras-squeeze-excite-network"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [ResNet50]"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original ResNet\n","```\n","1) Support Functions\n","2) Almost orginal ResNet\n","```\n","3. ResNet50\n","```\n","1) ResNet50\n","2) ResNet50 Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606112080025,"user_tz":-540,"elapsed":31196,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"dd467680-8236-422e-fb8f-ea0217271b66"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606112080030,"user_tz":-540,"elapsed":31185,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"03199a62-83fc-421b-9db1-40b99640b329"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1606112082142,"user_tz":-540,"elapsed":33291,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1606112082545,"user_tz":-540,"elapsed":33687,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606112082546,"user_tz":-540,"elapsed":33670,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"06ad89d7-38de-42a8-ad54-7cfc481e516d"},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606112085826,"user_tz":-540,"elapsed":36940,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"d7cc744d-3997-487c-92af-804f88111407"},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606112086455,"user_tz":-540,"elapsed":37555,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"dc70b39a-d9e0-4563-bad5-8f218b0750a1"},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"5QEPaq7XQBs8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606112086456,"user_tz":-540,"elapsed":37543,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"8ef791fa-2e39-45fc-ff30-bcc5456f55b1"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 8719118297792263572\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 17938308832282740264\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 8362952633399144303\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15695549568\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 6973910078947283450\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UmBWKpp_cNUa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606112086458,"user_tz":-540,"elapsed":37532,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"fb0682ca-648f-4e25-cf74-59588069780f"},"source":["!cat /proc/cpuinfo"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OOsm86eVUBko"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"DgwOtB_QEhll"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"i5hoO5oVDDJh","executionInfo":{"status":"ok","timestamp":1606112086459,"user_tz":-540,"elapsed":37531,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'MIT'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 224 # sizes after cropping\n","super_size = 256 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 128\n","weight_decay = 2e-3\n","epochs = 70"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1606112086460,"user_tz":-540,"elapsed":37529,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSIGjI-lnPzM","executionInfo":{"status":"ok","timestamp":1606112086462,"user_tz":-540,"elapsed":37529,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1606112086463,"user_tz":-540,"elapsed":37527,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XrNLBwoJCRR9"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"Zs3J4oAbnPzR","executionInfo":{"status":"ok","timestamp":1606112086464,"user_tz":-540,"elapsed":37525,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1606112086465,"user_tz":-540,"elapsed":37522,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOCgiW4fnPzW","executionInfo":{"status":"ok","timestamp":1606112086468,"user_tz":-540,"elapsed":37522,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"sh3c_SsjnPzY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606112105584,"user_tz":-540,"elapsed":56631,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"bf0d93ea-2ee3-4910-9e2d-b44104e0c96a"},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Found 12466 images belonging to 67 classes.\n","Found 1564 images belonging to 67 classes.\n","Found 1590 images belonging to 67 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original ResNet\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"n2aVgcbl5z0A"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"napBoZvjmK6S"},"source":["def _resnet_block(input_tensor, filters, k=1, strides=(1, 1), weight_decay = weight_decay):\n","\n","    init = input_tensor\n","    channel_axis = -1\n","\n","    if strides != (1, 1) or init.get_shape()[channel_axis] != filters * k:\n","        x = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","                      use_bias=False, strides=strides)(input_tensor)\n","        init = BatchNormalization(axis=channel_axis)(x)\n","\n","\n","    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False, strides=strides)(input_tensor)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False)(x)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","\n","    m = add([x, init])\n","    m = Activation('relu')(m)\n","\n","    return m"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-rGAsFnzmK6X"},"source":["def _resnet_bottleneck_block(input_tensor, filters, k=1, strides=(1, 1), weight_decay = weight_decay):\n","\n","    init = input_tensor\n","    channel_axis = -1\n","    bottleneck_expand = 4\n","\n","    if strides != (1, 1) or init.get_shape()[channel_axis] != bottleneck_expand * filters * k:\n","        x = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","                      use_bias=False, strides=strides)(input_tensor)\n","        init = BatchNormalization(axis=channel_axis)(x)\n","\n","\n","    x = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False)(input_tensor)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False, strides=strides)(x)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False)(x)\n","    x = BatchNormalization(axis=channel_axis)(x)    \n","\n","    m = add([x, init])\n","    m = Activation('relu')(m)\n","\n","    return m"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4XWPZ9p0mK6a"},"source":["### 2) Almost Orginial ResNet\n"]},{"cell_type":"code","metadata":{"id":"UJQUF8nAmK6a"},"source":["def _create_resnet(classes, img_input, initial_conv_filters, filters, depth, width, bottleneck, weight_decay):\n","\n","    channel_axis = -1\n","    N = list(depth)\n","\n","    # block 1 (initial conv block)\n","    x = Conv2D(initial_conv_filters, (7, 7), padding='same', use_bias=False, strides=(2, 2), kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(img_input)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","\n","    # block 2 (projection block)\n","    for i in range(N[0]):\n","        if bottleneck:\n","            x = _resnet_bottleneck_block(x, filters[0], width)\n","        else:\n","            x = _resnet_block(x, filters[0], width)\n","\n","    # block 3 - N\n","    for k in range(1, len(N)):\n","        if bottleneck:\n","            x = _resnet_bottleneck_block(x, filters[k], width, strides=(2, 2))\n","        else:\n","            x = _resnet_block(x, filters[k], width, strides=(2, 2))\n","\n","        for i in range(N[k] - 1):\n","            if bottleneck:\n","                x = _resnet_bottleneck_block(x, filters[k], width)\n","            else:\n","                x = _resnet_block(x, filters[k], width)\n","\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(classes, use_bias=False, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n","\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YQUZXeZAo67V"},"source":["def ResNet(input_shape=None, initial_conv_filters=64, depth=[3, 4, 6, 3], filters=[64, 128, 256, 512],\n","             width=1, bottleneck=False, weight_decay=weight_decay, name=None, classes=1000):\n","\n","\n","    img_input = Input(shape=input_shape)\n","\n","    x = _create_resnet(classes, img_input, initial_conv_filters, filters, depth, width, bottleneck, weight_decay)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","\n","    inputs = img_input\n","\n","    # Create model.\n","    model = Model(inputs, x, name = name)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOAp8LsWRMR6"},"source":["## 3. ResNet50\n","---"]},{"cell_type":"markdown","metadata":{"id":"18V3G5o-RMR7"},"source":["### 1) ResNet50"]},{"cell_type":"code","metadata":{"id":"cHQpj9MVo62T"},"source":["# ResNet50\n","model = ResNet(input_shape=input_sizes, depth=[3, 4, 6, 3], width=1, bottleneck=True, weight_decay=weight_decay, classes=classes, name='ResNet50')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"85bYcB6bpTUW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605450438201,"user_tz":-540,"elapsed":91713,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"6eb80f38-5ef2-451a-e370-3ec552d162bf"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"ResNet50\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 112, 112, 64) 9408        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 56, 56, 64)   4096        max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 56, 56, 64)   36864       activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 56, 56, 256)  16384       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 56, 56, 256)  16384       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 56, 56, 256)  1024        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 56, 56, 256)  1024        conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 56, 56, 256)  0           batch_normalization_3[0][0]      \n","                                                                 batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 56, 56, 256)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 56, 56, 64)   16384       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 56, 56, 64)   256         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 56, 56, 64)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 56, 56, 64)   36864       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 56, 56, 64)   256         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 56, 56, 64)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 56, 56, 256)  16384       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 56, 56, 256)  1024        conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 56, 56, 256)  0           batch_normalization_6[0][0]      \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 56, 56, 64)   16384       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 56, 56, 64)   256         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 56, 56, 64)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 56, 56, 64)   36864       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 56, 56, 64)   256         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 56, 56, 64)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 56, 56, 256)  16384       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 56, 56, 256)  1024        conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 56, 56, 256)  0           batch_normalization_9[0][0]      \n","                                                                 activation_5[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 56, 56, 128)  32768       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 56, 56, 128)  512         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 56, 56, 128)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 28, 28, 128)  147456      activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 28, 28, 512)  65536       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 28, 28, 512)  131072      activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 28, 28, 512)  2048        conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_13[0][0]     \n","                                                                 batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 28, 28, 128)  65536       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 28, 28, 128)  0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 28, 28, 128)  147456      activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 28, 28, 512)  65536       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_16[0][0]     \n","                                                                 activation_11[0][0]              \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 28, 28, 128)  65536       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 28, 28, 128)  147456      activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 28, 28, 512)  65536       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_19[0][0]     \n","                                                                 activation_14[0][0]              \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 28, 28, 128)  65536       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 28, 28, 128)  0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 28, 28, 128)  147456      activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 28, 28, 512)  65536       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 28, 28, 512)  2048        conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_22[0][0]     \n","                                                                 activation_17[0][0]              \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 28, 28, 256)  131072      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 28, 28, 256)  1024        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 28, 28, 256)  0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 14, 14, 256)  589824      activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 14, 14, 256)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 14, 14, 1024) 262144      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 14, 14, 1024) 524288      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 14, 14, 1024) 4096        conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 14, 14, 1024) 4096        conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_26[0][0]     \n","                                                                 batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 14, 14, 256)  262144      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 14, 14, 256)  1024        conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 14, 14, 256)  0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 14, 14, 256)  589824      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 14, 14, 256)  0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 14, 14, 1024) 262144      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 14, 14, 1024) 4096        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_29[0][0]     \n","                                                                 activation_23[0][0]              \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 14, 14, 256)  262144      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 14, 14, 256)  1024        conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 14, 14, 256)  0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 14, 14, 256)  589824      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 14, 14, 256)  0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 14, 14, 1024) 262144      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 14, 14, 1024) 4096        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_32[0][0]     \n","                                                                 activation_26[0][0]              \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 14, 14, 256)  262144      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 14, 14, 256)  0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 14, 14, 256)  589824      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 14, 14, 256)  0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 14, 14, 1024) 262144      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 14, 14, 1024) 4096        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_35[0][0]     \n","                                                                 activation_29[0][0]              \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 14, 14, 256)  262144      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 14, 14, 256)  1024        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 14, 14, 256)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 14, 14, 256)  589824      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 14, 14, 256)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 14, 14, 1024) 262144      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 14, 14, 1024) 4096        conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_38[0][0]     \n","                                                                 activation_32[0][0]              \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 14, 14, 256)  262144      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 14, 14, 256)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 14, 14, 256)  589824      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 14, 14, 1024) 262144      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 14, 14, 1024) 4096        conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_41[0][0]     \n","                                                                 activation_35[0][0]              \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 14, 14, 512)  524288      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 14, 14, 512)  2048        conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 14, 14, 512)  0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 7, 7, 512)    2359296     activation_39[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 7, 7, 512)    0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 7, 7, 2048)   1048576     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 7, 7, 2048)   2097152     activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 7, 7, 2048)   8192        conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 7, 7, 2048)   8192        conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_45[0][0]     \n","                                                                 batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 7, 7, 512)    1048576     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 7, 7, 512)    2048        conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 7, 7, 512)    0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 7, 7, 512)    2359296     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 7, 7, 512)    0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 7, 7, 2048)   1048576     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 7, 7, 2048)   8192        conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_48[0][0]     \n","                                                                 activation_41[0][0]              \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 7, 7, 512)    1048576     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 7, 7, 512)    2048        conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 7, 7, 512)    0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 7, 7, 512)    2359296     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 7, 7, 512)    0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 7, 7, 2048)   1048576     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 7, 7, 2048)   8192        conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_51[0][0]     \n","                                                                 activation_44[0][0]              \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 2048)         0           activation_47[0][0]              \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 67)           137216      global_average_pooling2d[0][0]   \n","==================================================================================================\n","Total params: 23,698,112\n","Trainable params: 23,645,120\n","Non-trainable params: 52,992\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AispA2HmDSs_"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e4TEeLLw9al1"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8643H3mcjj3"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwH0Q16iRMSH"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMuhpBHjRMSN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605476794356,"user_tz":-540,"elapsed":26447802,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"a710288c-141a-425a-cb2c-87c7b5a1d5b7"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_5/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_6/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_7/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_8/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_9/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_10/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_12/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_13/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_14/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_11/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_15/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_16/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_17/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_18/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_19/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_20/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_21/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_22/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_23/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_25/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_26/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_27/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_24/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_28/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_29/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_30/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_31/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_32/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_33/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_34/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_35/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_36/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_37/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_38/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_39/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_40/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_41/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_42/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_44/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_45/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_46/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_43/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_47/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_48/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_49/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_50/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_51/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for conv2d_52/kernel:0\n","0.0(L1), 0.0002030692426719948(L2) weight decay set for dense/kernel:0\n","97/97 [==============================] - ETA: 0s - loss: 3.9993 - accuracy: 0.0975 - top5_acc: 0.3370 - macro_f1score: 0.0011  \n","Epoch 00001: val_loss improved from inf to 592.85065, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.01953, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/001.h5\n","97/97 [==============================] - 9684s 100s/step - loss: 3.9993 - accuracy: 0.0975 - top5_acc: 0.3370 - macro_f1score: 0.0011 - val_loss: 592.8506 - val_accuracy: 0.0195 - val_top5_acc: 0.4954 - val_macro_f1score: 0.0014\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","97/97 [==============================] - ETA: 0s - loss: 3.4455 - accuracy: 0.1493 - top5_acc: 0.4390 - macro_f1score: 0.0036\n","Epoch 00002: val_loss improved from 592.85065 to 4.37977, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/002.h5\n","\n","Epoch 00002: val_accuracy improved from 0.01953 to 0.07292, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/002.h5\n","97/97 [==============================] - 247s 3s/step - loss: 3.4455 - accuracy: 0.1493 - top5_acc: 0.4390 - macro_f1score: 0.0036 - val_loss: 4.3798 - val_accuracy: 0.0729 - val_top5_acc: 0.2578 - val_macro_f1score: 0.0019\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","97/97 [==============================] - ETA: 0s - loss: 3.1688 - accuracy: 0.1928 - top5_acc: 0.5080 - macro_f1score: 0.0143\n","Epoch 00003: val_loss improved from 4.37977 to 4.12111, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/003.h5\n","\n","Epoch 00003: val_accuracy improved from 0.07292 to 0.10547, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/003.h5\n","97/97 [==============================] - 248s 3s/step - loss: 3.1688 - accuracy: 0.1928 - top5_acc: 0.5080 - macro_f1score: 0.0143 - val_loss: 4.1211 - val_accuracy: 0.1055 - val_top5_acc: 0.3151 - val_macro_f1score: 0.0140\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","97/97 [==============================] - ETA: 0s - loss: 3.0322 - accuracy: 0.2265 - top5_acc: 0.5458 - macro_f1score: 0.0243\n","Epoch 00004: val_loss did not improve from 4.12111\n","\n","Epoch 00004: val_accuracy did not improve from 0.10547\n","97/97 [==============================] - 247s 3s/step - loss: 3.0322 - accuracy: 0.2265 - top5_acc: 0.5458 - macro_f1score: 0.0243 - val_loss: 8.1638 - val_accuracy: 0.0788 - val_top5_acc: 0.2858 - val_macro_f1score: 0.0162\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","97/97 [==============================] - ETA: 0s - loss: 2.8176 - accuracy: 0.2718 - top5_acc: 0.5973 - macro_f1score: 0.0465\n","Epoch 00005: val_loss did not improve from 4.12111\n","\n","Epoch 00005: val_accuracy did not improve from 0.10547\n","97/97 [==============================] - 246s 3s/step - loss: 2.8176 - accuracy: 0.2718 - top5_acc: 0.5973 - macro_f1score: 0.0465 - val_loss: 4.4204 - val_accuracy: 0.1016 - val_top5_acc: 0.3464 - val_macro_f1score: 0.0193\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","97/97 [==============================] - ETA: 0s - loss: 2.6209 - accuracy: 0.3176 - top5_acc: 0.6464 - macro_f1score: 0.0760\n","Epoch 00006: val_loss improved from 4.12111 to 3.33632, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/006.h5\n","\n","Epoch 00006: val_accuracy improved from 0.10547 to 0.19727, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/006.h5\n","97/97 [==============================] - 248s 3s/step - loss: 2.6209 - accuracy: 0.3176 - top5_acc: 0.6464 - macro_f1score: 0.0760 - val_loss: 3.3363 - val_accuracy: 0.1973 - val_top5_acc: 0.4961 - val_macro_f1score: 0.0391\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","97/97 [==============================] - ETA: 0s - loss: 2.4502 - accuracy: 0.3484 - top5_acc: 0.6837 - macro_f1score: 0.1031\n","Epoch 00007: val_loss improved from 3.33632 to 2.96853, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/007.h5\n","\n","Epoch 00007: val_accuracy improved from 0.19727 to 0.25977, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/007.h5\n","97/97 [==============================] - 245s 3s/step - loss: 2.4502 - accuracy: 0.3484 - top5_acc: 0.6837 - macro_f1score: 0.1031 - val_loss: 2.9685 - val_accuracy: 0.2598 - val_top5_acc: 0.5846 - val_macro_f1score: 0.0680\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","97/97 [==============================] - ETA: 0s - loss: 2.3038 - accuracy: 0.3823 - top5_acc: 0.7187 - macro_f1score: 0.1354\n","Epoch 00008: val_loss improved from 2.96853 to 2.78879, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/008.h5\n","\n","Epoch 00008: val_accuracy improved from 0.25977 to 0.28776, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/008.h5\n","97/97 [==============================] - 244s 3s/step - loss: 2.3038 - accuracy: 0.3823 - top5_acc: 0.7187 - macro_f1score: 0.1354 - val_loss: 2.7888 - val_accuracy: 0.2878 - val_top5_acc: 0.6133 - val_macro_f1score: 0.0906\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","97/97 [==============================] - ETA: 0s - loss: 2.1485 - accuracy: 0.4133 - top5_acc: 0.7466 - macro_f1score: 0.1637\n","Epoch 00009: val_loss improved from 2.78879 to 2.69897, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/009.h5\n","\n","Epoch 00009: val_accuracy improved from 0.28776 to 0.31185, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/009.h5\n","97/97 [==============================] - 242s 2s/step - loss: 2.1485 - accuracy: 0.4133 - top5_acc: 0.7466 - macro_f1score: 0.1637 - val_loss: 2.6990 - val_accuracy: 0.3118 - val_top5_acc: 0.6458 - val_macro_f1score: 0.1057\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","97/97 [==============================] - ETA: 0s - loss: 2.0325 - accuracy: 0.4491 - top5_acc: 0.7680 - macro_f1score: 0.1844\n","Epoch 00010: val_loss improved from 2.69897 to 2.47373, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/010.h5\n","\n","Epoch 00010: val_accuracy improved from 0.31185 to 0.34961, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/010.h5\n","97/97 [==============================] - 243s 3s/step - loss: 2.0325 - accuracy: 0.4491 - top5_acc: 0.7680 - macro_f1score: 0.1844 - val_loss: 2.4737 - val_accuracy: 0.3496 - val_top5_acc: 0.6934 - val_macro_f1score: 0.1305\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","97/97 [==============================] - ETA: 0s - loss: 1.9332 - accuracy: 0.4652 - top5_acc: 0.7950 - macro_f1score: 0.2048\n","Epoch 00011: val_loss improved from 2.47373 to 2.38624, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/011.h5\n","\n","Epoch 00011: val_accuracy improved from 0.34961 to 0.37109, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/011.h5\n","97/97 [==============================] - 242s 2s/step - loss: 1.9332 - accuracy: 0.4652 - top5_acc: 0.7950 - macro_f1score: 0.2048 - val_loss: 2.3862 - val_accuracy: 0.3711 - val_top5_acc: 0.7201 - val_macro_f1score: 0.1654\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","97/97 [==============================] - ETA: 0s - loss: 1.8614 - accuracy: 0.4805 - top5_acc: 0.8066 - macro_f1score: 0.2275\n","Epoch 00012: val_loss did not improve from 2.38624\n","\n","Epoch 00012: val_accuracy did not improve from 0.37109\n","97/97 [==============================] - 241s 2s/step - loss: 1.8614 - accuracy: 0.4805 - top5_acc: 0.8066 - macro_f1score: 0.2275 - val_loss: 3.0869 - val_accuracy: 0.2923 - val_top5_acc: 0.5970 - val_macro_f1score: 0.1127\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","97/97 [==============================] - ETA: 0s - loss: 1.7597 - accuracy: 0.5105 - top5_acc: 0.8207 - macro_f1score: 0.2540\n","Epoch 00013: val_loss did not improve from 2.38624\n","\n","Epoch 00013: val_accuracy did not improve from 0.37109\n","97/97 [==============================] - 238s 2s/step - loss: 1.7597 - accuracy: 0.5105 - top5_acc: 0.8207 - macro_f1score: 0.2540 - val_loss: 2.4754 - val_accuracy: 0.3568 - val_top5_acc: 0.7090 - val_macro_f1score: 0.1598\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","97/97 [==============================] - ETA: 0s - loss: 1.6785 - accuracy: 0.5229 - top5_acc: 0.8394 - macro_f1score: 0.2669\n","Epoch 00014: val_loss improved from 2.38624 to 2.16755, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/014.h5\n","\n","Epoch 00014: val_accuracy improved from 0.37109 to 0.42643, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/014.h5\n","97/97 [==============================] - 242s 2s/step - loss: 1.6785 - accuracy: 0.5229 - top5_acc: 0.8394 - macro_f1score: 0.2669 - val_loss: 2.1676 - val_accuracy: 0.4264 - val_top5_acc: 0.7428 - val_macro_f1score: 0.1926\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","97/97 [==============================] - ETA: 0s - loss: 1.5818 - accuracy: 0.5531 - top5_acc: 0.8544 - macro_f1score: 0.2952\n","Epoch 00015: val_loss improved from 2.16755 to 2.14132, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/015.h5\n","\n","Epoch 00015: val_accuracy improved from 0.42643 to 0.43620, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/015.h5\n","97/97 [==============================] - 244s 3s/step - loss: 1.5818 - accuracy: 0.5531 - top5_acc: 0.8544 - macro_f1score: 0.2952 - val_loss: 2.1413 - val_accuracy: 0.4362 - val_top5_acc: 0.7754 - val_macro_f1score: 0.2145\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","97/97 [==============================] - ETA: 0s - loss: 1.5183 - accuracy: 0.5683 - top5_acc: 0.8639 - macro_f1score: 0.3169\n","Epoch 00016: val_loss did not improve from 2.14132\n","\n","Epoch 00016: val_accuracy did not improve from 0.43620\n","97/97 [==============================] - 239s 2s/step - loss: 1.5183 - accuracy: 0.5683 - top5_acc: 0.8639 - macro_f1score: 0.3169 - val_loss: 2.4760 - val_accuracy: 0.3711 - val_top5_acc: 0.7070 - val_macro_f1score: 0.2030\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","97/97 [==============================] - ETA: 0s - loss: 1.4543 - accuracy: 0.5796 - top5_acc: 0.8757 - macro_f1score: 0.3280\n","Epoch 00017: val_loss did not improve from 2.14132\n","\n","Epoch 00017: val_accuracy did not improve from 0.43620\n","97/97 [==============================] - 239s 2s/step - loss: 1.4543 - accuracy: 0.5796 - top5_acc: 0.8757 - macro_f1score: 0.3280 - val_loss: 3.2254 - val_accuracy: 0.3125 - val_top5_acc: 0.6283 - val_macro_f1score: 0.1582\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","97/97 [==============================] - ETA: 0s - loss: 1.4354 - accuracy: 0.5939 - top5_acc: 0.8757 - macro_f1score: 0.3362\n","Epoch 00018: val_loss improved from 2.14132 to 2.13200, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/018.h5\n","\n","Epoch 00018: val_accuracy improved from 0.43620 to 0.44336, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/018.h5\n","97/97 [==============================] - 242s 2s/step - loss: 1.4354 - accuracy: 0.5939 - top5_acc: 0.8757 - macro_f1score: 0.3362 - val_loss: 2.1320 - val_accuracy: 0.4434 - val_top5_acc: 0.7734 - val_macro_f1score: 0.2278\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","97/97 [==============================] - ETA: 0s - loss: 1.3733 - accuracy: 0.5991 - top5_acc: 0.8867 - macro_f1score: 0.3525\n","Epoch 00019: val_loss did not improve from 2.13200\n","\n","Epoch 00019: val_accuracy did not improve from 0.44336\n","97/97 [==============================] - 242s 2s/step - loss: 1.3733 - accuracy: 0.5991 - top5_acc: 0.8867 - macro_f1score: 0.3525 - val_loss: 4.1710 - val_accuracy: 0.2448 - val_top5_acc: 0.5638 - val_macro_f1score: 0.1315\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","97/97 [==============================] - ETA: 0s - loss: 1.3113 - accuracy: 0.6185 - top5_acc: 0.8986 - macro_f1score: 0.3625\n","Epoch 00020: val_loss did not improve from 2.13200\n","\n","Epoch 00020: val_accuracy improved from 0.44336 to 0.45312, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/020.h5\n","97/97 [==============================] - 242s 2s/step - loss: 1.3113 - accuracy: 0.6185 - top5_acc: 0.8986 - macro_f1score: 0.3625 - val_loss: 2.5515 - val_accuracy: 0.4531 - val_top5_acc: 0.7663 - val_macro_f1score: 0.2355\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","97/97 [==============================] - ETA: 0s - loss: 1.2528 - accuracy: 0.6302 - top5_acc: 0.9026 - macro_f1score: 0.3783\n","Epoch 00021: val_loss did not improve from 2.13200\n","\n","Epoch 00021: val_accuracy did not improve from 0.45312\n","97/97 [==============================] - 240s 2s/step - loss: 1.2528 - accuracy: 0.6302 - top5_acc: 0.9026 - macro_f1score: 0.3783 - val_loss: 2.2697 - val_accuracy: 0.4473 - val_top5_acc: 0.7799 - val_macro_f1score: 0.2462\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","97/97 [==============================] - ETA: 0s - loss: 1.2214 - accuracy: 0.6393 - top5_acc: 0.9071 - macro_f1score: 0.3950\n","Epoch 00022: val_loss did not improve from 2.13200\n","\n","Epoch 00022: val_accuracy did not improve from 0.45312\n","97/97 [==============================] - 238s 2s/step - loss: 1.2214 - accuracy: 0.6393 - top5_acc: 0.9071 - macro_f1score: 0.3950 - val_loss: 2.4759 - val_accuracy: 0.4297 - val_top5_acc: 0.7415 - val_macro_f1score: 0.2306\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","97/97 [==============================] - ETA: 0s - loss: 1.1403 - accuracy: 0.6578 - top5_acc: 0.9208 - macro_f1score: 0.4095\n","Epoch 00023: val_loss did not improve from 2.13200\n","\n","Epoch 00023: val_accuracy did not improve from 0.45312\n","97/97 [==============================] - 238s 2s/step - loss: 1.1403 - accuracy: 0.6578 - top5_acc: 0.9208 - macro_f1score: 0.4095 - val_loss: 3.2115 - val_accuracy: 0.3789 - val_top5_acc: 0.7285 - val_macro_f1score: 0.2218\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","97/97 [==============================] - ETA: 0s - loss: 1.1349 - accuracy: 0.6646 - top5_acc: 0.9186 - macro_f1score: 0.4113\n","Epoch 00024: val_loss did not improve from 2.13200\n","\n","Epoch 00024: val_accuracy did not improve from 0.45312\n","97/97 [==============================] - 238s 2s/step - loss: 1.1349 - accuracy: 0.6646 - top5_acc: 0.9186 - macro_f1score: 0.4113 - val_loss: 125.1482 - val_accuracy: 0.0872 - val_top5_acc: 0.3255 - val_macro_f1score: 0.0300\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","97/97 [==============================] - ETA: 0s - loss: 1.0872 - accuracy: 0.6743 - top5_acc: 0.9265 - macro_f1score: 0.4243\n","Epoch 00025: val_loss did not improve from 2.13200\n","\n","Epoch 00025: val_accuracy did not improve from 0.45312\n","97/97 [==============================] - 238s 2s/step - loss: 1.0872 - accuracy: 0.6743 - top5_acc: 0.9265 - macro_f1score: 0.4243 - val_loss: 2.4156 - val_accuracy: 0.4518 - val_top5_acc: 0.7493 - val_macro_f1score: 0.2528\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","97/97 [==============================] - ETA: 0s - loss: 1.0140 - accuracy: 0.6920 - top5_acc: 0.9367 - macro_f1score: 0.4424\n","Epoch 00026: val_loss did not improve from 2.13200\n","\n","Epoch 00026: val_accuracy improved from 0.45312 to 0.45378, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/026.h5\n","97/97 [==============================] - 241s 2s/step - loss: 1.0140 - accuracy: 0.6920 - top5_acc: 0.9367 - macro_f1score: 0.4424 - val_loss: 2.2352 - val_accuracy: 0.4538 - val_top5_acc: 0.7858 - val_macro_f1score: 0.2521\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","97/97 [==============================] - ETA: 0s - loss: 0.9907 - accuracy: 0.7038 - top5_acc: 0.9369 - macro_f1score: 0.4564\n","Epoch 00027: val_loss improved from 2.13200 to 2.04642, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/027.h5\n","\n","Epoch 00027: val_accuracy improved from 0.45378 to 0.48047, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/027.h5\n","97/97 [==============================] - 242s 2s/step - loss: 0.9907 - accuracy: 0.7038 - top5_acc: 0.9369 - macro_f1score: 0.4564 - val_loss: 2.0464 - val_accuracy: 0.4805 - val_top5_acc: 0.8132 - val_macro_f1score: 0.2736\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","97/97 [==============================] - ETA: 0s - loss: 0.9397 - accuracy: 0.7146 - top5_acc: 0.9420 - macro_f1score: 0.4680\n","Epoch 00028: val_loss improved from 2.04642 to 2.03509, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/028.h5\n","\n","Epoch 00028: val_accuracy improved from 0.48047 to 0.49219, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/028.h5\n","97/97 [==============================] - 243s 3s/step - loss: 0.9397 - accuracy: 0.7146 - top5_acc: 0.9420 - macro_f1score: 0.4680 - val_loss: 2.0351 - val_accuracy: 0.4922 - val_top5_acc: 0.8060 - val_macro_f1score: 0.3059\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","97/97 [==============================] - ETA: 0s - loss: 0.8952 - accuracy: 0.7271 - top5_acc: 0.9484 - macro_f1score: 0.4815\n","Epoch 00029: val_loss did not improve from 2.03509\n","\n","Epoch 00029: val_accuracy did not improve from 0.49219\n","97/97 [==============================] - 239s 2s/step - loss: 0.8952 - accuracy: 0.7271 - top5_acc: 0.9484 - macro_f1score: 0.4815 - val_loss: 2.0938 - val_accuracy: 0.4844 - val_top5_acc: 0.8073 - val_macro_f1score: 0.2777\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","97/97 [==============================] - ETA: 0s - loss: 0.8476 - accuracy: 0.7406 - top5_acc: 0.9562 - macro_f1score: 0.4955\n","Epoch 00030: val_loss did not improve from 2.03509\n","\n","Epoch 00030: val_accuracy did not improve from 0.49219\n","97/97 [==============================] - 238s 2s/step - loss: 0.8476 - accuracy: 0.7406 - top5_acc: 0.9562 - macro_f1score: 0.4955 - val_loss: 2.6419 - val_accuracy: 0.4342 - val_top5_acc: 0.7520 - val_macro_f1score: 0.2445\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","97/97 [==============================] - ETA: 0s - loss: 0.5383 - accuracy: 0.8394 - top5_acc: 0.9790 - macro_f1score: 0.5870\n","Epoch 00031: val_loss improved from 2.03509 to 1.41352, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/031.h5\n","\n","Epoch 00031: val_accuracy improved from 0.49219 to 0.62435, saving model to /content/drive/My Drive/Colab Notebooks/Paper/MIT/No_GAN/model_output/1/ResNet50/031.h5\n","97/97 [==============================] - 240s 2s/step - loss: 0.5383 - accuracy: 0.8394 - top5_acc: 0.9790 - macro_f1score: 0.5870 - val_loss: 1.4135 - val_accuracy: 0.6243 - val_top5_acc: 0.8854 - val_macro_f1score: 0.3884\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","97/97 [==============================] - ETA: 0s - loss: 0.3636 - accuracy: 0.8919 - top5_acc: 0.9892 - macro_f1score: 0.6466\n","Epoch 00032: val_loss did not improve from 1.41352\n","\n","Epoch 00032: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 238s 2s/step - loss: 0.3636 - accuracy: 0.8919 - top5_acc: 0.9892 - macro_f1score: 0.6466 - val_loss: 1.4691 - val_accuracy: 0.6152 - val_top5_acc: 0.8906 - val_macro_f1score: 0.4047\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","97/97 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.9080 - top5_acc: 0.9916 - macro_f1score: 0.6637\n","Epoch 00033: val_loss did not improve from 1.41352\n","\n","Epoch 00033: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 238s 2s/step - loss: 0.3038 - accuracy: 0.9080 - top5_acc: 0.9916 - macro_f1score: 0.6637 - val_loss: 1.6092 - val_accuracy: 0.6029 - val_top5_acc: 0.8724 - val_macro_f1score: 0.3845\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","97/97 [==============================] - ETA: 0s - loss: 0.2902 - accuracy: 0.9108 - top5_acc: 0.9934 - macro_f1score: 0.6689\n","Epoch 00034: val_loss did not improve from 1.41352\n","\n","Epoch 00034: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.2902 - accuracy: 0.9108 - top5_acc: 0.9934 - macro_f1score: 0.6689 - val_loss: 1.6639 - val_accuracy: 0.6003 - val_top5_acc: 0.8750 - val_macro_f1score: 0.3927\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","97/97 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.9206 - top5_acc: 0.9954 - macro_f1score: 0.6792\n","Epoch 00035: val_loss did not improve from 1.41352\n","\n","Epoch 00035: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 238s 2s/step - loss: 0.2564 - accuracy: 0.9206 - top5_acc: 0.9954 - macro_f1score: 0.6792 - val_loss: 1.7345 - val_accuracy: 0.6042 - val_top5_acc: 0.8639 - val_macro_f1score: 0.4023\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","97/97 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9254 - top5_acc: 0.9961 - macro_f1score: 0.6831\n","Epoch 00036: val_loss did not improve from 1.41352\n","\n","Epoch 00036: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.2332 - accuracy: 0.9254 - top5_acc: 0.9961 - macro_f1score: 0.6831 - val_loss: 1.8721 - val_accuracy: 0.5827 - val_top5_acc: 0.8652 - val_macro_f1score: 0.3764\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","97/97 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.9341 - top5_acc: 0.9961 - macro_f1score: 0.6926\n","Epoch 00037: val_loss did not improve from 1.41352\n","\n","Epoch 00037: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 239s 2s/step - loss: 0.2168 - accuracy: 0.9341 - top5_acc: 0.9961 - macro_f1score: 0.6926 - val_loss: 1.7839 - val_accuracy: 0.5977 - val_top5_acc: 0.8672 - val_macro_f1score: 0.3930\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.9400 - top5_acc: 0.9977 - macro_f1score: 0.6987\n","Epoch 00038: val_loss did not improve from 1.41352\n","\n","Epoch 00038: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 235s 2s/step - loss: 0.1955 - accuracy: 0.9400 - top5_acc: 0.9977 - macro_f1score: 0.6987 - val_loss: 1.7979 - val_accuracy: 0.6042 - val_top5_acc: 0.8743 - val_macro_f1score: 0.4182\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9426 - top5_acc: 0.9983 - macro_f1score: 0.6958\n","Epoch 00039: val_loss did not improve from 1.41352\n","\n","Epoch 00039: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 239s 2s/step - loss: 0.1874 - accuracy: 0.9426 - top5_acc: 0.9983 - macro_f1score: 0.6958 - val_loss: 1.8815 - val_accuracy: 0.5898 - val_top5_acc: 0.8626 - val_macro_f1score: 0.3842\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1761 - accuracy: 0.9455 - top5_acc: 0.9984 - macro_f1score: 0.7000\n","Epoch 00040: val_loss did not improve from 1.41352\n","\n","Epoch 00040: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.1761 - accuracy: 0.9455 - top5_acc: 0.9984 - macro_f1score: 0.7000 - val_loss: 2.0901 - val_accuracy: 0.5736 - val_top5_acc: 0.8509 - val_macro_f1score: 0.3814\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1673 - accuracy: 0.9516 - top5_acc: 0.9982 - macro_f1score: 0.7065\n","Epoch 00041: val_loss did not improve from 1.41352\n","\n","Epoch 00041: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.1673 - accuracy: 0.9516 - top5_acc: 0.9982 - macro_f1score: 0.7065 - val_loss: 1.9429 - val_accuracy: 0.5859 - val_top5_acc: 0.8587 - val_macro_f1score: 0.3885\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.9549 - top5_acc: 0.9984 - macro_f1score: 0.7063\n","Epoch 00042: val_loss did not improve from 1.41352\n","\n","Epoch 00042: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.1534 - accuracy: 0.9549 - top5_acc: 0.9984 - macro_f1score: 0.7063 - val_loss: 1.9628 - val_accuracy: 0.5924 - val_top5_acc: 0.8672 - val_macro_f1score: 0.3816\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9541 - top5_acc: 0.9989 - macro_f1score: 0.7082\n","Epoch 00043: val_loss did not improve from 1.41352\n","\n","Epoch 00043: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 238s 2s/step - loss: 0.1525 - accuracy: 0.9541 - top5_acc: 0.9989 - macro_f1score: 0.7082 - val_loss: 1.9709 - val_accuracy: 0.5866 - val_top5_acc: 0.8542 - val_macro_f1score: 0.3918\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 0.9582 - top5_acc: 0.9987 - macro_f1score: 0.7139\n","Epoch 00044: val_loss did not improve from 1.41352\n","\n","Epoch 00044: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.1424 - accuracy: 0.9582 - top5_acc: 0.9987 - macro_f1score: 0.7139 - val_loss: 2.0402 - val_accuracy: 0.5794 - val_top5_acc: 0.8516 - val_macro_f1score: 0.3859\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.9598 - top5_acc: 0.9995 - macro_f1score: 0.7156\n","Epoch 00045: val_loss did not improve from 1.41352\n","\n","Epoch 00045: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.1337 - accuracy: 0.9598 - top5_acc: 0.9995 - macro_f1score: 0.7156 - val_loss: 2.1334 - val_accuracy: 0.5755 - val_top5_acc: 0.8490 - val_macro_f1score: 0.3844\n","Learning rate:  0.0001\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 46/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9630 - top5_acc: 0.9992 - macro_f1score: 0.7247\n","Epoch 00046: val_loss did not improve from 1.41352\n","\n","Epoch 00046: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 238s 2s/step - loss: 0.1243 - accuracy: 0.9630 - top5_acc: 0.9992 - macro_f1score: 0.7247 - val_loss: 1.9809 - val_accuracy: 0.6074 - val_top5_acc: 0.8724 - val_macro_f1score: 0.4049\n","Learning rate:  0.0001\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 47/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9591 - top5_acc: 0.9991 - macro_f1score: 0.7154\n","Epoch 00047: val_loss did not improve from 1.41352\n","\n","Epoch 00047: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 238s 2s/step - loss: 0.1330 - accuracy: 0.9591 - top5_acc: 0.9991 - macro_f1score: 0.7154 - val_loss: 2.1729 - val_accuracy: 0.5872 - val_top5_acc: 0.8548 - val_macro_f1score: 0.3869\n","Learning rate:  0.0001\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 48/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9634 - top5_acc: 0.9994 - macro_f1score: 0.7173\n","Epoch 00048: val_loss did not improve from 1.41352\n","\n","Epoch 00048: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.1234 - accuracy: 0.9634 - top5_acc: 0.9994 - macro_f1score: 0.7173 - val_loss: 2.1676 - val_accuracy: 0.5827 - val_top5_acc: 0.8587 - val_macro_f1score: 0.3771\n","Learning rate:  0.0001\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 49/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9649 - top5_acc: 0.9994 - macro_f1score: 0.7206\n","Epoch 00049: val_loss did not improve from 1.41352\n","\n","Epoch 00049: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 239s 2s/step - loss: 0.1155 - accuracy: 0.9649 - top5_acc: 0.9994 - macro_f1score: 0.7206 - val_loss: 2.3749 - val_accuracy: 0.5658 - val_top5_acc: 0.8490 - val_macro_f1score: 0.3728\n","Learning rate:  0.0001\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 50/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9644 - top5_acc: 0.9997 - macro_f1score: 0.7196\n","Epoch 00050: val_loss did not improve from 1.41352\n","\n","Epoch 00050: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 238s 2s/step - loss: 0.1133 - accuracy: 0.9644 - top5_acc: 0.9997 - macro_f1score: 0.7196 - val_loss: 2.1324 - val_accuracy: 0.5827 - val_top5_acc: 0.8646 - val_macro_f1score: 0.3799\n","Learning rate:  0.0001\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 51/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9694 - top5_acc: 0.9997 - macro_f1score: 0.7292\n","Epoch 00051: val_loss did not improve from 1.41352\n","\n","Epoch 00051: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 239s 2s/step - loss: 0.1070 - accuracy: 0.9694 - top5_acc: 0.9997 - macro_f1score: 0.7292 - val_loss: 2.0969 - val_accuracy: 0.5827 - val_top5_acc: 0.8535 - val_macro_f1score: 0.3826\n","Learning rate:  0.0001\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 52/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9724 - top5_acc: 0.9996 - macro_f1score: 0.7170\n","Epoch 00052: val_loss did not improve from 1.41352\n","\n","Epoch 00052: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 239s 2s/step - loss: 0.0968 - accuracy: 0.9724 - top5_acc: 0.9996 - macro_f1score: 0.7170 - val_loss: 2.1428 - val_accuracy: 0.6055 - val_top5_acc: 0.8652 - val_macro_f1score: 0.3943\n","Learning rate:  0.0001\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 53/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9657 - top5_acc: 0.9996 - macro_f1score: 0.7275\n","Epoch 00053: val_loss did not improve from 1.41352\n","\n","Epoch 00053: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 236s 2s/step - loss: 0.1142 - accuracy: 0.9657 - top5_acc: 0.9996 - macro_f1score: 0.7275 - val_loss: 2.0481 - val_accuracy: 0.5944 - val_top5_acc: 0.8581 - val_macro_f1score: 0.3898\n","Learning rate:  0.0001\n","\n","Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 54/70\n","97/97 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9698 - top5_acc: 1.0000 - macro_f1score: 0.7221\n","Epoch 00054: val_loss did not improve from 1.41352\n","\n","Epoch 00054: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 238s 2s/step - loss: 0.1041 - accuracy: 0.9698 - top5_acc: 1.0000 - macro_f1score: 0.7221 - val_loss: 2.2403 - val_accuracy: 0.5807 - val_top5_acc: 0.8535 - val_macro_f1score: 0.3786\n","Learning rate:  0.0001\n","\n","Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 55/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9736 - top5_acc: 0.9999 - macro_f1score: 0.7267\n","Epoch 00055: val_loss did not improve from 1.41352\n","\n","Epoch 00055: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.0935 - accuracy: 0.9736 - top5_acc: 0.9999 - macro_f1score: 0.7267 - val_loss: 2.1061 - val_accuracy: 0.6029 - val_top5_acc: 0.8757 - val_macro_f1score: 0.3807\n","Learning rate:  0.0001\n","\n","Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 56/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9743 - top5_acc: 0.9997 - macro_f1score: 0.7354\n","Epoch 00056: val_loss did not improve from 1.41352\n","\n","Epoch 00056: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.0914 - accuracy: 0.9743 - top5_acc: 0.9997 - macro_f1score: 0.7354 - val_loss: 2.0471 - val_accuracy: 0.5905 - val_top5_acc: 0.8633 - val_macro_f1score: 0.3789\n","Learning rate:  0.0001\n","\n","Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 57/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9730 - top5_acc: 0.9996 - macro_f1score: 0.7283\n","Epoch 00057: val_loss did not improve from 1.41352\n","\n","Epoch 00057: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.0955 - accuracy: 0.9730 - top5_acc: 0.9996 - macro_f1score: 0.7283 - val_loss: 2.2408 - val_accuracy: 0.5736 - val_top5_acc: 0.8535 - val_macro_f1score: 0.3759\n","Learning rate:  0.0001\n","\n","Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 58/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9762 - top5_acc: 0.9998 - macro_f1score: 0.7351\n","Epoch 00058: val_loss did not improve from 1.41352\n","\n","Epoch 00058: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 238s 2s/step - loss: 0.0879 - accuracy: 0.9762 - top5_acc: 0.9998 - macro_f1score: 0.7351 - val_loss: 2.0984 - val_accuracy: 0.5807 - val_top5_acc: 0.8483 - val_macro_f1score: 0.3753\n","Learning rate:  0.0001\n","\n","Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 59/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9773 - top5_acc: 0.9997 - macro_f1score: 0.7349\n","Epoch 00059: val_loss did not improve from 1.41352\n","\n","Epoch 00059: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 235s 2s/step - loss: 0.0861 - accuracy: 0.9773 - top5_acc: 0.9997 - macro_f1score: 0.7349 - val_loss: 2.0552 - val_accuracy: 0.5964 - val_top5_acc: 0.8737 - val_macro_f1score: 0.3933\n","Learning rate:  0.0001\n","\n","Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 60/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9742 - top5_acc: 0.9996 - macro_f1score: 0.7262\n","Epoch 00060: val_loss did not improve from 1.41352\n","\n","Epoch 00060: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 236s 2s/step - loss: 0.0923 - accuracy: 0.9742 - top5_acc: 0.9996 - macro_f1score: 0.7262 - val_loss: 2.1704 - val_accuracy: 0.5710 - val_top5_acc: 0.8613 - val_macro_f1score: 0.3832\n","Learning rate:  1e-05\n","\n","Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 61/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9835 - top5_acc: 0.9999 - macro_f1score: 0.7423\n","Epoch 00061: val_loss did not improve from 1.41352\n","\n","Epoch 00061: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.0659 - accuracy: 0.9835 - top5_acc: 0.9999 - macro_f1score: 0.7423 - val_loss: 1.9246 - val_accuracy: 0.6120 - val_top5_acc: 0.8652 - val_macro_f1score: 0.4185\n","Learning rate:  1e-05\n","\n","Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 62/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9912 - top5_acc: 0.9998 - macro_f1score: 0.7498\n","Epoch 00062: val_loss did not improve from 1.41352\n","\n","Epoch 00062: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 236s 2s/step - loss: 0.0450 - accuracy: 0.9912 - top5_acc: 0.9998 - macro_f1score: 0.7498 - val_loss: 1.8622 - val_accuracy: 0.6061 - val_top5_acc: 0.8685 - val_macro_f1score: 0.4136\n","Learning rate:  1e-05\n","\n","Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 63/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9921 - top5_acc: 0.9998 - macro_f1score: 0.7464\n","Epoch 00063: val_loss did not improve from 1.41352\n","\n","Epoch 00063: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.0412 - accuracy: 0.9921 - top5_acc: 0.9998 - macro_f1score: 0.7464 - val_loss: 1.8421 - val_accuracy: 0.6094 - val_top5_acc: 0.8704 - val_macro_f1score: 0.4106\n","Learning rate:  1e-05\n","\n","Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 64/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9925 - top5_acc: 1.0000 - macro_f1score: 0.7479\n","Epoch 00064: val_loss did not improve from 1.41352\n","\n","Epoch 00064: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 236s 2s/step - loss: 0.0401 - accuracy: 0.9925 - top5_acc: 1.0000 - macro_f1score: 0.7479 - val_loss: 1.8212 - val_accuracy: 0.6133 - val_top5_acc: 0.8678 - val_macro_f1score: 0.4100\n","Learning rate:  1e-05\n","\n","Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 65/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9936 - top5_acc: 1.0000 - macro_f1score: 0.7505\n","Epoch 00065: val_loss did not improve from 1.41352\n","\n","Epoch 00065: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 239s 2s/step - loss: 0.0377 - accuracy: 0.9936 - top5_acc: 1.0000 - macro_f1score: 0.7505 - val_loss: 1.7968 - val_accuracy: 0.6159 - val_top5_acc: 0.8659 - val_macro_f1score: 0.3939\n","Learning rate:  1e-05\n","\n","Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 66/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9941 - top5_acc: 0.9998 - macro_f1score: 0.7425\n","Epoch 00066: val_loss did not improve from 1.41352\n","\n","Epoch 00066: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 237s 2s/step - loss: 0.0386 - accuracy: 0.9941 - top5_acc: 0.9998 - macro_f1score: 0.7425 - val_loss: 1.7680 - val_accuracy: 0.6159 - val_top5_acc: 0.8717 - val_macro_f1score: 0.4016\n","Learning rate:  1e-05\n","\n","Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 67/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9938 - top5_acc: 0.9999 - macro_f1score: 0.7498\n","Epoch 00067: val_loss did not improve from 1.41352\n","\n","Epoch 00067: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 235s 2s/step - loss: 0.0405 - accuracy: 0.9938 - top5_acc: 0.9999 - macro_f1score: 0.7498 - val_loss: 1.7441 - val_accuracy: 0.6191 - val_top5_acc: 0.8698 - val_macro_f1score: 0.4156\n","Learning rate:  1e-05\n","\n","Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 68/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9934 - top5_acc: 1.0000 - macro_f1score: 0.7416\n","Epoch 00068: val_loss did not improve from 1.41352\n","\n","Epoch 00068: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 236s 2s/step - loss: 0.0408 - accuracy: 0.9934 - top5_acc: 1.0000 - macro_f1score: 0.7416 - val_loss: 1.7113 - val_accuracy: 0.6178 - val_top5_acc: 0.8704 - val_macro_f1score: 0.4149\n","Learning rate:  1e-05\n","\n","Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 69/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9942 - top5_acc: 0.9998 - macro_f1score: 0.7448\n","Epoch 00069: val_loss did not improve from 1.41352\n","\n","Epoch 00069: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 235s 2s/step - loss: 0.0402 - accuracy: 0.9942 - top5_acc: 0.9998 - macro_f1score: 0.7448 - val_loss: 1.7070 - val_accuracy: 0.6224 - val_top5_acc: 0.8704 - val_macro_f1score: 0.4189\n","Learning rate:  1e-05\n","\n","Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 70/70\n","97/97 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9953 - top5_acc: 1.0000 - macro_f1score: 0.7482\n","Epoch 00070: val_loss did not improve from 1.41352\n","\n","Epoch 00070: val_accuracy did not improve from 0.62435\n","97/97 [==============================] - 234s 2s/step - loss: 0.0396 - accuracy: 0.9953 - top5_acc: 1.0000 - macro_f1score: 0.7482 - val_loss: 1.7024 - val_accuracy: 0.6204 - val_top5_acc: 0.8685 - val_macro_f1score: 0.4148\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6J7qM483RMST"},"source":["### 2) ResNet50 Evaluate"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"zg1v-zqzRMSU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605477908495,"user_tz":-540,"elapsed":27561927,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"f1dc73f7-b3fe-45b4-c202-c9d2445a63a8"},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["12/12 [==============================] - 983s 82s/step - loss: 1.7258 - accuracy: 0.5990 - top5_acc: 0.8828 - macro_f1score: 0.3903\n","[Test Loss: 1.7258 /  Test Top-1 Accuracy: 0.5990 / Test Top-5 Accuracy: 0.8828 / Test Macro f1: 0.3903]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mWbV6MR0RMSY"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_HOf2qVRMSe"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DLCKPSirRMSi"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'ResNet50.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWoU3mT7RMSn"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yovtXW4cRMSs","colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"status":"ok","timestamp":1605477909531,"user_tz":-540,"elapsed":27562930,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"50608780-cf72-4b6e-ac7d-be4675f7f67f"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3gUVffHP4cOAVSKShEBpYjSiwVEURBUBEFUEAQsiA17r9gbr/oTQUV9QRQBFQUEFJUXFUWkiyCgiBFCJ7RQQiC5vz/OLtmE3c0m2WQnyfk8zzyzM3PnztnZ3e+eOffec8U5h2EYhlHwKRZrAwzDMIzoYIJuGIZRSDBBNwzDKCSYoBuGYRQSTNANwzAKCSbohmEYhQQTdI8hIl+JyIBol40lIhIvIh3zoN7vReRG3+u+IvJNJGVzcJ1aIrJXRIrn1FbDyA9M0KOA78fuX9JE5EDAdt/s1OWcu9g590G0y3oREXlIRH4Msr+KiKSIyBmR1uWcG+ecuyhKdmX4A3LOrXPOlXfOpUajft81amX63jgR2RewfW6UrlNNRKaKyEbfNWpHeN73IrJTREpHww4jfzBBjwK+H3t551x5YB1wWcC+cf5yIlIidlZ6ko+Ac0SkTqb9vYHfnXPLY2BTvhDwJ+H/3gA0Ddg3J0qXSgO+Bq6I9ASf6J8LOKBblOyI9Nr2G8kFJuh5iIicLyIJIvKgiGwGRovIcSIyTUS2+TygaSJSM+CcwDDCQBH5SUSG+cr+IyIX57BsHRH5UUSSROQ7ERkhIh+FsDsSG58RkZ999X0jIlUCjl8rIv+KSKKIPBrq/jjnEoD/AddmOtQfGJuVHZlsHigiPwVsdxKRVSKyW0TeBCTg2Cki8j+ffdtFZJyIHOs79iFQC/jS5yk/ICK1fd5tCV+Z6j6vd4eIrBGRQQF1DxWRT0RkrO/erBCRVqHuQYj3cozv/G2++/iYiBQLeJ8/i8ibvve2SkQuDHOPtzjnRgILsmFCf2AeMAbIENITkZNE5HOfbYm+e+s/NkhEVvre9x8i0sK334nIqQHlxojIs77XOfmNVBKR0aJPHTtFZLJv/3IRuSygXEnf59s8G++9QGOCnvecCFQCTgZuQu/5aN92LeAA8GbIs+FMYDVQBXgZeF9EJAdlPwbmA5WBoRwtooFEYuM1wHXA8UAp4D4AEWkEvOWrv7rvekFF2McHgbaISAOgmc/e7N4rfx1VgM+Bx9B78TfQNrAI8ILPvtOAk9B7gnPuWjI+Zb0c5BITgATf+b2A50XkgoDj3XxljgWmRmJzJoYDxwB1gfNQgb0u4PiZvvdUBXgS+FxEKmXzGuHoD4zzLZ1F5AQA0TaEacC/QG2gBvo+EZEr0XvYH6iI3oPECK+X3d/Ih0A54HT0+/eab/9YoF9AuUuATc65JRHaUfBxztkSxQWIBzr6Xp8PpABlwpRvBuwM2P4euNH3eiCwJuBYOfQx+MTslEV/FIeBcgHHPwI+ivA9BbPxsYDtW4Gvfa+fACYEHIvz3YOOIeouB+wBzvFtPwdMyeG9+sn3uj8wL6CcoAJ8Y4h6LweWBPsMfdu1ffeyBCr+qUCFgOMvAGN8r4cC3wUcawQciOAeO+BUoLjvfjUKODYY+D7gfW4EJOD4fODaLOov4btG7SzKtQMOAVV826uAu32vzwa2ASWCnDcTuDPcewvYHgM8m5PfCFANDSMdF6RcdSAJqOjb/gx4INLfbmFYzEPPe7Y555L9GyJSTkTe8T1K7wF+BI6V0D0oNvtfOOf2+16Wz2bZ6sCOgH0A60MZHKGNmwNe7w+wqXpg3c65fYTx1Hw2fQr09z1N9EU9rZzcKz+ZbXCB2yJygohMEJENvno/Qr3dSPDfy6SAff+i3qqfzPemjEQeG64ClPTVGar+Db73FHi8uoicK+mNqisivF5mBgDfOOe2+7Y/Jj3schLwr3PucJDzTkKfGnJCdn4jJ6H3f2fmSpxzG4GfgSt8IbSL0aeMIoMJet6TOZ3lvUAD4EznXEWgvW9/qDBKNNgEVBKRcgH7TgpTPjc2bgqs23fNylmc8wFwFdAJqAB8mUs7MtsgZHy/z6OfS2Nfvf0y1RkuBelG9F5WCNhXC9iQhU2Rsh31kE8OU3+NTGG3WsBG59wcl96oenp2LywiZdHP4TwR2eyLad8NNBWRpuifYq0Qf07rgVNCVL0ffRLzc2Km49n5jaxH7/+xIa71Afp5Xgn84pyL1udSIDBBz38qoDHBXb6455N5fUHn3L/AQmCoiJQSkbOBy8KckhsbPwO6ikg7ESkFPE3W37M5wC5gFBquScmlHdOB00Wkp0987iCjiFQA9gK7RaQGcH+m87eg8eujcM6tB+YCL4hIGRFpAtyAevm5xmnXyE+A50SkgoicDNyTqf7jgTt8jX5Xou0AM0LVKSJlAH/3w9K+7WBcjoaTGqFhjma+uuegYaz56J/liyIS53v//raJ94D7RKSlKKf6bAdYClwjIsVFpAvaLhCOkJ+7c24T8BUw0td4WlJE2gecOxloAdyJ70mvKGGCnv+8DpRFPbF5aJey/KAvGgNNBJ4FJgIHQ5TNsY3OuRXAbeij+iZgJxq/DneOQ398J5PxR5gjO3zhgiuBF9H3Ww99FPfzFPqj342K/+eZqngBeExEdonIfUEu0QeNq28EvgCedM59F4ltETIE2AesBX5C7+V/A47/ir6n7WibQy/nXLgGyAPoHxhoTPxAiHIDgNFOu1Ru9i9og2Rf1EO+DI31r0M/16sBnHOf+mz5GI1jT0YbOkHF9TL0T7uv71g4svrcr0WfYlYBW4G7/AeccweASUAdjv5cCz2SMRRnFBVEZCKwyjmX508IRvQQkYFo4267WNviVUTkCaC+c65floULGeahFxFEpLVo/+tivsfe7mTtKRlGgcIXorkBDd8VOUzQiw4not389gJvALe4otQ/1yj0iA7wWg985Zw7KqVEUcBCLoZhGIUE89ANwzAKCTFLhFOlShVXu3btWF3eMAyjQLJo0aLtzrmqwY7FTNBr167NwoULY3V5wzCMAomI/BvqmIVcDMMwCgkm6IZhGIUEE3TDMIxCgqdmBzl06BAJCQkkJydnXdjwNGXKlKFmzZqULFky1qYYRpEhS0EXkf8CXYGtzrmj5nj0ZX37PzSZ/H5goHNucU6MSUhIoEKFCtSuXZvQczgYXsc5R2JiIgkJCdSpk3l2OcMw8opIQi5jgC5hjl+MJgqqh8428lZOjUlOTqZy5com5gUcEaFy5cr2pGUY+UyWgu4bQrsjTJHuwFinzEMT0VfLqUEm5oUD+xwNI/+JRgy9Bhlnv0nw7duUuaCI3IR68dSqVSsKlzYMw4geaWmwdy8kJcG+fZCSknEpVgxKlDh6KVkyfUlJgf370xd/fXv2pC9du0KrbE0dHhn52ijqnBuFLwtaq1atPJdEJjExkQsv1AnUN2/eTPHixalaVQdkzZ8/n1KlSoU8d+HChYwdO5Y33ngj7DXOOecc5s6dGxVbe/XqxYIFCxg4cCBvvhl+HuJmzZrRsGFDJkyYkOtrG0ZBYdkyGD8e/vlHhXXfPl3v36/Ce+hQ+rJ/vx7PD0480buCvoGM03vVJHrTceUrlStXZunSpQAMHTqU8uXLc9996fMbHD58mBIlgt+yVq1a0SqCTygaYg7ai+SZZ55h+fLlLF++PGzZlStXkpqaypw5c9i3bx9xcXFRscEwvMjGjfDxx/DhhyroJUpAnTpQvrwuVatCuXJQqlRGzzouTo9XqKBLXByULq3l/GWdg8OH05dDh9LX/qV0aa3fv8TFQcWK6Uv58urp5wXREPSpwO0iMgE4E9jtmyaqUDBw4EDKlCnDkiVLaNu2Lb179+bOO+8kOTmZsmXLMnr0aBo0aMD333/PsGHDmDZtGkOHDmXdunWsXbuWdevWcdddd3HHHXcAUL58efbu3cv333/P0KFDqVKlCsuXL6dly5Z89NFHiAgzZszgnnvuIS4ujrZt27J27VqmTZuWwa64uDjatWvHmjVrsnwP48eP59prr2XlypVMmTKFa665BoAFCxZw5513sm/fPkqXLs2sWbMoV64cDz74IF9//TXFihVj0KBBDBkyJPo31jCiiHPwyy/w6qvwxRcaOmnTBoYPh6uvVhEvCkTSbXE8cD5QRUQS0Pn9SgI4595G5zK8BFiDdlu8LhqG3XUX+JzlqNGsGbz+evbPS0hIYO7cuRQvXpw9e/YwZ84cSpQowXfffccjjzzCpEmTjjpn1apVzJ49m6SkJBo0aMAtt9xyVJ/sJUuWsGLFCqpXr07btm35+eefadWqFYMHD+bHH3+kTp069OnTJ6dv9wgTJ07k22+/ZdWqVQwfPpxrrrmGlJQUrr76aiZOnEjr1q3Zs2cPZcuWZdSoUcTHx7N06VJKlCjBjh3h2sMNI2f4s3YHaztPSoI//4TVq2HLlvS4c1KShklq14Z69aB+fahbF2bNUiH/9Vc47ji4/3647jpo0CBf35InyFLQnXNhFcU3H+RtUbPIg1x55ZUUL14cgN27dzNgwAD++usvRIRDhw4FPefSSy+ldOnSlC5dmuOPP54tW7ZQs2bNDGXatGlzZF+zZs2Ij4+nfPny1K1b90j/7T59+jBqVM4nX1m4cCFVqlShVq1a1KhRg+uvv54dO3awYcMGqlWrRuvWrQGoWLEiAN999x0333zzkdBSpUqVQtZtFH6cg82bYc0aXf7+W0MK3bpBkybBBTk1VcstWwa//67rVatUkA8c0CU5GYoXh2OPTV9Kl4a1a2FTkOd7f9iieHHYsCH9D8HPKafAm2/CwIFatqjiqZGigeTEk84rAmPOjz/+OB06dOCLL74gPj6e888/P+g5pUuXPvK6ePHiHD58OEdlsssXX3zBU089BcB7773H+PHjWbVqFf5UxXv27GHSpEmcddZZub6WUfhITob582HOHPjxRw1jJCWlHy9eXMMZTzyh3nGPHtC5s8atFy+GRYv0ydrfuFismHrSjRqpaJctm74cPgy7dqUvBw5oXfXrq3fdoAFUr67x7MCmq4MHVfj//BP++kvLX3qp2lbU8ayge5Xdu3dTo0YNAMaMGRP1+hs0aMDatWuJj4+ndu3aTJw4MVvn9+jRgx49egCQlpZGjx49+P3336levToAs2fP5plnnmHAgAFs2rSJBQsW0Lp1a5KSkihbtiydOnXinXfeoUOHDkdCLuale48DB1TMVq1K934bN9aw4mmnpTfgxcfDggW6/PknJCamLzt3qoftb/QrVUr3paToNc44A/r21fWpp+pSqxbs2AFTp2qs+o034D//0fLlykHz5nDDDWpH06ZqS9my0X3vpUtrvaedFt16CwMm6NnkgQceYMCAATz77LNceumlUa+/bNmyjBw5ki5duhAXF3ckJBKM2rVrs2fPHlJSUpg8eTLffPMNjRo1OnJ8zpw51KhR44iYA7Rv354//viDxMREJk6cyJAhQzhw4ABly5blu+++48Ybb+TPP/+kSZMmlCxZkkGDBnH77bdH/X0a4dm3T0MVixdrLHn79vRl27aMYQe/KB88qNulSkHDhlomMTF9X/362jh4xhlQubLGm0Uy9rOuWBHatdMl1P/4CSfAoEG67N6tXnytWupRm5ccW2I2p2irVq1c5gkuVq5cyWn2t8vevXspX748zjluu+026tWrx9133x1rs7KNfZ4Z2b5dRXr1avWqV6+GhAQV23Ll1JMtXVr7TK9apaEN0JDDCSdAlSq6VK6s3fAaNtSlXj09788/YckSXZYvhxo1tK9z69bqvYcZRmEUIERkkXMuaB9p89A9yLvvvssHH3xASkoKzZs3Z/DgwbE2ycgBaWnqYc+YAdOna9jD7z/FxaWL8aFDGkLZt0896lNOgV69oEULXWrWDN74mBl/GMLXK9Uogpige5C77767QHrkRZU9e+Dff7Whzt8bZM0a9ca3blUxbtMGnnoKzj5bhbxGjchE2jCygwm6YUSIc9oQ+fXX2gNk7VoV8sxd9StVUi+7c2fo1Am6dCk6A1uM2GKCbhhhSEuD2bPh889VyNeu1f1162oj4Fln6UCXk0/WfaecErox0TDyGhN0wwjC7t0wZgyMHKmNjeXKwYUXwr33qsddt26sLTSMozFBNwwfW7bA3LnqiY8bp42UZ52lSZ569YIyZWJtoWGExyaJDqBDhw7MnDkzw77XX3+dW265JeQ5559/Pv7ul5dccgm7du06qszQoUMZNmxY2GtPnjyZP/7448j2E088wXfffZcd84OSmJhIhw4dKF++fET9yZs1a0bv3r1zfd2CQGoqfPopDBigg2ZOPBF69oSxY+Gqq2DhQu1j3a+fiblRMDAPPYA+ffowYcIEOnfufGTfhAkTePnllyM6f8aMGTm+9uTJk+nateuRgUFPP/10jusKxNLsHk1yMnzwAbzyiuYcqVoV2raFm2+Gc86Bli21X7dhFDTMQw+gV69eTJ8+nRTf2Of4+Hg2btzIueeeyy233EKrVq04/fTTefLJJ4OeX7t2bbZv3w7Ac889R/369WnXrh2rV68+Uubdd9+ldevWNG3alCuuuIL9+/czd+5cpk6dyv3330+zZs34+++/GThwIJ999hkAs2bNonnz5jRu3Jjrr7+eg74hgbVr1+bJJ5+kRYsWNG7cmFWrVh1lkz/NbpkIXEx/mt2LLrqIKVOmHNm/YMECzjnnHJo2bUqbNm1ISkoiNTWV++67jzPOOIMmTZowfPjwCO9y/nPokDZmzpoFzz+vg3JuvllHSk6apMmgvvgC7rtPBd3E3CioeNdDj0H+3EqVKtGmTRu++uorunfvzoQJE7jqqqsQEZ577jkqVapEamoqF154IcuWLaNJkyZB61m0aBETJkxg6dKlHD58mBYtWtCyZUsAevbsyaBBgwB47LHHeP/99xkyZAjdunWja9eu9OrVK0NdycnJDBw4kFmzZlG/fn369+/PW2+9xV133QVAlSpVWLx4MSNHjmTYsGG89957Ob49hSnN7sGD8Oij2jtl3ToNr/jp2FFj5B06WF9wo3BhHnom/GEX0HCLPx/5J598QosWLWjevDkrVqzIEO/OzJw5c+jRowflypWjYsWKdOvW7cix5cuXc+6559K4cWPGjRvHihUrwtqzevVq6tSpQ/369QEYMGAAP/7445HjPXv2BKBly5bEx8fn6D1DxjS7F154IUuWLGHHjh2sXr36qDS7/lzwgwcP9mSa3XXroH17TRrVtCk89BC8/752P1y/Hr79Fi64wMTcKHx410OPUf7c7t27c/fdd7N48WL2799Py5Yt+eeffxg2bBgLFizguOOOY+DAgSQnJ+eo/oEDBzJ58mSaNm3KmDFj+P7773Nlrz8Fb3bT7xbWNLvffKND31NSNJzi+78zjCKBeeiZKF++PB06dOD6668/4p3v2bOHuLg4jjnmGLZs2cJXX30Vto727dszefJkDhw4QFJSEl9++eWRY0lJSVSrVo1Dhw4xbty4I/srVKhAUmDiaR8NGjQgPj7+yFRzH374Ieedd16u32ePHj1YunQpS5cupUWLFnzyySf8/vvvxMfHEx8fz5QpUxg/fjwNGjQ4kmbXb//hw4ePpNn1/4nEOuTiHDz7rPYRr1ZNe6iYmBtFDRP0IPTp04fffvvtiKA3bdqU5s2b07BhQ6655hratm0b9vwWLVpw9dVX07RpUy6++OIMKXCfeeYZzjzzTNq2bUvDhg2P7O/duzevvPIKzZs35++//z6yv0yZMowePZorr7ySxo0bU6xYMW6++eZsvZ/atWtzzz33MGbMGGrWrHlUuCjSNLtNmzalU6dOJCcnc+ONN1KrVi2aNGlC06ZN+fjjj7NlU7T59lt4/HHo0wfmzdNUsYZR1LD0uUaekZ+fZ69e8MMPmo7WeqkYhZlw6XPNQzcKPJs3w5QpOp+kiblRlDFBNwo8Y8bo/JS+3qCGUWTxnKDHKgRkRJf8+hzT0uDdd+G88yxubhieEvQyZcqQmJhool7Acc6RmJgY0ejU3DJ7to4CvemmPL+UYXgeT/VDr1mzJgkJCWzbti3Wphi5pEyZMtSsWTPPrzNqlOYfty6KhuExQS9ZsiR16tSJtRlGAWHrVs3Bcvvtlg3RMMBjIRfDyA4ffKCJt6wx1DAUE3SjQOKcNoa2a6cz3RuGYYJuFFB++EEnbLbGUMNIxwTdKJB88AEce6yOEDUMQzFBNwokc+fC+edD2bKxtsQwvIMJulHg2LkT/vwT2rSJtSWG4S1M0I0Chy+Trwm6YWTCBN0ocMyfr7MNtQqab84wii4m6EaBY/58aNgQjjkm1pYYhreISNBFpIuIrBaRNSLyUJDjtURktogsEZFlInJJ9E01DO1/Pn++hVsMIxhZCrqIFAdGABcDjYA+ItIoU7HHgE+cc82B3sDIaBtqGKATQG/ZYoJuGMGIxENvA6xxzq11zqUAE4Dumco4oKLv9THAxuiZaBjpzJ+vaxN0wziaSAS9BrA+YDvBty+QoUA/EUkAZgBDglUkIjeJyEIRWWgZFY2cMH++zkrUpEmsLTEM7xGtRtE+wBjnXE3gEuBDETmqbufcKOdcK+dcq6pVq0bp0kZRYv58aN4cSpWKtSWG4T0iEfQNwEkB2zV9+wK5AfgEwDn3C1AGqBINAw3Dz+HDsHChhVsMIxSRCPoCoJ6I1BGRUmij59RMZdYBFwKIyGmooFtMxYgqK1fC/v0m6IYRiiwF3Tl3GLgdmAmsRHuzrBCRp0Wkm6/YvcAgEfkNGA8MdDaPnBFlfv1V1ybohhGciGYscs7NQBs7A/c9EfD6D6BtdE0zjIzMnw/HHQennhprSwzDm9hIUaPA4B9QJBJrSwzDm5igGwWCfftg+XILtxhGOEzQjQLBkiWQmmqCbhjhMEE3CgT+BtHWrWNrh2F4GRN0o0Awfz6cfDKccEKsLTEM72KCbhQI5s+HM8+MtRWG4W1M0A1P4xx89BHEx1u4xTCywgTd8Czr10PXrnDtteqdDxgQa4sMw9uYoBueIy0N3noLTj8dvv8eXnsNfv4ZLJ+bYYQnopGihpFfLF0Kt90Gc+dCx44wahTUqRNrqwyjYGAeuuEJdu6E22+Hli3hr79g9Gj45hsTc8PIDiboRkxJTYX334cGDTTMcuutsHo1DBxoQ/wNI7uYoBsxIS0NPv0UzjgDbrwR6teHRYtg+HBNwGUYRvYxQTfyFefgyy+hRQu46iooVgw++wx+/BGaNYu1dYZRsDFBN/KNBQugfXvo1k2TbY0bB8uWwRVXqLAbhpE77Gdk5DkJCdC/vybW+usveOcd+OMPuOYaKF481tYZRuHBui0aeUZqKjz/PLzwgsbMH35YlwoVYm2ZYRROTNCNPCEpCfr0genT4cor4eWXoXbtWFtlGIUbE3Qj6qxbB5ddBitWwMiRcMstsbbIMIoGJuhGVFmwQBs99+9X77xz51hbZBhFB2sUNaJCUhL85z9w3nlQpowO3TcxN4z8xTx0I1ds2QJvvKGhlV27oFMn+PBDm4jCMGKBCbqRbQ4d0iyIEydqrvKUFOjZE+6/3yahMIxYYoJuRERqKsycCZMmweTJsGMHxMVpjvL77oN69WJtoWEYJuhGliQlQa9emv2wYkVt9OzVCy66CMqWjbV1hmH4MUE3wrJpE1x6qQ7RHzECbrgBSpeOtVWGYQTDBN0IycqVcPHFsH27JtS6+OJYW2QYRjhM0I2gzJkD3btDyZLaANqqVawtMgwjK6wfunGEtDT46ivtP96+PVSpAr/8YmJuGAUFE3SDAwc0Pn7aaXDJJfD77/DMM/Drr1C3bqytMwwjUizkUoRJS4Px4zUD4vr10Lq15ijv1QtKlYq1dYZhZBcT9CLKTz/BPfdo7pUWLeCDD+D88wvQPJ5PPQVjx8JNN8GgQVCpUqwtMox09u3TORXnzYONG3Xo9Iknpi9168Ixx0T9siboRYzkZNXADz+E6tVVyPv1K4AzBv3wg86c8dBDKu79+8Odd2rcyDByQ2qq9tfdujXj/rQ0+PdfncV81Spdtm5VYT72WF3i4nT/smVaD+i+ffsy1jVihM6IHmVM0IsQSUnac2X2bHjsMdXCuLhYW5VDEhKgRw949FH4v/+DMWN0KqT+/eGll9QLMooeycnw3Xeag6Jq1fBl9+7VBqOlS+G332DNGoiP1/zPhw6FP/ekk6BhQ12SkjSR0bp1sGcPnHIKPPKI2nDmmdq7YP9+TXy0ebMuTZtG7S0HIs65rAuJdAH+DygOvOecezFImauAoYADfnPOXROuzlatWrmFCxfmxGYjB2zfrv3IlyxR7evXL9YW5QLn9J/o1lth2DDdt22bpnt89VVN9zh0KAwZov0uCzs7d2ry+XbtYm1J7Hn4YXjxRY0dtmwJXbpot62SJdO96lWrdA7Ev/7S7xKod92ggc7C4l9OPPHoR9eaNaF+fShfPp/fWDoissg5F7zvmXMu7IKK+N9AXaAU8BvQKFOZesAS4Djf9vFZ1duyZUtn5A/r1jnXsKFzZco49+WXsbYmCmzf7hw499prRx9bvdq5iy/W46ed5tzo0c799JNzCQnOpaZqmT17dN+bbzo3aJBzo0ZFfu1//nHu9dedu/lmvVasSU117rzz9P2+8kreXuvwYecGDHCuaVPnPv/cubS0yM5LSXFu0iS973nJli3OxcU5d8klzj39tHNt2zpXrJjeG/9SsqR+L3r2dO6pp5ybMsW5f/+N/L14AGChC6XXoQ64dLE+G5gZsP0w8HCmMi8DN2ZVV+Bigp63pKU598cfzo0c6VytWs5VrOjcDz/E2qoosXSpfnU/+yz48bQ056ZOda5OnaN/zNWqZdxXrpyuX3wx9PX++su5oUOda9Ys/bxSpZwrW9a54cPT/yhiwVtvqT2NG+v6mWfy5jppac7deqteo3p1Xbdp49ysWeHPO3zYud69tXy1as599FHuxDPcuffeqwK+cmX6vh079M9n6lTn/vzTuUOHcn5tj5BbQe+Fhln829cCb2YqM9kn6j8D84AuIeq6CVgILKxVq1b+3YEiQlqacxMnOnfllc4df3y69tSt6+NV61oAAB+zSURBVNzixbG2LopMm6ZvbN688OVSUvTH/dVXKnwPPqge5rPP6qPK+vUqONdco/W9+mrG89PSnHvjDedKl3ZOxLl27ZwbNkwFfsOG9CeBCy/Ux6DskpKi5+VU4P7917ny5Z3r2FGF6tpr1Z5HHom+x/nkk1r3Aw/otd5/37maNXVfp07qPWQmLc25G2/UMnfd5VyrVvr63HP1Tzk7HDrk3GOPOXfCCc7NnXv08Y0b9RH02mtz9PYKEvkh6NOAL4CSQB1gPXBsuHrNQ48uW7Y41727fqI1azrXr59z773n3Jo1BeppMjLeflvfaEJCdOo7dMi5Xr20zhEjdN+WLfroDroOdq20NOfeeUcf8485xrmPP876WklJzn36qXN9++o54NzJJzs3eLBzX3zh3O7dkdmcluZcly567bVrdV9qarqA3nNP9D74N9/UOq+7LmOdBw7on+Bxx+kTy/PP65+U37577tHzHn003b5333WucmX1pO+/PzKPecOG9LBShQoq6pn/QO+807nixfXPtpCTHyGXt4HrArZnAa3D1WuCHj0+/9y5KlXUkfzPf2IbAcgXHntMf7yHD0evzpQU57p1SxfDE07QGzp8eNbC+Pffzp1zjp47ZIhzBw8GL3PVVVonqKgNHKiCePnl6mmDcyVKOHfRRc7997/O7dwZ+ppjxmj5N97IuD811bnbb9djJ56odb/wgnOzZzu3d2/495GW5ty2bRmXDz/Up5Pu3UOL7+bN6X+IzZs7t2SJxqf99yPz/UtMdO6mm9KfbrZvD23TzJnOVa2qobGxY51bsUJFvUUL5/bt0zIJCXpfr78+/PsrJORW0EsAa32et79R9PRMZboAH/heV/F56JXD1WuCnnu2bXOuf3/9FFu0cG758lhblE8MHKiPIdEmOTk9jHLGGc4tWxb5uSkpzt19t5579tnpHv2+fc49/rgKTlycepLff3+0OB48qPsfeEBjZP6Y/2WXacPu8uXp52zc6Nyxx2qjX7B/77Q0Fb9rr3Wufv302FuVKs7973/B7d+8WUMhge0L/qV9e+f278/6HkyapH+ExYvreQMHhvcuRo9Wz75OnYz3Oi3NuV9/1YZnEf0sAkM606bp/quuSo/tlyiR/qRSyMmVoOv5XAL86evt8qhv39NAN99rAV4F/gB+B3pnVacJes7Zu1fDwBUq6G/niSfSn3SLBB07OnfWWXlT94EDGhKJRMCCMXGiCvfxx2uvk1q19Gd2zTWRh4jS0pybP1+fFGrUSBfW0qWda9lSG0BLl3Zu1arI6tu+XUXwtNP0C/PGGxm95oUL9Q+ybFntHTJ8ePry7rvZ652SmKg9hwYPjiyc8ssv2lgaF6ehtIcfTm/MLlVKRd3viQfy0kta5tZb9Y9v8ODIbSzg5FrQ82IxQc8+KSn6nT/xRP3kLr88eFtUoadBA33E9yorVmg/UXCuSZPcdS9KTXXu99+1d8h99+mfWbVqR4daImH3bvX4QcMTycnOjRunjYm1asWu5XzDBufOPFPtKl7cuc6d1XsPF3JKS9OGIr/w//tvvpkba0zQCwErVqg2gD5p//xzrC2KEWlp6s3dfXesLQnPnj3OTZ/uvW5yqakaAoJ0T7h9e20EjiUHDmi8fOvW7J3TrZtzzz2Xd3Z5kHCCbkP/PY5z8N57mqakfHn4/HO4/PIClEQr2uzerXkxataMtSXhqVBBcxF7jWLF4Omndej5DTfAbbfBa6/FfkRtmTI6SW12z5kyJW/sKaCYoHuYXbs0kdann0LHjppQq8inKElI0LXXBd3rXHGF5sIpcFnZjHCYoHuUf/6BCy5Q/XrxRbj/fvvtASbo0cS+UIUOE3QPkpoK114LO3Zo3vIzz4y1RR7CBN0wQmKC7kGGDYOff9YQi4l5JhIStAGhWrVYW2IYnsOeuTzG0qXw+OM6DVzfvrG2xoOsX68NCbFuxDMMD2KC7iGSkzXUUrkyvP12Ee7JEo6EBJ1cwDCMo7CQi4d4/HFYvhxmzFBRN4KQkKCzxBiGcRTmoXuE77/XCXduvllnFjJCkJBgDaKGEQIT9Bhz4AA8+aTOlHXKKekzqhlB2LNHFxN0wwiKCXqMcA4mT4ZGjXTgXs+eOpF9gZ20OT/YsEHXJuiGERSLoceA3bvhmms0Vn766TB7Npx/fqytKgBYH3TDCIt56DFgyBCYOVNj5kuWmJhHzPr1ujZBN4ygmIeez3z6qQ4YevJJuOeeWFtTwPB76DVqxNYOw/Ao5qHnIxs3ai+W1q3h0UdjbU0BJCEBTjgBSpWKtSWG4UlM0PMJ5+C667RXy0cf2UDHI6xcqSlchw+H7dvDl7Uui4YRFhP0fGLkSPjmG42b168fa2s8wLZtKuSNG2vC9zvugOrVtbvP1Klw6NDR55igG0ZYTNDzgVWr4L77dMDQzTfH2poYc/AgvPwynHoqvPMO3HKLdkdctkxF/eefoXt3aNsW0tIynmuCbhhhMUHPY+bMgU6dtH/5++8X8fwsaWlw5ZXw4IPQvr3mORg+HKpUUU992DAV7ZdeggUL4Lvv0s/dtw927jRBN4wwmKDnEamp8NRT2iWxTBkNtxT5jK/PPQdffgmvv67rYDlZSpbU+faqVoURI9L3Wx90w8gSE/Q8YP16nW1o6FAdQLR4MbRoEWurYszXX2tfzX79NLQSjtKl4cYbYdo0+Pdf3ecXdMu0aBghMUGPMjNmQLNmsGgRjB2rfc4rVIi1VTHmn3/0n61xY42bRxJ3GjxY1++8o2vz0A0jS0zQo0RqKjzxBFx6qTqRixdrbvMiz4EDOiFxWhp8/jmUKxfZeSefDF27ag+YgwdtUJFhRICNFI0C27erA/rttzBwoHZRLFs21laFYc0aSEmB006Lfivtrl2waRNs3qzLp59qfoMvv9R0ktnhttu0C+Nnn6mgV6miDRKGYQTFBD2XLF6svey2bYN334UbbigAPVk6dYL4eH2U6NxZc/deeCEce2zu6n3/fY19Z+bZZ9Xbzi4dO0K9eto4WrmyhVsMIwtM0HNBcrL2whOBuXM90vC5Y4c2KobKw3v4sDY0XnSRBvc/+UTDGnFxGvTv2TPn116+XD3o//5X5/30L8cdl7P6ihXTfur33APHHAPnnptz2wyjCGAx9Fzw2muwdq06pp4Qc1Dv++67Qx/fskXzEPTsqaGM7dvhxx/hjDM01v3ii3o8J+zerZ50nz7QoYOGdHIq5n4GDtT41e7d5qEbRhaYoOeQDRu0W/Xll6uGRpW0NJgyRb3T3bsjP+/gQfjtN82PEopNm3Tt7xRfsqR6vrNnQ+/e8PDDKqIHD2bf7j171JOOJscdB3376mvrsmgYYTFBzyEPPaTRi//8J4qVpqTAmDHqLV9+Obz9NowfH/n5a9Zodxv/zD7B2LhR19WrZ9xftix8/LF2nh87VuPXWSXLyszu3dEXdNDG0WLFoEGD6NdtGIUIE/QcMHeuZky8916oWzdKlU6dqr1ArrtO08N+/LFm8Zo0KfI6/J75xo2hwyahBB20MeDJJ/VPZMGC8KGbYOzeDRUrZu+cSGjWTPuy9+gR/boNoxBhgp5N0tLSEwM+/HCUKnUObr8dypeHr77Sbn59+mice/ZsbeiMBL+gHzwIiYnBy2zapMJ9/PGh6+ndGwYN0gbTbdsifx95EXLxU6uWeumGYYTEfiHZZPRoHQX68suqv1Hht980X8D992sXQn+/x549NYTy5ZeR1RMYOw8Vdtm4USeJKJFFB6ebb9YQ0OjRkV0b8i7kYhhGRJigZ4MdO9QrP+ccHUgUNaZNUxG/9NKM+1u10obAzz+PrJ6VK6FSJX0dTtCDhVsyc/rpmhHx7bePTmMbirwKuRiGERERCbqIdBGR1SKyRkQeClPuChFxItIqeiZ6hzvuUFF/880oDx768kto00Y950BE1EufORP27g1fR1oarF6tWcEgtKBv2hR52sdbb9XY9cyZWZc9dEiH+ZuHbhgxI0tBF5HiwAjgYqAR0EdEGgUpVwG4E/g12kZ6gS++gHHjdC7Q5s2jWPHmzTB/fuiRlD17akz8q6/C1/PvvyqoHTroH0FuPXTQRsgTToC33sq67J49ujZBN4yYEYmH3gZY45xb65xLASYA3YOUewZ4CUiOon2eYPt2DSk3a5YHkztPn67ryy4LfrxtW80NnlXYxR8/b9JEGzyDCfrhw7B1a+SCXqqU5jKYPj09jW0o/P3lLeRiGDEjEkGvAawP2E7w7TuCiLQATnLOTQ9XkYjcJCILRWThtuz0nogxt92mk+WMHZsHE85Pm6Zx8iZNgh8vXlz7pE+bprkGQrFqla5PO00zEgYTdP8o0ezMtHHTTXrOqFHhy5mHbhgxJ9eNoiJSDHgVuDerss65Uc65Vs65VlWrVs3tpfOFTz7RZehQTecdVZKTdSqjrl3DB+V79tQYeuCUbJlZuVI9+cqVQwt6uD7ooQhMY5uSErqc30M3QTeMmBGJoG8AAsdc1/Tt81MBOAP4XkTigbOAqYWhYXTLFm0XbN0aHnggDy4wezbs3x863OLnggs0lBEu7LJypXrnoIIdTND9w/6zI+igKQi2btWGhFBYyMUwYk4kgr4AqCcidUSkFNAbmOo/6Jzb7Zyr4pyr7ZyrDcwDujnnFuaJxfnIkCHqGH/wQdbdtnPEl1/qhA8dOoQvV6qUiv6UKRoHz4xzKuj+OTpr1NCBRZlDNH4PPbuTm3buDHXqhG8ctZCLYcScLAXdOXcYuB2YCawEPnHOrRCRp0WkW14bGCu+/lrnZnjssXTHN6o4p3HxTp0im7ShZ0/tM/njj0cf27ZNj/kN9c/q4xdwPxs36mjLcKNEg1GsmE6/9MMPobtPWsjFMGJORDF059wM51x959wpzrnnfPuecM5NDVL2/ILunR84oA2hDRro4M1skZCgDYnhEmQBLFumo0OzCrf46dJFE2gFy+3i7+GSWdAz27BpU2SjRINRq5auQ6UUsJCLYcQcGykahOef1zznb72lc0VEzKZNGu9+912N04TDP5w/8+jQUJQrp2U/++zosEsoQQ/moWc33OKncmVdh8ors2ePhoZsijjDiBkm6JlYtQpeegn69cs6tJ2BrVt1GreNG1VQw/VIARX01q11Rp9I6dtXr5O57pUrdcYhf77wUB56dgYVZcafUiCch27hFsOIKSboATinvVri4mDYsGycmJio+cPj43UQTp8+8PPP2oMlGFu26OjQSMMtfi6+WOf9HDcu4/5Vq7RB1N/18dhjNTwTLOSSW0EP5aFbHhfDiDkm6AF8/LH2JHzhhaPTqoRk1y6dn/PPPzWn+XnnqbinpMBPPwU/Z8oUXXfLZpty6dI6iekXX8C+fen7A7ssggp75r7ohw6pd5+XIRfz0A0jppig+0hM1LmIzzxT2zQj5rrr4PfftY94x466r107jSeHCrtMmqSTWYQaHRqOfv1UzP1/Cnv3auOqv8uin8yC7h8lmlMP3T83qIVcDMOzmKD7uP12Hd7/zjvZmEfhhx9g8mR46im45JL0/XFxmmM3mKDv3An/+59OyJyTlI3t2mms3B92CRzyH0hmQc/poCI/Zcpow6yFXAzDs5igo0P7J0zQ2deaNo3wpLQ0uO8+Fde77jr6eMeOOvNQ5nk5p07VXipXXJEzY4sV02TsM2dq//PMPVz81KiRcSq6nA4qCqRyZQu5GIaHKfKCvnlz+vD+Bx/MxokTJsDChfDcc9oAmRl/+OV//8u4f9Ik/RNo3TrHNtO3r85k9MknKuglSsCpp2YsU6NGxqnocpLHJTOVKlnIxTA8TJEWdOdg8GANSY8dm43xNsnJ8Mgjmhi9b9/gZVq21BBEYNglKUmTcfXsmbsZMho31vj7uHEq6KeeCiVLZiyTuevipk05GyUaSKVKwT1059RDt5CLYcSUIi3oY8dqBOT5549uUwzL8OGaH3zYsNAB9xIltCN7oKBPn65ec07DLYH07Qu//KKpAILlJvB74n5B988lWrx4zq8ZKuSyd6+GoMxDN4yYUmQFff16nVKufXu4885snJiYqGGWSy9Nn+4tFB076hRua9fq9qRJKqrnnJNju4/Qp496+YE5XALJ7KHnZlCRn1AhF0vMZRieoMgK+sMPa9vk6NHZ6NUC8MwzGjp5+eWsy/rj6LNm6SCjGTN0WrfceMl+TjpJ/40g+OOFv/EzMOQSDUHfsSO9odWP5XExDE9QJAV93Tpt07z5ZqhbNxsn/vILjBwJN94IjY6aVvVoGjRITwPwzTcq6tEIt/jp31/XwbrmlCqVcSq63ORx8VO5sv4LZs64aJkWDcMT5EWWb8/z+usarQjW2zAkf/+tIztPPlmD7pEgol76tGkaU69USUeSRouBA+GMM0IPUPL3RfePEo2Ghw4adqlQIX2/hVwMwxMUOQ991y5Nhti7d3ouqyxJTNQ8Ks5p2MQ/DD4SOnbU8ydOhO7dj+6NkhuKFYM2bUIf9wv6li26HS1Bz9wwaiEXw/AERU7Q335bIwb33RfhCcnJOknzunU63L5evexd8MILdZ2aGt1wSyT4BT0ag4ogdD4XC7kYhicoUoJ+8CD83//pJEERjQhNS9NcLT/9pPnN27bN/kWrVdN4e8WK6Y2k+YV/Krp//tHtaIZcArGQi2F4giIVQ//4Yx0ZOnZshCc89ZS2nr74Ilx9dc4v/PLLGuvJ1mwZUcDfdXGhbwKpvAy5iED58rmr3zCMXFFkBD0tTccBNW0aoaP87bfaRXHAAHjggdxdPNJZiaJNoKAXKwZVq+auvnCCXqFCNvt/GoYRbYqMoH/1FfzxB3z4YQSj7jdt0jS1p50GI0bkbph+LPEL+qJFOjNSbvu/ly6tmSSDhVws3GIYMafICPorr2ivliwjJ6mpOqw+KUkTa8XF5Yt9eYJf0JOStE98NAiWz8UScxmGJygSz8jz52vq8rvuiqDX4LPP6rRFI0bA6afni315hn8qOsh9Dxc/wfK5WC50w/AERULQX3lFHchBg7IoOHu2NoT266eDdgo6/qnoIPcNon6C5XOxkItheIJCL+hr1ujscLfemnFw41Hs36+hlvr14a23Cm7cPDN+IY+Wh24hF8PwLIU+hv7qqzrqfsiQLApOn66NoWPHFq7ud9H20C3kYhiepVB76Fu3ajbF/v0jcFA//VSTWXXokC+25Rt5EXLJnHHRQi6G4QkKtaC/+aaODs1ymP++fZpA64oropPa1kv4BT2aIZfDh7XnDEBKiqZHMEE3jJhTaAV9714V9O7dI+ixN2MGHDgAV16ZL7blK507a5bIYJNg5ITM+VwsMZdheIZCK+j//S/s3BnhIM9PPtFwi3/CiMLEaadpUrFgE1nnhMyjRS2Pi2F4hkIp6IcPa2No27Zw9tlZFN63TxtEC2O4JS/InKDLMi0ahmcolL1cJkzQOZzfeCOCwtOna7jlqqvy3K5CgYVcDMOzFDoPfc8eePBBaNYMunaN4IRPP9WJm889N89tKxRYyMUwPEuh89Aff1y7k3/xRQTJ//buVQ/9uuss3BIpFnIxDM9SqDz0RYu0Z8stt4Sfme0IFm7JPqVK6cArC7kYhueISNBFpIuIrBaRNSLyUJDj94jIHyKyTERmicjJ0Tc1PKmpMHiwdlaJdA7nI+GWdu3y1LZCR+Dwfwu5GIZnyFLQRaQ4MAK4GGgE9BGRRpmKLQFaOeeaAJ8BL0fb0KwYMUI99Ndfj1Bb/OGWXr0s3JJdKlfOGHIpU0Y9d8MwYkokHnobYI1zbq1zLgWYAHQPLOCcm+2c2+/bnAfUjK6Z4dmwAR57TMfQRBw9mT5dRzgWxsFEeU2gh255XAzDM0Qi6DWA9QHbCb59obgB+CrYARG5SUQWisjCbdu2RW5lFtx1Fxw6BCNHZiNJ4tdfq6dp4ZbskznkYuEWw/AEUW0UFZF+QCvglWDHnXOjnHOtnHOtquZ2fksfCxfCZ5/BI49A3brZOHHePDjnHAu35ITMIRcTdMPwBJEI+gbgpIDtmr59GRCRjsCjQDfn3MHomJc1zz+vE/PceWc2Ttq5E1atgrPOyjO7CjWBGRct5GIYniESQV8A1BOROiJSCugNTA0sICLNgXdQMd8afTODs2KF9je/445sasr8+bo2Qc8ZlSppt6KkJAu5GIaHyFLQnXOHgduBmcBK4BPn3AoReVpEuvmKvQKUBz4VkaUiMjVEdVHlhRd0Duc77sjmifPmabC9des8savQ4x/+n5hoIRfD8BARjRR1zs0AZmTa90TA645RtitL/v4bxo+Hu+9O15eImTcPzjgjiznpjJAEDv+3kItheIYCO1L0pZegZEm4995snpiWBr/+auGW3OAX9O3bNexiHrpheIICKegbNsCYMXD99TmYiOevv7RR9Mwz88K0ooH/kWjdOm0YNUE3DE9QIAV92DB1tCOavCIzv/6qa/PQc47fQ1+7VtcWcjEMT1DgBH3bNnjnHejXD2rXzkEF8+apAEVrSraiyHHH6To+XtfmoRuGJyhwgv7mmzpi/6GjUoRFyLx5mooxy9y6RkhKldIG5X/+0W0TdMPwBAVO1e65R5MkNmyYg5P37YNlyyzcEg0qVbKQi2F4jAIn6Mcco9N/5ohFi3RAjAl67qlUSeNfYB66YXiEAifouWLePF1bD5fcE9j53wTdMDxB0RP0U0+FKlVibUnBx9/TBSzkYhgeoegIunPwyy8WbokWfkEvVkynpDMMI+YUHUFfvx42b7ZwS7Twh1wqVsxGEnrDMPKSoiPoNqAouvg9dAu3GIZnKDqCPm+ezn3ZpEmsLSkc+AXdGkQNwzMUfEFPSYEBA2DSpPDl5s2Dli1tMuNo4Q+5mKAbhmco+IL+8sswdiz07QuLFwcvs2aN9kG3+Hn0sJCLYXiOgi3oq1bBM89A165QtaqOOPLPdeln0ya46CLtiXHLLbGxszBiIRfD8BwFV9DT0mDQIJ2y6L33NOSycaN66qmpWmbXLujcGbZuhRkztA+6ER0s5GIYnqPgCvqoUfDTT/Dqq3DCCZpwa/hwmDkTnn4a9u+Hyy5TL37yZD1uRA9/xkUTdMPwDBFNQec5NmzQZOgdO2qDqJ9Bg7Tx8+mnYfp0jalPmKDljOhSsiS8/z6ce26sLTEMw0fBE3Tn4NZb4fBhTYweOKhFBEaMgN9+00bQkSPhqqtiZ2th5/rrY22BYRgBFDxB/+wzmDpVpy2qW/fo42XLathl2TK44IL8t88wDCNGFLwYesWK0L073Hln6DJVqpiYG4ZR5Ch4HnrnzroYhmEYGSh4HrphGIYRFBN0wzCMQoIJumEYRiHBBN0wDKOQYIJuGIZRSDBBNwzDKCSYoBuGYRQSTNANwzAKCeKci82FRbYB/wY5VAXYns/m5BazOX8oaDYXNHvBbM4vcmPzyc65qsEOxEzQQyEiC51zrWJtR3Ywm/OHgmZzQbMXzOb8Iq9stpCLYRhGIcEE3TAMo5DgRUEfFWsDcoDZnD8UNJsLmr1gNucXeWKz52LohmEYRs7wooduGIZh5AATdMMwjEKCpwRdRLqIyGoRWSMiD8XanmCIyH9FZKuILA/YV0lEvhWRv3zr42JpYyAicpKIzBaRP0RkhYjc6dvvZZvLiMh8EfnNZ/NTvv11RORX3/djooiUirWtmRGR4iKyRESm+bY9bbOIxIvI7yKyVEQW+vZ5+btxrIh8JiKrRGSliJztcXsb+O6tf9kjInfllc2eEXQRKQ6MAC4GGgF9RKRRbK0KyhigS6Z9DwGznHP1gFm+ba9wGLjXOdcIOAu4zXdfvWzzQeAC51xToBnQRUTOAl4CXnPOnQrsBG6IoY2huBNYGbBdEGzu4JxrFtAv2svfjf8DvnbONQSaovfas/Y651b77m0zoCWwH/iCvLLZOeeJBTgbmBmw/TDwcKztCmFrbWB5wPZqoJrvdTVgdaxtDGP7FKBTQbEZKAcsBs5ER9aVCPZ98cIC1PT9OC8ApgFSAGyOB6pk2ufJ7wZwDPAPvs4cXrc3iP0XAT/npc2e8dCBGsD6gO0E376CwAnOuU2+15uBE2JpTChEpDbQHPgVj9vsC10sBbYC3wJ/A7ucc4d9Rbz4/XgdeABI821Xxvs2O+AbEVkkIjf59nn1u1EH2AaM9oW13hOROLxrb2Z6A+N9r/PEZi8JeqHA6V+u5/qCikh5YBJwl3NuT+AxL9rsnEt1+phaE2gDNIyxSWERka7AVufcoljbkk3aOedaoKHO20SkfeBBj303SgAtgLecc82BfWQKVXjM3iP42k66AZ9mPhZNm70k6BuAkwK2a/r2FQS2iEg1AN96a4ztyYCIlETFfJxz7nPfbk/b7Mc5twuYjYYrjhWREr5DXvt+tAW6iUg8MAENu/wf3rYZ59wG33orGtttg3e/GwlAgnPuV9/2Z6jAe9XeQC4GFjvntvi288RmLwn6AqCer1dAKfTxZGqMbYqUqcAA3+sBaJzaE4iIAO8DK51zrwYc8rLNVUXkWN/rsmjMfyUq7L18xTxls3PuYedcTedcbfS7+z/nXF88bLOIxIlIBf9rNMa7HI9+N5xzm4H1ItLAt+tC4A88am8m+pAeboG8sjnWDQWZGg0uAf5E46WPxtqeEDaOBzYBh1CP4QY0VjoL+Av4DqgUazsD7G2HPs4tA5b6lks8bnMTYInP5uXAE779dYH5wBr00bV0rG0NYf/5wDSv2+yz7TffssL/m/P4d6MZsND33ZgMHOdle302xwGJwDEB+/LEZhv6bxiGUUjwUsjFMAzDyAUm6IZhGIUEE3TDMIxCggm6YRhGIcEE3TAMo5Bggm4YhlFIMEE3DMMoJPw/R0V6Ra8WHRgAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"IA98syIrYvyu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPiie2jka1EN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0z6BwcAulnw","executionInfo":{"status":"ok","timestamp":1606112133819,"user_tz":-540,"elapsed":1053,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / ResNet50"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c","executionInfo":{"status":"ok","timestamp":1606112134253,"user_tz":-540,"elapsed":1480,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak","executionInfo":{"status":"ok","timestamp":1606112134254,"user_tz":-540,"elapsed":1478,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pFcw51AuDG4","executionInfo":{"status":"ok","timestamp":1606112143859,"user_tz":-540,"elapsed":11079,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["model=load_model(os.path.join(dir,'model_output',number,'ResNet50','031.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWlrnY9EuDG-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606112527442,"user_tz":-540,"elapsed":394649,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"c23568a8-4632-49fc-b700-c0c373885ab2"},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["12/12 [==============================] - 332s 28s/step - loss: 1.4342 - accuracy: 0.6061 - top5_acc: 0.8789 - macro_f1score: 0.3910\n","[Test Loss: 1.4342 /  Test Top-1 Accuracy: 0.6061 / Test Top-5 Accuracy: 0.8789 / Test Macro f1: 0.3910]\n","\n"],"name":"stdout"}]}]}
