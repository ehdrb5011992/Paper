{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"14.SE-DenseNet121.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ucbQyskZRiX_","executionInfo":{"status":"ok","timestamp":1604974907430,"user_tz":-540,"elapsed":799,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["#모형 출처 : https://github.com/titu1994/keras-squeeze-excite-network"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [SE-DenseNet121]\n"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original SE-DenseNet121\n","```\n","1) Support Functions\n","2) Almost orginal SE-DenseNet121\n","```\n","3. SE-DenseNet121\n","```\n","1) SE-DenseNet121\n","2) SE-DenseNet121 Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages\n"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","executionInfo":{"status":"ok","timestamp":1604974981901,"user_tz":-540,"elapsed":75248,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"df365530-91df-4fe0-f341-bbec977ca6f6","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","executionInfo":{"status":"ok","timestamp":1604974981902,"user_tz":-540,"elapsed":75237,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"b2c68138-265d-43f2-a2c4-036572088ec5","colab":{"base_uri":"https://localhost:8080/"}},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1604974984630,"user_tz":-540,"elapsed":77918,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1604974985165,"user_tz":-540,"elapsed":78440,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","executionInfo":{"status":"ok","timestamp":1604974985167,"user_tz":-540,"elapsed":78426,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"ad420239-5d88-4b1e-b4ad-f5a66d03afcf","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","executionInfo":{"status":"ok","timestamp":1604974985170,"user_tz":-540,"elapsed":78415,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"cd64cdf0-fa5e-4780-803b-1ef83d32e2e1","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.__version__"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.3.0'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","executionInfo":{"status":"ok","timestamp":1604974990921,"user_tz":-540,"elapsed":84119,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"57b1857e-cfe5-4086-9ca2-b85d788fce84","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Kf057Rw2yigs","executionInfo":{"status":"ok","timestamp":1604974990923,"user_tz":-540,"elapsed":84100,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"ba0b52a7-b3dc-407c-ec55-f45ac829d427","colab":{"base_uri":"https://localhost:8080/"}},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 3104972061247312680\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 7733624407175754262\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 15212205197745990468\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15695488000\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 4145250184094658417\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TqbqUuWahvH1","executionInfo":{"status":"ok","timestamp":1604974990926,"user_tz":-540,"elapsed":84090,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"4412dc51-4e75-4f07-f16a-ac16738d5c8d","colab":{"base_uri":"https://localhost:8080/"}},"source":["!cat /proc/cpuinfo"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"BeJ7UtuOEgWY","executionInfo":{"status":"ok","timestamp":1604974990927,"user_tz":-540,"elapsed":84073,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CALTECH'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 224 # sizes after cropping\n","super_size = 256 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 64\n","weight_decay = 1e-3\n","epochs = 70"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1604974990928,"user_tz":-540,"elapsed":84066,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbP99pIGoIUp","executionInfo":{"status":"ok","timestamp":1604974990928,"user_tz":-540,"elapsed":84042,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1604974990929,"user_tz":-540,"elapsed":84029,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wzhKX9OVoIUw"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"Iz9u1paNoIUx","executionInfo":{"status":"ok","timestamp":1604974990929,"user_tz":-540,"elapsed":84022,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1604974990930,"user_tz":-540,"elapsed":84017,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"c2IcuMY2oIU3","executionInfo":{"status":"ok","timestamp":1604974990930,"user_tz":-540,"elapsed":84013,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"4t6c_JewoIU7","executionInfo":{"status":"ok","timestamp":1604975055958,"user_tz":-540,"elapsed":149023,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"c5c20919-79af-4bf5-b7d8-7c4ab2113df0","colab":{"base_uri":"https://localhost:8080/"}},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Found 24509 images belonging to 257 classes.\n","Found 2980 images belonging to 257 classes.\n","Found 3118 images belonging to 257 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gn_DwVVV1qmT"},"source":["## 2. Support Functions & Almost Original SE-DenseNet121\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"GrcgSgWh1qmT"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS","executionInfo":{"status":"ok","timestamp":1604975055961,"user_tz":-540,"elapsed":149018,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60:\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"j4GEYryamRkV","executionInfo":{"status":"ok","timestamp":1604975055963,"user_tz":-540,"elapsed":149015,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["def squeeze_excite_block(input, reduction_ratio=16, weight_decay=weight_decay):\n","\n","    init = input\n","    channel_axis = -1\n","    filters = init.get_shape()[channel_axis]\n","    se_shape = (1, 1, filters)\n","\n","    se = GlobalAveragePooling2D()(init)\n","    se = Reshape(se_shape)(se)\n","    se = Dense(filters // reduction_ratio, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay), use_bias=False)(se)\n","    se = Dense(filters, activation='sigmoid', kernel_regularizer=l2(weight_decay), use_bias=False)(se)\n","\n","    x = multiply([init, se])\n","    return x"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"aBovAVC3gVsB","executionInfo":{"status":"ok","timestamp":1604975055964,"user_tz":-540,"elapsed":149012,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["def __conv_block(ip, nb_filter, bottleneck=False, dropout_rate=None, weight_decay=weight_decay):\n","\n","    concat_axis = -1\n","\n","    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n","    x = Activation('relu')(x)\n","\n","    if bottleneck:\n","        inter_channel = nb_filter * 4  # Obtained from https://github.com/liuzhuang13/DenseNet/blob/master/densenet.lua\n","\n","        x = Conv2D(inter_channel, (1, 1), kernel_initializer='he_uniform', padding='same', use_bias=False,\n","                   kernel_regularizer=l2(weight_decay))(x)\n","        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","        x = Activation('relu')(x)\n","\n","    x = Conv2D(nb_filter, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n","    if dropout_rate:\n","        x = Dropout(dropout_rate)(x)\n","\n","    return x"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEOp1A-0gdee","executionInfo":{"status":"ok","timestamp":1604975055966,"user_tz":-540,"elapsed":149009,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["def __dense_block(x, nb_layers, nb_filter, growth_rate, bottleneck=False, dropout_rate=None, weight_decay=weight_decay,\n","                  grow_nb_filters=True, return_concat_list=False):\n","\n","    concat_axis = -1\n","\n","    x_list = [x]\n","\n","    for i in range(nb_layers):\n","        cb = __conv_block(x, growth_rate, bottleneck, dropout_rate, weight_decay)\n","        x_list.append(cb)\n","\n","        x = concatenate([x, cb], axis=concat_axis)\n","\n","        if grow_nb_filters:\n","            nb_filter += growth_rate\n","\n","    # squeeze and excite block\n","    x = squeeze_excite_block(x)\n","\n","    if return_concat_list:\n","        return x, nb_filter, x_list\n","    else:\n","        return x, nb_filter"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"-K3RzQuCgdc_","executionInfo":{"status":"ok","timestamp":1604975055968,"user_tz":-540,"elapsed":149009,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["def __transition_block(ip, nb_filter, compression=1.0, weight_decay=weight_decay):\n","\n","    concat_axis = -1\n","\n","    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n","    x = Activation('relu')(x)\n","    x = Conv2D(int(nb_filter * compression), (1, 1), kernel_initializer='he_uniform', padding='same', use_bias=False,\n","               kernel_regularizer=l2(weight_decay))(x)\n","    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n","\n","    # squeeze and excite block\n","    x = squeeze_excite_block(x)\n","\n","    return x"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2HhTzaFgdbi","executionInfo":{"status":"ok","timestamp":1604975055969,"user_tz":-540,"elapsed":149007,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["def __create_dense_net(nb_classes, img_input, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1,\n","                       nb_layers_per_block=-1, bottleneck=False, reduction=0.0, dropout_rate=None, weight_decay=weight_decay,\n","                       subsample_initial_block=False, activation='softmax'):\n","\n","    concat_axis = -1\n","\n","    if reduction != 0.0:\n","        assert 1.0 >= reduction > 0.0, 'reduction value must lie between 0.0 and 1.0'\n","\n","    # layers in each dense block\n","    if type(nb_layers_per_block) is list or type(nb_layers_per_block) is tuple:\n","        nb_layers = list(nb_layers_per_block)  # Convert tuple to list\n","\n","        assert len(nb_layers) == nb_dense_block, 'If list, nb_layer is used as provided. ' \\\n","                                                 'Note that list size must be (nb_dense_block)'\n","        final_nb_layer = nb_layers[-1]\n","        nb_layers = nb_layers[:-1]\n","    else:\n","        if nb_layers_per_block == -1:\n","            assert (depth - 4) % 3 == 0, 'Depth must be 3 N + 4 if nb_layers_per_block == -1'\n","            count = int((depth - 4) / 3)\n","            nb_layers = [count for _ in range(nb_dense_block)]\n","            final_nb_layer = count\n","        else:\n","            final_nb_layer = nb_layers_per_block\n","            nb_layers = [nb_layers_per_block] * nb_dense_block\n","\n","    # compute initial nb_filter if -1, else accept users initial nb_filter\n","    if nb_filter <= 0:\n","        nb_filter = 2 * growth_rate\n","\n","    # compute compression factor\n","    compression = 1.0 - reduction\n","\n","    # Initial convolution\n","    if subsample_initial_block:\n","        initial_kernel = (7, 7)\n","        initial_strides = (2, 2)\n","    else:\n","        initial_kernel = (3, 3)\n","        initial_strides = (1, 1)\n","\n","    x = Conv2D(nb_filter, initial_kernel, kernel_initializer='he_uniform', padding='same',\n","               strides=initial_strides, use_bias=False, kernel_regularizer=l2(weight_decay))(img_input)\n","\n","    if subsample_initial_block:\n","        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","        x = Activation('relu')(x)\n","        x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","\n","    # Add dense blocks\n","    for block_idx in range(nb_dense_block - 1):\n","        x, nb_filter = __dense_block(x, nb_layers[block_idx], nb_filter, growth_rate, bottleneck=bottleneck,\n","                                     dropout_rate=dropout_rate, weight_decay=weight_decay)\n","        # add transition_block\n","        x = __transition_block(x, nb_filter, compression=compression, weight_decay=weight_decay)\n","        nb_filter = int(nb_filter * compression)\n","\n","    # The last dense_block does not have a transition_block\n","    x, nb_filter = __dense_block(x, final_nb_layer, nb_filter, growth_rate, bottleneck=bottleneck,\n","                                 dropout_rate=dropout_rate, weight_decay=weight_decay)\n","\n","    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","    x = Activation('relu')(x)\n","    x = GlobalAveragePooling2D()(x)\n","\n","    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay), activation=activation)(x)\n","\n","    return x"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Lho4zoe1qmc"},"source":["### 2) Almost Orginial SE-DenseNet121\n","\n"]},{"cell_type":"code","metadata":{"id":"7focbQW_gdZq","executionInfo":{"status":"ok","timestamp":1604975055971,"user_tz":-540,"elapsed":149005,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["def SE_DenseNet(input_shape=None, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1, nb_layers_per_block=-1, bottleneck=False,\n","               reduction=0.0, dropout_rate=0.0, weight_decay=weight_decay, subsample_initial_block=False,\n","               weights=None, classes=classes, activation='softmax', name=None):\n","\n","\n","    if activation not in ['softmax', 'sigmoid']:\n","        raise ValueError('activation must be one of \"softmax\" or \"sigmoid\"')\n","\n","    if activation == 'sigmoid' and classes != 1:\n","        raise ValueError('sigmoid activation can only be used when classes = 1')\n","\n","    img_input = Input(shape=input_shape)\n","\n","    x = __create_dense_net(classes, img_input, depth, nb_dense_block,\n","                           growth_rate, nb_filter, nb_layers_per_block, bottleneck, reduction,\n","                           dropout_rate, weight_decay, subsample_initial_block, activation)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","\n","    inputs = img_input\n","\n","    # Create model.\n","    model = Model(inputs, x, name= name )\n","\n","    return model\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"cCqpFfbZgdWF","executionInfo":{"status":"ok","timestamp":1604975055974,"user_tz":-540,"elapsed":149004,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["def SE_DenseNet121(input_shape=None, bottleneck=True, reduction=0.5, growth_rate = 32, dropout_rate=0.0, weight_decay=weight_decay, classes=classes, activation='softmax', name = None):\n","\n","    return SE_DenseNet(input_shape, depth=121, nb_dense_block=4, growth_rate=growth_rate, nb_filter=64,\n","                      nb_layers_per_block=[6, 12, 24, 16], bottleneck=bottleneck, reduction=reduction,\n","                      dropout_rate=dropout_rate, weight_decay=weight_decay, subsample_initial_block=True,\n","                      classes=classes, activation=activation , name = name)"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Y24Va7X1qmf"},"source":["## 3. SE-DenseNet121\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"Wiva9k1w1qmg"},"source":["### 1) SE-DenseNet121\n"]},{"cell_type":"code","metadata":{"id":"IA-KMy4xgdUD","executionInfo":{"status":"ok","timestamp":1604975059750,"user_tz":-540,"elapsed":152778,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["model = SE_DenseNet121(input_shape=input_sizes, classes = classes, dropout_rate = 0.2, growth_rate = 32, name = 'SE_DenseNet121')"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"YaOtPgAcgdRx","executionInfo":{"status":"ok","timestamp":1604975059754,"user_tz":-540,"elapsed":152771,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"4332c310-7430-40e4-f098-af4e41c5202c","colab":{"base_uri":"https://localhost:8080/"}},"source":["model.summary()"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Model: \"SE_DenseNet121\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 112, 112, 64) 9408        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 56, 56, 128)  8192        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 56, 56, 128)  512         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 56, 56, 128)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 56, 56, 32)   36864       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 56, 56, 32)   0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 56, 56, 96)   0           max_pooling2d[0][0]              \n","                                                                 dropout[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 56, 56, 96)   384         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 56, 56, 96)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 56, 56, 128)  12288       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 56, 56, 128)  512         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 56, 56, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 56, 56, 32)   36864       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 56, 56, 32)   0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 56, 56, 128)  0           concatenate[0][0]                \n","                                                                 dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 56, 56, 128)  512         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 56, 56, 128)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 56, 56, 128)  16384       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 56, 56, 128)  512         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 56, 56, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 56, 56, 32)   36864       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 56, 56, 32)   0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 56, 56, 160)  0           concatenate_1[0][0]              \n","                                                                 dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 56, 56, 160)  640         concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 56, 56, 160)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 56, 56, 128)  20480       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 56, 56, 128)  512         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 56, 56, 128)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 56, 56, 32)   36864       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 56, 56, 32)   0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 56, 56, 192)  0           concatenate_2[0][0]              \n","                                                                 dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 56, 56, 192)  768         concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 56, 56, 192)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 56, 56, 128)  24576       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 56, 56, 128)  512         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 56, 56, 128)  0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 56, 56, 32)   36864       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 56, 56, 32)   0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 56, 56, 224)  0           concatenate_3[0][0]              \n","                                                                 dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 56, 56, 224)  896         concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 56, 56, 224)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 56, 56, 128)  28672       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 56, 56, 128)  512         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 56, 56, 128)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 56, 56, 32)   36864       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 56, 56, 32)   0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 56, 56, 256)  0           concatenate_4[0][0]              \n","                                                                 dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 256)          0           concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 1, 1, 256)    0           global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1, 1, 16)     4096        reshape[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1, 1, 256)    4096        dense[0][0]                      \n","__________________________________________________________________________________________________\n","multiply (Multiply)             (None, 56, 56, 256)  0           concatenate_5[0][0]              \n","                                                                 dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 56, 56, 256)  1024        multiply[0][0]                   \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 56, 56, 256)  0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 56, 56, 128)  32768       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 28, 28, 128)  0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","global_average_pooling2d_1 (Glo (None, 128)          0           average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 1, 1, 128)    0           global_average_pooling2d_1[0][0] \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1, 1, 8)      1024        reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 1, 1, 128)    1024        dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 28, 28, 128)  0           average_pooling2d[0][0]          \n","                                                                 dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         multiply_1[0][0]                 \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 28, 28, 128)  16384       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 28, 28, 32)   36864       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 28, 28, 32)   0           conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 28, 28, 160)  0           multiply_1[0][0]                 \n","                                                                 dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 28, 28, 160)  640         concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 28, 28, 160)  0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 28, 28, 128)  20480       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 28, 28, 32)   36864       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 28, 28, 32)   0           conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 28, 28, 192)  0           concatenate_6[0][0]              \n","                                                                 dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 28, 28, 192)  768         concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 28, 28, 192)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 28, 28, 128)  24576       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 28, 28, 32)   36864       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 28, 28, 32)   0           conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 28, 28, 224)  0           concatenate_7[0][0]              \n","                                                                 dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 28, 28, 224)  896         concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 28, 28, 224)  0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 28, 28, 128)  28672       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 28, 28, 32)   36864       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 28, 28, 32)   0           conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 28, 28, 256)  0           concatenate_8[0][0]              \n","                                                                 dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 28, 28, 256)  1024        concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 28, 28, 256)  0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 28, 28, 128)  32768       activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 28, 28, 128)  0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 28, 28, 32)   36864       activation_23[0][0]              \n","__________________________________________________________________________________________________\n","dropout_10 (Dropout)            (None, 28, 28, 32)   0           conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_10 (Concatenate)    (None, 28, 28, 288)  0           concatenate_9[0][0]              \n","                                                                 dropout_10[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 28, 28, 288)  1152        concatenate_10[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 28, 28, 288)  0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 28, 28, 128)  36864       activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 28, 28, 128)  512         conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 28, 28, 128)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 28, 28, 32)   36864       activation_25[0][0]              \n","__________________________________________________________________________________________________\n","dropout_11 (Dropout)            (None, 28, 28, 32)   0           conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_11 (Concatenate)    (None, 28, 28, 320)  0           concatenate_10[0][0]             \n","                                                                 dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 28, 28, 320)  1280        concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 28, 28, 320)  0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 28, 28, 128)  40960       activation_26[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 28, 28, 128)  512         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 28, 28, 128)  0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 28, 28, 32)   36864       activation_27[0][0]              \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 28, 28, 32)   0           conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_12 (Concatenate)    (None, 28, 28, 352)  0           concatenate_11[0][0]             \n","                                                                 dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 28, 28, 352)  1408        concatenate_12[0][0]             \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 28, 28, 352)  0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 28, 28, 128)  45056       activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 28, 28, 128)  512         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 28, 28, 128)  0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 28, 28, 32)   36864       activation_29[0][0]              \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 28, 28, 32)   0           conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_13 (Concatenate)    (None, 28, 28, 384)  0           concatenate_12[0][0]             \n","                                                                 dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 28, 28, 384)  1536        concatenate_13[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 28, 28, 384)  0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 28, 28, 128)  49152       activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 28, 28, 128)  512         conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 28, 28, 128)  0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 28, 28, 32)   36864       activation_31[0][0]              \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 28, 28, 32)   0           conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 28, 28, 416)  0           concatenate_13[0][0]             \n","                                                                 dropout_14[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 28, 28, 416)  1664        concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 28, 28, 416)  0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 28, 28, 128)  53248       activation_32[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 28, 28, 128)  512         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 28, 28, 128)  0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 28, 28, 32)   36864       activation_33[0][0]              \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 28, 28, 32)   0           conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 28, 28, 448)  0           concatenate_14[0][0]             \n","                                                                 dropout_15[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 28, 28, 448)  1792        concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 28, 28, 448)  0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 28, 28, 128)  57344       activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 28, 28, 128)  512         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 28, 28, 128)  0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 28, 28, 32)   36864       activation_35[0][0]              \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 28, 28, 32)   0           conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 28, 28, 480)  0           concatenate_15[0][0]             \n","                                                                 dropout_16[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 28, 28, 480)  1920        concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 28, 28, 480)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 28, 28, 128)  61440       activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 28, 28, 128)  512         conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 28, 28, 128)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 28, 28, 32)   36864       activation_37[0][0]              \n","__________________________________________________________________________________________________\n","dropout_17 (Dropout)            (None, 28, 28, 32)   0           conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 28, 28, 512)  0           concatenate_16[0][0]             \n","                                                                 dropout_17[0][0]                 \n","__________________________________________________________________________________________________\n","global_average_pooling2d_2 (Glo (None, 512)          0           concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 1, 1, 512)    0           global_average_pooling2d_2[0][0] \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 1, 1, 32)     16384       reshape_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 1, 1, 512)    16384       dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","multiply_2 (Multiply)           (None, 28, 28, 512)  0           concatenate_17[0][0]             \n","                                                                 dense_5[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 28, 28, 512)  2048        multiply_2[0][0]                 \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 28, 28, 512)  0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 28, 28, 256)  131072      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 14, 14, 256)  0           conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","global_average_pooling2d_3 (Glo (None, 256)          0           average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","reshape_3 (Reshape)             (None, 1, 1, 256)    0           global_average_pooling2d_3[0][0] \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1, 1, 16)     4096        reshape_3[0][0]                  \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 1, 1, 256)    4096        dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","multiply_3 (Multiply)           (None, 14, 14, 256)  0           average_pooling2d_1[0][0]        \n","                                                                 dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        multiply_3[0][0]                 \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 14, 14, 256)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 14, 14, 128)  32768       activation_39[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 14, 14, 128)  512         conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 14, 14, 128)  0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 14, 14, 32)   36864       activation_40[0][0]              \n","__________________________________________________________________________________________________\n","dropout_18 (Dropout)            (None, 14, 14, 32)   0           conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 14, 14, 288)  0           multiply_3[0][0]                 \n","                                                                 dropout_18[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 14, 14, 288)  1152        concatenate_18[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 14, 14, 288)  0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 14, 14, 128)  36864       activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 14, 14, 128)  512         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 14, 14, 128)  0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 14, 14, 32)   36864       activation_42[0][0]              \n","__________________________________________________________________________________________________\n","dropout_19 (Dropout)            (None, 14, 14, 32)   0           conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_19 (Concatenate)    (None, 14, 14, 320)  0           concatenate_18[0][0]             \n","                                                                 dropout_19[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 14, 14, 320)  1280        concatenate_19[0][0]             \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 14, 14, 320)  0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 14, 14, 128)  40960       activation_43[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 14, 14, 128)  512         conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 14, 14, 128)  0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 14, 14, 32)   36864       activation_44[0][0]              \n","__________________________________________________________________________________________________\n","dropout_20 (Dropout)            (None, 14, 14, 32)   0           conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_20 (Concatenate)    (None, 14, 14, 352)  0           concatenate_19[0][0]             \n","                                                                 dropout_20[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 14, 14, 352)  1408        concatenate_20[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 14, 14, 352)  0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 14, 14, 128)  45056       activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 14, 14, 128)  512         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 14, 14, 128)  0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 14, 14, 32)   36864       activation_46[0][0]              \n","__________________________________________________________________________________________________\n","dropout_21 (Dropout)            (None, 14, 14, 32)   0           conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_21 (Concatenate)    (None, 14, 14, 384)  0           concatenate_20[0][0]             \n","                                                                 dropout_21[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 14, 14, 384)  1536        concatenate_21[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 14, 14, 384)  0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 14, 14, 128)  49152       activation_47[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 14, 14, 128)  512         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 14, 14, 128)  0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 14, 14, 32)   36864       activation_48[0][0]              \n","__________________________________________________________________________________________________\n","dropout_22 (Dropout)            (None, 14, 14, 32)   0           conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_22 (Concatenate)    (None, 14, 14, 416)  0           concatenate_21[0][0]             \n","                                                                 dropout_22[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 14, 14, 416)  1664        concatenate_22[0][0]             \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 14, 14, 416)  0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 14, 14, 128)  53248       activation_49[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 14, 14, 128)  512         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 14, 14, 128)  0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 14, 14, 32)   36864       activation_50[0][0]              \n","__________________________________________________________________________________________________\n","dropout_23 (Dropout)            (None, 14, 14, 32)   0           conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_23 (Concatenate)    (None, 14, 14, 448)  0           concatenate_22[0][0]             \n","                                                                 dropout_23[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 14, 14, 448)  1792        concatenate_23[0][0]             \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 14, 14, 448)  0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 14, 14, 128)  57344       activation_51[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 14, 14, 128)  512         conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 14, 14, 128)  0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 14, 14, 32)   36864       activation_52[0][0]              \n","__________________________________________________________________________________________________\n","dropout_24 (Dropout)            (None, 14, 14, 32)   0           conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_24 (Concatenate)    (None, 14, 14, 480)  0           concatenate_23[0][0]             \n","                                                                 dropout_24[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 14, 14, 480)  1920        concatenate_24[0][0]             \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 14, 14, 480)  0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 14, 14, 128)  61440       activation_53[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 14, 14, 128)  512         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","activation_54 (Activation)      (None, 14, 14, 128)  0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 14, 14, 32)   36864       activation_54[0][0]              \n","__________________________________________________________________________________________________\n","dropout_25 (Dropout)            (None, 14, 14, 32)   0           conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_25 (Concatenate)    (None, 14, 14, 512)  0           concatenate_24[0][0]             \n","                                                                 dropout_25[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 14, 14, 512)  2048        concatenate_25[0][0]             \n","__________________________________________________________________________________________________\n","activation_55 (Activation)      (None, 14, 14, 512)  0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 14, 14, 128)  65536       activation_55[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 14, 14, 128)  512         conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","activation_56 (Activation)      (None, 14, 14, 128)  0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 14, 14, 32)   36864       activation_56[0][0]              \n","__________________________________________________________________________________________________\n","dropout_26 (Dropout)            (None, 14, 14, 32)   0           conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_26 (Concatenate)    (None, 14, 14, 544)  0           concatenate_25[0][0]             \n","                                                                 dropout_26[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 14, 14, 544)  2176        concatenate_26[0][0]             \n","__________________________________________________________________________________________________\n","activation_57 (Activation)      (None, 14, 14, 544)  0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 14, 14, 128)  69632       activation_57[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 14, 14, 128)  512         conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","activation_58 (Activation)      (None, 14, 14, 128)  0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 14, 14, 32)   36864       activation_58[0][0]              \n","__________________________________________________________________________________________________\n","dropout_27 (Dropout)            (None, 14, 14, 32)   0           conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_27 (Concatenate)    (None, 14, 14, 576)  0           concatenate_26[0][0]             \n","                                                                 dropout_27[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 14, 14, 576)  2304        concatenate_27[0][0]             \n","__________________________________________________________________________________________________\n","activation_59 (Activation)      (None, 14, 14, 576)  0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, 14, 14, 128)  73728       activation_59[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 14, 14, 128)  512         conv2d_59[0][0]                  \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 14, 14, 128)  0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 14, 14, 32)   36864       activation_60[0][0]              \n","__________________________________________________________________________________________________\n","dropout_28 (Dropout)            (None, 14, 14, 32)   0           conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_28 (Concatenate)    (None, 14, 14, 608)  0           concatenate_27[0][0]             \n","                                                                 dropout_28[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 14, 14, 608)  2432        concatenate_28[0][0]             \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 14, 14, 608)  0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 14, 14, 128)  77824       activation_61[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 14, 14, 128)  512         conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 14, 14, 128)  0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, 14, 14, 32)   36864       activation_62[0][0]              \n","__________________________________________________________________________________________________\n","dropout_29 (Dropout)            (None, 14, 14, 32)   0           conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_29 (Concatenate)    (None, 14, 14, 640)  0           concatenate_28[0][0]             \n","                                                                 dropout_29[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 14, 14, 640)  2560        concatenate_29[0][0]             \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 14, 14, 640)  0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, 14, 14, 128)  81920       activation_63[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 14, 14, 128)  512         conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 14, 14, 128)  0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_64 (Conv2D)              (None, 14, 14, 32)   36864       activation_64[0][0]              \n","__________________________________________________________________________________________________\n","dropout_30 (Dropout)            (None, 14, 14, 32)   0           conv2d_64[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_30 (Concatenate)    (None, 14, 14, 672)  0           concatenate_29[0][0]             \n","                                                                 dropout_30[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 14, 14, 672)  2688        concatenate_30[0][0]             \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 14, 14, 672)  0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_65 (Conv2D)              (None, 14, 14, 128)  86016       activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 14, 14, 128)  512         conv2d_65[0][0]                  \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 14, 14, 128)  0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_66 (Conv2D)              (None, 14, 14, 32)   36864       activation_66[0][0]              \n","__________________________________________________________________________________________________\n","dropout_31 (Dropout)            (None, 14, 14, 32)   0           conv2d_66[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_31 (Concatenate)    (None, 14, 14, 704)  0           concatenate_30[0][0]             \n","                                                                 dropout_31[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 14, 14, 704)  2816        concatenate_31[0][0]             \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 14, 14, 704)  0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_67 (Conv2D)              (None, 14, 14, 128)  90112       activation_67[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 14, 14, 128)  512         conv2d_67[0][0]                  \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 14, 14, 128)  0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_68 (Conv2D)              (None, 14, 14, 32)   36864       activation_68[0][0]              \n","__________________________________________________________________________________________________\n","dropout_32 (Dropout)            (None, 14, 14, 32)   0           conv2d_68[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_32 (Concatenate)    (None, 14, 14, 736)  0           concatenate_31[0][0]             \n","                                                                 dropout_32[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 14, 14, 736)  2944        concatenate_32[0][0]             \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 14, 14, 736)  0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_69 (Conv2D)              (None, 14, 14, 128)  94208       activation_69[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 14, 14, 128)  512         conv2d_69[0][0]                  \n","__________________________________________________________________________________________________\n","activation_70 (Activation)      (None, 14, 14, 128)  0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_70 (Conv2D)              (None, 14, 14, 32)   36864       activation_70[0][0]              \n","__________________________________________________________________________________________________\n","dropout_33 (Dropout)            (None, 14, 14, 32)   0           conv2d_70[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_33 (Concatenate)    (None, 14, 14, 768)  0           concatenate_32[0][0]             \n","                                                                 dropout_33[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 14, 14, 768)  3072        concatenate_33[0][0]             \n","__________________________________________________________________________________________________\n","activation_71 (Activation)      (None, 14, 14, 768)  0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_71 (Conv2D)              (None, 14, 14, 128)  98304       activation_71[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 14, 14, 128)  512         conv2d_71[0][0]                  \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 14, 14, 128)  0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_72 (Conv2D)              (None, 14, 14, 32)   36864       activation_72[0][0]              \n","__________________________________________________________________________________________________\n","dropout_34 (Dropout)            (None, 14, 14, 32)   0           conv2d_72[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_34 (Concatenate)    (None, 14, 14, 800)  0           concatenate_33[0][0]             \n","                                                                 dropout_34[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 14, 14, 800)  3200        concatenate_34[0][0]             \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 14, 14, 800)  0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_73 (Conv2D)              (None, 14, 14, 128)  102400      activation_73[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 14, 14, 128)  512         conv2d_73[0][0]                  \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 14, 14, 128)  0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_74 (Conv2D)              (None, 14, 14, 32)   36864       activation_74[0][0]              \n","__________________________________________________________________________________________________\n","dropout_35 (Dropout)            (None, 14, 14, 32)   0           conv2d_74[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_35 (Concatenate)    (None, 14, 14, 832)  0           concatenate_34[0][0]             \n","                                                                 dropout_35[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 14, 14, 832)  3328        concatenate_35[0][0]             \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 14, 14, 832)  0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_75 (Conv2D)              (None, 14, 14, 128)  106496      activation_75[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 14, 14, 128)  512         conv2d_75[0][0]                  \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 14, 14, 128)  0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_76 (Conv2D)              (None, 14, 14, 32)   36864       activation_76[0][0]              \n","__________________________________________________________________________________________________\n","dropout_36 (Dropout)            (None, 14, 14, 32)   0           conv2d_76[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_36 (Concatenate)    (None, 14, 14, 864)  0           concatenate_35[0][0]             \n","                                                                 dropout_36[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 14, 14, 864)  3456        concatenate_36[0][0]             \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 14, 14, 864)  0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_77 (Conv2D)              (None, 14, 14, 128)  110592      activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 14, 14, 128)  512         conv2d_77[0][0]                  \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 14, 14, 128)  0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_78 (Conv2D)              (None, 14, 14, 32)   36864       activation_78[0][0]              \n","__________________________________________________________________________________________________\n","dropout_37 (Dropout)            (None, 14, 14, 32)   0           conv2d_78[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_37 (Concatenate)    (None, 14, 14, 896)  0           concatenate_36[0][0]             \n","                                                                 dropout_37[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 14, 14, 896)  3584        concatenate_37[0][0]             \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 14, 14, 896)  0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_79 (Conv2D)              (None, 14, 14, 128)  114688      activation_79[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 14, 14, 128)  512         conv2d_79[0][0]                  \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 14, 14, 128)  0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_80 (Conv2D)              (None, 14, 14, 32)   36864       activation_80[0][0]              \n","__________________________________________________________________________________________________\n","dropout_38 (Dropout)            (None, 14, 14, 32)   0           conv2d_80[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_38 (Concatenate)    (None, 14, 14, 928)  0           concatenate_37[0][0]             \n","                                                                 dropout_38[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 14, 14, 928)  3712        concatenate_38[0][0]             \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 14, 14, 928)  0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_81 (Conv2D)              (None, 14, 14, 128)  118784      activation_81[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 14, 14, 128)  512         conv2d_81[0][0]                  \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 14, 14, 128)  0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_82 (Conv2D)              (None, 14, 14, 32)   36864       activation_82[0][0]              \n","__________________________________________________________________________________________________\n","dropout_39 (Dropout)            (None, 14, 14, 32)   0           conv2d_82[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_39 (Concatenate)    (None, 14, 14, 960)  0           concatenate_38[0][0]             \n","                                                                 dropout_39[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 14, 14, 960)  3840        concatenate_39[0][0]             \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 14, 14, 960)  0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_83 (Conv2D)              (None, 14, 14, 128)  122880      activation_83[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 14, 14, 128)  512         conv2d_83[0][0]                  \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 14, 14, 128)  0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_84 (Conv2D)              (None, 14, 14, 32)   36864       activation_84[0][0]              \n","__________________________________________________________________________________________________\n","dropout_40 (Dropout)            (None, 14, 14, 32)   0           conv2d_84[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_40 (Concatenate)    (None, 14, 14, 992)  0           concatenate_39[0][0]             \n","                                                                 dropout_40[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 14, 14, 992)  3968        concatenate_40[0][0]             \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 14, 14, 992)  0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_85 (Conv2D)              (None, 14, 14, 128)  126976      activation_85[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 14, 14, 128)  512         conv2d_85[0][0]                  \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 14, 14, 128)  0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_86 (Conv2D)              (None, 14, 14, 32)   36864       activation_86[0][0]              \n","__________________________________________________________________________________________________\n","dropout_41 (Dropout)            (None, 14, 14, 32)   0           conv2d_86[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_41 (Concatenate)    (None, 14, 14, 1024) 0           concatenate_40[0][0]             \n","                                                                 dropout_41[0][0]                 \n","__________________________________________________________________________________________________\n","global_average_pooling2d_4 (Glo (None, 1024)         0           concatenate_41[0][0]             \n","__________________________________________________________________________________________________\n","reshape_4 (Reshape)             (None, 1, 1, 1024)   0           global_average_pooling2d_4[0][0] \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 1, 1, 64)     65536       reshape_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 1, 1, 1024)   65536       dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","multiply_4 (Multiply)           (None, 14, 14, 1024) 0           concatenate_41[0][0]             \n","                                                                 dense_9[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 14, 14, 1024) 4096        multiply_4[0][0]                 \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_87 (Conv2D)              (None, 14, 14, 512)  524288      activation_87[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_2 (AveragePoo (None, 7, 7, 512)    0           conv2d_87[0][0]                  \n","__________________________________________________________________________________________________\n","global_average_pooling2d_5 (Glo (None, 512)          0           average_pooling2d_2[0][0]        \n","__________________________________________________________________________________________________\n","reshape_5 (Reshape)             (None, 1, 1, 512)    0           global_average_pooling2d_5[0][0] \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 1, 1, 32)     16384       reshape_5[0][0]                  \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 1, 1, 512)    16384       dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_5 (Multiply)           (None, 7, 7, 512)    0           average_pooling2d_2[0][0]        \n","                                                                 dense_11[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 7, 7, 512)    2048        multiply_5[0][0]                 \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 7, 7, 512)    0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 7, 7, 128)    65536       activation_88[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 7, 7, 128)    512         conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 7, 7, 128)    0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 7, 7, 32)     36864       activation_89[0][0]              \n","__________________________________________________________________________________________________\n","dropout_42 (Dropout)            (None, 7, 7, 32)     0           conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_42 (Concatenate)    (None, 7, 7, 544)    0           multiply_5[0][0]                 \n","                                                                 dropout_42[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 7, 7, 544)    2176        concatenate_42[0][0]             \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 7, 7, 544)    0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 7, 7, 128)    69632       activation_90[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 7, 7, 128)    512         conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 7, 7, 128)    0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 7, 7, 32)     36864       activation_91[0][0]              \n","__________________________________________________________________________________________________\n","dropout_43 (Dropout)            (None, 7, 7, 32)     0           conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_43 (Concatenate)    (None, 7, 7, 576)    0           concatenate_42[0][0]             \n","                                                                 dropout_43[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 7, 7, 576)    2304        concatenate_43[0][0]             \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 7, 7, 576)    0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 7, 7, 128)    73728       activation_92[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 7, 7, 128)    512         conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 7, 7, 128)    0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 7, 7, 32)     36864       activation_93[0][0]              \n","__________________________________________________________________________________________________\n","dropout_44 (Dropout)            (None, 7, 7, 32)     0           conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_44 (Concatenate)    (None, 7, 7, 608)    0           concatenate_43[0][0]             \n","                                                                 dropout_44[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 7, 7, 608)    2432        concatenate_44[0][0]             \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 7, 7, 608)    0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 7, 7, 128)    77824       activation_94[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 7, 7, 128)    512         conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 7, 7, 128)    0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 7, 7, 32)     36864       activation_95[0][0]              \n","__________________________________________________________________________________________________\n","dropout_45 (Dropout)            (None, 7, 7, 32)     0           conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_45 (Concatenate)    (None, 7, 7, 640)    0           concatenate_44[0][0]             \n","                                                                 dropout_45[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 7, 7, 640)    2560        concatenate_45[0][0]             \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 7, 7, 640)    0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 7, 7, 128)    81920       activation_96[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 7, 7, 128)    512         conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 7, 7, 128)    0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 7, 7, 32)     36864       activation_97[0][0]              \n","__________________________________________________________________________________________________\n","dropout_46 (Dropout)            (None, 7, 7, 32)     0           conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_46 (Concatenate)    (None, 7, 7, 672)    0           concatenate_45[0][0]             \n","                                                                 dropout_46[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 7, 7, 672)    2688        concatenate_46[0][0]             \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 7, 7, 672)    0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 7, 7, 128)    86016       activation_98[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 7, 7, 128)    512         conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 7, 7, 128)    0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 7, 7, 32)     36864       activation_99[0][0]              \n","__________________________________________________________________________________________________\n","dropout_47 (Dropout)            (None, 7, 7, 32)     0           conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_47 (Concatenate)    (None, 7, 7, 704)    0           concatenate_46[0][0]             \n","                                                                 dropout_47[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 7, 7, 704)    2816        concatenate_47[0][0]             \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 7, 7, 704)    0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 7, 7, 128)    90112       activation_100[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 7, 7, 128)    512         conv2d_100[0][0]                 \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 7, 7, 128)    0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 7, 7, 32)     36864       activation_101[0][0]             \n","__________________________________________________________________________________________________\n","dropout_48 (Dropout)            (None, 7, 7, 32)     0           conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_48 (Concatenate)    (None, 7, 7, 736)    0           concatenate_47[0][0]             \n","                                                                 dropout_48[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 7, 7, 736)    2944        concatenate_48[0][0]             \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 7, 7, 736)    0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 7, 7, 128)    94208       activation_102[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 7, 7, 128)    512         conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 7, 7, 128)    0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 7, 7, 32)     36864       activation_103[0][0]             \n","__________________________________________________________________________________________________\n","dropout_49 (Dropout)            (None, 7, 7, 32)     0           conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_49 (Concatenate)    (None, 7, 7, 768)    0           concatenate_48[0][0]             \n","                                                                 dropout_49[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 7, 7, 768)    3072        concatenate_49[0][0]             \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 7, 7, 768)    0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 7, 7, 128)    98304       activation_104[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_105 (BatchN (None, 7, 7, 128)    512         conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","activation_105 (Activation)     (None, 7, 7, 128)    0           batch_normalization_105[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_105 (Conv2D)             (None, 7, 7, 32)     36864       activation_105[0][0]             \n","__________________________________________________________________________________________________\n","dropout_50 (Dropout)            (None, 7, 7, 32)     0           conv2d_105[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_50 (Concatenate)    (None, 7, 7, 800)    0           concatenate_49[0][0]             \n","                                                                 dropout_50[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_106 (BatchN (None, 7, 7, 800)    3200        concatenate_50[0][0]             \n","__________________________________________________________________________________________________\n","activation_106 (Activation)     (None, 7, 7, 800)    0           batch_normalization_106[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_106 (Conv2D)             (None, 7, 7, 128)    102400      activation_106[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_107 (BatchN (None, 7, 7, 128)    512         conv2d_106[0][0]                 \n","__________________________________________________________________________________________________\n","activation_107 (Activation)     (None, 7, 7, 128)    0           batch_normalization_107[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_107 (Conv2D)             (None, 7, 7, 32)     36864       activation_107[0][0]             \n","__________________________________________________________________________________________________\n","dropout_51 (Dropout)            (None, 7, 7, 32)     0           conv2d_107[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_51 (Concatenate)    (None, 7, 7, 832)    0           concatenate_50[0][0]             \n","                                                                 dropout_51[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_108 (BatchN (None, 7, 7, 832)    3328        concatenate_51[0][0]             \n","__________________________________________________________________________________________________\n","activation_108 (Activation)     (None, 7, 7, 832)    0           batch_normalization_108[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_108 (Conv2D)             (None, 7, 7, 128)    106496      activation_108[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_109 (BatchN (None, 7, 7, 128)    512         conv2d_108[0][0]                 \n","__________________________________________________________________________________________________\n","activation_109 (Activation)     (None, 7, 7, 128)    0           batch_normalization_109[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_109 (Conv2D)             (None, 7, 7, 32)     36864       activation_109[0][0]             \n","__________________________________________________________________________________________________\n","dropout_52 (Dropout)            (None, 7, 7, 32)     0           conv2d_109[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_52 (Concatenate)    (None, 7, 7, 864)    0           concatenate_51[0][0]             \n","                                                                 dropout_52[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_110 (BatchN (None, 7, 7, 864)    3456        concatenate_52[0][0]             \n","__________________________________________________________________________________________________\n","activation_110 (Activation)     (None, 7, 7, 864)    0           batch_normalization_110[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_110 (Conv2D)             (None, 7, 7, 128)    110592      activation_110[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_111 (BatchN (None, 7, 7, 128)    512         conv2d_110[0][0]                 \n","__________________________________________________________________________________________________\n","activation_111 (Activation)     (None, 7, 7, 128)    0           batch_normalization_111[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_111 (Conv2D)             (None, 7, 7, 32)     36864       activation_111[0][0]             \n","__________________________________________________________________________________________________\n","dropout_53 (Dropout)            (None, 7, 7, 32)     0           conv2d_111[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_53 (Concatenate)    (None, 7, 7, 896)    0           concatenate_52[0][0]             \n","                                                                 dropout_53[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_112 (BatchN (None, 7, 7, 896)    3584        concatenate_53[0][0]             \n","__________________________________________________________________________________________________\n","activation_112 (Activation)     (None, 7, 7, 896)    0           batch_normalization_112[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_112 (Conv2D)             (None, 7, 7, 128)    114688      activation_112[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_113 (BatchN (None, 7, 7, 128)    512         conv2d_112[0][0]                 \n","__________________________________________________________________________________________________\n","activation_113 (Activation)     (None, 7, 7, 128)    0           batch_normalization_113[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_113 (Conv2D)             (None, 7, 7, 32)     36864       activation_113[0][0]             \n","__________________________________________________________________________________________________\n","dropout_54 (Dropout)            (None, 7, 7, 32)     0           conv2d_113[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_54 (Concatenate)    (None, 7, 7, 928)    0           concatenate_53[0][0]             \n","                                                                 dropout_54[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_114 (BatchN (None, 7, 7, 928)    3712        concatenate_54[0][0]             \n","__________________________________________________________________________________________________\n","activation_114 (Activation)     (None, 7, 7, 928)    0           batch_normalization_114[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_114 (Conv2D)             (None, 7, 7, 128)    118784      activation_114[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_115 (BatchN (None, 7, 7, 128)    512         conv2d_114[0][0]                 \n","__________________________________________________________________________________________________\n","activation_115 (Activation)     (None, 7, 7, 128)    0           batch_normalization_115[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_115 (Conv2D)             (None, 7, 7, 32)     36864       activation_115[0][0]             \n","__________________________________________________________________________________________________\n","dropout_55 (Dropout)            (None, 7, 7, 32)     0           conv2d_115[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_55 (Concatenate)    (None, 7, 7, 960)    0           concatenate_54[0][0]             \n","                                                                 dropout_55[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_116 (BatchN (None, 7, 7, 960)    3840        concatenate_55[0][0]             \n","__________________________________________________________________________________________________\n","activation_116 (Activation)     (None, 7, 7, 960)    0           batch_normalization_116[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_116 (Conv2D)             (None, 7, 7, 128)    122880      activation_116[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_117 (BatchN (None, 7, 7, 128)    512         conv2d_116[0][0]                 \n","__________________________________________________________________________________________________\n","activation_117 (Activation)     (None, 7, 7, 128)    0           batch_normalization_117[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_117 (Conv2D)             (None, 7, 7, 32)     36864       activation_117[0][0]             \n","__________________________________________________________________________________________________\n","dropout_56 (Dropout)            (None, 7, 7, 32)     0           conv2d_117[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_56 (Concatenate)    (None, 7, 7, 992)    0           concatenate_55[0][0]             \n","                                                                 dropout_56[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_118 (BatchN (None, 7, 7, 992)    3968        concatenate_56[0][0]             \n","__________________________________________________________________________________________________\n","activation_118 (Activation)     (None, 7, 7, 992)    0           batch_normalization_118[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_118 (Conv2D)             (None, 7, 7, 128)    126976      activation_118[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_119 (BatchN (None, 7, 7, 128)    512         conv2d_118[0][0]                 \n","__________________________________________________________________________________________________\n","activation_119 (Activation)     (None, 7, 7, 128)    0           batch_normalization_119[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_119 (Conv2D)             (None, 7, 7, 32)     36864       activation_119[0][0]             \n","__________________________________________________________________________________________________\n","dropout_57 (Dropout)            (None, 7, 7, 32)     0           conv2d_119[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_57 (Concatenate)    (None, 7, 7, 1024)   0           concatenate_56[0][0]             \n","                                                                 dropout_57[0][0]                 \n","__________________________________________________________________________________________________\n","global_average_pooling2d_6 (Glo (None, 1024)         0           concatenate_57[0][0]             \n","__________________________________________________________________________________________________\n","reshape_6 (Reshape)             (None, 1, 1, 1024)   0           global_average_pooling2d_6[0][0] \n","__________________________________________________________________________________________________\n","dense_12 (Dense)                (None, 1, 1, 64)     65536       reshape_6[0][0]                  \n","__________________________________________________________________________________________________\n","dense_13 (Dense)                (None, 1, 1, 1024)   65536       dense_12[0][0]                   \n","__________________________________________________________________________________________________\n","multiply_6 (Multiply)           (None, 7, 7, 1024)   0           concatenate_57[0][0]             \n","                                                                 dense_13[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_120 (BatchN (None, 7, 7, 1024)   4096        multiply_6[0][0]                 \n","__________________________________________________________________________________________________\n","activation_120 (Activation)     (None, 7, 7, 1024)   0           batch_normalization_120[0][0]    \n","__________________________________________________________________________________________________\n","global_average_pooling2d_7 (Glo (None, 1024)         0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","dense_14 (Dense)                (None, 257)          263425      global_average_pooling2d_7[0][0] \n","==================================================================================================\n","Total params: 7,647,041\n","Trainable params: 7,563,393\n","Non-trainable params: 83,648\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pwRlyWzi1qmm","executionInfo":{"status":"ok","timestamp":1604975060228,"user_tz":-540,"elapsed":153242,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6K-e9yii3Qh","executionInfo":{"status":"ok","timestamp":1604975060668,"user_tz":-540,"elapsed":153672,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMBFQloJ7ZxC","executionInfo":{"status":"ok","timestamp":1604975060668,"user_tz":-540,"elapsed":153670,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wgOtwPW1qmp","executionInfo":{"status":"ok","timestamp":1604975060669,"user_tz":-540,"elapsed":153667,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"VmS0d9OS1qmr","executionInfo":{"status":"ok","timestamp":1605012550026,"user_tz":-540,"elapsed":37642986,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"08f9d445-bbf0-4ac3-b350-96e179fb0b6b","colab":{"base_uri":"https://localhost:8080/"}},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_5/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_6/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_7/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_8/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_9/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_10/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_11/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_12/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_1/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_13/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_2/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_3/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_14/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_15/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_16/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_17/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_18/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_19/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_20/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_21/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_22/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_23/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_24/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_25/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_26/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_27/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_28/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_29/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_30/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_31/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_32/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_33/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_34/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_35/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_36/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_37/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_4/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_5/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_38/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_6/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_7/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_39/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_40/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_41/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_42/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_43/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_44/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_45/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_46/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_47/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_48/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_49/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_50/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_51/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_52/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_53/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_54/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_55/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_56/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_57/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_58/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_59/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_60/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_61/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_62/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_63/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_64/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_65/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_66/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_67/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_68/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_69/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_70/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_71/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_72/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_73/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_74/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_75/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_76/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_77/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_78/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_79/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_80/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_81/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_82/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_83/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_84/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_85/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_86/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_8/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_9/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_87/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_10/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_11/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_88/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_89/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_90/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_91/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_92/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_93/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_94/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_95/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_96/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_97/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_98/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_99/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_100/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_101/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_102/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_103/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_104/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_105/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_106/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_107/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_108/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_109/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_110/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_111/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_112/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_113/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_114/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_115/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_116/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_117/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_118/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_119/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_12/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_13/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense_14/kernel:0\n","382/382 [==============================] - ETA: 0s - loss: 4.8493 - accuracy: 0.1023 - top5_acc: 0.2112 - macro_f1score: 0.0032 \n","Epoch 00001: val_loss improved from inf to 5.05711, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10122, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/001.h5\n","382/382 [==============================] - 9611s 25s/step - loss: 4.8493 - accuracy: 0.1023 - top5_acc: 0.2112 - macro_f1score: 0.0032 - val_loss: 5.0571 - val_accuracy: 0.1012 - val_top5_acc: 0.2140 - val_macro_f1score: 0.0066\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","382/382 [==============================] - ETA: 0s - loss: 4.1837 - accuracy: 0.1690 - top5_acc: 0.3248 - macro_f1score: 0.0090\n","Epoch 00002: val_loss improved from 5.05711 to 4.65978, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/002.h5\n","\n","Epoch 00002: val_accuracy improved from 0.10122 to 0.15285, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/002.h5\n","382/382 [==============================] - 431s 1s/step - loss: 4.1837 - accuracy: 0.1690 - top5_acc: 0.3248 - macro_f1score: 0.0090 - val_loss: 4.6598 - val_accuracy: 0.1529 - val_top5_acc: 0.2982 - val_macro_f1score: 0.0118\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","382/382 [==============================] - ETA: 0s - loss: 3.7703 - accuracy: 0.2200 - top5_acc: 0.4093 - macro_f1score: 0.0142\n","Epoch 00003: val_loss improved from 4.65978 to 4.45732, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/003.h5\n","\n","Epoch 00003: val_accuracy improved from 0.15285 to 0.17493, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/003.h5\n","382/382 [==============================] - 427s 1s/step - loss: 3.7703 - accuracy: 0.2200 - top5_acc: 0.4093 - macro_f1score: 0.0142 - val_loss: 4.4573 - val_accuracy: 0.1749 - val_top5_acc: 0.3346 - val_macro_f1score: 0.0141\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","382/382 [==============================] - ETA: 0s - loss: 3.3897 - accuracy: 0.2725 - top5_acc: 0.4885 - macro_f1score: 0.0206\n","Epoch 00004: val_loss improved from 4.45732 to 4.08916, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/004.h5\n","\n","Epoch 00004: val_accuracy improved from 0.17493 to 0.20312, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/004.h5\n","382/382 [==============================] - 413s 1s/step - loss: 3.3897 - accuracy: 0.2725 - top5_acc: 0.4885 - macro_f1score: 0.0206 - val_loss: 4.0892 - val_accuracy: 0.2031 - val_top5_acc: 0.4018 - val_macro_f1score: 0.0190\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","382/382 [==============================] - ETA: 0s - loss: 3.0562 - accuracy: 0.3279 - top5_acc: 0.5597 - macro_f1score: 0.0277\n","Epoch 00005: val_loss did not improve from 4.08916\n","\n","Epoch 00005: val_accuracy improved from 0.20312 to 0.22826, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/005.h5\n","382/382 [==============================] - 407s 1s/step - loss: 3.0562 - accuracy: 0.3279 - top5_acc: 0.5597 - macro_f1score: 0.0277 - val_loss: 4.1520 - val_accuracy: 0.2283 - val_top5_acc: 0.4171 - val_macro_f1score: 0.0253\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","382/382 [==============================] - ETA: 0s - loss: 2.7784 - accuracy: 0.3730 - top5_acc: 0.6128 - macro_f1score: 0.0367\n","Epoch 00006: val_loss improved from 4.08916 to 3.88227, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/006.h5\n","\n","Epoch 00006: val_accuracy improved from 0.22826 to 0.24898, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/006.h5\n","382/382 [==============================] - 406s 1s/step - loss: 2.7784 - accuracy: 0.3730 - top5_acc: 0.6128 - macro_f1score: 0.0367 - val_loss: 3.8823 - val_accuracy: 0.2490 - val_top5_acc: 0.4701 - val_macro_f1score: 0.0313\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","382/382 [==============================] - ETA: 0s - loss: 2.5232 - accuracy: 0.4186 - top5_acc: 0.6631 - macro_f1score: 0.0455\n","Epoch 00007: val_loss improved from 3.88227 to 3.44272, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/007.h5\n","\n","Epoch 00007: val_accuracy improved from 0.24898 to 0.31318, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/007.h5\n","382/382 [==============================] - 405s 1s/step - loss: 2.5232 - accuracy: 0.4186 - top5_acc: 0.6631 - macro_f1score: 0.0455 - val_loss: 3.4427 - val_accuracy: 0.3132 - val_top5_acc: 0.5418 - val_macro_f1score: 0.0406\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","382/382 [==============================] - ETA: 0s - loss: 2.3002 - accuracy: 0.4602 - top5_acc: 0.7032 - macro_f1score: 0.0554\n","Epoch 00008: val_loss did not improve from 3.44272\n","\n","Epoch 00008: val_accuracy did not improve from 0.31318\n","382/382 [==============================] - 405s 1s/step - loss: 2.3002 - accuracy: 0.4602 - top5_acc: 0.7032 - macro_f1score: 0.0554 - val_loss: 3.5158 - val_accuracy: 0.3050 - val_top5_acc: 0.5428 - val_macro_f1score: 0.0408\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","382/382 [==============================] - ETA: 0s - loss: 2.1064 - accuracy: 0.4970 - top5_acc: 0.7427 - macro_f1score: 0.0641\n","Epoch 00009: val_loss did not improve from 3.44272\n","\n","Epoch 00009: val_accuracy improved from 0.31318 to 0.32779, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/009.h5\n","382/382 [==============================] - 404s 1s/step - loss: 2.1064 - accuracy: 0.4970 - top5_acc: 0.7427 - macro_f1score: 0.0641 - val_loss: 3.4539 - val_accuracy: 0.3278 - val_top5_acc: 0.5594 - val_macro_f1score: 0.0489\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","382/382 [==============================] - ETA: 0s - loss: 1.9494 - accuracy: 0.5297 - top5_acc: 0.7706 - macro_f1score: 0.0720\n","Epoch 00010: val_loss did not improve from 3.44272\n","\n","Epoch 00010: val_accuracy improved from 0.32779 to 0.34817, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/010.h5\n","382/382 [==============================] - 401s 1s/step - loss: 1.9494 - accuracy: 0.5297 - top5_acc: 0.7706 - macro_f1score: 0.0720 - val_loss: 3.4725 - val_accuracy: 0.3482 - val_top5_acc: 0.5751 - val_macro_f1score: 0.0539\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","382/382 [==============================] - ETA: 0s - loss: 1.7894 - accuracy: 0.5624 - top5_acc: 0.7941 - macro_f1score: 0.0804\n","Epoch 00011: val_loss improved from 3.44272 to 3.31046, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/011.h5\n","\n","Epoch 00011: val_accuracy improved from 0.34817 to 0.35632, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/011.h5\n","382/382 [==============================] - 402s 1s/step - loss: 1.7894 - accuracy: 0.5624 - top5_acc: 0.7941 - macro_f1score: 0.0804 - val_loss: 3.3105 - val_accuracy: 0.3563 - val_top5_acc: 0.5924 - val_macro_f1score: 0.0546\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","382/382 [==============================] - ETA: 0s - loss: 1.6450 - accuracy: 0.5896 - top5_acc: 0.8197 - macro_f1score: 0.0887\n","Epoch 00012: val_loss improved from 3.31046 to 3.13444, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/012.h5\n","\n","Epoch 00012: val_accuracy improved from 0.35632 to 0.38451, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/012.h5\n","382/382 [==============================] - 402s 1s/step - loss: 1.6450 - accuracy: 0.5896 - top5_acc: 0.8197 - macro_f1score: 0.0887 - val_loss: 3.1344 - val_accuracy: 0.3845 - val_top5_acc: 0.6077 - val_macro_f1score: 0.0584\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","382/382 [==============================] - ETA: 0s - loss: 1.5164 - accuracy: 0.6164 - top5_acc: 0.8400 - macro_f1score: 0.0968\n","Epoch 00013: val_loss did not improve from 3.13444\n","\n","Epoch 00013: val_accuracy did not improve from 0.38451\n","382/382 [==============================] - 396s 1s/step - loss: 1.5164 - accuracy: 0.6164 - top5_acc: 0.8400 - macro_f1score: 0.0968 - val_loss: 3.4291 - val_accuracy: 0.3658 - val_top5_acc: 0.5927 - val_macro_f1score: 0.0583\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","382/382 [==============================] - ETA: 0s - loss: 1.3811 - accuracy: 0.6475 - top5_acc: 0.8612 - macro_f1score: 0.1032\n","Epoch 00014: val_loss did not improve from 3.13444\n","\n","Epoch 00014: val_accuracy did not improve from 0.38451\n","382/382 [==============================] - 397s 1s/step - loss: 1.3811 - accuracy: 0.6475 - top5_acc: 0.8612 - macro_f1score: 0.1032 - val_loss: 3.5065 - val_accuracy: 0.3560 - val_top5_acc: 0.5876 - val_macro_f1score: 0.0586\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","382/382 [==============================] - ETA: 0s - loss: 1.2894 - accuracy: 0.6675 - top5_acc: 0.8778 - macro_f1score: 0.1100\n","Epoch 00015: val_loss did not improve from 3.13444\n","\n","Epoch 00015: val_accuracy improved from 0.38451 to 0.39436, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/015.h5\n","382/382 [==============================] - 400s 1s/step - loss: 1.2894 - accuracy: 0.6675 - top5_acc: 0.8778 - macro_f1score: 0.1100 - val_loss: 3.3138 - val_accuracy: 0.3944 - val_top5_acc: 0.6145 - val_macro_f1score: 0.0645\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","382/382 [==============================] - ETA: 0s - loss: 1.1724 - accuracy: 0.6879 - top5_acc: 0.8960 - macro_f1score: 0.1167\n","Epoch 00016: val_loss did not improve from 3.13444\n","\n","Epoch 00016: val_accuracy improved from 0.39436 to 0.39742, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/016.h5\n","382/382 [==============================] - 398s 1s/step - loss: 1.1724 - accuracy: 0.6879 - top5_acc: 0.8960 - macro_f1score: 0.1167 - val_loss: 3.2476 - val_accuracy: 0.3974 - val_top5_acc: 0.6138 - val_macro_f1score: 0.0668\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","382/382 [==============================] - ETA: 0s - loss: 1.0728 - accuracy: 0.7136 - top5_acc: 0.9110 - macro_f1score: 0.1235\n","Epoch 00017: val_loss improved from 3.13444 to 3.02282, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/017.h5\n","\n","Epoch 00017: val_accuracy improved from 0.39742 to 0.43240, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/017.h5\n","382/382 [==============================] - 402s 1s/step - loss: 1.0728 - accuracy: 0.7136 - top5_acc: 0.9110 - macro_f1score: 0.1235 - val_loss: 3.0228 - val_accuracy: 0.4324 - val_top5_acc: 0.6498 - val_macro_f1score: 0.0730\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","382/382 [==============================] - ETA: 0s - loss: 0.9950 - accuracy: 0.7288 - top5_acc: 0.9215 - macro_f1score: 0.1284\n","Epoch 00018: val_loss did not improve from 3.02282\n","\n","Epoch 00018: val_accuracy did not improve from 0.43240\n","382/382 [==============================] - 399s 1s/step - loss: 0.9950 - accuracy: 0.7288 - top5_acc: 0.9215 - macro_f1score: 0.1284 - val_loss: 3.1946 - val_accuracy: 0.4266 - val_top5_acc: 0.6423 - val_macro_f1score: 0.0745\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","382/382 [==============================] - ETA: 0s - loss: 0.9050 - accuracy: 0.7523 - top5_acc: 0.9325 - macro_f1score: 0.1352\n","Epoch 00019: val_loss did not improve from 3.02282\n","\n","Epoch 00019: val_accuracy did not improve from 0.43240\n","382/382 [==============================] - 399s 1s/step - loss: 0.9050 - accuracy: 0.7523 - top5_acc: 0.9325 - macro_f1score: 0.1352 - val_loss: 3.3832 - val_accuracy: 0.4195 - val_top5_acc: 0.6416 - val_macro_f1score: 0.0755\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","382/382 [==============================] - ETA: 0s - loss: 0.8178 - accuracy: 0.7726 - top5_acc: 0.9457 - macro_f1score: 0.1405\n","Epoch 00020: val_loss did not improve from 3.02282\n","\n","Epoch 00020: val_accuracy did not improve from 0.43240\n","382/382 [==============================] - 402s 1s/step - loss: 0.8178 - accuracy: 0.7726 - top5_acc: 0.9457 - macro_f1score: 0.1405 - val_loss: 3.0999 - val_accuracy: 0.4276 - val_top5_acc: 0.6535 - val_macro_f1score: 0.0775\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","382/382 [==============================] - ETA: 0s - loss: 0.7518 - accuracy: 0.7930 - top5_acc: 0.9542 - macro_f1score: 0.1466\n","Epoch 00021: val_loss did not improve from 3.02282\n","\n","Epoch 00021: val_accuracy improved from 0.43240 to 0.45924, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/021.h5\n","382/382 [==============================] - 415s 1s/step - loss: 0.7518 - accuracy: 0.7930 - top5_acc: 0.9542 - macro_f1score: 0.1466 - val_loss: 3.0543 - val_accuracy: 0.4592 - val_top5_acc: 0.6889 - val_macro_f1score: 0.0840\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","382/382 [==============================] - ETA: 0s - loss: 0.6831 - accuracy: 0.8075 - top5_acc: 0.9588 - macro_f1score: 0.1521\n","Epoch 00022: val_loss did not improve from 3.02282\n","\n","Epoch 00022: val_accuracy did not improve from 0.45924\n","382/382 [==============================] - 413s 1s/step - loss: 0.6831 - accuracy: 0.8075 - top5_acc: 0.9588 - macro_f1score: 0.1521 - val_loss: 3.4843 - val_accuracy: 0.4293 - val_top5_acc: 0.6440 - val_macro_f1score: 0.0783\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","382/382 [==============================] - ETA: 0s - loss: 0.6274 - accuracy: 0.8210 - top5_acc: 0.9674 - macro_f1score: 0.1549\n","Epoch 00023: val_loss did not improve from 3.02282\n","\n","Epoch 00023: val_accuracy did not improve from 0.45924\n","382/382 [==============================] - 403s 1s/step - loss: 0.6274 - accuracy: 0.8210 - top5_acc: 0.9674 - macro_f1score: 0.1549 - val_loss: 3.3909 - val_accuracy: 0.4253 - val_top5_acc: 0.6501 - val_macro_f1score: 0.0764\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","382/382 [==============================] - ETA: 0s - loss: 0.5775 - accuracy: 0.8363 - top5_acc: 0.9724 - macro_f1score: 0.1610\n","Epoch 00024: val_loss improved from 3.02282 to 3.00082, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/024.h5\n","\n","Epoch 00024: val_accuracy did not improve from 0.45924\n","382/382 [==============================] - 403s 1s/step - loss: 0.5775 - accuracy: 0.8363 - top5_acc: 0.9724 - macro_f1score: 0.1610 - val_loss: 3.0008 - val_accuracy: 0.4579 - val_top5_acc: 0.6831 - val_macro_f1score: 0.0836\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","382/382 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.8454 - top5_acc: 0.9760 - macro_f1score: 0.1634\n","Epoch 00025: val_loss did not improve from 3.00082\n","\n","Epoch 00025: val_accuracy improved from 0.45924 to 0.46569, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/025.h5\n","382/382 [==============================] - 400s 1s/step - loss: 0.5381 - accuracy: 0.8454 - top5_acc: 0.9760 - macro_f1score: 0.1634 - val_loss: 3.3027 - val_accuracy: 0.4657 - val_top5_acc: 0.6790 - val_macro_f1score: 0.0865\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","382/382 [==============================] - ETA: 0s - loss: 0.4590 - accuracy: 0.8685 - top5_acc: 0.9823 - macro_f1score: 0.1707\n","Epoch 00026: val_loss did not improve from 3.00082\n","\n","Epoch 00026: val_accuracy improved from 0.46569 to 0.47962, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/026.h5\n","382/382 [==============================] - 408s 1s/step - loss: 0.4590 - accuracy: 0.8685 - top5_acc: 0.9823 - macro_f1score: 0.1707 - val_loss: 3.2454 - val_accuracy: 0.4796 - val_top5_acc: 0.6912 - val_macro_f1score: 0.0899\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","382/382 [==============================] - ETA: 0s - loss: 0.4578 - accuracy: 0.8675 - top5_acc: 0.9833 - macro_f1score: 0.1705\n","Epoch 00027: val_loss did not improve from 3.00082\n","\n","Epoch 00027: val_accuracy did not improve from 0.47962\n","382/382 [==============================] - 406s 1s/step - loss: 0.4578 - accuracy: 0.8675 - top5_acc: 0.9833 - macro_f1score: 0.1705 - val_loss: 3.2367 - val_accuracy: 0.4603 - val_top5_acc: 0.6912 - val_macro_f1score: 0.0872\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","382/382 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.8746 - top5_acc: 0.9854 - macro_f1score: 0.1737\n","Epoch 00028: val_loss did not improve from 3.00082\n","\n","Epoch 00028: val_accuracy did not improve from 0.47962\n","382/382 [==============================] - 404s 1s/step - loss: 0.4285 - accuracy: 0.8746 - top5_acc: 0.9854 - macro_f1score: 0.1737 - val_loss: 3.4098 - val_accuracy: 0.4599 - val_top5_acc: 0.6746 - val_macro_f1score: 0.0843\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","382/382 [==============================] - ETA: 0s - loss: 0.4108 - accuracy: 0.8803 - top5_acc: 0.9854 - macro_f1score: 0.1761\n","Epoch 00029: val_loss did not improve from 3.00082\n","\n","Epoch 00029: val_accuracy did not improve from 0.47962\n","382/382 [==============================] - 396s 1s/step - loss: 0.4108 - accuracy: 0.8803 - top5_acc: 0.9854 - macro_f1score: 0.1761 - val_loss: 3.3135 - val_accuracy: 0.4691 - val_top5_acc: 0.6889 - val_macro_f1score: 0.0896\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","382/382 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8909 - top5_acc: 0.9876 - macro_f1score: 0.1785\n","Epoch 00030: val_loss did not improve from 3.00082\n","\n","Epoch 00030: val_accuracy improved from 0.47962 to 0.48539, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/030.h5\n","382/382 [==============================] - 399s 1s/step - loss: 0.3798 - accuracy: 0.8909 - top5_acc: 0.9876 - macro_f1score: 0.1785 - val_loss: 3.0479 - val_accuracy: 0.4854 - val_top5_acc: 0.6936 - val_macro_f1score: 0.0899\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9583 - top5_acc: 0.9977 - macro_f1score: 0.1983\n","Epoch 00031: val_loss improved from 3.00082 to 2.59054, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/031.h5\n","\n","Epoch 00031: val_accuracy improved from 0.48539 to 0.54721, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/031.h5\n","382/382 [==============================] - 412s 1s/step - loss: 0.1710 - accuracy: 0.9583 - top5_acc: 0.9977 - macro_f1score: 0.1983 - val_loss: 2.5905 - val_accuracy: 0.5472 - val_top5_acc: 0.7385 - val_macro_f1score: 0.1046\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9819 - top5_acc: 0.9993 - macro_f1score: 0.2050\n","Epoch 00032: val_loss improved from 2.59054 to 2.51517, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/032.h5\n","\n","Epoch 00032: val_accuracy improved from 0.54721 to 0.56046, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/032.h5\n","382/382 [==============================] - 410s 1s/step - loss: 0.0998 - accuracy: 0.9819 - top5_acc: 0.9993 - macro_f1score: 0.2050 - val_loss: 2.5152 - val_accuracy: 0.5605 - val_top5_acc: 0.7452 - val_macro_f1score: 0.1062\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9863 - top5_acc: 0.9996 - macro_f1score: 0.2063\n","Epoch 00033: val_loss improved from 2.51517 to 2.47541, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/033.h5\n","\n","Epoch 00033: val_accuracy improved from 0.56046 to 0.56318, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/033.h5\n","382/382 [==============================] - 411s 1s/step - loss: 0.0850 - accuracy: 0.9863 - top5_acc: 0.9996 - macro_f1score: 0.2063 - val_loss: 2.4754 - val_accuracy: 0.5632 - val_top5_acc: 0.7514 - val_macro_f1score: 0.1085\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9890 - top5_acc: 0.9998 - macro_f1score: 0.2081\n","Epoch 00034: val_loss improved from 2.47541 to 2.44523, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/034.h5\n","\n","Epoch 00034: val_accuracy did not improve from 0.56318\n","382/382 [==============================] - 401s 1s/step - loss: 0.0737 - accuracy: 0.9890 - top5_acc: 0.9998 - macro_f1score: 0.2081 - val_loss: 2.4452 - val_accuracy: 0.5625 - val_top5_acc: 0.7517 - val_macro_f1score: 0.1091\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9902 - top5_acc: 0.9998 - macro_f1score: 0.2082\n","Epoch 00035: val_loss did not improve from 2.44523\n","\n","Epoch 00035: val_accuracy did not improve from 0.56318\n","382/382 [==============================] - 397s 1s/step - loss: 0.0715 - accuracy: 0.9902 - top5_acc: 0.9998 - macro_f1score: 0.2082 - val_loss: 2.4618 - val_accuracy: 0.5608 - val_top5_acc: 0.7503 - val_macro_f1score: 0.1057\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9930 - top5_acc: 0.9998 - macro_f1score: 0.2093\n","Epoch 00036: val_loss did not improve from 2.44523\n","\n","Epoch 00036: val_accuracy improved from 0.56318 to 0.56352, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/036.h5\n","382/382 [==============================] - 397s 1s/step - loss: 0.0633 - accuracy: 0.9930 - top5_acc: 0.9998 - macro_f1score: 0.2093 - val_loss: 2.4574 - val_accuracy: 0.5635 - val_top5_acc: 0.7510 - val_macro_f1score: 0.1068\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9939 - top5_acc: 0.9998 - macro_f1score: 0.2099\n","Epoch 00037: val_loss improved from 2.44523 to 2.37655, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/037.h5\n","\n","Epoch 00037: val_accuracy improved from 0.56352 to 0.57371, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/037.h5\n","382/382 [==============================] - 403s 1s/step - loss: 0.0625 - accuracy: 0.9939 - top5_acc: 0.9998 - macro_f1score: 0.2099 - val_loss: 2.3766 - val_accuracy: 0.5737 - val_top5_acc: 0.7605 - val_macro_f1score: 0.1091\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9930 - top5_acc: 0.9998 - macro_f1score: 0.2090\n","Epoch 00038: val_loss did not improve from 2.37655\n","\n","Epoch 00038: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 402s 1s/step - loss: 0.0600 - accuracy: 0.9930 - top5_acc: 0.9998 - macro_f1score: 0.2090 - val_loss: 2.3848 - val_accuracy: 0.5601 - val_top5_acc: 0.7571 - val_macro_f1score: 0.1071\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9953 - top5_acc: 0.9999 - macro_f1score: 0.2110\n","Epoch 00039: val_loss improved from 2.37655 to 2.34710, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/039.h5\n","\n","Epoch 00039: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 405s 1s/step - loss: 0.0539 - accuracy: 0.9953 - top5_acc: 0.9999 - macro_f1score: 0.2110 - val_loss: 2.3471 - val_accuracy: 0.5659 - val_top5_acc: 0.7619 - val_macro_f1score: 0.1090\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9949 - top5_acc: 0.9999 - macro_f1score: 0.2100\n","Epoch 00040: val_loss did not improve from 2.34710\n","\n","Epoch 00040: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 402s 1s/step - loss: 0.0548 - accuracy: 0.9949 - top5_acc: 0.9999 - macro_f1score: 0.2100 - val_loss: 2.3637 - val_accuracy: 0.5656 - val_top5_acc: 0.7629 - val_macro_f1score: 0.1074\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9948 - top5_acc: 0.9999 - macro_f1score: 0.2098\n","Epoch 00041: val_loss did not improve from 2.34710\n","\n","Epoch 00041: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 406s 1s/step - loss: 0.0530 - accuracy: 0.9948 - top5_acc: 0.9999 - macro_f1score: 0.2098 - val_loss: 2.4056 - val_accuracy: 0.5588 - val_top5_acc: 0.7588 - val_macro_f1score: 0.1054\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 0.9951 - top5_acc: 1.0000 - macro_f1score: 0.2095\n","Epoch 00042: val_loss improved from 2.34710 to 2.32341, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/042.h5\n","\n","Epoch 00042: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 406s 1s/step - loss: 0.0528 - accuracy: 0.9951 - top5_acc: 1.0000 - macro_f1score: 0.2095 - val_loss: 2.3234 - val_accuracy: 0.5690 - val_top5_acc: 0.7646 - val_macro_f1score: 0.1090\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9954 - top5_acc: 0.9999 - macro_f1score: 0.2100\n","Epoch 00043: val_loss did not improve from 2.32341\n","\n","Epoch 00043: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 404s 1s/step - loss: 0.0506 - accuracy: 0.9954 - top5_acc: 0.9999 - macro_f1score: 0.2100 - val_loss: 2.3479 - val_accuracy: 0.5724 - val_top5_acc: 0.7656 - val_macro_f1score: 0.1078\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9959 - top5_acc: 1.0000 - macro_f1score: 0.2101\n","Epoch 00044: val_loss did not improve from 2.32341\n","\n","Epoch 00044: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 404s 1s/step - loss: 0.0479 - accuracy: 0.9959 - top5_acc: 1.0000 - macro_f1score: 0.2101 - val_loss: 2.3668 - val_accuracy: 0.5632 - val_top5_acc: 0.7582 - val_macro_f1score: 0.1063\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9960 - top5_acc: 1.0000 - macro_f1score: 0.2103\n","Epoch 00045: val_loss did not improve from 2.32341\n","\n","Epoch 00045: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 401s 1s/step - loss: 0.0472 - accuracy: 0.9960 - top5_acc: 1.0000 - macro_f1score: 0.2103 - val_loss: 2.3643 - val_accuracy: 0.5649 - val_top5_acc: 0.7578 - val_macro_f1score: 0.1090\n","Learning rate:  0.0001\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 46/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9957 - top5_acc: 1.0000 - macro_f1score: 0.2092\n","Epoch 00046: val_loss did not improve from 2.32341\n","\n","Epoch 00046: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 394s 1s/step - loss: 0.0478 - accuracy: 0.9957 - top5_acc: 1.0000 - macro_f1score: 0.2092 - val_loss: 2.3670 - val_accuracy: 0.5628 - val_top5_acc: 0.7612 - val_macro_f1score: 0.1061\n","Learning rate:  0.0001\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 47/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9964 - top5_acc: 1.0000 - macro_f1score: 0.2107\n","Epoch 00047: val_loss did not improve from 2.32341\n","\n","Epoch 00047: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 400s 1s/step - loss: 0.0454 - accuracy: 0.9964 - top5_acc: 1.0000 - macro_f1score: 0.2107 - val_loss: 2.3624 - val_accuracy: 0.5649 - val_top5_acc: 0.7649 - val_macro_f1score: 0.1078\n","Learning rate:  0.0001\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 48/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9956 - top5_acc: 1.0000 - macro_f1score: 0.2104\n","Epoch 00048: val_loss did not improve from 2.32341\n","\n","Epoch 00048: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 403s 1s/step - loss: 0.0452 - accuracy: 0.9956 - top5_acc: 1.0000 - macro_f1score: 0.2104 - val_loss: 2.3993 - val_accuracy: 0.5588 - val_top5_acc: 0.7514 - val_macro_f1score: 0.1063\n","Learning rate:  0.0001\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 49/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9971 - top5_acc: 0.9999 - macro_f1score: 0.2109\n","Epoch 00049: val_loss did not improve from 2.32341\n","\n","Epoch 00049: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 403s 1s/step - loss: 0.0449 - accuracy: 0.9971 - top5_acc: 0.9999 - macro_f1score: 0.2109 - val_loss: 2.3585 - val_accuracy: 0.5686 - val_top5_acc: 0.7636 - val_macro_f1score: 0.1076\n","Learning rate:  0.0001\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 50/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9970 - top5_acc: 0.9999 - macro_f1score: 0.2108\n","Epoch 00050: val_loss did not improve from 2.32341\n","\n","Epoch 00050: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 403s 1s/step - loss: 0.0441 - accuracy: 0.9970 - top5_acc: 0.9999 - macro_f1score: 0.2108 - val_loss: 2.3869 - val_accuracy: 0.5696 - val_top5_acc: 0.7619 - val_macro_f1score: 0.1093\n","Learning rate:  0.0001\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 51/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9966 - top5_acc: 1.0000 - macro_f1score: 0.2104\n","Epoch 00051: val_loss did not improve from 2.32341\n","\n","Epoch 00051: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 403s 1s/step - loss: 0.0432 - accuracy: 0.9966 - top5_acc: 1.0000 - macro_f1score: 0.2104 - val_loss: 2.3240 - val_accuracy: 0.5642 - val_top5_acc: 0.7649 - val_macro_f1score: 0.1057\n","Learning rate:  0.0001\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 52/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9971 - top5_acc: 1.0000 - macro_f1score: 0.2110\n","Epoch 00052: val_loss improved from 2.32341 to 2.31572, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/052.h5\n","\n","Epoch 00052: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 406s 1s/step - loss: 0.0414 - accuracy: 0.9971 - top5_acc: 1.0000 - macro_f1score: 0.2110 - val_loss: 2.3157 - val_accuracy: 0.5693 - val_top5_acc: 0.7646 - val_macro_f1score: 0.1084\n","Learning rate:  0.0001\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 53/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9970 - top5_acc: 0.9999 - macro_f1score: 0.2108\n","Epoch 00053: val_loss improved from 2.31572 to 2.29914, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/053.h5\n","\n","Epoch 00053: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 399s 1s/step - loss: 0.0417 - accuracy: 0.9970 - top5_acc: 0.9999 - macro_f1score: 0.2108 - val_loss: 2.2991 - val_accuracy: 0.5727 - val_top5_acc: 0.7734 - val_macro_f1score: 0.1087\n","Learning rate:  0.0001\n","\n","Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 54/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9964 - top5_acc: 1.0000 - macro_f1score: 0.2109\n","Epoch 00054: val_loss did not improve from 2.29914\n","\n","Epoch 00054: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 392s 1s/step - loss: 0.0419 - accuracy: 0.9964 - top5_acc: 1.0000 - macro_f1score: 0.2109 - val_loss: 2.3693 - val_accuracy: 0.5656 - val_top5_acc: 0.7578 - val_macro_f1score: 0.1086\n","Learning rate:  0.0001\n","\n","Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 55/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9961 - top5_acc: 1.0000 - macro_f1score: 0.2102\n","Epoch 00055: val_loss did not improve from 2.29914\n","\n","Epoch 00055: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 392s 1s/step - loss: 0.0423 - accuracy: 0.9961 - top5_acc: 1.0000 - macro_f1score: 0.2102 - val_loss: 2.3174 - val_accuracy: 0.5662 - val_top5_acc: 0.7568 - val_macro_f1score: 0.1089\n","Learning rate:  0.0001\n","\n","Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 56/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9972 - top5_acc: 1.0000 - macro_f1score: 0.2112\n","Epoch 00056: val_loss did not improve from 2.29914\n","\n","Epoch 00056: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 391s 1s/step - loss: 0.0408 - accuracy: 0.9972 - top5_acc: 1.0000 - macro_f1score: 0.2112 - val_loss: 2.3439 - val_accuracy: 0.5700 - val_top5_acc: 0.7619 - val_macro_f1score: 0.1089\n","Learning rate:  0.0001\n","\n","Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 57/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9971 - top5_acc: 1.0000 - macro_f1score: 0.2111\n","Epoch 00057: val_loss improved from 2.29914 to 2.29519, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/057.h5\n","\n","Epoch 00057: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 394s 1s/step - loss: 0.0409 - accuracy: 0.9971 - top5_acc: 1.0000 - macro_f1score: 0.2111 - val_loss: 2.2952 - val_accuracy: 0.5686 - val_top5_acc: 0.7653 - val_macro_f1score: 0.1075\n","Learning rate:  0.0001\n","\n","Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 58/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9962 - top5_acc: 1.0000 - macro_f1score: 0.2108\n","Epoch 00058: val_loss did not improve from 2.29519\n","\n","Epoch 00058: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 393s 1s/step - loss: 0.0397 - accuracy: 0.9962 - top5_acc: 1.0000 - macro_f1score: 0.2108 - val_loss: 2.3180 - val_accuracy: 0.5662 - val_top5_acc: 0.7605 - val_macro_f1score: 0.1084\n","Learning rate:  0.0001\n","\n","Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 59/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9964 - top5_acc: 1.0000 - macro_f1score: 0.2116\n","Epoch 00059: val_loss did not improve from 2.29519\n","\n","Epoch 00059: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 395s 1s/step - loss: 0.0404 - accuracy: 0.9964 - top5_acc: 1.0000 - macro_f1score: 0.2116 - val_loss: 2.3489 - val_accuracy: 0.5669 - val_top5_acc: 0.7592 - val_macro_f1score: 0.1084\n","Learning rate:  0.0001\n","\n","Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 60/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9974 - top5_acc: 1.0000 - macro_f1score: 0.2114\n","Epoch 00060: val_loss did not improve from 2.29519\n","\n","Epoch 00060: val_accuracy did not improve from 0.57371\n","382/382 [==============================] - 399s 1s/step - loss: 0.0378 - accuracy: 0.9974 - top5_acc: 1.0000 - macro_f1score: 0.2114 - val_loss: 2.3342 - val_accuracy: 0.5730 - val_top5_acc: 0.7643 - val_macro_f1score: 0.1080\n","Learning rate:  1e-05\n","\n","Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 61/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2112\n","Epoch 00061: val_loss improved from 2.29519 to 2.21557, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/061.h5\n","\n","Epoch 00061: val_accuracy improved from 0.57371 to 0.58084, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/061.h5\n","382/382 [==============================] - 400s 1s/step - loss: 0.0338 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2112 - val_loss: 2.2156 - val_accuracy: 0.5808 - val_top5_acc: 0.7717 - val_macro_f1score: 0.1103\n","Learning rate:  1e-05\n","\n","Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 62/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9987 - top5_acc: 1.0000 - macro_f1score: 0.2116\n","Epoch 00062: val_loss improved from 2.21557 to 2.17092, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/062.h5\n","\n","Epoch 00062: val_accuracy improved from 0.58084 to 0.58220, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/062.h5\n","382/382 [==============================] - 401s 1s/step - loss: 0.0318 - accuracy: 0.9987 - top5_acc: 1.0000 - macro_f1score: 0.2116 - val_loss: 2.1709 - val_accuracy: 0.5822 - val_top5_acc: 0.7745 - val_macro_f1score: 0.1102\n","Learning rate:  1e-05\n","\n","Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 63/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9983 - top5_acc: 1.0000 - macro_f1score: 0.2111\n","Epoch 00063: val_loss improved from 2.17092 to 2.15876, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/063.h5\n","\n","Epoch 00063: val_accuracy did not improve from 0.58220\n","382/382 [==============================] - 398s 1s/step - loss: 0.0344 - accuracy: 0.9983 - top5_acc: 1.0000 - macro_f1score: 0.2111 - val_loss: 2.1588 - val_accuracy: 0.5819 - val_top5_acc: 0.7745 - val_macro_f1score: 0.1093\n","Learning rate:  1e-05\n","\n","Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 64/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9982 - top5_acc: 0.9999 - macro_f1score: 0.2103\n","Epoch 00064: val_loss improved from 2.15876 to 2.12276, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/064.h5\n","\n","Epoch 00064: val_accuracy improved from 0.58220 to 0.58560, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/064.h5\n","382/382 [==============================] - 400s 1s/step - loss: 0.0377 - accuracy: 0.9982 - top5_acc: 0.9999 - macro_f1score: 0.2103 - val_loss: 2.1228 - val_accuracy: 0.5856 - val_top5_acc: 0.7765 - val_macro_f1score: 0.1096\n","Learning rate:  1e-05\n","\n","Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 65/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.2103\n","Epoch 00065: val_loss improved from 2.12276 to 2.11091, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/065.h5\n","\n","Epoch 00065: val_accuracy did not improve from 0.58560\n","382/382 [==============================] - 397s 1s/step - loss: 0.0396 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.2103 - val_loss: 2.1109 - val_accuracy: 0.5853 - val_top5_acc: 0.7782 - val_macro_f1score: 0.1093\n","Learning rate:  1e-05\n","\n","Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 66/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9985 - top5_acc: 1.0000 - macro_f1score: 0.2114\n","Epoch 00066: val_loss improved from 2.11091 to 2.08875, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/066.h5\n","\n","Epoch 00066: val_accuracy did not improve from 0.58560\n","382/382 [==============================] - 397s 1s/step - loss: 0.0428 - accuracy: 0.9985 - top5_acc: 1.0000 - macro_f1score: 0.2114 - val_loss: 2.0888 - val_accuracy: 0.5842 - val_top5_acc: 0.7772 - val_macro_f1score: 0.1092\n","Learning rate:  1e-05\n","\n","Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 67/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9982 - top5_acc: 1.0000 - macro_f1score: 0.2102\n","Epoch 00067: val_loss improved from 2.08875 to 2.06118, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/067.h5\n","\n","Epoch 00067: val_accuracy did not improve from 0.58560\n","382/382 [==============================] - 400s 1s/step - loss: 0.0469 - accuracy: 0.9982 - top5_acc: 1.0000 - macro_f1score: 0.2102 - val_loss: 2.0612 - val_accuracy: 0.5822 - val_top5_acc: 0.7782 - val_macro_f1score: 0.1081\n","Learning rate:  1e-05\n","\n","Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 68/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9986 - top5_acc: 0.9999 - macro_f1score: 0.2119\n","Epoch 00068: val_loss improved from 2.06118 to 2.05513, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/068.h5\n","\n","Epoch 00068: val_accuracy improved from 0.58560 to 0.58628, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/068.h5\n","382/382 [==============================] - 402s 1s/step - loss: 0.0505 - accuracy: 0.9986 - top5_acc: 0.9999 - macro_f1score: 0.2119 - val_loss: 2.0551 - val_accuracy: 0.5863 - val_top5_acc: 0.7775 - val_macro_f1score: 0.1083\n","Learning rate:  1e-05\n","\n","Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 69/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9982 - top5_acc: 1.0000 - macro_f1score: 0.2116\n","Epoch 00069: val_loss did not improve from 2.05513\n","\n","Epoch 00069: val_accuracy did not improve from 0.58628\n","382/382 [==============================] - 407s 1s/step - loss: 0.0539 - accuracy: 0.9982 - top5_acc: 1.0000 - macro_f1score: 0.2116 - val_loss: 2.0568 - val_accuracy: 0.5832 - val_top5_acc: 0.7745 - val_macro_f1score: 0.1084\n","Learning rate:  1e-05\n","\n","Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 70/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9984 - top5_acc: 1.0000 - macro_f1score: 0.2111\n","Epoch 00070: val_loss improved from 2.05513 to 2.02046, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/SE_DenseNet121/070.h5\n","\n","Epoch 00070: val_accuracy did not improve from 0.58628\n","382/382 [==============================] - 398s 1s/step - loss: 0.0597 - accuracy: 0.9984 - top5_acc: 1.0000 - macro_f1score: 0.2111 - val_loss: 2.0205 - val_accuracy: 0.5839 - val_top5_acc: 0.7772 - val_macro_f1score: 0.1074\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FAr6jLIR1qmu"},"source":["### 2) SE-DenseNet121 Evaluate"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"ZvKx1in81qmu","executionInfo":{"status":"ok","timestamp":1605013606078,"user_tz":-540,"elapsed":38699029,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"f420e835-8269-4f8c-b9a9-1912c9f5ed82","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["48/48 [==============================] - 1016s 21s/step - loss: 2.0764 - accuracy: 0.5658 - top5_acc: 0.7702 - macro_f1score: 0.1030\n","[Test Loss: 2.0764 /  Test Top-1 Accuracy: 0.5658 / Test Top-5 Accuracy: 0.7702 / Test Macro f1: 0.1030]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fbdRXP391qmx","executionInfo":{"status":"ok","timestamp":1605013606082,"user_tz":-540,"elapsed":38699029,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRtTWKDk1qm0","executionInfo":{"status":"ok","timestamp":1605013606083,"user_tz":-540,"elapsed":38699027,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lB5x2Y_1qm3","executionInfo":{"status":"ok","timestamp":1605013606085,"user_tz":-540,"elapsed":38699024,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'SE_DenseNet121.txt'))"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQVReEQO1qm5","executionInfo":{"status":"ok","timestamp":1605013606086,"user_tz":-540,"elapsed":38698990,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEBcd6Hx1qm8","executionInfo":{"status":"ok","timestamp":1605013606800,"user_tz":-540,"elapsed":38699689,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"1655f459-6a3d-46a1-f3a7-1208b90bb5f4","colab":{"base_uri":"https://localhost:8080/","height":808}},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":39,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Jkbe4ajm1qnG","executionInfo":{"status":"ok","timestamp":1605013606802,"user_tz":-540,"elapsed":38699686,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":[""],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLDgyUtp1qnJ","executionInfo":{"status":"ok","timestamp":1605013606803,"user_tz":-540,"elapsed":38699659,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / SE-DenseNet121"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"2cgpzDgH1qnL","executionInfo":{"status":"error","timestamp":1605013614800,"user_tz":-540,"elapsed":38707642,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"df63d3f5-3589-4996-f931-fd91f7f9ccc4","colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["model=load_model(os.path.join(dir,'model_output',number,'SE_DenseNet121','026.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc})"],"execution_count":41,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-7bca2c7a654b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model_output'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SE_DenseNet121'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'026.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"macro_f1score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmacro_f1score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"top5_acc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtop5_acc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    180\u001b[0m     if (h5py is not None and (\n\u001b[1;32m    181\u001b[0m         isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 182\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    192\u001b[0m       \u001b[0;31m# Compile model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m       model.compile(**saving_utils.compile_args_from_training_config(\n\u001b[0;32m--> 194\u001b[0;31m           training_config, custom_objects))\n\u001b[0m\u001b[1;32m    195\u001b[0m       \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtry_build_compiled_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mcompile_args_from_training_config\u001b[0;34m(training_config, custom_objects)\u001b[0m\n\u001b[1;32m    209\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0moptimizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;31m# Recover losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       printable_module_name='optimizer')\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 347\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m   \u001b[0mcls_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unknown optimizer: AdamW"]}]},{"cell_type":"code","metadata":{"id":"I0IvhWkE1qnN","executionInfo":{"status":"aborted","timestamp":1605013613202,"user_tz":-540,"elapsed":38706040,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[]}]}