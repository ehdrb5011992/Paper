{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05.ResNet50.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"veB_9DzkobyH","executionInfo":{"status":"ok","timestamp":1606099074425,"user_tz":-540,"elapsed":1718,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["#모형 출처 : https://github.com/titu1994/keras-squeeze-excite-network"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [ResNet50]"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original ResNet\n","```\n","1) Support Functions\n","2) Almost orginal ResNet\n","```\n","3. ResNet50\n","```\n","1) ResNet50\n","2) ResNet50 Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099114972,"user_tz":-540,"elapsed":42246,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"715946cd-d8cd-40ab-b87b-3da58bf44aa8"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099114977,"user_tz":-540,"elapsed":42242,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"35982646-7f75-432c-ccab-67dbea6c46bf"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1606099117480,"user_tz":-540,"elapsed":44743,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1606099118178,"user_tz":-540,"elapsed":45439,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606099118180,"user_tz":-540,"elapsed":45430,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"29cd9c2c-d2b7-4e5e-cb9b-90c5cbf7323d"},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099118182,"user_tz":-540,"elapsed":45420,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"92615717-9db9-48fd-9c39-824f30533217"},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606099121789,"user_tz":-540,"elapsed":49015,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"aa3281c5-d435-419f-eec9-7fe266cb1e9e"},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"5QEPaq7XQBs8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099121791,"user_tz":-540,"elapsed":49008,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"64aa9b84-b258-4b3b-d48c-ee1495136a09"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 2566292995541539503\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 16071315339364825387\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 14165652720101269682\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15473775744\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 17694099078933823825\n","physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UmBWKpp_cNUa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099121792,"user_tz":-540,"elapsed":48999,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"aff63770-2bbf-4718-b3bd-cf53814d4863"},"source":["!cat /proc/cpuinfo"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.152\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.30\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.152\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.30\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.152\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.30\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.152\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.30\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OOsm86eVUBko"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"DgwOtB_QEhll"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"i5hoO5oVDDJh","executionInfo":{"status":"ok","timestamp":1606099121793,"user_tz":-540,"elapsed":48997,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CALTECH'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 224 # sizes after cropping\n","super_size = 256 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 128\n","weight_decay = 2e-3\n","epochs = 70"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1606099121795,"user_tz":-540,"elapsed":48996,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSIGjI-lnPzM","executionInfo":{"status":"ok","timestamp":1606099121796,"user_tz":-540,"elapsed":48994,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1606099121797,"user_tz":-540,"elapsed":48993,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XrNLBwoJCRR9"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"Zs3J4oAbnPzR","executionInfo":{"status":"ok","timestamp":1606099121798,"user_tz":-540,"elapsed":48993,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1606099121798,"user_tz":-540,"elapsed":48991,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOCgiW4fnPzW","executionInfo":{"status":"ok","timestamp":1606099121799,"user_tz":-540,"elapsed":48990,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"sh3c_SsjnPzY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099175339,"user_tz":-540,"elapsed":102523,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"f9f91f53-95a4-4b78-d4e8-cea1dbd14b93"},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Found 24509 images belonging to 257 classes.\n","Found 2980 images belonging to 257 classes.\n","Found 3118 images belonging to 257 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original ResNet\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"n2aVgcbl5z0A"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"napBoZvjmK6S"},"source":["def _resnet_block(input_tensor, filters, k=1, strides=(1, 1), weight_decay = weight_decay):\n","\n","    init = input_tensor\n","    channel_axis = -1\n","\n","    if strides != (1, 1) or init.get_shape()[channel_axis] != filters * k:\n","        x = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","                      use_bias=False, strides=strides)(input_tensor)\n","        init = BatchNormalization(axis=channel_axis)(x)\n","\n","\n","    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False, strides=strides)(input_tensor)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False)(x)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","\n","    m = add([x, init])\n","    m = Activation('relu')(m)\n","\n","    return m"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-rGAsFnzmK6X"},"source":["def _resnet_bottleneck_block(input_tensor, filters, k=1, strides=(1, 1), weight_decay = weight_decay):\n","\n","    init = input_tensor\n","    channel_axis = -1\n","    bottleneck_expand = 4\n","\n","    if strides != (1, 1) or init.get_shape()[channel_axis] != bottleneck_expand * filters * k:\n","        x = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","                      use_bias=False, strides=strides)(input_tensor)\n","        init = BatchNormalization(axis=channel_axis)(x)\n","\n","\n","    x = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False)(input_tensor)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False, strides=strides)(x)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False)(x)\n","    x = BatchNormalization(axis=channel_axis)(x)    \n","\n","    m = add([x, init])\n","    m = Activation('relu')(m)\n","\n","    return m"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4XWPZ9p0mK6a"},"source":["### 2) Almost Orginial ResNet\n"]},{"cell_type":"code","metadata":{"id":"UJQUF8nAmK6a"},"source":["def _create_resnet(classes, img_input, initial_conv_filters, filters, depth, width, bottleneck, weight_decay):\n","\n","    channel_axis = -1\n","    N = list(depth)\n","\n","    # block 1 (initial conv block)\n","    x = Conv2D(initial_conv_filters, (7, 7), padding='same', use_bias=False, strides=(2, 2), kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(img_input)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","\n","    # block 2 (projection block)\n","    for i in range(N[0]):\n","        if bottleneck:\n","            x = _resnet_bottleneck_block(x, filters[0], width)\n","        else:\n","            x = _resnet_block(x, filters[0], width)\n","\n","    # block 3 - N\n","    for k in range(1, len(N)):\n","        if bottleneck:\n","            x = _resnet_bottleneck_block(x, filters[k], width, strides=(2, 2))\n","        else:\n","            x = _resnet_block(x, filters[k], width, strides=(2, 2))\n","\n","        for i in range(N[k] - 1):\n","            if bottleneck:\n","                x = _resnet_bottleneck_block(x, filters[k], width)\n","            else:\n","                x = _resnet_block(x, filters[k], width)\n","\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(classes, use_bias=False, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n","\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YQUZXeZAo67V"},"source":["def ResNet(input_shape=None, initial_conv_filters=64, depth=[3, 4, 6, 3], filters=[64, 128, 256, 512],\n","             width=1, bottleneck=False, weight_decay=weight_decay, name=None, classes=1000):\n","\n","\n","    img_input = Input(shape=input_shape)\n","\n","    x = _create_resnet(classes, img_input, initial_conv_filters, filters, depth, width, bottleneck, weight_decay)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","\n","    inputs = img_input\n","\n","    # Create model.\n","    model = Model(inputs, x, name = name)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOAp8LsWRMR6"},"source":["## 3. ResNet50\n","---"]},{"cell_type":"markdown","metadata":{"id":"18V3G5o-RMR7"},"source":["### 1) ResNet50"]},{"cell_type":"code","metadata":{"id":"cHQpj9MVo62T"},"source":["# ResNet50\n","model = ResNet(input_shape=input_sizes, depth=[3, 4, 6, 3], width=1, bottleneck=True, weight_decay=weight_decay, classes=classes, name='ResNet50')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"85bYcB6bpTUW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605237062435,"user_tz":-540,"elapsed":107985,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"01a03c4f-4062-4263-e48d-b8f050889f4e"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"ResNet50\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 112, 112, 64) 9408        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 56, 56, 64)   4096        max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 56, 56, 64)   36864       activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 56, 56, 256)  16384       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 56, 56, 256)  16384       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 56, 56, 256)  1024        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 56, 56, 256)  1024        conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 56, 56, 256)  0           batch_normalization_3[0][0]      \n","                                                                 batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 56, 56, 256)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 56, 56, 64)   16384       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 56, 56, 64)   256         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 56, 56, 64)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 56, 56, 64)   36864       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 56, 56, 64)   256         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 56, 56, 64)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 56, 56, 256)  16384       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 56, 56, 256)  1024        conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 56, 56, 256)  0           batch_normalization_6[0][0]      \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 56, 56, 64)   16384       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 56, 56, 64)   256         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 56, 56, 64)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 56, 56, 64)   36864       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 56, 56, 64)   256         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 56, 56, 64)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 56, 56, 256)  16384       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 56, 56, 256)  1024        conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 56, 56, 256)  0           batch_normalization_9[0][0]      \n","                                                                 activation_5[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 56, 56, 128)  32768       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 56, 56, 128)  512         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 56, 56, 128)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 28, 28, 128)  147456      activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 28, 28, 512)  65536       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 28, 28, 512)  131072      activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 28, 28, 512)  2048        conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_13[0][0]     \n","                                                                 batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 28, 28, 128)  65536       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 28, 28, 128)  0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 28, 28, 128)  147456      activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 28, 28, 512)  65536       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_16[0][0]     \n","                                                                 activation_11[0][0]              \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 28, 28, 128)  65536       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 28, 28, 128)  147456      activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 28, 28, 512)  65536       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_19[0][0]     \n","                                                                 activation_14[0][0]              \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 28, 28, 128)  65536       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 28, 28, 128)  0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 28, 28, 128)  147456      activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 28, 28, 512)  65536       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 28, 28, 512)  2048        conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_22[0][0]     \n","                                                                 activation_17[0][0]              \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 28, 28, 256)  131072      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 28, 28, 256)  1024        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 28, 28, 256)  0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 14, 14, 256)  589824      activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 14, 14, 256)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 14, 14, 1024) 262144      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 14, 14, 1024) 524288      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 14, 14, 1024) 4096        conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 14, 14, 1024) 4096        conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_26[0][0]     \n","                                                                 batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 14, 14, 256)  262144      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 14, 14, 256)  1024        conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 14, 14, 256)  0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 14, 14, 256)  589824      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 14, 14, 256)  0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 14, 14, 1024) 262144      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 14, 14, 1024) 4096        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_29[0][0]     \n","                                                                 activation_23[0][0]              \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 14, 14, 256)  262144      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 14, 14, 256)  1024        conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 14, 14, 256)  0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 14, 14, 256)  589824      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 14, 14, 256)  0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 14, 14, 1024) 262144      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 14, 14, 1024) 4096        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_32[0][0]     \n","                                                                 activation_26[0][0]              \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 14, 14, 256)  262144      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 14, 14, 256)  0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 14, 14, 256)  589824      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 14, 14, 256)  0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 14, 14, 1024) 262144      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 14, 14, 1024) 4096        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_35[0][0]     \n","                                                                 activation_29[0][0]              \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 14, 14, 256)  262144      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 14, 14, 256)  1024        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 14, 14, 256)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 14, 14, 256)  589824      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 14, 14, 256)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 14, 14, 1024) 262144      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 14, 14, 1024) 4096        conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_38[0][0]     \n","                                                                 activation_32[0][0]              \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 14, 14, 256)  262144      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 14, 14, 256)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 14, 14, 256)  589824      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 14, 14, 1024) 262144      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 14, 14, 1024) 4096        conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_41[0][0]     \n","                                                                 activation_35[0][0]              \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 14, 14, 512)  524288      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 14, 14, 512)  2048        conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 14, 14, 512)  0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 7, 7, 512)    2359296     activation_39[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 7, 7, 512)    0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 7, 7, 2048)   1048576     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 7, 7, 2048)   2097152     activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 7, 7, 2048)   8192        conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 7, 7, 2048)   8192        conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_45[0][0]     \n","                                                                 batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 7, 7, 512)    1048576     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 7, 7, 512)    2048        conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 7, 7, 512)    0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 7, 7, 512)    2359296     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 7, 7, 512)    0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 7, 7, 2048)   1048576     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 7, 7, 2048)   8192        conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_48[0][0]     \n","                                                                 activation_41[0][0]              \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 7, 7, 512)    1048576     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 7, 7, 512)    2048        conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 7, 7, 512)    0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 7, 7, 512)    2359296     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 7, 7, 512)    0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 7, 7, 2048)   1048576     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 7, 7, 2048)   8192        conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_51[0][0]     \n","                                                                 activation_44[0][0]              \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 2048)         0           activation_47[0][0]              \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 257)          526336      global_average_pooling2d[0][0]   \n","==================================================================================================\n","Total params: 24,087,232\n","Trainable params: 24,034,240\n","Non-trainable params: 52,992\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AispA2HmDSs_"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e4TEeLLw9al1"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8643H3mcjj3"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwH0Q16iRMSH"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMuhpBHjRMSN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605274759038,"user_tz":-540,"elapsed":37804535,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"43f7af8d-b498-4650-f5dc-a053259a7dbb"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_5/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_6/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_7/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_8/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_9/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_10/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_12/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_13/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_14/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_11/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_15/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_16/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_17/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_18/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_19/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_20/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_21/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_22/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_23/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_25/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_26/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_27/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_24/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_28/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_29/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_30/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_31/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_32/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_33/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_34/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_35/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_36/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_37/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_38/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_39/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_40/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_41/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_42/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_44/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_45/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_46/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_43/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_47/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_48/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_49/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_50/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_51/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for conv2d_52/kernel:0\n","0.0(L1), 0.00014471492793207425(L2) weight decay set for dense/kernel:0\n","191/191 [==============================] - ETA: 0s - loss: 5.4367 - accuracy: 0.0634 - top5_acc: 0.1492 - macro_f1score: 2.9150e-04 \n","Epoch 00001: val_loss improved from inf to 5.22857, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.05537, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/001.h5\n","191/191 [==============================] - 7233s 38s/step - loss: 5.4367 - accuracy: 0.0634 - top5_acc: 0.1492 - macro_f1score: 2.9150e-04 - val_loss: 5.2286 - val_accuracy: 0.0554 - val_top5_acc: 0.1342 - val_macro_f1score: 0.0000e+00\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","191/191 [==============================] - ETA: 0s - loss: 4.7029 - accuracy: 0.1122 - top5_acc: 0.2356 - macro_f1score: 0.0034\n","Epoch 00002: val_loss improved from 5.22857 to 4.92842, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/002.h5\n","\n","Epoch 00002: val_accuracy improved from 0.05537 to 0.07812, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/002.h5\n","191/191 [==============================] - 471s 2s/step - loss: 4.7029 - accuracy: 0.1122 - top5_acc: 0.2356 - macro_f1score: 0.0034 - val_loss: 4.9284 - val_accuracy: 0.0781 - val_top5_acc: 0.1780 - val_macro_f1score: 0.0018\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","191/191 [==============================] - ETA: 0s - loss: 4.3722 - accuracy: 0.1431 - top5_acc: 0.2957 - macro_f1score: 0.0080\n","Epoch 00003: val_loss improved from 4.92842 to 4.52862, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/003.h5\n","\n","Epoch 00003: val_accuracy improved from 0.07812 to 0.12058, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/003.h5\n","191/191 [==============================] - 462s 2s/step - loss: 4.3722 - accuracy: 0.1431 - top5_acc: 0.2957 - macro_f1score: 0.0080 - val_loss: 4.5286 - val_accuracy: 0.1206 - val_top5_acc: 0.2636 - val_macro_f1score: 0.0053\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","191/191 [==============================] - ETA: 0s - loss: 4.1337 - accuracy: 0.1775 - top5_acc: 0.3462 - macro_f1score: 0.0116\n","Epoch 00004: val_loss did not improve from 4.52862\n","\n","Epoch 00004: val_accuracy did not improve from 0.12058\n","191/191 [==============================] - 456s 2s/step - loss: 4.1337 - accuracy: 0.1775 - top5_acc: 0.3462 - macro_f1score: 0.0116 - val_loss: 4.7021 - val_accuracy: 0.1114 - val_top5_acc: 0.2435 - val_macro_f1score: 0.0061\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","191/191 [==============================] - ETA: 0s - loss: 3.9606 - accuracy: 0.1970 - top5_acc: 0.3728 - macro_f1score: 0.0147\n","Epoch 00005: val_loss improved from 4.52862 to 4.35303, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/005.h5\n","\n","Epoch 00005: val_accuracy improved from 0.12058 to 0.14912, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/005.h5\n","191/191 [==============================] - 457s 2s/step - loss: 3.9606 - accuracy: 0.1970 - top5_acc: 0.3728 - macro_f1score: 0.0147 - val_loss: 4.3530 - val_accuracy: 0.1491 - val_top5_acc: 0.2901 - val_macro_f1score: 0.0072\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","191/191 [==============================] - ETA: 0s - loss: 3.7167 - accuracy: 0.2301 - top5_acc: 0.4270 - macro_f1score: 0.0209\n","Epoch 00006: val_loss improved from 4.35303 to 4.18146, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/006.h5\n","\n","Epoch 00006: val_accuracy improved from 0.14912 to 0.18716, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/006.h5\n","191/191 [==============================] - 456s 2s/step - loss: 3.7167 - accuracy: 0.2301 - top5_acc: 0.4270 - macro_f1score: 0.0209 - val_loss: 4.1815 - val_accuracy: 0.1872 - val_top5_acc: 0.3607 - val_macro_f1score: 0.0144\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","191/191 [==============================] - ETA: 0s - loss: 3.5007 - accuracy: 0.2641 - top5_acc: 0.4694 - macro_f1score: 0.0271\n","Epoch 00007: val_loss improved from 4.18146 to 4.16191, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/007.h5\n","\n","Epoch 00007: val_accuracy improved from 0.18716 to 0.19769, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/007.h5\n","191/191 [==============================] - 456s 2s/step - loss: 3.5007 - accuracy: 0.2641 - top5_acc: 0.4694 - macro_f1score: 0.0271 - val_loss: 4.1619 - val_accuracy: 0.1977 - val_top5_acc: 0.3733 - val_macro_f1score: 0.0180\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","191/191 [==============================] - ETA: 0s - loss: 3.3224 - accuracy: 0.2867 - top5_acc: 0.5076 - macro_f1score: 0.0345\n","Epoch 00008: val_loss improved from 4.16191 to 3.85503, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/008.h5\n","\n","Epoch 00008: val_accuracy improved from 0.19769 to 0.22520, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/008.h5\n","191/191 [==============================] - 456s 2s/step - loss: 3.3224 - accuracy: 0.2867 - top5_acc: 0.5076 - macro_f1score: 0.0345 - val_loss: 3.8550 - val_accuracy: 0.2252 - val_top5_acc: 0.4331 - val_macro_f1score: 0.0272\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","191/191 [==============================] - ETA: 0s - loss: 3.1824 - accuracy: 0.3120 - top5_acc: 0.5347 - macro_f1score: 0.0408\n","Epoch 00009: val_loss did not improve from 3.85503\n","\n","Epoch 00009: val_accuracy improved from 0.22520 to 0.22588, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/009.h5\n","191/191 [==============================] - 455s 2s/step - loss: 3.1824 - accuracy: 0.3120 - top5_acc: 0.5347 - macro_f1score: 0.0408 - val_loss: 3.9524 - val_accuracy: 0.2259 - val_top5_acc: 0.4185 - val_macro_f1score: 0.0267\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","191/191 [==============================] - ETA: 0s - loss: 2.9648 - accuracy: 0.3429 - top5_acc: 0.5779 - macro_f1score: 0.0522\n","Epoch 00010: val_loss improved from 3.85503 to 3.68392, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/010.h5\n","\n","Epoch 00010: val_accuracy improved from 0.22588 to 0.26529, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/010.h5\n","191/191 [==============================] - 448s 2s/step - loss: 2.9648 - accuracy: 0.3429 - top5_acc: 0.5779 - macro_f1score: 0.0522 - val_loss: 3.6839 - val_accuracy: 0.2653 - val_top5_acc: 0.4732 - val_macro_f1score: 0.0410\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","191/191 [==============================] - ETA: 0s - loss: 2.7703 - accuracy: 0.3819 - top5_acc: 0.6138 - macro_f1score: 0.0636\n","Epoch 00011: val_loss improved from 3.68392 to 3.48799, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/011.h5\n","\n","Epoch 00011: val_accuracy improved from 0.26529 to 0.29416, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/011.h5\n","191/191 [==============================] - 449s 2s/step - loss: 2.7703 - accuracy: 0.3819 - top5_acc: 0.6138 - macro_f1score: 0.0636 - val_loss: 3.4880 - val_accuracy: 0.2942 - val_top5_acc: 0.5105 - val_macro_f1score: 0.0471\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","191/191 [==============================] - ETA: 0s - loss: 2.5808 - accuracy: 0.4113 - top5_acc: 0.6526 - macro_f1score: 0.0753\n","Epoch 00012: val_loss did not improve from 3.48799\n","\n","Epoch 00012: val_accuracy did not improve from 0.29416\n","191/191 [==============================] - 455s 2s/step - loss: 2.5808 - accuracy: 0.4113 - top5_acc: 0.6526 - macro_f1score: 0.0753 - val_loss: 6.8546 - val_accuracy: 0.2466 - val_top5_acc: 0.4562 - val_macro_f1score: 0.0476\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","191/191 [==============================] - ETA: 0s - loss: 2.4264 - accuracy: 0.4415 - top5_acc: 0.6809 - macro_f1score: 0.0883\n","Epoch 00013: val_loss did not improve from 3.48799\n","\n","Epoch 00013: val_accuracy improved from 0.29416 to 0.31590, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/013.h5\n","191/191 [==============================] - 452s 2s/step - loss: 2.4264 - accuracy: 0.4415 - top5_acc: 0.6809 - macro_f1score: 0.0883 - val_loss: 3.5573 - val_accuracy: 0.3159 - val_top5_acc: 0.5350 - val_macro_f1score: 0.0564\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","191/191 [==============================] - ETA: 0s - loss: 2.2985 - accuracy: 0.4614 - top5_acc: 0.7060 - macro_f1score: 0.0975\n","Epoch 00014: val_loss improved from 3.48799 to 3.20553, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/014.h5\n","\n","Epoch 00014: val_accuracy improved from 0.31590 to 0.32880, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/014.h5\n","191/191 [==============================] - 449s 2s/step - loss: 2.2985 - accuracy: 0.4614 - top5_acc: 0.7060 - macro_f1score: 0.0975 - val_loss: 3.2055 - val_accuracy: 0.3288 - val_top5_acc: 0.5618 - val_macro_f1score: 0.0654\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","191/191 [==============================] - ETA: 0s - loss: 2.1642 - accuracy: 0.4876 - top5_acc: 0.7277 - macro_f1score: 0.1089\n","Epoch 00015: val_loss did not improve from 3.20553\n","\n","Epoch 00015: val_accuracy improved from 0.32880 to 0.35768, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/015.h5\n","191/191 [==============================] - 441s 2s/step - loss: 2.1642 - accuracy: 0.4876 - top5_acc: 0.7277 - macro_f1score: 0.1089 - val_loss: 3.2704 - val_accuracy: 0.3577 - val_top5_acc: 0.5781 - val_macro_f1score: 0.0788\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","191/191 [==============================] - ETA: 0s - loss: 2.0097 - accuracy: 0.5178 - top5_acc: 0.7561 - macro_f1score: 0.1226\n","Epoch 00016: val_loss did not improve from 3.20553\n","\n","Epoch 00016: val_accuracy did not improve from 0.35768\n","191/191 [==============================] - 424s 2s/step - loss: 2.0097 - accuracy: 0.5178 - top5_acc: 0.7561 - macro_f1score: 0.1226 - val_loss: 3.6343 - val_accuracy: 0.2925 - val_top5_acc: 0.5282 - val_macro_f1score: 0.0648\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","191/191 [==============================] - ETA: 0s - loss: 1.8968 - accuracy: 0.5395 - top5_acc: 0.7785 - macro_f1score: 0.1324\n","Epoch 00017: val_loss improved from 3.20553 to 3.08533, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/017.h5\n","\n","Epoch 00017: val_accuracy improved from 0.35768 to 0.36651, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/017.h5\n","191/191 [==============================] - 419s 2s/step - loss: 1.8968 - accuracy: 0.5395 - top5_acc: 0.7785 - macro_f1score: 0.1324 - val_loss: 3.0853 - val_accuracy: 0.3665 - val_top5_acc: 0.5829 - val_macro_f1score: 0.0829\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","191/191 [==============================] - ETA: 0s - loss: 1.7775 - accuracy: 0.5627 - top5_acc: 0.7978 - macro_f1score: 0.1447\n","Epoch 00018: val_loss did not improve from 3.08533\n","\n","Epoch 00018: val_accuracy did not improve from 0.36651\n","191/191 [==============================] - 402s 2s/step - loss: 1.7775 - accuracy: 0.5627 - top5_acc: 0.7978 - macro_f1score: 0.1447 - val_loss: 3.4308 - val_accuracy: 0.3105 - val_top5_acc: 0.5425 - val_macro_f1score: 0.0663\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","191/191 [==============================] - ETA: 0s - loss: 1.6718 - accuracy: 0.5866 - top5_acc: 0.8156 - macro_f1score: 0.1552\n","Epoch 00019: val_loss improved from 3.08533 to 2.80912, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/019.h5\n","\n","Epoch 00019: val_accuracy improved from 0.36651 to 0.42595, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/019.h5\n","191/191 [==============================] - 437s 2s/step - loss: 1.6718 - accuracy: 0.5866 - top5_acc: 0.8156 - macro_f1score: 0.1552 - val_loss: 2.8091 - val_accuracy: 0.4260 - val_top5_acc: 0.6552 - val_macro_f1score: 0.1073\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","191/191 [==============================] - ETA: 0s - loss: 1.5579 - accuracy: 0.6088 - top5_acc: 0.8296 - macro_f1score: 0.1674\n","Epoch 00020: val_loss improved from 2.80912 to 2.72720, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/020.h5\n","\n","Epoch 00020: val_accuracy did not improve from 0.42595\n","191/191 [==============================] - 442s 2s/step - loss: 1.5579 - accuracy: 0.6088 - top5_acc: 0.8296 - macro_f1score: 0.1674 - val_loss: 2.7272 - val_accuracy: 0.4229 - val_top5_acc: 0.6535 - val_macro_f1score: 0.1133\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","191/191 [==============================] - ETA: 0s - loss: 1.4600 - accuracy: 0.6268 - top5_acc: 0.8497 - macro_f1score: 0.1754\n","Epoch 00021: val_loss did not improve from 2.72720\n","\n","Epoch 00021: val_accuracy improved from 0.42595 to 0.43139, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/021.h5\n","191/191 [==============================] - 436s 2s/step - loss: 1.4600 - accuracy: 0.6268 - top5_acc: 0.8497 - macro_f1score: 0.1754 - val_loss: 2.8124 - val_accuracy: 0.4314 - val_top5_acc: 0.6620 - val_macro_f1score: 0.1173\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","191/191 [==============================] - ETA: 0s - loss: 1.3601 - accuracy: 0.6480 - top5_acc: 0.8658 - macro_f1score: 0.1851\n","Epoch 00022: val_loss improved from 2.72720 to 2.58991, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/022.h5\n","\n","Epoch 00022: val_accuracy improved from 0.43139 to 0.45279, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/022.h5\n","191/191 [==============================] - 442s 2s/step - loss: 1.3601 - accuracy: 0.6480 - top5_acc: 0.8658 - macro_f1score: 0.1851 - val_loss: 2.5899 - val_accuracy: 0.4528 - val_top5_acc: 0.6841 - val_macro_f1score: 0.1198\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","191/191 [==============================] - ETA: 0s - loss: 1.3031 - accuracy: 0.6617 - top5_acc: 0.8738 - macro_f1score: 0.1911\n","Epoch 00023: val_loss did not improve from 2.58991\n","\n","Epoch 00023: val_accuracy did not improve from 0.45279\n","191/191 [==============================] - 433s 2s/step - loss: 1.3031 - accuracy: 0.6617 - top5_acc: 0.8738 - macro_f1score: 0.1911 - val_loss: 2.9074 - val_accuracy: 0.4219 - val_top5_acc: 0.6359 - val_macro_f1score: 0.1134\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","191/191 [==============================] - ETA: 0s - loss: 1.1829 - accuracy: 0.6866 - top5_acc: 0.8917 - macro_f1score: 0.2065\n","Epoch 00024: val_loss did not improve from 2.58991\n","\n","Epoch 00024: val_accuracy did not improve from 0.45279\n","191/191 [==============================] - 424s 2s/step - loss: 1.1829 - accuracy: 0.6866 - top5_acc: 0.8917 - macro_f1score: 0.2065 - val_loss: 2.8572 - val_accuracy: 0.4474 - val_top5_acc: 0.6702 - val_macro_f1score: 0.1239\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","191/191 [==============================] - ETA: 0s - loss: 1.1035 - accuracy: 0.7058 - top5_acc: 0.9025 - macro_f1score: 0.2162\n","Epoch 00025: val_loss did not improve from 2.58991\n","\n","Epoch 00025: val_accuracy improved from 0.45279 to 0.46094, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/025.h5\n","191/191 [==============================] - 436s 2s/step - loss: 1.1035 - accuracy: 0.7058 - top5_acc: 0.9025 - macro_f1score: 0.2162 - val_loss: 2.8275 - val_accuracy: 0.4609 - val_top5_acc: 0.6899 - val_macro_f1score: 0.1298\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","191/191 [==============================] - ETA: 0s - loss: 1.0146 - accuracy: 0.7264 - top5_acc: 0.9153 - macro_f1score: 0.2248\n","Epoch 00026: val_loss did not improve from 2.58991\n","\n","Epoch 00026: val_accuracy did not improve from 0.46094\n","191/191 [==============================] - 443s 2s/step - loss: 1.0146 - accuracy: 0.7264 - top5_acc: 0.9153 - macro_f1score: 0.2248 - val_loss: 3.2292 - val_accuracy: 0.3832 - val_top5_acc: 0.6097 - val_macro_f1score: 0.1018\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","191/191 [==============================] - ETA: 0s - loss: 0.9811 - accuracy: 0.7307 - top5_acc: 0.9240 - macro_f1score: 0.2297\n","Epoch 00027: val_loss did not improve from 2.58991\n","\n","Epoch 00027: val_accuracy improved from 0.46094 to 0.48030, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/027.h5\n","191/191 [==============================] - 435s 2s/step - loss: 0.9811 - accuracy: 0.7307 - top5_acc: 0.9240 - macro_f1score: 0.2297 - val_loss: 2.7904 - val_accuracy: 0.4803 - val_top5_acc: 0.6980 - val_macro_f1score: 0.1462\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","191/191 [==============================] - ETA: 0s - loss: 0.8691 - accuracy: 0.7565 - top5_acc: 0.9349 - macro_f1score: 0.2431\n","Epoch 00028: val_loss did not improve from 2.58991\n","\n","Epoch 00028: val_accuracy did not improve from 0.48030\n","191/191 [==============================] - 444s 2s/step - loss: 0.8691 - accuracy: 0.7565 - top5_acc: 0.9349 - macro_f1score: 0.2431 - val_loss: 2.6973 - val_accuracy: 0.4725 - val_top5_acc: 0.6868 - val_macro_f1score: 0.1401\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","191/191 [==============================] - ETA: 0s - loss: 0.8296 - accuracy: 0.7677 - top5_acc: 0.9424 - macro_f1score: 0.2490\n","Epoch 00029: val_loss did not improve from 2.58991\n","\n","Epoch 00029: val_accuracy did not improve from 0.48030\n","191/191 [==============================] - 452s 2s/step - loss: 0.8296 - accuracy: 0.7677 - top5_acc: 0.9424 - macro_f1score: 0.2490 - val_loss: 2.7681 - val_accuracy: 0.4647 - val_top5_acc: 0.6878 - val_macro_f1score: 0.1422\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","191/191 [==============================] - ETA: 0s - loss: 0.7509 - accuracy: 0.7870 - top5_acc: 0.9534 - macro_f1score: 0.2578\n","Epoch 00030: val_loss did not improve from 2.58991\n","\n","Epoch 00030: val_accuracy did not improve from 0.48030\n","191/191 [==============================] - 457s 2s/step - loss: 0.7509 - accuracy: 0.7870 - top5_acc: 0.9534 - macro_f1score: 0.2578 - val_loss: 2.8891 - val_accuracy: 0.4691 - val_top5_acc: 0.6929 - val_macro_f1score: 0.1420\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","191/191 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.9068 - top5_acc: 0.9843 - macro_f1score: 0.3161\n","Epoch 00031: val_loss improved from 2.58991 to 2.09945, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/031.h5\n","\n","Epoch 00031: val_accuracy improved from 0.48030 to 0.58594, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/031.h5\n","191/191 [==============================] - 459s 2s/step - loss: 0.3608 - accuracy: 0.9068 - top5_acc: 0.9843 - macro_f1score: 0.3161 - val_loss: 2.0995 - val_accuracy: 0.5859 - val_top5_acc: 0.7741 - val_macro_f1score: 0.1885\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","191/191 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.9425 - top5_acc: 0.9938 - macro_f1score: 0.3376\n","Epoch 00032: val_loss did not improve from 2.09945\n","\n","Epoch 00032: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 456s 2s/step - loss: 0.2180 - accuracy: 0.9425 - top5_acc: 0.9938 - macro_f1score: 0.3376 - val_loss: 2.2193 - val_accuracy: 0.5795 - val_top5_acc: 0.7690 - val_macro_f1score: 0.1871\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","191/191 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.9548 - top5_acc: 0.9955 - macro_f1score: 0.3437\n","Epoch 00033: val_loss did not improve from 2.09945\n","\n","Epoch 00033: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 457s 2s/step - loss: 0.1763 - accuracy: 0.9548 - top5_acc: 0.9955 - macro_f1score: 0.3437 - val_loss: 2.3131 - val_accuracy: 0.5754 - val_top5_acc: 0.7643 - val_macro_f1score: 0.1875\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","191/191 [==============================] - ETA: 0s - loss: 0.1542 - accuracy: 0.9617 - top5_acc: 0.9973 - macro_f1score: 0.3499\n","Epoch 00034: val_loss did not improve from 2.09945\n","\n","Epoch 00034: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 456s 2s/step - loss: 0.1542 - accuracy: 0.9617 - top5_acc: 0.9973 - macro_f1score: 0.3499 - val_loss: 2.3316 - val_accuracy: 0.5737 - val_top5_acc: 0.7619 - val_macro_f1score: 0.1913\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","191/191 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9671 - top5_acc: 0.9977 - macro_f1score: 0.3521\n","Epoch 00035: val_loss did not improve from 2.09945\n","\n","Epoch 00035: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 451s 2s/step - loss: 0.1390 - accuracy: 0.9671 - top5_acc: 0.9977 - macro_f1score: 0.3521 - val_loss: 2.3402 - val_accuracy: 0.5802 - val_top5_acc: 0.7643 - val_macro_f1score: 0.1917\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","191/191 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9718 - top5_acc: 0.9984 - macro_f1score: 0.3546\n","Epoch 00036: val_loss did not improve from 2.09945\n","\n","Epoch 00036: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 446s 2s/step - loss: 0.1224 - accuracy: 0.9718 - top5_acc: 0.9984 - macro_f1score: 0.3546 - val_loss: 2.3051 - val_accuracy: 0.5785 - val_top5_acc: 0.7643 - val_macro_f1score: 0.1878\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","191/191 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9756 - top5_acc: 0.9989 - macro_f1score: 0.3551\n","Epoch 00037: val_loss did not improve from 2.09945\n","\n","Epoch 00037: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 445s 2s/step - loss: 0.1148 - accuracy: 0.9756 - top5_acc: 0.9989 - macro_f1score: 0.3551 - val_loss: 2.3559 - val_accuracy: 0.5832 - val_top5_acc: 0.7660 - val_macro_f1score: 0.1895\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","191/191 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.9792 - top5_acc: 0.9994 - macro_f1score: 0.3585\n","Epoch 00038: val_loss did not improve from 2.09945\n","\n","Epoch 00038: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 442s 2s/step - loss: 0.1046 - accuracy: 0.9792 - top5_acc: 0.9994 - macro_f1score: 0.3585 - val_loss: 2.3620 - val_accuracy: 0.5679 - val_top5_acc: 0.7615 - val_macro_f1score: 0.1874\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9807 - top5_acc: 0.9994 - macro_f1score: 0.3575\n","Epoch 00039: val_loss did not improve from 2.09945\n","\n","Epoch 00039: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 425s 2s/step - loss: 0.0987 - accuracy: 0.9807 - top5_acc: 0.9994 - macro_f1score: 0.3575 - val_loss: 2.3316 - val_accuracy: 0.5710 - val_top5_acc: 0.7666 - val_macro_f1score: 0.1868\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9828 - top5_acc: 0.9995 - macro_f1score: 0.3595\n","Epoch 00040: val_loss did not improve from 2.09945\n","\n","Epoch 00040: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 430s 2s/step - loss: 0.0955 - accuracy: 0.9828 - top5_acc: 0.9995 - macro_f1score: 0.3595 - val_loss: 2.2926 - val_accuracy: 0.5822 - val_top5_acc: 0.7666 - val_macro_f1score: 0.1943\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9844 - top5_acc: 0.9998 - macro_f1score: 0.3601\n","Epoch 00041: val_loss did not improve from 2.09945\n","\n","Epoch 00041: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 455s 2s/step - loss: 0.0923 - accuracy: 0.9844 - top5_acc: 0.9998 - macro_f1score: 0.3601 - val_loss: 2.3203 - val_accuracy: 0.5754 - val_top5_acc: 0.7636 - val_macro_f1score: 0.1881\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9877 - top5_acc: 0.9997 - macro_f1score: 0.3625\n","Epoch 00042: val_loss did not improve from 2.09945\n","\n","Epoch 00042: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 455s 2s/step - loss: 0.0830 - accuracy: 0.9877 - top5_acc: 0.9997 - macro_f1score: 0.3625 - val_loss: 2.2999 - val_accuracy: 0.5754 - val_top5_acc: 0.7677 - val_macro_f1score: 0.1876\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9874 - top5_acc: 0.9996 - macro_f1score: 0.3628\n","Epoch 00043: val_loss did not improve from 2.09945\n","\n","Epoch 00043: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 436s 2s/step - loss: 0.0832 - accuracy: 0.9874 - top5_acc: 0.9996 - macro_f1score: 0.3628 - val_loss: 2.3185 - val_accuracy: 0.5785 - val_top5_acc: 0.7632 - val_macro_f1score: 0.1882\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9867 - top5_acc: 0.9996 - macro_f1score: 0.3628\n","Epoch 00044: val_loss did not improve from 2.09945\n","\n","Epoch 00044: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 428s 2s/step - loss: 0.0849 - accuracy: 0.9867 - top5_acc: 0.9996 - macro_f1score: 0.3628 - val_loss: 2.2967 - val_accuracy: 0.5771 - val_top5_acc: 0.7653 - val_macro_f1score: 0.1866\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9887 - top5_acc: 0.9997 - macro_f1score: 0.3636\n","Epoch 00045: val_loss did not improve from 2.09945\n","\n","Epoch 00045: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 434s 2s/step - loss: 0.0803 - accuracy: 0.9887 - top5_acc: 0.9997 - macro_f1score: 0.3636 - val_loss: 2.2847 - val_accuracy: 0.5720 - val_top5_acc: 0.7711 - val_macro_f1score: 0.1849\n","Learning rate:  0.0001\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 46/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9886 - top5_acc: 0.9998 - macro_f1score: 0.3635\n","Epoch 00046: val_loss did not improve from 2.09945\n","\n","Epoch 00046: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 445s 2s/step - loss: 0.0779 - accuracy: 0.9886 - top5_acc: 0.9998 - macro_f1score: 0.3635 - val_loss: 2.3033 - val_accuracy: 0.5710 - val_top5_acc: 0.7711 - val_macro_f1score: 0.1863\n","Learning rate:  0.0001\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 47/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9883 - top5_acc: 0.9999 - macro_f1score: 0.3624\n","Epoch 00047: val_loss did not improve from 2.09945\n","\n","Epoch 00047: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 445s 2s/step - loss: 0.0774 - accuracy: 0.9883 - top5_acc: 0.9999 - macro_f1score: 0.3624 - val_loss: 2.3139 - val_accuracy: 0.5679 - val_top5_acc: 0.7653 - val_macro_f1score: 0.1823\n","Learning rate:  0.0001\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 48/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9900 - top5_acc: 0.9998 - macro_f1score: 0.3637\n","Epoch 00048: val_loss did not improve from 2.09945\n","\n","Epoch 00048: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 454s 2s/step - loss: 0.0750 - accuracy: 0.9900 - top5_acc: 0.9998 - macro_f1score: 0.3637 - val_loss: 2.3237 - val_accuracy: 0.5666 - val_top5_acc: 0.7636 - val_macro_f1score: 0.1863\n","Learning rate:  0.0001\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 49/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9896 - top5_acc: 0.9999 - macro_f1score: 0.3640\n","Epoch 00049: val_loss did not improve from 2.09945\n","\n","Epoch 00049: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 448s 2s/step - loss: 0.0755 - accuracy: 0.9896 - top5_acc: 0.9999 - macro_f1score: 0.3640 - val_loss: 2.2466 - val_accuracy: 0.5768 - val_top5_acc: 0.7694 - val_macro_f1score: 0.1861\n","Learning rate:  0.0001\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 50/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9892 - top5_acc: 0.9997 - macro_f1score: 0.3634\n","Epoch 00050: val_loss did not improve from 2.09945\n","\n","Epoch 00050: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 437s 2s/step - loss: 0.0763 - accuracy: 0.9892 - top5_acc: 0.9997 - macro_f1score: 0.3634 - val_loss: 2.3337 - val_accuracy: 0.5707 - val_top5_acc: 0.7615 - val_macro_f1score: 0.1839\n","Learning rate:  0.0001\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 51/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9908 - top5_acc: 0.9999 - macro_f1score: 0.3661\n","Epoch 00051: val_loss did not improve from 2.09945\n","\n","Epoch 00051: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 449s 2s/step - loss: 0.0708 - accuracy: 0.9908 - top5_acc: 0.9999 - macro_f1score: 0.3661 - val_loss: 2.2347 - val_accuracy: 0.5754 - val_top5_acc: 0.7673 - val_macro_f1score: 0.1871\n","Learning rate:  0.0001\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 52/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9892 - top5_acc: 0.9996 - macro_f1score: 0.3630\n","Epoch 00052: val_loss did not improve from 2.09945\n","\n","Epoch 00052: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 450s 2s/step - loss: 0.0745 - accuracy: 0.9892 - top5_acc: 0.9996 - macro_f1score: 0.3630 - val_loss: 2.3357 - val_accuracy: 0.5615 - val_top5_acc: 0.7578 - val_macro_f1score: 0.1829\n","Learning rate:  0.0001\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 53/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9893 - top5_acc: 0.9998 - macro_f1score: 0.3656\n","Epoch 00053: val_loss did not improve from 2.09945\n","\n","Epoch 00053: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 430s 2s/step - loss: 0.0729 - accuracy: 0.9893 - top5_acc: 0.9998 - macro_f1score: 0.3656 - val_loss: 2.3521 - val_accuracy: 0.5591 - val_top5_acc: 0.7534 - val_macro_f1score: 0.1797\n","Learning rate:  0.0001\n","\n","Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 54/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9897 - top5_acc: 0.9998 - macro_f1score: 0.3661\n","Epoch 00054: val_loss did not improve from 2.09945\n","\n","Epoch 00054: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 426s 2s/step - loss: 0.0737 - accuracy: 0.9897 - top5_acc: 0.9998 - macro_f1score: 0.3661 - val_loss: 2.3054 - val_accuracy: 0.5686 - val_top5_acc: 0.7609 - val_macro_f1score: 0.1791\n","Learning rate:  0.0001\n","\n","Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 55/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9902 - top5_acc: 0.9998 - macro_f1score: 0.3647\n","Epoch 00055: val_loss did not improve from 2.09945\n","\n","Epoch 00055: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 424s 2s/step - loss: 0.0710 - accuracy: 0.9902 - top5_acc: 0.9998 - macro_f1score: 0.3647 - val_loss: 2.2630 - val_accuracy: 0.5713 - val_top5_acc: 0.7663 - val_macro_f1score: 0.1829\n","Learning rate:  0.0001\n","\n","Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 56/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9909 - top5_acc: 0.9998 - macro_f1score: 0.3659\n","Epoch 00056: val_loss did not improve from 2.09945\n","\n","Epoch 00056: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 422s 2s/step - loss: 0.0697 - accuracy: 0.9909 - top5_acc: 0.9998 - macro_f1score: 0.3659 - val_loss: 2.3521 - val_accuracy: 0.5526 - val_top5_acc: 0.7565 - val_macro_f1score: 0.1784\n","Learning rate:  0.0001\n","\n","Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 57/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9902 - top5_acc: 0.9999 - macro_f1score: 0.3655\n","Epoch 00057: val_loss did not improve from 2.09945\n","\n","Epoch 00057: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 417s 2s/step - loss: 0.0715 - accuracy: 0.9902 - top5_acc: 0.9999 - macro_f1score: 0.3655 - val_loss: 2.3535 - val_accuracy: 0.5554 - val_top5_acc: 0.7554 - val_macro_f1score: 0.1821\n","Learning rate:  0.0001\n","\n","Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 58/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9919 - top5_acc: 0.9999 - macro_f1score: 0.3647\n","Epoch 00058: val_loss did not improve from 2.09945\n","\n","Epoch 00058: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 429s 2s/step - loss: 0.0657 - accuracy: 0.9919 - top5_acc: 0.9999 - macro_f1score: 0.3647 - val_loss: 2.3684 - val_accuracy: 0.5632 - val_top5_acc: 0.7514 - val_macro_f1score: 0.1825\n","Learning rate:  0.0001\n","\n","Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 59/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9905 - top5_acc: 0.9998 - macro_f1score: 0.3645\n","Epoch 00059: val_loss did not improve from 2.09945\n","\n","Epoch 00059: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 423s 2s/step - loss: 0.0707 - accuracy: 0.9905 - top5_acc: 0.9998 - macro_f1score: 0.3645 - val_loss: 2.4061 - val_accuracy: 0.5472 - val_top5_acc: 0.7435 - val_macro_f1score: 0.1740\n","Learning rate:  0.0001\n","\n","Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 60/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9900 - top5_acc: 0.9997 - macro_f1score: 0.3649\n","Epoch 00060: val_loss did not improve from 2.09945\n","\n","Epoch 00060: val_accuracy did not improve from 0.58594\n","191/191 [==============================] - 422s 2s/step - loss: 0.0734 - accuracy: 0.9900 - top5_acc: 0.9997 - macro_f1score: 0.3649 - val_loss: 2.3393 - val_accuracy: 0.5608 - val_top5_acc: 0.7565 - val_macro_f1score: 0.1783\n","Learning rate:  1e-05\n","\n","Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 61/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9957 - top5_acc: 1.0000 - macro_f1score: 0.3686\n","Epoch 00061: val_loss did not improve from 2.09945\n","\n","Epoch 00061: val_accuracy improved from 0.58594 to 0.58798, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/061.h5\n","191/191 [==============================] - 426s 2s/step - loss: 0.0477 - accuracy: 0.9957 - top5_acc: 1.0000 - macro_f1score: 0.3686 - val_loss: 2.1195 - val_accuracy: 0.5880 - val_top5_acc: 0.7785 - val_macro_f1score: 0.1874\n","Learning rate:  1e-05\n","\n","Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 62/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.3701\n","Epoch 00062: val_loss improved from 2.09945 to 2.08248, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/062.h5\n","\n","Epoch 00062: val_accuracy improved from 0.58798 to 0.59103, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/062.h5\n","191/191 [==============================] - 430s 2s/step - loss: 0.0382 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.3701 - val_loss: 2.0825 - val_accuracy: 0.5910 - val_top5_acc: 0.7785 - val_macro_f1score: 0.1837\n","Learning rate:  1e-05\n","\n","Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 63/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9980 - top5_acc: 0.9999 - macro_f1score: 0.3686\n","Epoch 00063: val_loss improved from 2.08248 to 2.05953, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/063.h5\n","\n","Epoch 00063: val_accuracy did not improve from 0.59103\n","191/191 [==============================] - 431s 2s/step - loss: 0.0384 - accuracy: 0.9980 - top5_acc: 0.9999 - macro_f1score: 0.3686 - val_loss: 2.0595 - val_accuracy: 0.5866 - val_top5_acc: 0.7806 - val_macro_f1score: 0.1906\n","Learning rate:  1e-05\n","\n","Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 64/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9989 - top5_acc: 1.0000 - macro_f1score: 0.3692\n","Epoch 00064: val_loss improved from 2.05953 to 2.03954, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/064.h5\n","\n","Epoch 00064: val_accuracy did not improve from 0.59103\n","191/191 [==============================] - 426s 2s/step - loss: 0.0393 - accuracy: 0.9989 - top5_acc: 1.0000 - macro_f1score: 0.3692 - val_loss: 2.0395 - val_accuracy: 0.5904 - val_top5_acc: 0.7772 - val_macro_f1score: 0.1857\n","Learning rate:  1e-05\n","\n","Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 65/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9987 - top5_acc: 1.0000 - macro_f1score: 0.3685\n","Epoch 00065: val_loss improved from 2.03954 to 2.00833, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/065.h5\n","\n","Epoch 00065: val_accuracy did not improve from 0.59103\n","191/191 [==============================] - 426s 2s/step - loss: 0.0406 - accuracy: 0.9987 - top5_acc: 1.0000 - macro_f1score: 0.3685 - val_loss: 2.0083 - val_accuracy: 0.5887 - val_top5_acc: 0.7782 - val_macro_f1score: 0.1851\n","Learning rate:  1e-05\n","\n","Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 66/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.3684\n","Epoch 00066: val_loss improved from 2.00833 to 2.00589, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/066.h5\n","\n","Epoch 00066: val_accuracy did not improve from 0.59103\n","191/191 [==============================] - 429s 2s/step - loss: 0.0423 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.3684 - val_loss: 2.0059 - val_accuracy: 0.5887 - val_top5_acc: 0.7802 - val_macro_f1score: 0.1884\n","Learning rate:  1e-05\n","\n","Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 67/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9991 - top5_acc: 1.0000 - macro_f1score: 0.3694\n","Epoch 00067: val_loss improved from 2.00589 to 1.98569, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/067.h5\n","\n","Epoch 00067: val_accuracy did not improve from 0.59103\n","191/191 [==============================] - 427s 2s/step - loss: 0.0446 - accuracy: 0.9991 - top5_acc: 1.0000 - macro_f1score: 0.3694 - val_loss: 1.9857 - val_accuracy: 0.5873 - val_top5_acc: 0.7816 - val_macro_f1score: 0.1871\n","Learning rate:  1e-05\n","\n","Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 68/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.3689\n","Epoch 00068: val_loss did not improve from 1.98569\n","\n","Epoch 00068: val_accuracy did not improve from 0.59103\n","191/191 [==============================] - 422s 2s/step - loss: 0.0482 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.3689 - val_loss: 2.0002 - val_accuracy: 0.5846 - val_top5_acc: 0.7768 - val_macro_f1score: 0.1808\n","Learning rate:  1e-05\n","\n","Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 69/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9985 - top5_acc: 1.0000 - macro_f1score: 0.3689\n","Epoch 00069: val_loss improved from 1.98569 to 1.96137, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/069.h5\n","\n","Epoch 00069: val_accuracy did not improve from 0.59103\n","191/191 [==============================] - 421s 2s/step - loss: 0.0510 - accuracy: 0.9985 - top5_acc: 1.0000 - macro_f1score: 0.3689 - val_loss: 1.9614 - val_accuracy: 0.5876 - val_top5_acc: 0.7806 - val_macro_f1score: 0.1824\n","Learning rate:  1e-05\n","\n","Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 70/70\n","191/191 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9987 - top5_acc: 1.0000 - macro_f1score: 0.3693\n","Epoch 00070: val_loss improved from 1.96137 to 1.95524, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNet50/070.h5\n","\n","Epoch 00070: val_accuracy did not improve from 0.59103\n","191/191 [==============================] - 422s 2s/step - loss: 0.0540 - accuracy: 0.9987 - top5_acc: 1.0000 - macro_f1score: 0.3693 - val_loss: 1.9552 - val_accuracy: 0.5904 - val_top5_acc: 0.7802 - val_macro_f1score: 0.1816\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6J7qM483RMST"},"source":["### 2) ResNet50 Evaluate"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"zg1v-zqzRMSU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605275625818,"user_tz":-540,"elapsed":38671310,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"737df565-7342-4d97-ebc1-5e12872fd72b"},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["24/24 [==============================] - 813s 34s/step - loss: 1.9771 - accuracy: 0.5745 - top5_acc: 0.7780 - macro_f1score: 0.1799\n","[Test Loss: 1.9771 /  Test Top-1 Accuracy: 0.5745 / Test Top-5 Accuracy: 0.7780 / Test Macro f1: 0.1799]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mWbV6MR0RMSY"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_HOf2qVRMSe"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DLCKPSirRMSi"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'ResNet50.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWoU3mT7RMSn"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yovtXW4cRMSs","colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"status":"ok","timestamp":1605275627176,"user_tz":-540,"elapsed":38672645,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"1e4c8327-63b8-4a27-85b4-6777e5beed46"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e9Lr4I0QQIGFSkqvaiIgquI6IK6oKAgiFhYsdd1EbGgq6I/LFhwUQGVxIIURVSw0BYpgpQgihAg1NA7JOH8/nhnyCSZSZ1kSt7P88wzmXvPvfPOzcw7Z8499xxxzmGMMSbylQh1AMYYY4LDEroxxkQJS+jGGBMlLKEbY0yUsIRujDFRwhK6McZECUvoYUZEvhGR/sEuG0oikigilxfCfn8SkUGev28Wke9yUzYfz1NfRA6KSMn8xmpMUbCEHgSeD7v3dkJEjvg8vjkv+3LOXeWcGxfssuFIRB4Xkdl+ltcQkeMicl5u9+Wc+9g51yVIcWX4AnLObXTOVXLOpQVj/57nqJ/pfeNE5JDP445Bep5Onvek73NlWwkQtU5EEoIRgyk6pUIdQDRwzlXy/i0iicAg59zMzOVEpJRzLrUoYwtzHwHPiUgD59x6n+W9gRXOuZUhiqvQOec2Ar7vGwc0d86tLYSn2+Kci8lD+UuAWkApEWnrnFtUCDH5ZZ+RgrEaeiHy1I6SROQxEdkGfCAip4rIVyKSLCJ7PH/H+Gzj24wwQETmishIT9n1InJVPss2EJHZInJARGaKyGgR+ShA3LmJ8VkRmefZ33ciUsNnfT8R2SAiu0Tk34GOj3MuCfgB6Jdp1S3A+JziyBTzABGZ6/P4ChH5XUT2icibgPisO0tEfvDEt1NEPhaRqp51E4D6wDRPbfZREYn11KBLecqcLiJTRWS3iKwVkdt99j1cRD4VkfGeY7NKRNoEOgYBXksVz/bJnuM4VERK+LzOeSLypue1/S4if8vL/nOhPzAFmO752ze2c0Xke89r3y4iT3iWlxSRJ0TkL8/rXiIi9TIfO0/ZzO/beSLyfyKyCxie3f/Hs009EZnkOT67PMeijCem833K1RKRwyJSM8jHJ2xZQi98tYFqwBnAHegx/8DzuD5wBHgzm+3bA2uAGsBLwFgRkXyU/QRYCFQHhpM1ifrKTYw3AbeiNbkywMMAItIUeNuz/9M9z5dd7XCcbywi0gho4Yk3r8fKu48awCRgKHos/gI6+BYBXvDE1wSohx4TnHP9gI3A3z3NLC/5eYo4IMmzfU/geRG5zGd9d0+ZqsDU3MScyRtAFeBM4FL0C+5Wn/XtPa+pBvAUMElEqmWzv1qe5LvekzgrBiooIhU8r+ljz623iJTxrKsMzARmoK/9bGCWZ9MHgT5AN+AUYCBwOJevtz2wDjgNGEE2/x/R8xhfARuAWKAuEOecO44e874+++0DzHLOJecyjsjnnLNbEG9AInC55+9OwHGgXDblWwB7fB7/hDbZAAwA1vqsqwA4oHZeyqLJMBWo4LP+I+CjXL4mfzEO9Xn8T2CG5+9h6AfMu66i5xhcHmDfFYD9wEWexyOAKfk8VnM9f98CLPApJ2gCHhRgv9cCS/39Dz2PYz3HshSaXNKAyj7rXwA+9Pw9HJjps64pcCQXx9ihCbKk53g19Vl3J/CTz+vcAojP+oVAvwD7re2JoQTQAJgNvJtNHH2BZM9rLQfsA67zrOvje5wybbcG6OFn+cljl83/bWMOx+bk/we40Bufn3Lt0S9j8TxeDNyQn89xpN6shl74kp1zR70PRKSCiLzr+Sm9H/2AVZXAPSi2ef9wznlrPJXyWPZ0YLfPMoBNgQLOZYzbfP4+7BPT6b77ds4dAnYFei5PTJ8Bt3h+TdwMjM9DHP5kjsH5PhaR00QkTkQ2e/b7EVrbzQ3vsTzgs2wDWlP0ynxsyvk2OeSgBlDas89A+9/seU2+608XkY6SfuJzFYBzbptzLsE5d8LpeYpHgX9k8/z9gU+dc6me9+0XpDe71EN/GfiT3bqcZHgv5vD/qQdscH7a2Z1zv6DHu5OINEa/IKfmM6aIZAm98GUezvIhoBHQ3jl3CnoCCnzaeAvBVqCa5+e0V71syhckxq2++/Y8Z/UcthkH3ABcAVQGphUwjswxCBlf7/Po/+V8z377ZtpndkOQbkGPZWWfZfWBzTnElFs7gRS0mSnQ/utmanarj574nOO0maiSc+7cAPt3BPjci56fuAzoKyLbRM/79AS6eZqxNqHNQP5sAs7ys/yQ5973vVfbT0y+svv/bALqZ/MFOc5Tvh/wuW9lqjiwhF70KqNtwXs97Z5PFfYTOuc2oD8/h3tOHl0I/L2QYvwcuEZELva0vT5Dzu+zOcBeYAzp7aEFieNr4FwRud7zwb+XjEmkMnAQ2CcidYFHMm2/nQCJyzm3CZgPvCAi5USkGXAbWossMKddIz8FRohIZRE5A22f9t1/LeBeESktIr3Qdubp/vYnIp1F5AxR9YD/oCc8/ekH/IF+ibbw3M5Bm6v6oG3XdUTkfhEp64mvvWfb/wLPikhDz3M1E5HqTtuvN6NfEiVFZCD+E7+v7P4/C9Ev7P+ISEXP/8D3/MhHwHVoUh+fw/NEHUvoRW8UUB6tiS1ATzAVhZvR9sddwHNAPHAsQNl8x+icWwXcjZ7U3ArsQRNCdts49MN3Bhk/hPmKwzm3E+iFJq9dQENgnk+Rp4FWaPvw1+gJVF8vAENFZK+IPOznKfqgbcNbgC+Bp5yfbqoFcA9as10HzEWP5fs+639BX9NO9JxDT+dcoGatlugX0CHP/Qr0C86f/sBbnmaakzfgHaC/p5npCrQysA34E+js2fZV9IvoO/ScyFj0fwdwO5qUdwHneuLITsD/j+cL7+9oc8pG9L11o8/6TcCvaA1/Tg7PE3W8Jw9MMSMi8cDvzrlC/4VggkdEBqAnFC8OdSzhSkTeR5ughoY6lqJmFxYVEyLSFtgNrAe6AD3QGqwxUUNEYoHr0V8mxY41uRQftdHuYgeB14HBzrmlIY3ImCASkWeBlcDLLuOVx8WGNbkYY0yUsBq6McZEiZC1odeoUcPFxsaG6umNMSYiLVmyZKdzzu/4NCFL6LGxsSxevDhUT2+MMRFJRDYEWmdNLsYYEyUsoRtjTJSwhG6MMVHCEroxxkQJS+jGGBMlckzoIvK+iOwQEb/zO3pGVntddCqu5SLSKvhhGmOMyUluaugfAl2zWX8VOvJbQ3SKtbcLHpYxxpi8yrEfunNutmfAm0B6AOM9Q6AuEJGqIlLHObc1SDEaU+jS0uDIETh8WG9Hj8KxY3o7ehSOH9fbsWN6n5KScXvn/N9SU/WWlqb3zoGI/1uJEul/B9r3iRMZ//Y+zrwcMu7Te+/dxlveu65kyfQyaWkZy3nXlyql95n3430+73N64/d9Hd4RRgIdJ9+bb3nffXpj9d68MZ84occ2JUVvaWlZ/7+ZtxfJelx948urzK85p/38/e/Qtm3enycnwbiwqC4Zp5BK8izLktBF5A60Fk/9+vWD8NTGpDt2DLZv19u2ben327bB1q1627FDy/kmAG/iNtHD35diQbbPTnb7DrSf008P34Sea865MeisNLRp08ZGBTNBsWULvPACvPee/8R86qlQpw7Urg3t2kG5clC6tNY4S5eGMmWgYkWoUEFv5cvrrWzZ9Fu5clrOeytdOuuH1V+tu3TprLXb7GqnvrXdzPv2rcH71rz9Lfc+T+ZavG9N3Bt/5hp5yZIZy504oWV8f2V412d+Pn81bN/XEOg4Zb55y/k7Ps6lx5yWpjH4/j9LBGhIzvzLJqdfRvnh/dUTKsFI6JvJOF9jDMGbX9GYgHbsgP/8B95+WxPNLbfAhRfCaadlvJUrF+pITTjwTeCF+RyhFIyEPhUYIiJxQHtgn7Wfm8L24Ydw993avt2vHwwbBmcGmr7YmGIix4QuIhOBTkANEUlCJ+otDeCcewednLYbsBY4DNxaWMEaA7BxI/zzn9CmjTazNGoU6oiMCQ+56eXSJ4f1Dp0U2Jgi8cADev/RR2Dn1o1JZ3OKmogyYwZMmgTPP2/J3JjM7NJ/EzGOHYN77oFzzoEHHwx1NMaEH6uhm4gxciSsXQvffqtdCY0xGVkN3USEDRtgxAjo2RO6dAl1NMaEJ0voJuw5B/ffr318X3011NEYE74soZuwtnw5dO4MkydrX/N69XLexpjiyhK6CUt79ugJ0JYtYeVKePddeOSRUEdlTHizk6ImrOzcqVeBvvgi7N4NgwfDM89AtWqhjsyY8GcJ3YScc/Dzz1oLnzRJh6e97DJtL2/ePNTRGRM5LKGbkPr6a21KWb0aqlaFu+6CO+6Ac88NdWTGRB5L6CYk/vhDL+GfPh0aN4Zx46BXLx221hiTP5bQTZHat0/7k48apcn71VdhyBAdx9oYUzCW0E2R2L4dXnsN3npLk/rAgToey2mnhToyY6KHJXRTqBIT4eWX4f33dSyWf/wDnnhCuyMaY4LLEropFGlp2pwydKj2YrnlFnj0UR1YyxhTOCyhm6D76y8YMADmzoXrr9emlpiYUEdlTPSzK0VN0DinfcmbN4cVK2DCBPj8c0vmxhQVS+gmKH77Tcdcuesunah5xQro2zf0k+YaU5xYQjcFkpysSbxVq/QxV7791gbRMiYULKGbfHEORo+Ghg3hv//VgbT+/FOv8ixh7ypjQsI+eibPnNPL9YcMgXbtdIjbUaPg1FNDHZkxxZv1cjF5cuKE1sbfeksT+muvWY3cmHBhH0WTa2lpcPvtmswfeQRef92SuTHhxD6OJldSUvTioPff15mDXnzRerAYE26sycVka88ePek5erRO1PzCC/D446GOyhjjjyV049eaNfB//6cXBx0+DJ06wZtvwjXXhDoyY0wgltBNFnFx0L+/Nqn07asnQW3mIGPCnyV0c5Jz2qTy739Dx47w2Wc2vK0xkcQSugH0pOfgwTB2LNx0k578LFs21FEZY/LCerkY9u+Hq6/WZD50KHz0kSVzYyKR1dCLuSNH9ETn//6nCX3gwFBHZIzJL0voxVhKik7MPHcufPIJ9O4d6oiMMQVhCb2YOnECbr0Vvv4a3n7bkrkx0cDa0Ish5+C+++Djj2HECB3+1hgT+SyhFzMnTmi3xDffhIcegn/9K9QRGWOCxZpcipHdu3Wuz2nTYNAgePllG4/FmGhiCb2Y+OUXuPFG2LJFR0kcMsSSuTHRxppcopxzmsA7dtTHc+fqpfyWzI2JPpbQo9iJE3r15333QdeusHSpzjBkjIlOuUroItJVRNaIyFoRyTJ4qojUF5EfRWSpiCwXkW7BD9XkRWqqDrD17rs63O2UKTZFnDHRLseELiIlgdHAVUBToI+INM1UbCjwqXOuJdAbeCvYgZrcO3YMbrhBL+EfMUIH3LImFmOiX25q6O2Atc65dc6540Ac0CNTGQec4vm7CrAleCGavDhyBK69Fr78Usczf+KJUEdkjCkquenlUhfY5PM4CWifqcxw4DsRuQeoCFzub0cicgdwB0D9+vXzGqvJweHDOi7LTz/Be+9p10RjTPERrJOifYAPnXMxQDdggohk2bdzboxzro1zrk3NmjWD9NQG4OhRuO46Tebjx1syN6Y4yk1C3wzU83kc41nm6zbgUwDn3P+AckCNYARocnb8uLaZf/edzv/Zt2+oIzLGhEJuEvoioKGINBCRMuhJz6mZymwE/gYgIk3QhJ4czECNf6mpcPPNevXn6NE2/K0xxVmObejOuVQRGQJ8C5QE3nfOrRKRZ4DFzrmpwEPAeyLyAHqCdIBzzhVm4AbS0vRS/s8/h1degX/+M9QRGRNiJ07AwoXaBunlHOzaBUlJ6beDB6FpU2jWTCfMbdwYSpfWMaX379fb7t0Zt0lKguRkXb5rl96XKKFX7V12GXTuDOeeq93MfvsNlizR28aNUKqU7t97f/vtcMUVQX/5ubr03zk3HZieadkwn78TgA7BDc3k5PHH00dMfPDBUEdTxI4c0Q+dTXpqvJyDO+7QmVoCKVcOYmKgfHn4/nttrwRNsiVLZvwi8FWqFJx+ur7fqleHhg31/tAhPXE1ZYqWq1oVDhzQ2hZAzZpw9tn6ODVVvzBSUvQLoRDYWC4R6sMPYeRIrZUXy66JgwfDuHFay+rSRW+XXAIVK4Y6ssK1eTPMmAF79mRcfuqpcNVVmnRyy7noukDhlVc0mT/wAHTvnnHdqadqIq9WLf01p6TAmjWwfDmsWKFJ95RT0m9Vq+o2MTFQq5bWxgPZsAF+/BHmzYPataF1a73FxBTpMZZQtYy0adPGLV68OCTPHenmzdNfeB07wjffaOWiWHFOPyg1a2qNafZsrVmVKQMXXqg/fS+7DNq312X5lZKiP7G3b9faWKCutvv3ay1tx46My8uUgUaNoEkTTRBeBw/CokWwYAFs2gRt28LFF2tNLvOH/8QJSEjQGuCUKbpddtq21QsRevTQZoSSJTOu37wZpk6FyZM15vbtdaS2667L+EZKTdU32ty5Om5E69bZP2929u7VhFnQ/0d2pkzR19CzJ8TFZZ98I5yILHHOtfG7zhJ6ZNmwQT+zVaroCIrVqoU6ohDYsAFiY+GNNzQZHTmiiee777SW9OuvmvTLl4eWLaFBAy3foAHUqQPbtkFiIqxfr7f9+zPuPzVVE/nOnRmX16un36IdO8I552jC++47nZDV+xM7kLp1NbHv2AErV2qiBqhcWX+ig9bsOnTQn/feNtvNmzUe0ITYo4fWPs84I+sx8SbqhQt1WYkS6V96tWtrm6/3M9ewoX7pff89rFunx+XOO+G88/QM+1dfZWwW6NEDnnlG25xz4hysWgXTp+uUWPPm6fFp0ED30adP1i+agli6VL8Qzz1Xv6QqVAjevsOQJfQocfCgft43bNDKXePGoY4oRD75RLv2/PqrJuzM9uzRWvsPP+jP6cRErQn7Jt0SJTRBx8bqz3HfmrFvIvTeNm/WL405c2DrVi0nojVXb5PPWWdljOPwYf1Jn5CgCW71av0GvvBCuOACHSmtalUtM2eO3ubP12QXE6NfAjExWnPPS3PKli360y0xUX9dbNum96VK6ZVn116rbx4RPSYzZmgXqW++0e1PPRWuvlqT+IUXajPGK6/oF1+vXvDww/q6MyflXbu0GWzMGH1NAC1aQLdu+mX26quafM87D55/XmMpaHPEli16HEX0i6xOnYLtLwJYQo8Czul45l98oZ+7Ll1CHVEI3X23Xj21Z48mqdxISdEa79atWlutVy9/bVXOaY32jz/0p1KNKLrc4q+/9Pi0b5/12OzZo0n9tde0ZlG5Mlx0kf5aadIEJk3S7lbHjumXwIAB+qVQt276Pk6cgM8+gyefhD//1GasqlV1X6ecol92rVqlf9lVqZJ9vCtX6mS4iYn6ZduiRbCPSFiyhB4F4uP1vfvCC9q7pVhr2VKTwcyZoY6k+Nm1C779Vn9NzJ2rSRU0+fbrp71Mzj8/+32kpMCECdr84+0iuH+//opYsyb9ZG3TpvrL5K67Mv76OXECRo3S3gCnnKK/2C73O9pIVLKEHuGSk/W93aCB/iLPbaU0Kh04oLW6oUPh6adDHY3ZvVubk1q1Ck4Po3370k8Yz5unX9ppaZrY775bPwgDB+q5ku7dddCiWrUK/rwRJLuEXpxTQ8S49159n7//fjFP5qAf9BMn9GSCCb1q1dKnwwqGKlW0tu2tcW/Zom3y776rTTgAlSppu/6tt0ZXt8sgiN6+PVFi8mTthfXkk3ouqdibP18/xO0zD/hpotLpp8Pw4doTIC4O7r9fr8IcONCSuR/W5BLG9uzRX5innaa/Qotdf3N/unTRttbffgt1JMaERHZNLlZDD2MPPqjt5x98YMkc0LbUBQusucWYACyhh6nPPtPL+x9/3H9X62JpxQo9KXrRRaGOxJiwZAk9DC1YALfconnrySdDHU0YmT9f762GboxfltDDzPr12hurbl09IVq2bKgjCiPz5umVgLGxoY7EmLBkCT2M7N2rPbNSU3UIDJulL5N58/Rni/VuMMYvS+hhIiVFB4pbu1avom7UKNQRhZnNm7XrmjW3GBNQcb9MJWzcey/MmqUnQjt1CnU0Ycjaz43JkdXQw8DEifDOO/Doo9C/f6ijCVPz5qUPh2uM8csSeoitXavjGXXooFPJRb24OB2He+7cvG03f76Obmgd8o0JyBJ6CB07pkPilimjtfRiMU7L+PE6sFLHjjrE6vbt2ZffuFHH7Vi61JpbjMlBcUghYevRR3WOhilTdHjuiPfyy5qsv/rK/xRgzukkBL1769CRI0dq38xnntGZ1w8cSB9KdfVqnQ3o999123r1dHhWY0xAltBDZPJkeP11HWso83y2YWHiRG3iOPvs3JX/v//TbyjQJNy0adYy69freNqdO2s7U//+OoXcffdlLVu+PFx6qZbr0kX3Z90VjcmWJfQQ2LRJR/5s0wZefDHU0fgxerQm2iuu0FpyTsaO1YFnLrlEp36bO9d/QvfOddmund43apQ+J+fRoxlnXK9WrfAmFDYmSllCL2LOaaXz+HE9Pxh2Oevbb7XGfOqpOrnAhg1ZJyT2FR8Pt9+uM8NPngz162uPlDvuyFp24UKteZ97bvoyERubxZggsZOiRWz8eJ2T9z//yTqncMglJMANN+jA695eKB98ELj8119D37464/oXX+g4BR06BO7BsnChzmxjPVWMKRSW0IvQli3aZn7xxTqbVlhJTtZZ2CtUgGnTtMnkiis0oaelZS2/ZYsm/xYt9CRohQq6vEMHnUR527aM5VNS9Aywt7nFGBN0ltCLiHMweLA2FY8d678TSMgcOQLXXaczvvt2ubntNu02+MMPWbd56ilN0p9+qm3eXhdfrPfz5mUsv2qVPo8ldGMKTTillagWFwdTp8Kzz8I554Q6Go89e+CFF+DMMzUBjxuXMeH26KEnJ8eOzbhdQoJOcPrPf2r3Q18tW0K5clmbXTKfEDXGBJ2dFC0CO3bAPfdoLnvggSJ+8m3b4KWXtBZ92ml6q15dT2C+9x4cOqTdAj/5RLsT+ipbVtvI33lHuxtWr67Ln3hCJ+odOjTr85Upo/N9Zq6hL1yo22f+AjDGBI0l9CLw8MN6zcz770PJkkX85PHx2kdcRNt9vEqVgj594KGH9KKeQG67TTvMf/yxjiA2b542y4wYATVq+N+mQwftj3noEFSsqMsWLtR+7daX3JhCY00uhWztWs2F99yTsbdekVm1SmvGx4/ricylS7Wbzfr12uUmu2QO0KyZdpgfO1a/EB55RGdiv//+wNtcfLGeSPU2sxw8qHFYc4sxhcpq6IXsxRe1l95DD4UogIQE7bFSqpTO9lOnTt73MXCgtpcPG6YXAb33XnqvFn8uvFBr4nPnajPOr7/CiROW0I0pZFZDL0SbNul5xttuy18eLTDnNKEX9KdBnz56ovO556BJEx1UKztVq2pfdm87urem3rZtweIwxmTLEnohGjlSc6p3iJMit3279mTxdxl+XlStqtMpgV4RlZthITt00CFvvU0vsbFQq1bB4jDGZMsSeiHZsUNbJvr2zf7K+UK1apXeFzShg/a3HD0a/v733JXv0EHPBK9cqQndmluMKXSW0AvJqFF6EdHjj4cwiIQEvQ9GQo+N1Xb03PZS8V5gNGmSjgdjCd2YQmcJvRDs3auV2V69QjzZc0KCDrJVu3bRP/cZZ2hvmLff1seW0I0pdJbQC8Gbb+ocDU88EeJAVq0K3TjiIlpLT07WcQ5atSr6GIwpZiyhB9mhQ9rccvXVOXfxLlTOpSf0UPFOGXfeeekXGBljCk2uErqIdBWRNSKyVkT8tgqLyA0ikiAiq0Tkk+CGGTneeEOvkvd3VXyRSk6G3btDm9C97ejW3GJMkcix/5mIlARGA1cAScAiEZnqnEvwKdMQ+BfQwTm3R0SKZf+0vXt12JRrroELLghxMN4ToiG5PNWjWTMdxfHmm0MXgzHFSG6uFG0HrHXOrQMQkTigB5DgU+Z2YLRzbg+Ac25HsAONBK++qt2+n3021JEQ3C6L+VWqlPZyMcYUidw0udQFNvk8TvIs83UOcI6IzBORBSLS1d+OROQOEVksIouTk5PzF3GYSk7WMbB69dI5H0IuIUFHWDz99FBHYowpIsE6KVoKaAh0AvoA74lI1cyFnHNjnHNtnHNtatasGaSnDg8vvgiHD8Mzz4Q6Eg/vGC42uqExxUZuEvpmoJ7P4xjPMl9JwFTnXIpzbj3wB5rgi4UtW7Tfeb9+0LhxqKPxCMYYLsaYiJKbhL4IaCgiDUSkDNAbmJqpzGS0do6I1ECbYNYFMc6wNmIEpKbqYIRFyjnYnPm7Fdi5U8ceCGX7uTGmyOWY0J1zqcAQ4FtgNfCpc26ViDwjIt09xb4FdolIAvAj8IhzbldhBR1OEhN1zJZBg3Qmt6DynZDCny+/1Pk/58/PuDyYl/wbYyJGrtrQnXPTnXPnOOfOcs6N8Cwb5pyb6vnbOecedM41dc6d75yLK8ygw8mIEToLUVD7nTsHr7yiE1MsXx643PjxWvbFFzMuD4cui8aYImdXihbAzp0wYQL07w91M/f7ya+0NJ3q7eGHtQ/ku+/6L7dvH3zzjY7VMnUqrF6dvi4hQef8jIkJUlDGmEhgCb0A3nsPjh3T/BsUhw/DP/6hg8E8/DDceCNMnKhPktmUKTqt3PjxUL68Dr7uFcoxXIwxIWMJPZ9SUuCtt+CKK4LUVL1jh07XNnWqjh/w8stw661aS582LWv5+Hgd0fDqq3WKuAkTtLsNpHdZNMYUK5bQ8+nLLyEpKUi18+PHoWtXWLFCdzxkiC6//HK9MGjcuIzld++G776DG27QWviDD2pTzWuv6bpt26z93JhiyBJ6Pr3+Opx1FnTrFoSdPfUULF0KcXHQo0f68pIltXP7N9/odHJeX36p/SRvvFEfn3mmXqL6zjuwYIEusxq6McWOJfR8WLJE5z8eMkSH+i6QuXN1RK9Bg6B796zr+/fX2vfHH6cvi4/XbxPfMcYfeUQHYX/kEX1sCd2YYscSej688YZ2Irn11gLu6MABuOUWbQt/9e4TQ+cAABnISURBVFX/ZZo00eFnP/xQuygmJ8MPP2jt3PekZ+vW8Le/aft5hQpQv34BgzPGRBpL6Hm0fbt2PBkwAKpUKeDOHnxQr0waPx4qVw5crn9/bV9ftgy++EJr7N7mFl++tfMC/3QwxkQa+9Tn0Zgxeg7Te94y36ZNg//+Fx57LH0iiEB694YyZfTkaFycDhhz/vlZy3Xpoj1lunQpYHDGmEiUm/HQjcexYzrncdeuBZz8ec8ebTNv3hyefjrn8tWqafv6uHF6QdGwYf77mItoc4wxpliyGnoeDBsGW7emt2zk24wZ2u989GiteedG//46JZJz/ptbjDHFntXQc2nuXL3W54474LLLCrizOXP0rGr79rnf5sor4bTT9NakSQEDMMZEI0voueDtjNKggY6ZVWBz58JFF+kUbblVurS2u5cvH4QAjDHRyBJ6Ljz0kHZG8VasC2TPHli5Ui8Eyqu2bQv45MaYaGZt6Dn4+msdhOvRR6FDhyDscP58bQfv2DEIOzPGmHSW0LOxcyfcdhs0a5a7zignN+reHf780//6uXO1+aRdu6DFaYwxYAk9W489pmNdTZgAZcvmcqOXXtK27rff9r9+zhy9qrNChaDFaYwxYAk9oPXrtdv34MFaQ8+V5GTtigg63sqJExnXHz0KixblfCGRMcbkgyX0AF58UQc7fPTRPGw0cqQm7aee0rHJ587NuH7RIr3M1NrPjTGFwBK6H0lJ8MEHOm9ErqeW89bOe/fWK48qVNBaui9vgr/ooqDGa4wxYAndr5df1taSxx7Lw0avvKJTyD35JFSsCNdcA599puOWe82dqxcF1agR9JiNMcYSeibbt+sAXP36QWxsLjfauVPnAe3dWwfOAv07ORl+/FEfp6XpIOrW3GKMKSSW0DN55RVt5n788Txu5K2de111lQ6JGxenj1et0oG17ISoMaaQWEL3sWuXTvx8441wzjm53GjnTp3x4sYbM46xUq4cXHstTJqk3xBz5uhyq6EbYwqJJXQfo0bBoUPw73/ncaPMtXOv3r11hMTvvtP287p1dXYiY4wpBJbQPfbv14mfr78ezj03lxudOKGzDXXr5n8Oz8sv17HMJ07UGnrHjv7HMTfGmCCwhO7x/vua1PPUdv6//8GmTVoT96dMGf2G+Pxz2LzZ2s+NMYXKEjraAeX113XwrTwNaBgfr2MCdO8euEzv3tqGDtZ+bowpVDZ8LjB1ql7q/9JLedgoLU37mXfrBqecErhcp046KcXRo3loyzHGmLyzhI6e1zzjDO2Ukmtz5sC2bTlPB1eyJDz/vI6DXrJkgeI0xpjsFPuE/uuvMHu2DsOSlwmEiI/Xy/uvuSbnsgMH5js+Y4zJrWLfhj5qlM5CNGhQHjZKTdUTnX//u17mb4wxYaBYJ/StW/VCzltvhSpV8rDhDz/oBUU5NbcYY0wRKtYJ/a23tLJ9770BChw/DgcPZl0eH6+X9V91VaHGZ4wxeVFsE/qRI/DOO9pqcvbZAQo99BDUqQNffJG+7PhxvZy/Rw+9vN8YY8JEsU3on3yirSb33x+gQFqatsccPQo9e+pMF6mp8P33ejm/NbcYY8JMse3lMm6cjqXVqVOAAvPna8afMEGHvX35ZViyRE+CVq0KXboUZbjGGJOjYpnQk5K0G/mzz2YztMrkyXrpfvfu0LcvtG8Pd90Fx47pWdQyZYo0ZmOMyUmxbHL59FO9D9hq4pwm9L/9Lf0q0AEDtNZ+5ZVw331FEaYxxuRJrhK6iHQVkTUislZEAg5fJSL/EBEnIm2CF2LwxcVB69bQsGGAAqtWwbp1euLTV6tWMGMGNG9e6DEaY0xe5ZjQRaQkMBq4CmgK9BGRLGPFikhl4D7gl2AHGUx//QWLFgUeIBHQ2jlkP+iWMcaEmdzU0NsBa51z65xzx4E4oIefcs8CLwJHgxhf0MXH6/0NN2RTaPJkuOAC7bJojDERIjcJvS6wyedxkmfZSSLSCqjnnPs6iLEVirg4HSa3fv0ABTZt0t4seRqpyxhjQq/AJ0VFpATwKvBQLsreISKLRWRxcnJyQZ86zxISYMWKHJpbpk7V+8zt58YYE+Zyk9A3A/V8Hsd4lnlVBs4DfhKRROACYKq/E6POuTHOuTbOuTY1a9bMf9T5FB8PJUrodUIBTZ4MjRpB48ZFFpcxxgRDbhL6IqChiDQQkTJAb2Cqd6Vzbp9zroZzLtY5FwssALo75xYXSsT55Jw2t3TuDLVrByi0dy/89JM1txhjIlKOCd05lwoMAb4FVgOfOudWicgzIhIx3UCWLYM//sihuWX6dL2835pbjDERKFdXijrnpgPTMy0bFqBsp4KHFXxxcTqBxfXXZ1No8mSdLq59+yKLyxhjgqVYXCmakqIJ/coroVq1AIWWLoVvvtHaeYlicViMMVGmWGSu556DjRvhzjv9rExJgaefhnbtdOqie+4p8viMMSYYoj6hL1gAI0ZAv3469nkGK1fqBUTDh+uVRqtWwXnnhSJMY4wpsKgebfHgQU3kMTHwxhuZVk6dCr166dxzX3yRQ+O6McaEv6hO6A89pGO3/PSTnzlD33oL6taFX36BEPSJN8aYYIvaJpdp02DMGHjkEbjkkkwrjx2D2bPhmmssmRtjokZUJvQdO2DQIB3l9pln/BRYsEAnFb388iKPzRhjCktUNrk8/zzs2QOzZkHZsn4KzJypXRMvvbTIYzPGmMISdTX0lBT4+GO9ej9gh5VZs7SbYpaGdWOMiVxRl9BnzNC5nW+5JUCB/fth4UKdXs4YY6JI1CX0ceOgVi29KtSvn3+GtDRrPzfGRJ2oSui7d2vvlptugtKlAxSaNQvKl4cLLyzS2IwxprBFVUKPj4fjx7NpbgE9IXrxxQHOlhpjTOSKqoQ+fjycfz60aBGgwLZtenm/NbcYY6JQ1CT0P/7Q7uW33AIiAQrNmqX3dkLUGBOFoiahjx+vXctvvjmbQrNm6fi5AavwxhgTuaIioZ84ARMmQJcuUKdOgELOaft5585QsmSRxmeMMUUhKhL6zz/reOfZngxduxY2bbL2c2NM1IqKhD5+PFSunMNUoDNn6r21nxtjolTEJ/SjR+Hzz3Vo8woVsik4axbUrw9nn11ksRljTFGK+MG5Zs3SiSx69cqmUGoq/PijVuEDdoExJvKlpKSQlJTE0aNHQx2KKaBy5coRExND6YBXSWYV8Ql9yhRtbuncOZtC06frZaTduxdZXMaEQlJSEpUrVyY2NhaxykvEcs6xa9cukpKSaNCgQa63i+gmlxMndCa5q67K4cLPMWO0+8vVVxdZbMaEwtGjR6levbol8wgnIlSvXj3Pv7QiOqH/8gts357DydCNG+Gbb+C227IZ4MWY6GHJPDrk5/8Y0Ql9yhQoVQq6dcum0Nix2gd90KAii8sYY0IhohP65MnQqRNUrRqgQGoq/Pe/0LUrnHFGUYZmTLG0a9cuWrRoQYsWLahduzZ169Y9+fj48ePZbrt48WLuvffeHJ/joosuCkqsiYmJlC9f/mR8d911V7blW7RoQe/evYPy3IUlYk+KrlmjtyFD0K4uTZtmvUx0+nTYsgVGjw5JjMYUN9WrV2fZsmUADB8+nEqVKvHwww+fXJ+amkqpUv7TTps2bWjTpk2OzzF//vzgBAucddZZJ+PNzurVq0lLS2POnDkcOnSIihUrBi2GYIrYhD5lit73uOwANLsSYmNh7lyoXTu9kJ0MNcXY/fdDLnJVnrRoAaNG5W2bAQMGUK5cOZYuXUqHDh3o3bs39913H0ePHqV8+fJ88MEHNGrUiJ9++omRI0fy1VdfMXz4cDZu3Mi6devYuHEj999//8nae6VKlTh48CA//fQTw4cPp0aNGqxcuZLWrVvz0UcfISJMnz6dBx98kIoVK9KhQwfWrVvHV199le/XPXHiRPr168fq1auZMmUKN910EwCLFi3ivvvu49ChQ5QtW5ZZs2ZRoUIFHnvsMWbMmEGJEiW4/fbbueeee/L93HkR0Qm9ZUuot22RzkD01186TdHPP2sbjPdk6BNP2MlQY0IsKSmJ+fPnU7JkSfbv38+cOXMoVaoUM2fO5IknnuCLL77Iss3vv//Ojz/+yIEDB2jUqBGDBw/O0id76dKlrFq1itNPP50OHTowb9482rRpw5133sns2bNp0KABffr0CRjX+vXradmyJaeccgrPPfccHTt29FsuPj6e77//nt9//5033niDm266iePHj3PjjTcSHx9P27Zt2b9/P+XLl2fMmDEkJiaybNkySpUqxe7duwt28PIgIhP69u3wv//B8OFoVxfQ2S369tXa+Hff2clQU+zltSZdmHr16kVJz6B4+/bto3///vz555+ICCkpKX63ufrqqylbtixly5alVq1abN++nZiYmAxl2rVrd3JZixYtSExMpFKlSpx55pkn+2/36dOHMWPGZNl/nTp12LhxI9WrV2fJkiVce+21rFq1ilNOOSVDucWLF1OjRg3q169P3bp1GThwILt372bz5s3UqVOHtm3bApzcbubMmdx1110nm5aqVauW38OWZxF5UnTaNM3VPXqgg6A3agQ33ACffKKPe/bUhG4nQ40JC75tzk8++SSdO3dm5cqVTJs2LWBf67I+F5eULFmS1NTUfJUJpGzZslSvXh2A1q1bc9ZZZ/HHH3/w5ZdfnjxRunjxYiZOnMjvv/9ObGwsZ511Fvv37/f7iyIcRGRCnzJF83Sz853W0Nu31xU9e8K778KMGbB5M9xxR2gDNcZksW/fPurWrQvAhx9+GPT9N2rUiHXr1pGYmAhoc4k/ycnJpKWlAbBu3Tr+/PNPzjzzTK677jqWLVvGsmXLaNWqFZ9++ikrVqwgMTGRxMREpkyZwsSJE2nUqBFbt25l0aJFABw4cIDU1FSuuOIK3n333ZNfLkXZ5BJxCf3gQfj+e7j2WpCNG7T95YIL0gsMGgRvvKGd0+1kqDFh59FHH+Vf//oXLVu2zFONOrfKly/PW2+9RdeuXWndujWVK1emSpUqWcrNnj2bZs2a0aJFC3r27Mk777yTpXlkzpw51K1bl9NPP/3ksksuuYSEhAR27dpFfHw899xzD82bN+eKK67g6NGjDBo0iPr169OsWTOaN2/OJ598EvTXGIg454rsyXy1adPGLV68OM/bTZoE//gH/PADdN4eB336wK+/6hlSY4q51atX06RJk1CHEXIHDx6kUqVKOOe4++67adiwIQ888ECow8ozf/9PEVninPPbvzPiauj79kGTJtCxI9rcUr68zgxtjDEe7733Hi1atODcc89l37593HnnnaEOqUhEXA0d9ISoCHDhhdolcfbs4AZnTISyGnp0ifoaOniS+bFj2tTiPSFqjDHFXEQmdAB++w2OH894QtQYY4qxyE3oCxbovSV0Y4wBcpnQRaSriKwRkbUi8rif9Q+KSIKILBeRWSJS+FfzLFgAdevqzRhjTM4JXURKAqOBq4CmQB8RaZqp2FKgjXOuGfA58FKwA83il1+sdm5MmOncuTPffvtthmWjRo1i8ODBAbfp1KkT3g4S3bp1Y+/evVnKDB8+nJEjR2b73JMnTyYhIeHk42HDhjFz5sy8hO9XJA2zm5saejtgrXNunXPuOBAHZJgjyDn3o3PusOfhAiCGwrRjB6xbZwndmDDTp08f4uLiMiyLi4vLdoAsX9OnT6dqwAkOspc5oT/zzDNcfvnl+dpXZt5hdpctW8Y777wTsFzmYXaLWm4G56oLbPJ5nARk17XkNuCbggSVI++AXNbDxZjAQjB+bs+ePRk6dCjHjx+nTJkyJCYmsmXLFjp27MjgwYNZtGgRR44coWfPnjz99NNZto+NjT05GNaIESMYN24ctWrVol69erRu3RrQPuZjxozh+PHjnH322UyYMIFly5YxdepUfv75Z5577jm++OILnn32Wa655hp69uzJrFmzePjhh0lNTaVt27a8/fbblC1bltjYWPr378+0adNISUnhs88+o3Hjxvk+PKEeZjeoJ0VFpC/QBng5wPo7RGSxiCxOTk7O/xP98guULAmef7AxJjxUq1aNdu3a8c03WqeLi4vjhhtuQEQYMWIEixcvZvny5fz8888sX7484H6WLFlCXFwcy5YtY/r06SfHSwG4/vrrWbRoEb/99htNmjRh7NixXHTRRXTv3p2XX36ZZcuWcdZZZ50sf/ToUQYMGEB8fDwrVqwgNTWVt99+++T6GjVq8OuvvzJ48OCAzTreYXYvvfRS5syZEzDu+Ph4evfuTZ8+fZg4cSLAyWF2X3vtNX777TdmzpyZZZjd5cuXc/PNN+fuIGcjNzX0zUA9n8cxnmUZiMjlwL+BS51zx/ztyDk3BhgDemFRnqP1WrAAmjeHChXyvQtjol6Ixs/1Nrv06NGDuLg4xo4dC8Cnn37KmDFjSE1NZevWrSQkJNCsWTO/+5gzZw7XXXcdFTyf8e7du59ct3LlSoYOHcrevXs5ePAgV155ZbbxrFmzhgYNGnDOOecA0L9/f0aPHs39998P6BcE6IiLkyZNyrJ9JA2zm5sa+iKgoYg0EJEyQG9gqm8BEWkJvAt0d87tKHBU2UlLg4ULrbnFmDDVo0cPZs2axa+//srhw4dp3bo169evZ+TIkcyaNYvly5dz9dVXBxw2NycDBgzgzTffZMWKFTz11FP53o+Xdwje7IbojZRhdnNM6M65VGAI8C2wGvjUObdKRJ4REe/X5stAJeAzEVkmIlMD7K7gfv8dDhywE6LGhKlKlSrRuXNnBg4cePJk6P79+6lYsSJVqlRh+/btJ5tkArnkkkuYPHkyR44c4cCBA0ybNu3kugMHDlCnTh1SUlL4+OOPTy6vXLkyBw4cyLKvRo0akZiYyNq1awGYMGECl156aa5fTyQNs5urGYucc9OB6ZmWDfP5OzinknPDLigyJuz16dOH66677mSPl+bNm9OyZUsaN25MvXr16NChQ7bbt2rVihtvvJHmzZtTq1atk80VAM8++yzt27enZs2atG/f/mQS7927N7fffjuvv/46n3/++cny5cqV44MPPqBXr14nT4rm1PXQ1+zZsxk2bBilS5emRIkSBRpm98iRI5QvX56ZM2cyaNAg/vjjD5o1a0bp0qW5/fbbGTJkSK7j8ifyBueaOhXefx++/NIzqIsxxssG54oueR2cK/LmFO3eXW/GGGMyiNyxXIwxxmRgCd2YKBOqZlQTXPn5P1pCNyaKlCtXjl27dllSj3DOOXbt2kW5cuXytF3ktaEbYwKKiYkhKSmJAl2JbcJCuXLliInJ27BYltCNiSKlS5emQYMGoQ7DhIg1uRhjTJSwhG6MMVHCEroxxkSJkF0pKiLJwAY/q2oAO4s4nIKymItGpMUcafGCxVxUChLzGc65mv5WhCyhByIiiwNd1hquLOaiEWkxR1q8YDEXlcKK2ZpcjDEmSlhCN8aYKBGOCX1MqAPIB4u5aERazJEWL1jMRaVQYg67NnRjjDH5E441dGOMMflgCd0YY6JEWCV0EekqImtEZK2IPB7qePwRkfdFZIeIrPRZVk1EvheRPz33p4YyRl8iUk9EfhSRBBFZJSL3eZaHc8zlRGShiPzmiflpz/IGIvKL5/0R75m0PKyISEkRWSoiX3keh3XMIpIoIis8cwEv9iwL5/dGVRH5XER+F5HVInJhmMfbyHNsvbf9InJ/YcUcNgldREoCo4GrgKZAHxFpGtqo/PoQ6Jpp2ePALOdcQ2CW53G4SAUecs41BS4A7vYc13CO+RhwmXOuOdAC6CoiFwAvAv/nnDsb2APcFsIYA7kPnUzdKxJi7uyca+HTLzqc3xuvATOcc42B5uixDtt4nXNrPMe2BdAaOAx8SWHF7JwLixtwIfCtz+N/Af8KdVwBYo0FVvo8XgPU8fxdB1gT6hiziX0KcEWkxAxUAH4F2qNX1pXy934JhxsQ4/lwXgZ8BUgExJwI1Mi0LCzfG0AVYD2ezhzhHq+f+LsA8woz5rCpoQN1gU0+j5M8yyLBac65rZ6/twGnhTKYQEQkFmgJ/EKYx+xpulgG7AC+B/4C9jrnUj1FwvH9MQp4FDjheVyd8I/ZAd+JyBIRucOzLFzfGw2AZOADT7PWf0WkIuEbb2a9gYmevwsl5nBK6FHB6Vdu2PUFFZFKwBfA/c65/b7rwjFm51ya05+pMUA7oHGIQ8qWiFwD7HDOLQl1LHl0sXOuFdrUebeIXOK7MszeG6WAVsDbzrmWwCEyNVWEWbwnec6ddAc+y7wumDGHU0LfDNTzeRzjWRYJtotIHQDP/Y4Qx5OBiJRGk/nHzrlJnsVhHbOXc24v8CPaXFFVRLyTsoTb+6MD0F1EEoE4tNnlNcI7Zpxzmz33O9C23XaE73sjCUhyzv3iefw5muDDNV5fVwG/Oue2ex4XSszhlNAXAQ09vQLKoD9PpoY4ptyaCvT3/N0fbacOCyIiwFhgtXPuVZ9V4RxzTRGp6vm7PNrmvxpN7D09xcIqZufcv5xzMc65WPS9+4Nz7mbCOGYRqSgilb1/o228KwnT94ZzbhuwSUQaeRb9DUggTOPNpA/pzS1QWDGH+kRBppMG3YA/0PbSf4c6ngAxTgS2AilojeE2tK10FvAnMBOoFuo4feK9GP05txxY5rl1C/OYmwFLPTGvBIZ5lp8JLATWoj9dy4Y61gDxdwK+CveYPbH95rmt8n7mwvy90QJY7HlvTAZODed4PTFXBHYBVXyWFUrMdum/McZEiXBqcjHGGFMAltCNMSZKWEI3xpgoYQndGGOihCV0Y4yJEpbQjTEmSlhCN8aYKPH/2QW3CxytZsQAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"IA98syIrYvyu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8FN2jQW6xRM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0z6BwcAulnw","executionInfo":{"status":"ok","timestamp":1606099208117,"user_tz":-540,"elapsed":1173,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / ResNet50"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c","executionInfo":{"status":"ok","timestamp":1606099208697,"user_tz":-540,"elapsed":1743,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak","executionInfo":{"status":"ok","timestamp":1606099208698,"user_tz":-540,"elapsed":1732,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pFcw51AuDG4","executionInfo":{"status":"ok","timestamp":1606099220638,"user_tz":-540,"elapsed":13657,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["model=load_model(os.path.join(dir,'model_output',number,'ResNet50','070.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWlrnY9EuDG-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606100747930,"user_tz":-540,"elapsed":1540945,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"6850a846-a6f3-418b-c862-37cd3694d7cc"},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["24/24 [==============================] - 1444s 60s/step - loss: 1.9720 - accuracy: 0.5749 - top5_acc: 0.7783 - macro_f1score: 0.1818\n","[Test Loss: 1.9720 /  Test Top-1 Accuracy: 0.5749 / Test Top-5 Accuracy: 0.7783 / Test Macro f1: 0.1818]\n","\n"],"name":"stdout"}]}]}
