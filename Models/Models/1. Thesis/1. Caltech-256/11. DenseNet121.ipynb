{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11.DenseNet121.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ucbQyskZRiX_","executionInfo":{"status":"ok","timestamp":1606099428117,"user_tz":-540,"elapsed":1221,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["#모형 출처 : https://github.com/titu1994/keras-squeeze-excite-network"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [DenseNet121]\n"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original DenseNet121\n","```\n","1) Support Functions\n","2) Almost orginal DenseNet121\n","```\n","3. DenseNet121\n","```\n","1) DenseNet121\n","2) DenseNet121 Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages\n"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099446195,"user_tz":-540,"elapsed":19283,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"3a1e8bb6-8fdb-4cae-9704-9ab0621cbb5a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099446198,"user_tz":-540,"elapsed":19272,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"1b674f6f-22c8-4a1e-d66e-45390711ad71"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1606099448673,"user_tz":-540,"elapsed":21742,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1606099448676,"user_tz":-540,"elapsed":21741,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606099448677,"user_tz":-540,"elapsed":21723,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"8f32779e-d900-4fb9-b622-c6be303dbf24"},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606099451840,"user_tz":-540,"elapsed":24862,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"d2102376-6efd-46d6-f16f-1afa5cdf3c54"},"source":["tf.__version__"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.3.0'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606099452407,"user_tz":-540,"elapsed":25411,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"b368a459-ffa1-4266-e077-e52aac399433"},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Kf057Rw2yigs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099452408,"user_tz":-540,"elapsed":25399,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"ced61a1b-68d8-445a-e413-90434af365e6"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 8494531085533431773\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 1167741017251339089\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 17414263906393405966\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15695549568\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 8444279738434843678\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EpLlsyj3hxeJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099452409,"user_tz":-540,"elapsed":25385,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"3406bf92-99a5-4126-c3f1-ebf1d4c68976"},"source":["!cat /proc/cpuinfo"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"BeJ7UtuOEgWY","executionInfo":{"status":"ok","timestamp":1606099452410,"user_tz":-540,"elapsed":25383,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CALTECH'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 224 # sizes after cropping\n","super_size = 256 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 64\n","weight_decay = 1e-3\n","epochs = 70"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1606099452410,"user_tz":-540,"elapsed":25380,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbP99pIGoIUp","executionInfo":{"status":"ok","timestamp":1606099452412,"user_tz":-540,"elapsed":25380,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1606099452414,"user_tz":-540,"elapsed":25380,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wzhKX9OVoIUw"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"Iz9u1paNoIUx","executionInfo":{"status":"ok","timestamp":1606099452415,"user_tz":-540,"elapsed":25377,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1606099452415,"user_tz":-540,"elapsed":25375,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"c2IcuMY2oIU3","executionInfo":{"status":"ok","timestamp":1606099452416,"user_tz":-540,"elapsed":25374,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"4t6c_JewoIU7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099498182,"user_tz":-540,"elapsed":71131,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"8cb273cf-f7d8-46e7-8f45-36b5ae33d7bc"},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Found 24509 images belonging to 257 classes.\n","Found 2980 images belonging to 257 classes.\n","Found 3118 images belonging to 257 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gn_DwVVV1qmT"},"source":["## 2. Support Functions & Almost Original DenseNet121\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"GrcgSgWh1qmT"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aBovAVC3gVsB"},"source":["def __conv_block(ip, nb_filter, bottleneck=False, dropout_rate=None, weight_decay=weight_decay):\n","\n","    concat_axis = -1\n","\n","    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n","    x = Activation('relu')(x)\n","\n","    if bottleneck:\n","        inter_channel = nb_filter * 4  # Obtained from https://github.com/liuzhuang13/DenseNet/blob/master/densenet.lua\n","\n","        x = Conv2D(inter_channel, (1, 1), kernel_initializer='he_uniform', padding='same', use_bias=False,\n","                   kernel_regularizer=l2(weight_decay))(x)\n","        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","        x = Activation('relu')(x)\n","\n","    x = Conv2D(nb_filter, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n","    if dropout_rate:\n","        x = Dropout(dropout_rate)(x)\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEOp1A-0gdee"},"source":["def __dense_block(x, nb_layers, nb_filter, growth_rate, bottleneck=False, dropout_rate=None, weight_decay=weight_decay,\n","                  grow_nb_filters=True, return_concat_list=False):\n","\n","    concat_axis = -1\n","\n","    x_list = [x]\n","\n","    for i in range(nb_layers):\n","        cb = __conv_block(x, growth_rate, bottleneck, dropout_rate, weight_decay)\n","        x_list.append(cb)\n","\n","        x = concatenate([x, cb], axis=concat_axis)\n","\n","        if grow_nb_filters:\n","            nb_filter += growth_rate\n","\n","    if return_concat_list:\n","        return x, nb_filter, x_list\n","    else:\n","        return x, nb_filter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-K3RzQuCgdc_"},"source":["def __transition_block(ip, nb_filter, compression=1.0, weight_decay=weight_decay):\n","\n","    concat_axis = -1\n","\n","    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n","    x = Activation('relu')(x)\n","    x = Conv2D(int(nb_filter * compression), (1, 1), kernel_initializer='he_uniform', padding='same', use_bias=False,\n","               kernel_regularizer=l2(weight_decay))(x)\n","    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n","\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2HhTzaFgdbi"},"source":["def __create_dense_net(nb_classes, img_input, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1,\n","                       nb_layers_per_block=-1, bottleneck=False, reduction=0.0, dropout_rate=None, weight_decay=weight_decay,\n","                       subsample_initial_block=False, activation='softmax'):\n","\n","    concat_axis = -1\n","\n","    if reduction != 0.0:\n","        assert 1.0 >= reduction > 0.0, 'reduction value must lie between 0.0 and 1.0'\n","\n","    # layers in each dense block\n","    if type(nb_layers_per_block) is list or type(nb_layers_per_block) is tuple:\n","        nb_layers = list(nb_layers_per_block)  # Convert tuple to list\n","\n","        assert len(nb_layers) == nb_dense_block, 'If list, nb_layer is used as provided. ' \\\n","                                                 'Note that list size must be (nb_dense_block)'\n","        final_nb_layer = nb_layers[-1]\n","        nb_layers = nb_layers[:-1]\n","    else:\n","        if nb_layers_per_block == -1:\n","            assert (depth - 4) % 3 == 0, 'Depth must be 3 N + 4 if nb_layers_per_block == -1'\n","            count = int((depth - 4) / 3)\n","            nb_layers = [count for _ in range(nb_dense_block)]\n","            final_nb_layer = count\n","        else:\n","            final_nb_layer = nb_layers_per_block\n","            nb_layers = [nb_layers_per_block] * nb_dense_block\n","\n","    # compute initial nb_filter if -1, else accept users initial nb_filter\n","    if nb_filter <= 0:\n","        nb_filter = 2 * growth_rate\n","\n","    # compute compression factor\n","    compression = 1.0 - reduction\n","\n","    # Initial convolution\n","    if subsample_initial_block:\n","        initial_kernel = (7, 7)\n","        initial_strides = (2, 2)\n","    else:\n","        initial_kernel = (3, 3)\n","        initial_strides = (1, 1)\n","\n","    x = Conv2D(nb_filter, initial_kernel, kernel_initializer='he_uniform', padding='same',\n","               strides=initial_strides, use_bias=False, kernel_regularizer=l2(weight_decay))(img_input)\n","\n","    if subsample_initial_block:\n","        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","        x = Activation('relu')(x)\n","        x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","\n","    # Add dense blocks\n","    for block_idx in range(nb_dense_block - 1):\n","        x, nb_filter = __dense_block(x, nb_layers[block_idx], nb_filter, growth_rate, bottleneck=bottleneck,\n","                                     dropout_rate=dropout_rate, weight_decay=weight_decay)\n","        # add transition_block\n","        x = __transition_block(x, nb_filter, compression=compression, weight_decay=weight_decay)\n","        nb_filter = int(nb_filter * compression)\n","\n","    # The last dense_block does not have a transition_block\n","    x, nb_filter = __dense_block(x, final_nb_layer, nb_filter, growth_rate, bottleneck=bottleneck,\n","                                 dropout_rate=dropout_rate, weight_decay=weight_decay)\n","\n","    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","    x = Activation('relu')(x)\n","    x = GlobalAveragePooling2D()(x)\n","\n","    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay),  activation=activation)(x)\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Lho4zoe1qmc"},"source":["### 2) Almost Orginial DenseNet121\n","\n"]},{"cell_type":"code","metadata":{"id":"7focbQW_gdZq"},"source":["def DenseNet(input_shape=None, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1, nb_layers_per_block=-1, bottleneck=False,\n","               reduction=0.0, dropout_rate=0.0, weight_decay=weight_decay, subsample_initial_block=False,\n","               weights=None, classes=classes, activation='softmax', name=None):\n","\n","\n","    if activation not in ['softmax', 'sigmoid']:\n","        raise ValueError('activation must be one of \"softmax\" or \"sigmoid\"')\n","\n","    if activation == 'sigmoid' and classes != 1:\n","        raise ValueError('sigmoid activation can only be used when classes = 1')\n","\n","    img_input = Input(shape=input_shape)\n","\n","    x = __create_dense_net(classes, img_input, depth, nb_dense_block,\n","                           growth_rate, nb_filter, nb_layers_per_block, bottleneck, reduction,\n","                           dropout_rate, weight_decay, subsample_initial_block, activation)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","\n","    inputs = img_input\n","\n","    # Create model.\n","    model = Model(inputs, x, name= name )\n","\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cCqpFfbZgdWF"},"source":["def DenseNet121(input_shape=None, bottleneck=True, reduction=0.5, growth_rate = 32, dropout_rate=0.0, weight_decay=weight_decay, classes=classes, activation='softmax', name = None):\n","\n","    return DenseNet(input_shape, depth=121, nb_dense_block=4, growth_rate=growth_rate, nb_filter=64,\n","                      nb_layers_per_block=[6, 12, 24, 16], bottleneck=bottleneck, reduction=reduction,\n","                      dropout_rate=dropout_rate, weight_decay=weight_decay, subsample_initial_block=True,\n","                      classes=classes, activation=activation , name = name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Y24Va7X1qmf"},"source":["## 3. DenseNet121\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"Wiva9k1w1qmg"},"source":["### 1) DenseNet121\n"]},{"cell_type":"code","metadata":{"id":"IA-KMy4xgdUD"},"source":["# densenet\n","\n","model = DenseNet121(input_shape=input_sizes, classes = classes, dropout_rate = 0.2, growth_rate = 32, name = 'DenseNet121')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YaOtPgAcgdRx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604975291587,"user_tz":-540,"elapsed":114047,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"6ddca52c-b439-4956-d8e9-62a088c7cb31"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"DenseNet121\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 112, 112, 64) 9408        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 56, 56, 128)  8192        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 56, 56, 128)  512         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 56, 56, 128)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 56, 56, 32)   36864       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 56, 56, 32)   0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 56, 56, 96)   0           max_pooling2d[0][0]              \n","                                                                 dropout[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 56, 56, 96)   384         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 56, 56, 96)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 56, 56, 128)  12288       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 56, 56, 128)  512         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 56, 56, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 56, 56, 32)   36864       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 56, 56, 32)   0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 56, 56, 128)  0           concatenate[0][0]                \n","                                                                 dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 56, 56, 128)  512         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 56, 56, 128)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 56, 56, 128)  16384       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 56, 56, 128)  512         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 56, 56, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 56, 56, 32)   36864       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 56, 56, 32)   0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 56, 56, 160)  0           concatenate_1[0][0]              \n","                                                                 dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 56, 56, 160)  640         concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 56, 56, 160)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 56, 56, 128)  20480       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 56, 56, 128)  512         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 56, 56, 128)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 56, 56, 32)   36864       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 56, 56, 32)   0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 56, 56, 192)  0           concatenate_2[0][0]              \n","                                                                 dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 56, 56, 192)  768         concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 56, 56, 192)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 56, 56, 128)  24576       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 56, 56, 128)  512         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 56, 56, 128)  0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 56, 56, 32)   36864       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 56, 56, 32)   0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 56, 56, 224)  0           concatenate_3[0][0]              \n","                                                                 dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 56, 56, 224)  896         concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 56, 56, 224)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 56, 56, 128)  28672       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 56, 56, 128)  512         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 56, 56, 128)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 56, 56, 32)   36864       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 56, 56, 32)   0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 56, 56, 256)  0           concatenate_4[0][0]              \n","                                                                 dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 56, 56, 256)  1024        concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 56, 56, 256)  0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 56, 56, 128)  32768       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 28, 28, 128)  0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 28, 28, 128)  16384       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 28, 28, 32)   36864       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 28, 28, 32)   0           conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 28, 28, 160)  0           average_pooling2d[0][0]          \n","                                                                 dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 28, 28, 160)  640         concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 28, 28, 160)  0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 28, 28, 128)  20480       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 28, 28, 32)   36864       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 28, 28, 32)   0           conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 28, 28, 192)  0           concatenate_6[0][0]              \n","                                                                 dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 28, 28, 192)  768         concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 28, 28, 192)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 28, 28, 128)  24576       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 28, 28, 32)   36864       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 28, 28, 32)   0           conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 28, 28, 224)  0           concatenate_7[0][0]              \n","                                                                 dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 28, 28, 224)  896         concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 28, 28, 224)  0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 28, 28, 128)  28672       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 28, 28, 32)   36864       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 28, 28, 32)   0           conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 28, 28, 256)  0           concatenate_8[0][0]              \n","                                                                 dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 28, 28, 256)  1024        concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 28, 28, 256)  0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 28, 28, 128)  32768       activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 28, 28, 128)  0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 28, 28, 32)   36864       activation_23[0][0]              \n","__________________________________________________________________________________________________\n","dropout_10 (Dropout)            (None, 28, 28, 32)   0           conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_10 (Concatenate)    (None, 28, 28, 288)  0           concatenate_9[0][0]              \n","                                                                 dropout_10[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 28, 28, 288)  1152        concatenate_10[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 28, 28, 288)  0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 28, 28, 128)  36864       activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 28, 28, 128)  512         conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 28, 28, 128)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 28, 28, 32)   36864       activation_25[0][0]              \n","__________________________________________________________________________________________________\n","dropout_11 (Dropout)            (None, 28, 28, 32)   0           conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_11 (Concatenate)    (None, 28, 28, 320)  0           concatenate_10[0][0]             \n","                                                                 dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 28, 28, 320)  1280        concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 28, 28, 320)  0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 28, 28, 128)  40960       activation_26[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 28, 28, 128)  512         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 28, 28, 128)  0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 28, 28, 32)   36864       activation_27[0][0]              \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 28, 28, 32)   0           conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_12 (Concatenate)    (None, 28, 28, 352)  0           concatenate_11[0][0]             \n","                                                                 dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 28, 28, 352)  1408        concatenate_12[0][0]             \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 28, 28, 352)  0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 28, 28, 128)  45056       activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 28, 28, 128)  512         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 28, 28, 128)  0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 28, 28, 32)   36864       activation_29[0][0]              \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 28, 28, 32)   0           conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_13 (Concatenate)    (None, 28, 28, 384)  0           concatenate_12[0][0]             \n","                                                                 dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 28, 28, 384)  1536        concatenate_13[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 28, 28, 384)  0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 28, 28, 128)  49152       activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 28, 28, 128)  512         conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 28, 28, 128)  0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 28, 28, 32)   36864       activation_31[0][0]              \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 28, 28, 32)   0           conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 28, 28, 416)  0           concatenate_13[0][0]             \n","                                                                 dropout_14[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 28, 28, 416)  1664        concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 28, 28, 416)  0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 28, 28, 128)  53248       activation_32[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 28, 28, 128)  512         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 28, 28, 128)  0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 28, 28, 32)   36864       activation_33[0][0]              \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 28, 28, 32)   0           conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 28, 28, 448)  0           concatenate_14[0][0]             \n","                                                                 dropout_15[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 28, 28, 448)  1792        concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 28, 28, 448)  0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 28, 28, 128)  57344       activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 28, 28, 128)  512         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 28, 28, 128)  0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 28, 28, 32)   36864       activation_35[0][0]              \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 28, 28, 32)   0           conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 28, 28, 480)  0           concatenate_15[0][0]             \n","                                                                 dropout_16[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 28, 28, 480)  1920        concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 28, 28, 480)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 28, 28, 128)  61440       activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 28, 28, 128)  512         conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 28, 28, 128)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 28, 28, 32)   36864       activation_37[0][0]              \n","__________________________________________________________________________________________________\n","dropout_17 (Dropout)            (None, 28, 28, 32)   0           conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 28, 28, 512)  0           concatenate_16[0][0]             \n","                                                                 dropout_17[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 28, 28, 512)  2048        concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 28, 28, 512)  0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 28, 28, 256)  131072      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 14, 14, 256)  0           conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 14, 14, 256)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 14, 14, 128)  32768       activation_39[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 14, 14, 128)  512         conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 14, 14, 128)  0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 14, 14, 32)   36864       activation_40[0][0]              \n","__________________________________________________________________________________________________\n","dropout_18 (Dropout)            (None, 14, 14, 32)   0           conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 14, 14, 288)  0           average_pooling2d_1[0][0]        \n","                                                                 dropout_18[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 14, 14, 288)  1152        concatenate_18[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 14, 14, 288)  0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 14, 14, 128)  36864       activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 14, 14, 128)  512         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 14, 14, 128)  0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 14, 14, 32)   36864       activation_42[0][0]              \n","__________________________________________________________________________________________________\n","dropout_19 (Dropout)            (None, 14, 14, 32)   0           conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_19 (Concatenate)    (None, 14, 14, 320)  0           concatenate_18[0][0]             \n","                                                                 dropout_19[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 14, 14, 320)  1280        concatenate_19[0][0]             \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 14, 14, 320)  0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 14, 14, 128)  40960       activation_43[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 14, 14, 128)  512         conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 14, 14, 128)  0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 14, 14, 32)   36864       activation_44[0][0]              \n","__________________________________________________________________________________________________\n","dropout_20 (Dropout)            (None, 14, 14, 32)   0           conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_20 (Concatenate)    (None, 14, 14, 352)  0           concatenate_19[0][0]             \n","                                                                 dropout_20[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 14, 14, 352)  1408        concatenate_20[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 14, 14, 352)  0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 14, 14, 128)  45056       activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 14, 14, 128)  512         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 14, 14, 128)  0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 14, 14, 32)   36864       activation_46[0][0]              \n","__________________________________________________________________________________________________\n","dropout_21 (Dropout)            (None, 14, 14, 32)   0           conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_21 (Concatenate)    (None, 14, 14, 384)  0           concatenate_20[0][0]             \n","                                                                 dropout_21[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 14, 14, 384)  1536        concatenate_21[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 14, 14, 384)  0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 14, 14, 128)  49152       activation_47[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 14, 14, 128)  512         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 14, 14, 128)  0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 14, 14, 32)   36864       activation_48[0][0]              \n","__________________________________________________________________________________________________\n","dropout_22 (Dropout)            (None, 14, 14, 32)   0           conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_22 (Concatenate)    (None, 14, 14, 416)  0           concatenate_21[0][0]             \n","                                                                 dropout_22[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 14, 14, 416)  1664        concatenate_22[0][0]             \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 14, 14, 416)  0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 14, 14, 128)  53248       activation_49[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 14, 14, 128)  512         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 14, 14, 128)  0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 14, 14, 32)   36864       activation_50[0][0]              \n","__________________________________________________________________________________________________\n","dropout_23 (Dropout)            (None, 14, 14, 32)   0           conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_23 (Concatenate)    (None, 14, 14, 448)  0           concatenate_22[0][0]             \n","                                                                 dropout_23[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 14, 14, 448)  1792        concatenate_23[0][0]             \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 14, 14, 448)  0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 14, 14, 128)  57344       activation_51[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 14, 14, 128)  512         conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 14, 14, 128)  0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 14, 14, 32)   36864       activation_52[0][0]              \n","__________________________________________________________________________________________________\n","dropout_24 (Dropout)            (None, 14, 14, 32)   0           conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_24 (Concatenate)    (None, 14, 14, 480)  0           concatenate_23[0][0]             \n","                                                                 dropout_24[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 14, 14, 480)  1920        concatenate_24[0][0]             \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 14, 14, 480)  0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 14, 14, 128)  61440       activation_53[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 14, 14, 128)  512         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","activation_54 (Activation)      (None, 14, 14, 128)  0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 14, 14, 32)   36864       activation_54[0][0]              \n","__________________________________________________________________________________________________\n","dropout_25 (Dropout)            (None, 14, 14, 32)   0           conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_25 (Concatenate)    (None, 14, 14, 512)  0           concatenate_24[0][0]             \n","                                                                 dropout_25[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 14, 14, 512)  2048        concatenate_25[0][0]             \n","__________________________________________________________________________________________________\n","activation_55 (Activation)      (None, 14, 14, 512)  0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 14, 14, 128)  65536       activation_55[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 14, 14, 128)  512         conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","activation_56 (Activation)      (None, 14, 14, 128)  0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 14, 14, 32)   36864       activation_56[0][0]              \n","__________________________________________________________________________________________________\n","dropout_26 (Dropout)            (None, 14, 14, 32)   0           conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_26 (Concatenate)    (None, 14, 14, 544)  0           concatenate_25[0][0]             \n","                                                                 dropout_26[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 14, 14, 544)  2176        concatenate_26[0][0]             \n","__________________________________________________________________________________________________\n","activation_57 (Activation)      (None, 14, 14, 544)  0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 14, 14, 128)  69632       activation_57[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 14, 14, 128)  512         conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","activation_58 (Activation)      (None, 14, 14, 128)  0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 14, 14, 32)   36864       activation_58[0][0]              \n","__________________________________________________________________________________________________\n","dropout_27 (Dropout)            (None, 14, 14, 32)   0           conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_27 (Concatenate)    (None, 14, 14, 576)  0           concatenate_26[0][0]             \n","                                                                 dropout_27[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 14, 14, 576)  2304        concatenate_27[0][0]             \n","__________________________________________________________________________________________________\n","activation_59 (Activation)      (None, 14, 14, 576)  0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, 14, 14, 128)  73728       activation_59[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 14, 14, 128)  512         conv2d_59[0][0]                  \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 14, 14, 128)  0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 14, 14, 32)   36864       activation_60[0][0]              \n","__________________________________________________________________________________________________\n","dropout_28 (Dropout)            (None, 14, 14, 32)   0           conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_28 (Concatenate)    (None, 14, 14, 608)  0           concatenate_27[0][0]             \n","                                                                 dropout_28[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 14, 14, 608)  2432        concatenate_28[0][0]             \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 14, 14, 608)  0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 14, 14, 128)  77824       activation_61[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 14, 14, 128)  512         conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 14, 14, 128)  0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, 14, 14, 32)   36864       activation_62[0][0]              \n","__________________________________________________________________________________________________\n","dropout_29 (Dropout)            (None, 14, 14, 32)   0           conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_29 (Concatenate)    (None, 14, 14, 640)  0           concatenate_28[0][0]             \n","                                                                 dropout_29[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 14, 14, 640)  2560        concatenate_29[0][0]             \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 14, 14, 640)  0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, 14, 14, 128)  81920       activation_63[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 14, 14, 128)  512         conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 14, 14, 128)  0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_64 (Conv2D)              (None, 14, 14, 32)   36864       activation_64[0][0]              \n","__________________________________________________________________________________________________\n","dropout_30 (Dropout)            (None, 14, 14, 32)   0           conv2d_64[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_30 (Concatenate)    (None, 14, 14, 672)  0           concatenate_29[0][0]             \n","                                                                 dropout_30[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 14, 14, 672)  2688        concatenate_30[0][0]             \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 14, 14, 672)  0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_65 (Conv2D)              (None, 14, 14, 128)  86016       activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 14, 14, 128)  512         conv2d_65[0][0]                  \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 14, 14, 128)  0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_66 (Conv2D)              (None, 14, 14, 32)   36864       activation_66[0][0]              \n","__________________________________________________________________________________________________\n","dropout_31 (Dropout)            (None, 14, 14, 32)   0           conv2d_66[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_31 (Concatenate)    (None, 14, 14, 704)  0           concatenate_30[0][0]             \n","                                                                 dropout_31[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 14, 14, 704)  2816        concatenate_31[0][0]             \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 14, 14, 704)  0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_67 (Conv2D)              (None, 14, 14, 128)  90112       activation_67[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 14, 14, 128)  512         conv2d_67[0][0]                  \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 14, 14, 128)  0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_68 (Conv2D)              (None, 14, 14, 32)   36864       activation_68[0][0]              \n","__________________________________________________________________________________________________\n","dropout_32 (Dropout)            (None, 14, 14, 32)   0           conv2d_68[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_32 (Concatenate)    (None, 14, 14, 736)  0           concatenate_31[0][0]             \n","                                                                 dropout_32[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 14, 14, 736)  2944        concatenate_32[0][0]             \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 14, 14, 736)  0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_69 (Conv2D)              (None, 14, 14, 128)  94208       activation_69[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 14, 14, 128)  512         conv2d_69[0][0]                  \n","__________________________________________________________________________________________________\n","activation_70 (Activation)      (None, 14, 14, 128)  0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_70 (Conv2D)              (None, 14, 14, 32)   36864       activation_70[0][0]              \n","__________________________________________________________________________________________________\n","dropout_33 (Dropout)            (None, 14, 14, 32)   0           conv2d_70[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_33 (Concatenate)    (None, 14, 14, 768)  0           concatenate_32[0][0]             \n","                                                                 dropout_33[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 14, 14, 768)  3072        concatenate_33[0][0]             \n","__________________________________________________________________________________________________\n","activation_71 (Activation)      (None, 14, 14, 768)  0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_71 (Conv2D)              (None, 14, 14, 128)  98304       activation_71[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 14, 14, 128)  512         conv2d_71[0][0]                  \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 14, 14, 128)  0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_72 (Conv2D)              (None, 14, 14, 32)   36864       activation_72[0][0]              \n","__________________________________________________________________________________________________\n","dropout_34 (Dropout)            (None, 14, 14, 32)   0           conv2d_72[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_34 (Concatenate)    (None, 14, 14, 800)  0           concatenate_33[0][0]             \n","                                                                 dropout_34[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 14, 14, 800)  3200        concatenate_34[0][0]             \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 14, 14, 800)  0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_73 (Conv2D)              (None, 14, 14, 128)  102400      activation_73[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 14, 14, 128)  512         conv2d_73[0][0]                  \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 14, 14, 128)  0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_74 (Conv2D)              (None, 14, 14, 32)   36864       activation_74[0][0]              \n","__________________________________________________________________________________________________\n","dropout_35 (Dropout)            (None, 14, 14, 32)   0           conv2d_74[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_35 (Concatenate)    (None, 14, 14, 832)  0           concatenate_34[0][0]             \n","                                                                 dropout_35[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 14, 14, 832)  3328        concatenate_35[0][0]             \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 14, 14, 832)  0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_75 (Conv2D)              (None, 14, 14, 128)  106496      activation_75[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 14, 14, 128)  512         conv2d_75[0][0]                  \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 14, 14, 128)  0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_76 (Conv2D)              (None, 14, 14, 32)   36864       activation_76[0][0]              \n","__________________________________________________________________________________________________\n","dropout_36 (Dropout)            (None, 14, 14, 32)   0           conv2d_76[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_36 (Concatenate)    (None, 14, 14, 864)  0           concatenate_35[0][0]             \n","                                                                 dropout_36[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 14, 14, 864)  3456        concatenate_36[0][0]             \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 14, 14, 864)  0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_77 (Conv2D)              (None, 14, 14, 128)  110592      activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 14, 14, 128)  512         conv2d_77[0][0]                  \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 14, 14, 128)  0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_78 (Conv2D)              (None, 14, 14, 32)   36864       activation_78[0][0]              \n","__________________________________________________________________________________________________\n","dropout_37 (Dropout)            (None, 14, 14, 32)   0           conv2d_78[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_37 (Concatenate)    (None, 14, 14, 896)  0           concatenate_36[0][0]             \n","                                                                 dropout_37[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 14, 14, 896)  3584        concatenate_37[0][0]             \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 14, 14, 896)  0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_79 (Conv2D)              (None, 14, 14, 128)  114688      activation_79[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 14, 14, 128)  512         conv2d_79[0][0]                  \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 14, 14, 128)  0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_80 (Conv2D)              (None, 14, 14, 32)   36864       activation_80[0][0]              \n","__________________________________________________________________________________________________\n","dropout_38 (Dropout)            (None, 14, 14, 32)   0           conv2d_80[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_38 (Concatenate)    (None, 14, 14, 928)  0           concatenate_37[0][0]             \n","                                                                 dropout_38[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 14, 14, 928)  3712        concatenate_38[0][0]             \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 14, 14, 928)  0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_81 (Conv2D)              (None, 14, 14, 128)  118784      activation_81[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 14, 14, 128)  512         conv2d_81[0][0]                  \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 14, 14, 128)  0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_82 (Conv2D)              (None, 14, 14, 32)   36864       activation_82[0][0]              \n","__________________________________________________________________________________________________\n","dropout_39 (Dropout)            (None, 14, 14, 32)   0           conv2d_82[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_39 (Concatenate)    (None, 14, 14, 960)  0           concatenate_38[0][0]             \n","                                                                 dropout_39[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 14, 14, 960)  3840        concatenate_39[0][0]             \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 14, 14, 960)  0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_83 (Conv2D)              (None, 14, 14, 128)  122880      activation_83[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 14, 14, 128)  512         conv2d_83[0][0]                  \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 14, 14, 128)  0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_84 (Conv2D)              (None, 14, 14, 32)   36864       activation_84[0][0]              \n","__________________________________________________________________________________________________\n","dropout_40 (Dropout)            (None, 14, 14, 32)   0           conv2d_84[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_40 (Concatenate)    (None, 14, 14, 992)  0           concatenate_39[0][0]             \n","                                                                 dropout_40[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 14, 14, 992)  3968        concatenate_40[0][0]             \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 14, 14, 992)  0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_85 (Conv2D)              (None, 14, 14, 128)  126976      activation_85[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 14, 14, 128)  512         conv2d_85[0][0]                  \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 14, 14, 128)  0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_86 (Conv2D)              (None, 14, 14, 32)   36864       activation_86[0][0]              \n","__________________________________________________________________________________________________\n","dropout_41 (Dropout)            (None, 14, 14, 32)   0           conv2d_86[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_41 (Concatenate)    (None, 14, 14, 1024) 0           concatenate_40[0][0]             \n","                                                                 dropout_41[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 14, 14, 1024) 4096        concatenate_41[0][0]             \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_87 (Conv2D)              (None, 14, 14, 512)  524288      activation_87[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_2 (AveragePoo (None, 7, 7, 512)    0           conv2d_87[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 7, 7, 512)    2048        average_pooling2d_2[0][0]        \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 7, 7, 512)    0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 7, 7, 128)    65536       activation_88[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 7, 7, 128)    512         conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 7, 7, 128)    0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 7, 7, 32)     36864       activation_89[0][0]              \n","__________________________________________________________________________________________________\n","dropout_42 (Dropout)            (None, 7, 7, 32)     0           conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_42 (Concatenate)    (None, 7, 7, 544)    0           average_pooling2d_2[0][0]        \n","                                                                 dropout_42[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 7, 7, 544)    2176        concatenate_42[0][0]             \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 7, 7, 544)    0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 7, 7, 128)    69632       activation_90[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 7, 7, 128)    512         conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 7, 7, 128)    0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 7, 7, 32)     36864       activation_91[0][0]              \n","__________________________________________________________________________________________________\n","dropout_43 (Dropout)            (None, 7, 7, 32)     0           conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_43 (Concatenate)    (None, 7, 7, 576)    0           concatenate_42[0][0]             \n","                                                                 dropout_43[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 7, 7, 576)    2304        concatenate_43[0][0]             \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 7, 7, 576)    0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 7, 7, 128)    73728       activation_92[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 7, 7, 128)    512         conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 7, 7, 128)    0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 7, 7, 32)     36864       activation_93[0][0]              \n","__________________________________________________________________________________________________\n","dropout_44 (Dropout)            (None, 7, 7, 32)     0           conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_44 (Concatenate)    (None, 7, 7, 608)    0           concatenate_43[0][0]             \n","                                                                 dropout_44[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 7, 7, 608)    2432        concatenate_44[0][0]             \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 7, 7, 608)    0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 7, 7, 128)    77824       activation_94[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 7, 7, 128)    512         conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 7, 7, 128)    0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 7, 7, 32)     36864       activation_95[0][0]              \n","__________________________________________________________________________________________________\n","dropout_45 (Dropout)            (None, 7, 7, 32)     0           conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_45 (Concatenate)    (None, 7, 7, 640)    0           concatenate_44[0][0]             \n","                                                                 dropout_45[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 7, 7, 640)    2560        concatenate_45[0][0]             \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 7, 7, 640)    0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 7, 7, 128)    81920       activation_96[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 7, 7, 128)    512         conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 7, 7, 128)    0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 7, 7, 32)     36864       activation_97[0][0]              \n","__________________________________________________________________________________________________\n","dropout_46 (Dropout)            (None, 7, 7, 32)     0           conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_46 (Concatenate)    (None, 7, 7, 672)    0           concatenate_45[0][0]             \n","                                                                 dropout_46[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 7, 7, 672)    2688        concatenate_46[0][0]             \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 7, 7, 672)    0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 7, 7, 128)    86016       activation_98[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 7, 7, 128)    512         conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 7, 7, 128)    0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 7, 7, 32)     36864       activation_99[0][0]              \n","__________________________________________________________________________________________________\n","dropout_47 (Dropout)            (None, 7, 7, 32)     0           conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_47 (Concatenate)    (None, 7, 7, 704)    0           concatenate_46[0][0]             \n","                                                                 dropout_47[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 7, 7, 704)    2816        concatenate_47[0][0]             \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 7, 7, 704)    0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 7, 7, 128)    90112       activation_100[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 7, 7, 128)    512         conv2d_100[0][0]                 \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 7, 7, 128)    0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 7, 7, 32)     36864       activation_101[0][0]             \n","__________________________________________________________________________________________________\n","dropout_48 (Dropout)            (None, 7, 7, 32)     0           conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_48 (Concatenate)    (None, 7, 7, 736)    0           concatenate_47[0][0]             \n","                                                                 dropout_48[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 7, 7, 736)    2944        concatenate_48[0][0]             \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 7, 7, 736)    0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 7, 7, 128)    94208       activation_102[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 7, 7, 128)    512         conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 7, 7, 128)    0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 7, 7, 32)     36864       activation_103[0][0]             \n","__________________________________________________________________________________________________\n","dropout_49 (Dropout)            (None, 7, 7, 32)     0           conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_49 (Concatenate)    (None, 7, 7, 768)    0           concatenate_48[0][0]             \n","                                                                 dropout_49[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 7, 7, 768)    3072        concatenate_49[0][0]             \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 7, 7, 768)    0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 7, 7, 128)    98304       activation_104[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_105 (BatchN (None, 7, 7, 128)    512         conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","activation_105 (Activation)     (None, 7, 7, 128)    0           batch_normalization_105[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_105 (Conv2D)             (None, 7, 7, 32)     36864       activation_105[0][0]             \n","__________________________________________________________________________________________________\n","dropout_50 (Dropout)            (None, 7, 7, 32)     0           conv2d_105[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_50 (Concatenate)    (None, 7, 7, 800)    0           concatenate_49[0][0]             \n","                                                                 dropout_50[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_106 (BatchN (None, 7, 7, 800)    3200        concatenate_50[0][0]             \n","__________________________________________________________________________________________________\n","activation_106 (Activation)     (None, 7, 7, 800)    0           batch_normalization_106[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_106 (Conv2D)             (None, 7, 7, 128)    102400      activation_106[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_107 (BatchN (None, 7, 7, 128)    512         conv2d_106[0][0]                 \n","__________________________________________________________________________________________________\n","activation_107 (Activation)     (None, 7, 7, 128)    0           batch_normalization_107[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_107 (Conv2D)             (None, 7, 7, 32)     36864       activation_107[0][0]             \n","__________________________________________________________________________________________________\n","dropout_51 (Dropout)            (None, 7, 7, 32)     0           conv2d_107[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_51 (Concatenate)    (None, 7, 7, 832)    0           concatenate_50[0][0]             \n","                                                                 dropout_51[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_108 (BatchN (None, 7, 7, 832)    3328        concatenate_51[0][0]             \n","__________________________________________________________________________________________________\n","activation_108 (Activation)     (None, 7, 7, 832)    0           batch_normalization_108[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_108 (Conv2D)             (None, 7, 7, 128)    106496      activation_108[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_109 (BatchN (None, 7, 7, 128)    512         conv2d_108[0][0]                 \n","__________________________________________________________________________________________________\n","activation_109 (Activation)     (None, 7, 7, 128)    0           batch_normalization_109[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_109 (Conv2D)             (None, 7, 7, 32)     36864       activation_109[0][0]             \n","__________________________________________________________________________________________________\n","dropout_52 (Dropout)            (None, 7, 7, 32)     0           conv2d_109[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_52 (Concatenate)    (None, 7, 7, 864)    0           concatenate_51[0][0]             \n","                                                                 dropout_52[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_110 (BatchN (None, 7, 7, 864)    3456        concatenate_52[0][0]             \n","__________________________________________________________________________________________________\n","activation_110 (Activation)     (None, 7, 7, 864)    0           batch_normalization_110[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_110 (Conv2D)             (None, 7, 7, 128)    110592      activation_110[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_111 (BatchN (None, 7, 7, 128)    512         conv2d_110[0][0]                 \n","__________________________________________________________________________________________________\n","activation_111 (Activation)     (None, 7, 7, 128)    0           batch_normalization_111[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_111 (Conv2D)             (None, 7, 7, 32)     36864       activation_111[0][0]             \n","__________________________________________________________________________________________________\n","dropout_53 (Dropout)            (None, 7, 7, 32)     0           conv2d_111[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_53 (Concatenate)    (None, 7, 7, 896)    0           concatenate_52[0][0]             \n","                                                                 dropout_53[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_112 (BatchN (None, 7, 7, 896)    3584        concatenate_53[0][0]             \n","__________________________________________________________________________________________________\n","activation_112 (Activation)     (None, 7, 7, 896)    0           batch_normalization_112[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_112 (Conv2D)             (None, 7, 7, 128)    114688      activation_112[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_113 (BatchN (None, 7, 7, 128)    512         conv2d_112[0][0]                 \n","__________________________________________________________________________________________________\n","activation_113 (Activation)     (None, 7, 7, 128)    0           batch_normalization_113[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_113 (Conv2D)             (None, 7, 7, 32)     36864       activation_113[0][0]             \n","__________________________________________________________________________________________________\n","dropout_54 (Dropout)            (None, 7, 7, 32)     0           conv2d_113[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_54 (Concatenate)    (None, 7, 7, 928)    0           concatenate_53[0][0]             \n","                                                                 dropout_54[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_114 (BatchN (None, 7, 7, 928)    3712        concatenate_54[0][0]             \n","__________________________________________________________________________________________________\n","activation_114 (Activation)     (None, 7, 7, 928)    0           batch_normalization_114[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_114 (Conv2D)             (None, 7, 7, 128)    118784      activation_114[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_115 (BatchN (None, 7, 7, 128)    512         conv2d_114[0][0]                 \n","__________________________________________________________________________________________________\n","activation_115 (Activation)     (None, 7, 7, 128)    0           batch_normalization_115[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_115 (Conv2D)             (None, 7, 7, 32)     36864       activation_115[0][0]             \n","__________________________________________________________________________________________________\n","dropout_55 (Dropout)            (None, 7, 7, 32)     0           conv2d_115[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_55 (Concatenate)    (None, 7, 7, 960)    0           concatenate_54[0][0]             \n","                                                                 dropout_55[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_116 (BatchN (None, 7, 7, 960)    3840        concatenate_55[0][0]             \n","__________________________________________________________________________________________________\n","activation_116 (Activation)     (None, 7, 7, 960)    0           batch_normalization_116[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_116 (Conv2D)             (None, 7, 7, 128)    122880      activation_116[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_117 (BatchN (None, 7, 7, 128)    512         conv2d_116[0][0]                 \n","__________________________________________________________________________________________________\n","activation_117 (Activation)     (None, 7, 7, 128)    0           batch_normalization_117[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_117 (Conv2D)             (None, 7, 7, 32)     36864       activation_117[0][0]             \n","__________________________________________________________________________________________________\n","dropout_56 (Dropout)            (None, 7, 7, 32)     0           conv2d_117[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_56 (Concatenate)    (None, 7, 7, 992)    0           concatenate_55[0][0]             \n","                                                                 dropout_56[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_118 (BatchN (None, 7, 7, 992)    3968        concatenate_56[0][0]             \n","__________________________________________________________________________________________________\n","activation_118 (Activation)     (None, 7, 7, 992)    0           batch_normalization_118[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_118 (Conv2D)             (None, 7, 7, 128)    126976      activation_118[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_119 (BatchN (None, 7, 7, 128)    512         conv2d_118[0][0]                 \n","__________________________________________________________________________________________________\n","activation_119 (Activation)     (None, 7, 7, 128)    0           batch_normalization_119[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_119 (Conv2D)             (None, 7, 7, 32)     36864       activation_119[0][0]             \n","__________________________________________________________________________________________________\n","dropout_57 (Dropout)            (None, 7, 7, 32)     0           conv2d_119[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_57 (Concatenate)    (None, 7, 7, 1024)   0           concatenate_56[0][0]             \n","                                                                 dropout_57[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_120 (BatchN (None, 7, 7, 1024)   4096        concatenate_57[0][0]             \n","__________________________________________________________________________________________________\n","activation_120 (Activation)     (None, 7, 7, 1024)   0           batch_normalization_120[0][0]    \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 1024)         0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 257)          263425      global_average_pooling2d[0][0]   \n","==================================================================================================\n","Total params: 7,300,929\n","Trainable params: 7,217,281\n","Non-trainable params: 83,648\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pwRlyWzi1qmm"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6K-e9yii3Qh"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8UHl5yto6_fc"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wgOtwPW1qmp"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VmS0d9OS1qmr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605015487600,"user_tz":-540,"elapsed":40309985,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"2bd46578-06cf-440c-8603-b1a8fdea5a85"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_5/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_6/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_7/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_8/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_9/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_10/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_11/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_12/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_13/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_14/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_15/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_16/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_17/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_18/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_19/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_20/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_21/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_22/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_23/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_24/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_25/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_26/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_27/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_28/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_29/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_30/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_31/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_32/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_33/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_34/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_35/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_36/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_37/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_38/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_39/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_40/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_41/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_42/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_43/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_44/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_45/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_46/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_47/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_48/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_49/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_50/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_51/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_52/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_53/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_54/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_55/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_56/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_57/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_58/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_59/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_60/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_61/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_62/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_63/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_64/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_65/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_66/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_67/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_68/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_69/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_70/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_71/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_72/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_73/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_74/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_75/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_76/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_77/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_78/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_79/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_80/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_81/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_82/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_83/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_84/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_85/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_86/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_87/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_88/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_89/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_90/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_91/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_92/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_93/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_94/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_95/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_96/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_97/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_98/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_99/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_100/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_101/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_102/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_103/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_104/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_105/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_106/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_107/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_108/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_109/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_110/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_111/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_112/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_113/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_114/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_115/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_116/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_117/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_118/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_119/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for dense/kernel:0\n","382/382 [==============================] - ETA: 0s - loss: 4.9511 - accuracy: 0.0942 - top5_acc: 0.1940 - macro_f1score: 0.0017 \n","Epoch 00001: val_loss improved from inf to 5.05398, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.08560, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/001.h5\n","382/382 [==============================] - 7140s 19s/step - loss: 4.9511 - accuracy: 0.0942 - top5_acc: 0.1940 - macro_f1score: 0.0017 - val_loss: 5.0540 - val_accuracy: 0.0856 - val_top5_acc: 0.1950 - val_macro_f1score: 0.0019\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","382/382 [==============================] - ETA: 0s - loss: 4.3845 - accuracy: 0.1454 - top5_acc: 0.2900 - macro_f1score: 0.0061\n","Epoch 00002: val_loss improved from 5.05398 to 4.52261, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/002.h5\n","\n","Epoch 00002: val_accuracy improved from 0.08560 to 0.13417, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/002.h5\n","382/382 [==============================] - 504s 1s/step - loss: 4.3845 - accuracy: 0.1454 - top5_acc: 0.2900 - macro_f1score: 0.0061 - val_loss: 4.5226 - val_accuracy: 0.1342 - val_top5_acc: 0.2948 - val_macro_f1score: 0.0078\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","382/382 [==============================] - ETA: 0s - loss: 4.0029 - accuracy: 0.1891 - top5_acc: 0.3665 - macro_f1score: 0.0098\n","Epoch 00003: val_loss did not improve from 4.52261\n","\n","Epoch 00003: val_accuracy did not improve from 0.13417\n","382/382 [==============================] - 496s 1s/step - loss: 4.0029 - accuracy: 0.1891 - top5_acc: 0.3665 - macro_f1score: 0.0098 - val_loss: 5.2867 - val_accuracy: 0.1104 - val_top5_acc: 0.2313 - val_macro_f1score: 0.0076\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","382/382 [==============================] - ETA: 0s - loss: 3.6526 - accuracy: 0.2352 - top5_acc: 0.4356 - macro_f1score: 0.0147\n","Epoch 00004: val_loss did not improve from 4.52261\n","\n","Epoch 00004: val_accuracy improved from 0.13417 to 0.15931, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/004.h5\n","382/382 [==============================] - 497s 1s/step - loss: 3.6526 - accuracy: 0.2352 - top5_acc: 0.4356 - macro_f1score: 0.0147 - val_loss: 4.8742 - val_accuracy: 0.1593 - val_top5_acc: 0.3220 - val_macro_f1score: 0.0142\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","382/382 [==============================] - ETA: 0s - loss: 3.3199 - accuracy: 0.2841 - top5_acc: 0.5025 - macro_f1score: 0.0209\n","Epoch 00005: val_loss did not improve from 4.52261\n","\n","Epoch 00005: val_accuracy did not improve from 0.15931\n","382/382 [==============================] - 497s 1s/step - loss: 3.3199 - accuracy: 0.2841 - top5_acc: 0.5025 - macro_f1score: 0.0209 - val_loss: 5.8294 - val_accuracy: 0.1359 - val_top5_acc: 0.2812 - val_macro_f1score: 0.0149\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","382/382 [==============================] - ETA: 0s - loss: 3.0118 - accuracy: 0.3348 - top5_acc: 0.5671 - macro_f1score: 0.0288\n","Epoch 00006: val_loss did not improve from 4.52261\n","\n","Epoch 00006: val_accuracy improved from 0.15931 to 0.18308, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/006.h5\n","382/382 [==============================] - 495s 1s/step - loss: 3.0118 - accuracy: 0.3348 - top5_acc: 0.5671 - macro_f1score: 0.0288 - val_loss: 5.0958 - val_accuracy: 0.1831 - val_top5_acc: 0.3675 - val_macro_f1score: 0.0206\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","382/382 [==============================] - ETA: 0s - loss: 2.7601 - accuracy: 0.3776 - top5_acc: 0.6220 - macro_f1score: 0.0357\n","Epoch 00007: val_loss did not improve from 4.52261\n","\n","Epoch 00007: val_accuracy improved from 0.18308 to 0.21841, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/007.h5\n","382/382 [==============================] - 495s 1s/step - loss: 2.7601 - accuracy: 0.3776 - top5_acc: 0.6220 - macro_f1score: 0.0357 - val_loss: 5.0650 - val_accuracy: 0.2184 - val_top5_acc: 0.4062 - val_macro_f1score: 0.0286\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","382/382 [==============================] - ETA: 0s - loss: 2.5497 - accuracy: 0.4153 - top5_acc: 0.6603 - macro_f1score: 0.0440\n","Epoch 00008: val_loss did not improve from 4.52261\n","\n","Epoch 00008: val_accuracy did not improve from 0.21841\n","382/382 [==============================] - 499s 1s/step - loss: 2.5497 - accuracy: 0.4153 - top5_acc: 0.6603 - macro_f1score: 0.0440 - val_loss: 5.4140 - val_accuracy: 0.2065 - val_top5_acc: 0.3971 - val_macro_f1score: 0.0286\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","382/382 [==============================] - ETA: 0s - loss: 2.3639 - accuracy: 0.4481 - top5_acc: 0.6943 - macro_f1score: 0.0515\n","Epoch 00009: val_loss did not improve from 4.52261\n","\n","Epoch 00009: val_accuracy improved from 0.21841 to 0.24457, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/009.h5\n","382/382 [==============================] - 508s 1s/step - loss: 2.3639 - accuracy: 0.4481 - top5_acc: 0.6943 - macro_f1score: 0.0515 - val_loss: 5.2817 - val_accuracy: 0.2446 - val_top5_acc: 0.4334 - val_macro_f1score: 0.0374\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","382/382 [==============================] - ETA: 0s - loss: 2.1988 - accuracy: 0.4812 - top5_acc: 0.7282 - macro_f1score: 0.0589\n","Epoch 00010: val_loss improved from 4.52261 to 4.17420, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/010.h5\n","\n","Epoch 00010: val_accuracy improved from 0.24457 to 0.29348, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/010.h5\n","382/382 [==============================] - 507s 1s/step - loss: 2.1988 - accuracy: 0.4812 - top5_acc: 0.7282 - macro_f1score: 0.0589 - val_loss: 4.1742 - val_accuracy: 0.2935 - val_top5_acc: 0.5109 - val_macro_f1score: 0.0440\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","382/382 [==============================] - ETA: 0s - loss: 2.0379 - accuracy: 0.5139 - top5_acc: 0.7533 - macro_f1score: 0.0673\n","Epoch 00011: val_loss did not improve from 4.17420\n","\n","Epoch 00011: val_accuracy improved from 0.29348 to 0.30571, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/011.h5\n","382/382 [==============================] - 505s 1s/step - loss: 2.0379 - accuracy: 0.5139 - top5_acc: 0.7533 - macro_f1score: 0.0673 - val_loss: 4.4101 - val_accuracy: 0.3057 - val_top5_acc: 0.5285 - val_macro_f1score: 0.0493\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","382/382 [==============================] - ETA: 0s - loss: 1.9226 - accuracy: 0.5377 - top5_acc: 0.7712 - macro_f1score: 0.0734\n","Epoch 00012: val_loss improved from 4.17420 to 4.08141, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/012.h5\n","\n","Epoch 00012: val_accuracy improved from 0.30571 to 0.33016, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/012.h5\n","382/382 [==============================] - 499s 1s/step - loss: 1.9226 - accuracy: 0.5377 - top5_acc: 0.7712 - macro_f1score: 0.0734 - val_loss: 4.0814 - val_accuracy: 0.3302 - val_top5_acc: 0.5730 - val_macro_f1score: 0.0554\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","382/382 [==============================] - ETA: 0s - loss: 1.7905 - accuracy: 0.5632 - top5_acc: 0.7971 - macro_f1score: 0.0799\n","Epoch 00013: val_loss did not improve from 4.08141\n","\n","Epoch 00013: val_accuracy did not improve from 0.33016\n","382/382 [==============================] - 494s 1s/step - loss: 1.7905 - accuracy: 0.5632 - top5_acc: 0.7971 - macro_f1score: 0.0799 - val_loss: 4.1476 - val_accuracy: 0.3285 - val_top5_acc: 0.5611 - val_macro_f1score: 0.0554\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","382/382 [==============================] - ETA: 0s - loss: 1.6706 - accuracy: 0.5888 - top5_acc: 0.8152 - macro_f1score: 0.0872\n","Epoch 00014: val_loss did not improve from 4.08141\n","\n","Epoch 00014: val_accuracy improved from 0.33016 to 0.34477, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/014.h5\n","382/382 [==============================] - 491s 1s/step - loss: 1.6706 - accuracy: 0.5888 - top5_acc: 0.8152 - macro_f1score: 0.0872 - val_loss: 4.2245 - val_accuracy: 0.3448 - val_top5_acc: 0.5713 - val_macro_f1score: 0.0581\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","382/382 [==============================] - ETA: 0s - loss: 1.5600 - accuracy: 0.6091 - top5_acc: 0.8341 - macro_f1score: 0.0931\n","Epoch 00015: val_loss improved from 4.08141 to 3.93739, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/015.h5\n","\n","Epoch 00015: val_accuracy improved from 0.34477 to 0.34613, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/015.h5\n","382/382 [==============================] - 502s 1s/step - loss: 1.5600 - accuracy: 0.6091 - top5_acc: 0.8341 - macro_f1score: 0.0931 - val_loss: 3.9374 - val_accuracy: 0.3461 - val_top5_acc: 0.5842 - val_macro_f1score: 0.0589\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","382/382 [==============================] - ETA: 0s - loss: 1.4551 - accuracy: 0.6286 - top5_acc: 0.8522 - macro_f1score: 0.1001\n","Epoch 00016: val_loss did not improve from 3.93739\n","\n","Epoch 00016: val_accuracy improved from 0.34613 to 0.35700, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/016.h5\n","382/382 [==============================] - 503s 1s/step - loss: 1.4551 - accuracy: 0.6286 - top5_acc: 0.8522 - macro_f1score: 0.1001 - val_loss: 4.1442 - val_accuracy: 0.3570 - val_top5_acc: 0.5707 - val_macro_f1score: 0.0593\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","382/382 [==============================] - ETA: 0s - loss: 1.3718 - accuracy: 0.6498 - top5_acc: 0.8659 - macro_f1score: 0.1044\n","Epoch 00017: val_loss improved from 3.93739 to 3.48381, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/017.h5\n","\n","Epoch 00017: val_accuracy improved from 0.35700 to 0.40048, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/017.h5\n","382/382 [==============================] - 500s 1s/step - loss: 1.3718 - accuracy: 0.6498 - top5_acc: 0.8659 - macro_f1score: 0.1044 - val_loss: 3.4838 - val_accuracy: 0.4005 - val_top5_acc: 0.6359 - val_macro_f1score: 0.0710\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","382/382 [==============================] - ETA: 0s - loss: 1.2782 - accuracy: 0.6691 - top5_acc: 0.8768 - macro_f1score: 0.1103\n","Epoch 00018: val_loss did not improve from 3.48381\n","\n","Epoch 00018: val_accuracy improved from 0.40048 to 0.40455, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/018.h5\n","382/382 [==============================] - 493s 1s/step - loss: 1.2782 - accuracy: 0.6691 - top5_acc: 0.8768 - macro_f1score: 0.1103 - val_loss: 3.9267 - val_accuracy: 0.4046 - val_top5_acc: 0.6107 - val_macro_f1score: 0.0710\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","382/382 [==============================] - ETA: 0s - loss: 1.1828 - accuracy: 0.6883 - top5_acc: 0.8934 - macro_f1score: 0.1164\n","Epoch 00019: val_loss did not improve from 3.48381\n","\n","Epoch 00019: val_accuracy did not improve from 0.40455\n","382/382 [==============================] - 491s 1s/step - loss: 1.1828 - accuracy: 0.6883 - top5_acc: 0.8934 - macro_f1score: 0.1164 - val_loss: 3.5943 - val_accuracy: 0.3971 - val_top5_acc: 0.6185 - val_macro_f1score: 0.0697\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","382/382 [==============================] - ETA: 0s - loss: 1.0883 - accuracy: 0.7075 - top5_acc: 0.9071 - macro_f1score: 0.1220\n","Epoch 00020: val_loss did not improve from 3.48381\n","\n","Epoch 00020: val_accuracy did not improve from 0.40455\n","382/382 [==============================] - 494s 1s/step - loss: 1.0883 - accuracy: 0.7075 - top5_acc: 0.9071 - macro_f1score: 0.1220 - val_loss: 4.1775 - val_accuracy: 0.3645 - val_top5_acc: 0.5917 - val_macro_f1score: 0.0640\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","382/382 [==============================] - ETA: 0s - loss: 1.0234 - accuracy: 0.7297 - top5_acc: 0.9158 - macro_f1score: 0.1286\n","Epoch 00021: val_loss did not improve from 3.48381\n","\n","Epoch 00021: val_accuracy improved from 0.40455 to 0.41372, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/021.h5\n","382/382 [==============================] - 491s 1s/step - loss: 1.0234 - accuracy: 0.7297 - top5_acc: 0.9158 - macro_f1score: 0.1286 - val_loss: 3.6134 - val_accuracy: 0.4137 - val_top5_acc: 0.6318 - val_macro_f1score: 0.0746\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","382/382 [==============================] - ETA: 0s - loss: 0.9607 - accuracy: 0.7395 - top5_acc: 0.9235 - macro_f1score: 0.1311\n","Epoch 00022: val_loss did not improve from 3.48381\n","\n","Epoch 00022: val_accuracy did not improve from 0.41372\n","382/382 [==============================] - 487s 1s/step - loss: 0.9607 - accuracy: 0.7395 - top5_acc: 0.9235 - macro_f1score: 0.1311 - val_loss: 4.4187 - val_accuracy: 0.3655 - val_top5_acc: 0.5693 - val_macro_f1score: 0.0645\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","382/382 [==============================] - ETA: 0s - loss: 0.8861 - accuracy: 0.7543 - top5_acc: 0.9328 - macro_f1score: 0.1366\n","Epoch 00023: val_loss did not improve from 3.48381\n","\n","Epoch 00023: val_accuracy did not improve from 0.41372\n","382/382 [==============================] - 474s 1s/step - loss: 0.8861 - accuracy: 0.7543 - top5_acc: 0.9328 - macro_f1score: 0.1366 - val_loss: 4.0469 - val_accuracy: 0.3995 - val_top5_acc: 0.6325 - val_macro_f1score: 0.0717\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","382/382 [==============================] - ETA: 0s - loss: 0.8255 - accuracy: 0.7712 - top5_acc: 0.9417 - macro_f1score: 0.1414\n","Epoch 00024: val_loss did not improve from 3.48381\n","\n","Epoch 00024: val_accuracy improved from 0.41372 to 0.44905, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/024.h5\n","382/382 [==============================] - 463s 1s/step - loss: 0.8255 - accuracy: 0.7712 - top5_acc: 0.9417 - macro_f1score: 0.1414 - val_loss: 3.5840 - val_accuracy: 0.4490 - val_top5_acc: 0.6664 - val_macro_f1score: 0.0829\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","382/382 [==============================] - ETA: 0s - loss: 0.7575 - accuracy: 0.7889 - top5_acc: 0.9503 - macro_f1score: 0.1464\n","Epoch 00025: val_loss did not improve from 3.48381\n","\n","Epoch 00025: val_accuracy did not improve from 0.44905\n","382/382 [==============================] - 470s 1s/step - loss: 0.7575 - accuracy: 0.7889 - top5_acc: 0.9503 - macro_f1score: 0.1464 - val_loss: 3.6181 - val_accuracy: 0.4477 - val_top5_acc: 0.6467 - val_macro_f1score: 0.0817\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","382/382 [==============================] - ETA: 0s - loss: 0.7105 - accuracy: 0.8013 - top5_acc: 0.9561 - macro_f1score: 0.1501\n","Epoch 00026: val_loss did not improve from 3.48381\n","\n","Epoch 00026: val_accuracy improved from 0.44905 to 0.45177, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/026.h5\n","382/382 [==============================] - 471s 1s/step - loss: 0.7105 - accuracy: 0.8013 - top5_acc: 0.9561 - macro_f1score: 0.1501 - val_loss: 3.5883 - val_accuracy: 0.4518 - val_top5_acc: 0.6692 - val_macro_f1score: 0.0846\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","382/382 [==============================] - ETA: 0s - loss: 0.6591 - accuracy: 0.8132 - top5_acc: 0.9618 - macro_f1score: 0.1533\n","Epoch 00027: val_loss did not improve from 3.48381\n","\n","Epoch 00027: val_accuracy did not improve from 0.45177\n","382/382 [==============================] - 470s 1s/step - loss: 0.6591 - accuracy: 0.8132 - top5_acc: 0.9618 - macro_f1score: 0.1533 - val_loss: 4.0766 - val_accuracy: 0.4273 - val_top5_acc: 0.6450 - val_macro_f1score: 0.0798\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","382/382 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.8259 - top5_acc: 0.9660 - macro_f1score: 0.1578\n","Epoch 00028: val_loss did not improve from 3.48381\n","\n","Epoch 00028: val_accuracy improved from 0.45177 to 0.45652, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/028.h5\n","382/382 [==============================] - 472s 1s/step - loss: 0.6149 - accuracy: 0.8259 - top5_acc: 0.9660 - macro_f1score: 0.1578 - val_loss: 3.6660 - val_accuracy: 0.4565 - val_top5_acc: 0.6760 - val_macro_f1score: 0.0839\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","382/382 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.8398 - top5_acc: 0.9720 - macro_f1score: 0.1625\n","Epoch 00029: val_loss did not improve from 3.48381\n","\n","Epoch 00029: val_accuracy did not improve from 0.45652\n","382/382 [==============================] - 470s 1s/step - loss: 0.5628 - accuracy: 0.8398 - top5_acc: 0.9720 - macro_f1score: 0.1625 - val_loss: 4.1784 - val_accuracy: 0.4351 - val_top5_acc: 0.6427 - val_macro_f1score: 0.0819\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","382/382 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.8442 - top5_acc: 0.9751 - macro_f1score: 0.1630\n","Epoch 00030: val_loss did not improve from 3.48381\n","\n","Epoch 00030: val_accuracy did not improve from 0.45652\n","382/382 [==============================] - 470s 1s/step - loss: 0.5429 - accuracy: 0.8442 - top5_acc: 0.9751 - macro_f1score: 0.1630 - val_loss: 4.0021 - val_accuracy: 0.4304 - val_top5_acc: 0.6386 - val_macro_f1score: 0.0802\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","382/382 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.9319 - top5_acc: 0.9922 - macro_f1score: 0.1876\n","Epoch 00031: val_loss improved from 3.48381 to 2.76511, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/031.h5\n","\n","Epoch 00031: val_accuracy improved from 0.45652 to 0.54484, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/031.h5\n","382/382 [==============================] - 475s 1s/step - loss: 0.2745 - accuracy: 0.9319 - top5_acc: 0.9922 - macro_f1score: 0.1876 - val_loss: 2.7651 - val_accuracy: 0.5448 - val_top5_acc: 0.7320 - val_macro_f1score: 0.1032\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9611 - top5_acc: 0.9976 - macro_f1score: 0.1960\n","Epoch 00032: val_loss improved from 2.76511 to 2.71936, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/032.h5\n","\n","Epoch 00032: val_accuracy improved from 0.54484 to 0.54789, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/032.h5\n","382/382 [==============================] - 474s 1s/step - loss: 0.1881 - accuracy: 0.9611 - top5_acc: 0.9976 - macro_f1score: 0.1960 - val_loss: 2.7194 - val_accuracy: 0.5479 - val_top5_acc: 0.7361 - val_macro_f1score: 0.1035\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9683 - top5_acc: 0.9980 - macro_f1score: 0.1989\n","Epoch 00033: val_loss improved from 2.71936 to 2.59637, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/033.h5\n","\n","Epoch 00033: val_accuracy improved from 0.54789 to 0.55639, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/033.h5\n","382/382 [==============================] - 475s 1s/step - loss: 0.1676 - accuracy: 0.9683 - top5_acc: 0.9980 - macro_f1score: 0.1989 - val_loss: 2.5964 - val_accuracy: 0.5564 - val_top5_acc: 0.7456 - val_macro_f1score: 0.1072\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9730 - top5_acc: 0.9985 - macro_f1score: 0.2007\n","Epoch 00034: val_loss improved from 2.59637 to 2.52804, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/034.h5\n","\n","Epoch 00034: val_accuracy improved from 0.55639 to 0.55910, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/034.h5\n","382/382 [==============================] - 477s 1s/step - loss: 0.1522 - accuracy: 0.9730 - top5_acc: 0.9985 - macro_f1score: 0.2007 - val_loss: 2.5280 - val_accuracy: 0.5591 - val_top5_acc: 0.7582 - val_macro_f1score: 0.1078\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.9787 - top5_acc: 0.9993 - macro_f1score: 0.2017\n","Epoch 00035: val_loss did not improve from 2.52804\n","\n","Epoch 00035: val_accuracy did not improve from 0.55910\n","382/382 [==============================] - 472s 1s/step - loss: 0.1397 - accuracy: 0.9787 - top5_acc: 0.9993 - macro_f1score: 0.2017 - val_loss: 2.5636 - val_accuracy: 0.5557 - val_top5_acc: 0.7463 - val_macro_f1score: 0.1050\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9803 - top5_acc: 0.9994 - macro_f1score: 0.2031\n","Epoch 00036: val_loss improved from 2.52804 to 2.50192, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/036.h5\n","\n","Epoch 00036: val_accuracy improved from 0.55910 to 0.56080, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/036.h5\n","382/382 [==============================] - 476s 1s/step - loss: 0.1312 - accuracy: 0.9803 - top5_acc: 0.9994 - macro_f1score: 0.2031 - val_loss: 2.5019 - val_accuracy: 0.5608 - val_top5_acc: 0.7605 - val_macro_f1score: 0.1083\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.9809 - top5_acc: 0.9992 - macro_f1score: 0.2032\n","Epoch 00037: val_loss did not improve from 2.50192\n","\n","Epoch 00037: val_accuracy did not improve from 0.56080\n","382/382 [==============================] - 471s 1s/step - loss: 0.1293 - accuracy: 0.9809 - top5_acc: 0.9992 - macro_f1score: 0.2032 - val_loss: 2.5478 - val_accuracy: 0.5479 - val_top5_acc: 0.7493 - val_macro_f1score: 0.1058\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9834 - top5_acc: 0.9995 - macro_f1score: 0.2036\n","Epoch 00038: val_loss improved from 2.50192 to 2.45092, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/038.h5\n","\n","Epoch 00038: val_accuracy improved from 0.56080 to 0.56590, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/038.h5\n","382/382 [==============================] - 476s 1s/step - loss: 0.1195 - accuracy: 0.9834 - top5_acc: 0.9995 - macro_f1score: 0.2036 - val_loss: 2.4509 - val_accuracy: 0.5659 - val_top5_acc: 0.7544 - val_macro_f1score: 0.1056\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9850 - top5_acc: 0.9995 - macro_f1score: 0.2045\n","Epoch 00039: val_loss did not improve from 2.45092\n","\n","Epoch 00039: val_accuracy did not improve from 0.56590\n","382/382 [==============================] - 474s 1s/step - loss: 0.1140 - accuracy: 0.9850 - top5_acc: 0.9995 - macro_f1score: 0.2045 - val_loss: 2.4877 - val_accuracy: 0.5615 - val_top5_acc: 0.7558 - val_macro_f1score: 0.1066\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9882 - top5_acc: 0.9995 - macro_f1score: 0.2052\n","Epoch 00040: val_loss improved from 2.45092 to 2.38263, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/040.h5\n","\n","Epoch 00040: val_accuracy improved from 0.56590 to 0.56827, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/040.h5\n","382/382 [==============================] - 476s 1s/step - loss: 0.1078 - accuracy: 0.9882 - top5_acc: 0.9995 - macro_f1score: 0.2052 - val_loss: 2.3826 - val_accuracy: 0.5683 - val_top5_acc: 0.7632 - val_macro_f1score: 0.1086\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9858 - top5_acc: 0.9996 - macro_f1score: 0.2050\n","Epoch 00041: val_loss did not improve from 2.38263\n","\n","Epoch 00041: val_accuracy did not improve from 0.56827\n","382/382 [==============================] - 472s 1s/step - loss: 0.1092 - accuracy: 0.9858 - top5_acc: 0.9996 - macro_f1score: 0.2050 - val_loss: 2.4524 - val_accuracy: 0.5673 - val_top5_acc: 0.7554 - val_macro_f1score: 0.1091\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9872 - top5_acc: 0.9997 - macro_f1score: 0.2065\n","Epoch 00042: val_loss improved from 2.38263 to 2.34986, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/042.h5\n","\n","Epoch 00042: val_accuracy improved from 0.56827 to 0.57575, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/042.h5\n","382/382 [==============================] - 476s 1s/step - loss: 0.1030 - accuracy: 0.9872 - top5_acc: 0.9997 - macro_f1score: 0.2065 - val_loss: 2.3499 - val_accuracy: 0.5757 - val_top5_acc: 0.7677 - val_macro_f1score: 0.1088\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9890 - top5_acc: 0.9998 - macro_f1score: 0.2066\n","Epoch 00043: val_loss did not improve from 2.34986\n","\n","Epoch 00043: val_accuracy did not improve from 0.57575\n","382/382 [==============================] - 472s 1s/step - loss: 0.0980 - accuracy: 0.9890 - top5_acc: 0.9998 - macro_f1score: 0.2066 - val_loss: 2.4335 - val_accuracy: 0.5642 - val_top5_acc: 0.7571 - val_macro_f1score: 0.1058\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9888 - top5_acc: 0.9997 - macro_f1score: 0.2068\n","Epoch 00044: val_loss improved from 2.34986 to 2.31764, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/044.h5\n","\n","Epoch 00044: val_accuracy improved from 0.57575 to 0.58254, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/044.h5\n","382/382 [==============================] - 471s 1s/step - loss: 0.0960 - accuracy: 0.9888 - top5_acc: 0.9997 - macro_f1score: 0.2068 - val_loss: 2.3176 - val_accuracy: 0.5825 - val_top5_acc: 0.7711 - val_macro_f1score: 0.1108\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9901 - top5_acc: 0.9998 - macro_f1score: 0.2067\n","Epoch 00045: val_loss improved from 2.31764 to 2.30215, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/045.h5\n","\n","Epoch 00045: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 471s 1s/step - loss: 0.0931 - accuracy: 0.9901 - top5_acc: 0.9998 - macro_f1score: 0.2067 - val_loss: 2.3022 - val_accuracy: 0.5778 - val_top5_acc: 0.7673 - val_macro_f1score: 0.1099\n","Learning rate:  0.0001\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 46/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9900 - top5_acc: 0.9999 - macro_f1score: 0.2067\n","Epoch 00046: val_loss did not improve from 2.30215\n","\n","Epoch 00046: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 469s 1s/step - loss: 0.0898 - accuracy: 0.9900 - top5_acc: 0.9999 - macro_f1score: 0.2067 - val_loss: 2.3533 - val_accuracy: 0.5717 - val_top5_acc: 0.7656 - val_macro_f1score: 0.1069\n","Learning rate:  0.0001\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 47/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9915 - top5_acc: 0.9999 - macro_f1score: 0.2078\n","Epoch 00047: val_loss did not improve from 2.30215\n","\n","Epoch 00047: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 467s 1s/step - loss: 0.0856 - accuracy: 0.9915 - top5_acc: 0.9999 - macro_f1score: 0.2078 - val_loss: 2.3032 - val_accuracy: 0.5798 - val_top5_acc: 0.7724 - val_macro_f1score: 0.1107\n","Learning rate:  0.0001\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 48/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9910 - top5_acc: 0.9999 - macro_f1score: 0.2080\n","Epoch 00048: val_loss did not improve from 2.30215\n","\n","Epoch 00048: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 466s 1s/step - loss: 0.0842 - accuracy: 0.9910 - top5_acc: 0.9999 - macro_f1score: 0.2080 - val_loss: 2.3918 - val_accuracy: 0.5703 - val_top5_acc: 0.7599 - val_macro_f1score: 0.1100\n","Learning rate:  0.0001\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 49/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9929 - top5_acc: 0.9999 - macro_f1score: 0.2090\n","Epoch 00049: val_loss improved from 2.30215 to 2.26248, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/049.h5\n","\n","Epoch 00049: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 467s 1s/step - loss: 0.0802 - accuracy: 0.9929 - top5_acc: 0.9999 - macro_f1score: 0.2090 - val_loss: 2.2625 - val_accuracy: 0.5805 - val_top5_acc: 0.7697 - val_macro_f1score: 0.1113\n","Learning rate:  0.0001\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 50/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9925 - top5_acc: 0.9998 - macro_f1score: 0.2091\n","Epoch 00050: val_loss did not improve from 2.26248\n","\n","Epoch 00050: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 463s 1s/step - loss: 0.0786 - accuracy: 0.9925 - top5_acc: 0.9998 - macro_f1score: 0.2091 - val_loss: 2.2926 - val_accuracy: 0.5761 - val_top5_acc: 0.7632 - val_macro_f1score: 0.1084\n","Learning rate:  0.0001\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 51/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9927 - top5_acc: 0.9999 - macro_f1score: 0.2089\n","Epoch 00051: val_loss did not improve from 2.26248\n","\n","Epoch 00051: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 464s 1s/step - loss: 0.0767 - accuracy: 0.9927 - top5_acc: 0.9999 - macro_f1score: 0.2089 - val_loss: 2.3167 - val_accuracy: 0.5734 - val_top5_acc: 0.7636 - val_macro_f1score: 0.1092\n","Learning rate:  0.0001\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 52/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9936 - top5_acc: 0.9998 - macro_f1score: 0.2090\n","Epoch 00052: val_loss did not improve from 2.26248\n","\n","Epoch 00052: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 464s 1s/step - loss: 0.0743 - accuracy: 0.9936 - top5_acc: 0.9998 - macro_f1score: 0.2090 - val_loss: 2.2721 - val_accuracy: 0.5788 - val_top5_acc: 0.7700 - val_macro_f1score: 0.1100\n","Learning rate:  0.0001\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 53/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9943 - top5_acc: 0.9999 - macro_f1score: 0.2090\n","Epoch 00053: val_loss did not improve from 2.26248\n","\n","Epoch 00053: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 466s 1s/step - loss: 0.0707 - accuracy: 0.9943 - top5_acc: 0.9999 - macro_f1score: 0.2090 - val_loss: 2.2877 - val_accuracy: 0.5805 - val_top5_acc: 0.7731 - val_macro_f1score: 0.1112\n","Learning rate:  0.0001\n","\n","Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 54/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9933 - top5_acc: 0.9999 - macro_f1score: 0.2088\n","Epoch 00054: val_loss did not improve from 2.26248\n","\n","Epoch 00054: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 465s 1s/step - loss: 0.0706 - accuracy: 0.9933 - top5_acc: 0.9999 - macro_f1score: 0.2088 - val_loss: 2.2875 - val_accuracy: 0.5730 - val_top5_acc: 0.7653 - val_macro_f1score: 0.1071\n","Learning rate:  0.0001\n","\n","Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 55/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9939 - top5_acc: 0.9999 - macro_f1score: 0.2097\n","Epoch 00055: val_loss did not improve from 2.26248\n","\n","Epoch 00055: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 464s 1s/step - loss: 0.0682 - accuracy: 0.9939 - top5_acc: 0.9999 - macro_f1score: 0.2097 - val_loss: 2.2876 - val_accuracy: 0.5808 - val_top5_acc: 0.7728 - val_macro_f1score: 0.1102\n","Learning rate:  0.0001\n","\n","Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 56/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9945 - top5_acc: 1.0000 - macro_f1score: 0.2084\n","Epoch 00056: val_loss improved from 2.26248 to 2.25595, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/056.h5\n","\n","Epoch 00056: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 468s 1s/step - loss: 0.0654 - accuracy: 0.9945 - top5_acc: 1.0000 - macro_f1score: 0.2084 - val_loss: 2.2560 - val_accuracy: 0.5812 - val_top5_acc: 0.7768 - val_macro_f1score: 0.1116\n","Learning rate:  0.0001\n","\n","Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 57/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9936 - top5_acc: 1.0000 - macro_f1score: 0.2091\n","Epoch 00057: val_loss did not improve from 2.25595\n","\n","Epoch 00057: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 465s 1s/step - loss: 0.0673 - accuracy: 0.9936 - top5_acc: 1.0000 - macro_f1score: 0.2091 - val_loss: 2.3356 - val_accuracy: 0.5751 - val_top5_acc: 0.7629 - val_macro_f1score: 0.1079\n","Learning rate:  0.0001\n","\n","Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 58/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9943 - top5_acc: 1.0000 - macro_f1score: 0.2094\n","Epoch 00058: val_loss did not improve from 2.25595\n","\n","Epoch 00058: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 460s 1s/step - loss: 0.0637 - accuracy: 0.9943 - top5_acc: 1.0000 - macro_f1score: 0.2094 - val_loss: 2.3284 - val_accuracy: 0.5683 - val_top5_acc: 0.7663 - val_macro_f1score: 0.1098\n","Learning rate:  0.0001\n","\n","Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 59/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9948 - top5_acc: 1.0000 - macro_f1score: 0.2091\n","Epoch 00059: val_loss did not improve from 2.25595\n","\n","Epoch 00059: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 464s 1s/step - loss: 0.0633 - accuracy: 0.9948 - top5_acc: 1.0000 - macro_f1score: 0.2091 - val_loss: 2.2856 - val_accuracy: 0.5802 - val_top5_acc: 0.7711 - val_macro_f1score: 0.1106\n","Learning rate:  0.0001\n","\n","Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 60/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9956 - top5_acc: 0.9999 - macro_f1score: 0.2093\n","Epoch 00060: val_loss did not improve from 2.25595\n","\n","Epoch 00060: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 467s 1s/step - loss: 0.0605 - accuracy: 0.9956 - top5_acc: 0.9999 - macro_f1score: 0.2093 - val_loss: 2.2736 - val_accuracy: 0.5727 - val_top5_acc: 0.7690 - val_macro_f1score: 0.1086\n","Learning rate:  1e-05\n","\n","Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 61/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9963 - top5_acc: 1.0000 - macro_f1score: 0.2098\n","Epoch 00061: val_loss improved from 2.25595 to 2.20230, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/061.h5\n","\n","Epoch 00061: val_accuracy did not improve from 0.58254\n","382/382 [==============================] - 467s 1s/step - loss: 0.0523 - accuracy: 0.9963 - top5_acc: 1.0000 - macro_f1score: 0.2098 - val_loss: 2.2023 - val_accuracy: 0.5819 - val_top5_acc: 0.7724 - val_macro_f1score: 0.1097\n","Learning rate:  1e-05\n","\n","Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 62/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9976 - top5_acc: 0.9999 - macro_f1score: 0.2103\n","Epoch 00062: val_loss improved from 2.20230 to 2.14307, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/062.h5\n","\n","Epoch 00062: val_accuracy improved from 0.58254 to 0.58288, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/062.h5\n","382/382 [==============================] - 468s 1s/step - loss: 0.0474 - accuracy: 0.9976 - top5_acc: 0.9999 - macro_f1score: 0.2103 - val_loss: 2.1431 - val_accuracy: 0.5829 - val_top5_acc: 0.7782 - val_macro_f1score: 0.1115\n","Learning rate:  1e-05\n","\n","Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 63/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9969 - top5_acc: 1.0000 - macro_f1score: 0.2111\n","Epoch 00063: val_loss improved from 2.14307 to 2.13146, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/063.h5\n","\n","Epoch 00063: val_accuracy improved from 0.58288 to 0.58798, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/063.h5\n","382/382 [==============================] - 472s 1s/step - loss: 0.0481 - accuracy: 0.9969 - top5_acc: 1.0000 - macro_f1score: 0.2111 - val_loss: 2.1315 - val_accuracy: 0.5880 - val_top5_acc: 0.7762 - val_macro_f1score: 0.1135\n","Learning rate:  1e-05\n","\n","Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 64/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2110\n","Epoch 00064: val_loss improved from 2.13146 to 2.11350, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/064.h5\n","\n","Epoch 00064: val_accuracy did not improve from 0.58798\n","382/382 [==============================] - 470s 1s/step - loss: 0.0501 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2110 - val_loss: 2.1135 - val_accuracy: 0.5866 - val_top5_acc: 0.7765 - val_macro_f1score: 0.1129\n","Learning rate:  1e-05\n","\n","Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 65/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9982 - top5_acc: 0.9999 - macro_f1score: 0.2109\n","Epoch 00065: val_loss improved from 2.11350 to 2.07557, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/065.h5\n","\n","Epoch 00065: val_accuracy improved from 0.58798 to 0.59137, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/065.h5\n","382/382 [==============================] - 467s 1s/step - loss: 0.0513 - accuracy: 0.9982 - top5_acc: 0.9999 - macro_f1score: 0.2109 - val_loss: 2.0756 - val_accuracy: 0.5914 - val_top5_acc: 0.7762 - val_macro_f1score: 0.1121\n","Learning rate:  1e-05\n","\n","Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 66/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.2109\n","Epoch 00066: val_loss improved from 2.07557 to 2.06281, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/066.h5\n","\n","Epoch 00066: val_accuracy did not improve from 0.59137\n","382/382 [==============================] - 459s 1s/step - loss: 0.0522 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.2109 - val_loss: 2.0628 - val_accuracy: 0.5904 - val_top5_acc: 0.7758 - val_macro_f1score: 0.1127\n","Learning rate:  1e-05\n","\n","Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 67/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2103\n","Epoch 00067: val_loss improved from 2.06281 to 2.04689, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/067.h5\n","\n","Epoch 00067: val_accuracy improved from 0.59137 to 0.59477, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/067.h5\n","382/382 [==============================] - 466s 1s/step - loss: 0.0570 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2103 - val_loss: 2.0469 - val_accuracy: 0.5948 - val_top5_acc: 0.7755 - val_macro_f1score: 0.1115\n","Learning rate:  1e-05\n","\n","Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 68/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9984 - top5_acc: 1.0000 - macro_f1score: 0.2105\n","Epoch 00068: val_loss improved from 2.04689 to 2.03957, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/068.h5\n","\n","Epoch 00068: val_accuracy did not improve from 0.59477\n","382/382 [==============================] - 462s 1s/step - loss: 0.0597 - accuracy: 0.9984 - top5_acc: 1.0000 - macro_f1score: 0.2105 - val_loss: 2.0396 - val_accuracy: 0.5927 - val_top5_acc: 0.7765 - val_macro_f1score: 0.1113\n","Learning rate:  1e-05\n","\n","Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 69/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2112\n","Epoch 00069: val_loss improved from 2.03957 to 2.03635, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/069.h5\n","\n","Epoch 00069: val_accuracy did not improve from 0.59477\n","382/382 [==============================] - 463s 1s/step - loss: 0.0616 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2112 - val_loss: 2.0363 - val_accuracy: 0.5887 - val_top5_acc: 0.7755 - val_macro_f1score: 0.1123\n","Learning rate:  1e-05\n","\n","Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 70/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9987 - top5_acc: 1.0000 - macro_f1score: 0.2104\n","Epoch 00070: val_loss improved from 2.03635 to 2.01737, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/DenseNet121/070.h5\n","\n","Epoch 00070: val_accuracy did not improve from 0.59477\n","382/382 [==============================] - 462s 1s/step - loss: 0.0634 - accuracy: 0.9987 - top5_acc: 1.0000 - macro_f1score: 0.2104 - val_loss: 2.0174 - val_accuracy: 0.5914 - val_top5_acc: 0.7745 - val_macro_f1score: 0.1101\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FAr6jLIR1qmu"},"source":["### 2) DenseNet121 Evaluate"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"ZvKx1in81qmu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605016405051,"user_tz":-540,"elapsed":41227414,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"1ec540ee-8892-4291-e615-32b87ae5366b"},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["48/48 [==============================] - 883s 18s/step - loss: 2.0033 - accuracy: 0.5895 - top5_acc: 0.7777 - macro_f1score: 0.1064\n","[Test Loss: 2.0033 /  Test Top-1 Accuracy: 0.5895 / Test Top-5 Accuracy: 0.7777 / Test Macro f1: 0.1064]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fbdRXP391qmx"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRtTWKDk1qm0"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lB5x2Y_1qm3"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'DenseNet121.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQVReEQO1qm5"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEBcd6Hx1qm8","colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"status":"ok","timestamp":1605016406085,"user_tz":-540,"elapsed":41228408,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"a6949997-6758-47ec-ae53-ecb23b0aa29f"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Jkbe4ajm1qnG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9uJISqVI6272"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLDgyUtp1qnJ","executionInfo":{"status":"ok","timestamp":1606099513852,"user_tz":-540,"elapsed":915,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / DenseNet121"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c","executionInfo":{"status":"ok","timestamp":1606099514622,"user_tz":-540,"elapsed":1674,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak","executionInfo":{"status":"ok","timestamp":1606099514623,"user_tz":-540,"elapsed":1669,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"2cgpzDgH1qnL","executionInfo":{"status":"ok","timestamp":1606099526819,"user_tz":-540,"elapsed":13847,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["model=load_model(os.path.join(dir,'model_output',number,'DenseNet121','070.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0IvhWkE1qnN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606100285839,"user_tz":-540,"elapsed":772861,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"b280e0ef-0e75-44f1-b058-f5642d07306d"},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["48/48 [==============================] - 723s 15s/step - loss: 1.9908 - accuracy: 0.5902 - top5_acc: 0.7793 - macro_f1score: 0.1076\n","[Test Loss: 1.9908 /  Test Top-1 Accuracy: 0.5902 / Test Top-5 Accuracy: 0.7793 / Test Macro f1: 0.1076]\n","\n"],"name":"stdout"}]}]}
