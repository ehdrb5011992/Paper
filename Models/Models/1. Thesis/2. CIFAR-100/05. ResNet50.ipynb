{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5.ResNet50.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"veB_9DzkobyH","executionInfo":{"status":"ok","timestamp":1606102879985,"user_tz":-540,"elapsed":1337,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["#모형 출처 : https://github.com/titu1994/keras-squeeze-excite-network"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [ResNet50]"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original ResNet\n","```\n","1) Support Functions\n","2) Almost orginal ResNet\n","```\n","3. ResNet50\n","```\n","1) ResNet50\n","2) ResNet50 Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606102915290,"user_tz":-540,"elapsed":36621,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"571ea6d8-c114-4689-b05c-eceeaa49d9e1"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606102915296,"user_tz":-540,"elapsed":36617,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"65e9765c-2d4b-49fb-8816-e7c22e856d4c"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1606102918824,"user_tz":-540,"elapsed":40143,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1606102919496,"user_tz":-540,"elapsed":40813,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606102919498,"user_tz":-540,"elapsed":40804,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"459b95b0-8a3d-4b49-b5c7-23e992eedd52"},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606102919501,"user_tz":-540,"elapsed":40797,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"dd768012-72ef-4916-b643-fdba58c8edb4"},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606102922749,"user_tz":-540,"elapsed":44033,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"c3a073c6-8c96-4284-85c7-b7e7a2073a1f"},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"5QEPaq7XQBs8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606102922754,"user_tz":-540,"elapsed":44028,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"0520796c-a596-4bb0-b78e-12685a2c4d9f"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 4436285460771579601\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 8729222620503090828\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 12471470501694898822\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15695549568\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 15973246536200161562\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UmBWKpp_cNUa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606102922755,"user_tz":-540,"elapsed":44021,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"a77bdb49-5863-4018-84f1-18b3ab61da15"},"source":["!cat /proc/cpuinfo"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OOsm86eVUBko"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"DgwOtB_QEhll"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"i5hoO5oVDDJh","executionInfo":{"status":"ok","timestamp":1606102922759,"user_tz":-540,"elapsed":44022,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CIFAR100'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 224 # sizes after cropping\n","super_size = 256 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 128\n","weight_decay = 2e-3\n","epochs = 70"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1606102922765,"user_tz":-540,"elapsed":44027,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSIGjI-lnPzM","executionInfo":{"status":"ok","timestamp":1606102922766,"user_tz":-540,"elapsed":44026,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1606102922766,"user_tz":-540,"elapsed":44023,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XrNLBwoJCRR9"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"Zs3J4oAbnPzR","executionInfo":{"status":"ok","timestamp":1606102922767,"user_tz":-540,"elapsed":44022,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1606102922767,"user_tz":-540,"elapsed":44020,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOCgiW4fnPzW","executionInfo":{"status":"ok","timestamp":1606102922768,"user_tz":-540,"elapsed":44018,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"sh3c_SsjnPzY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606102992649,"user_tz":-540,"elapsed":113890,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"7813b361-ae1c-4064-f7b7-71346884e7ea"},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Found 44923 images belonging to 100 classes.\n","Found 5077 images belonging to 100 classes.\n","Found 10000 images belonging to 100 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original ResNet\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"n2aVgcbl5z0A"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"napBoZvjmK6S"},"source":["def _resnet_block(input_tensor, filters, k=1, strides=(1, 1), weight_decay = weight_decay):\n","\n","    init = input_tensor\n","    channel_axis = -1\n","\n","    if strides != (1, 1) or init.get_shape()[channel_axis] != filters * k:\n","        x = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","                      use_bias=False, strides=strides)(input_tensor)\n","        init = BatchNormalization(axis=channel_axis)(x)\n","\n","\n","    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False, strides=strides)(input_tensor)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False)(x)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","\n","    m = add([x, init])\n","    m = Activation('relu')(m)\n","\n","    return m"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-rGAsFnzmK6X"},"source":["def _resnet_bottleneck_block(input_tensor, filters, k=1, strides=(1, 1), weight_decay = weight_decay):\n","\n","    init = input_tensor\n","    channel_axis = -1\n","    bottleneck_expand = 4\n","\n","    if strides != (1, 1) or init.get_shape()[channel_axis] != bottleneck_expand * filters * k:\n","        x = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","                      use_bias=False, strides=strides)(input_tensor)\n","        init = BatchNormalization(axis=channel_axis)(x)\n","\n","\n","    x = Conv2D(filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False)(input_tensor)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters * k, (3, 3), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False, strides=strides)(x)\n","    x = BatchNormalization(axis=channel_axis)(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(bottleneck_expand * filters * k, (1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay),\n","               use_bias=False)(x)\n","    x = BatchNormalization(axis=channel_axis)(x)    \n","\n","    m = add([x, init])\n","    m = Activation('relu')(m)\n","\n","    return m"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4XWPZ9p0mK6a"},"source":["### 2) Almost Orginial ResNet\n"]},{"cell_type":"code","metadata":{"id":"UJQUF8nAmK6a"},"source":["def _create_resnet(classes, img_input, initial_conv_filters, filters, depth, width, bottleneck, weight_decay):\n","\n","    channel_axis = -1\n","    N = list(depth)\n","\n","    # block 1 (initial conv block)\n","    x = Conv2D(initial_conv_filters, (7, 7), padding='same', use_bias=False, strides=(2, 2), kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(img_input)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","\n","    # block 2 (projection block)\n","    for i in range(N[0]):\n","        if bottleneck:\n","            x = _resnet_bottleneck_block(x, filters[0], width)\n","        else:\n","            x = _resnet_block(x, filters[0], width)\n","\n","    # block 3 - N\n","    for k in range(1, len(N)):\n","        if bottleneck:\n","            x = _resnet_bottleneck_block(x, filters[k], width, strides=(2, 2))\n","        else:\n","            x = _resnet_block(x, filters[k], width, strides=(2, 2))\n","\n","        for i in range(N[k] - 1):\n","            if bottleneck:\n","                x = _resnet_bottleneck_block(x, filters[k], width)\n","            else:\n","                x = _resnet_block(x, filters[k], width)\n","\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(classes, use_bias=False, kernel_regularizer=l2(weight_decay), activation='softmax')(x)\n","\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YQUZXeZAo67V"},"source":["def ResNet(input_shape=None, initial_conv_filters=64, depth=[3, 4, 6, 3], filters=[64, 128, 256, 512],\n","             width=1, bottleneck=False, weight_decay=weight_decay, name=None, classes=1000):\n","\n","\n","    img_input = Input(shape=input_shape)\n","\n","    x = _create_resnet(classes, img_input, initial_conv_filters, filters, depth, width, bottleneck, weight_decay)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","\n","    inputs = img_input\n","\n","    # Create model.\n","    model = Model(inputs, x, name = name)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOAp8LsWRMR6"},"source":["## 3. ResNet50\n","---"]},{"cell_type":"markdown","metadata":{"id":"18V3G5o-RMR7"},"source":["### 1) ResNet50"]},{"cell_type":"code","metadata":{"id":"cHQpj9MVo62T"},"source":["# ResNet50\n","model = ResNet(input_shape=input_sizes, depth=[3, 4, 6, 3], width=1, bottleneck=True, weight_decay=weight_decay, classes=classes, name='ResNet50')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"85bYcB6bpTUW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605572051028,"user_tz":-540,"elapsed":126561,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"14709a08-7aa6-45b2-e568-df535fb41090"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"ResNet50\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 112, 112, 64) 9408        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 56, 56, 64)   4096        max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 56, 56, 64)   36864       activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 56, 56, 256)  16384       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 56, 56, 256)  16384       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 56, 56, 256)  1024        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 56, 56, 256)  1024        conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 56, 56, 256)  0           batch_normalization_3[0][0]      \n","                                                                 batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 56, 56, 256)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 56, 56, 64)   16384       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 56, 56, 64)   256         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 56, 56, 64)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 56, 56, 64)   36864       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 56, 56, 64)   256         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 56, 56, 64)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 56, 56, 256)  16384       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 56, 56, 256)  1024        conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 56, 56, 256)  0           batch_normalization_6[0][0]      \n","                                                                 activation_2[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 56, 56, 64)   16384       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 56, 56, 64)   256         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 56, 56, 64)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 56, 56, 64)   36864       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 56, 56, 64)   256         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 56, 56, 64)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 56, 56, 256)  16384       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 56, 56, 256)  1024        conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 56, 56, 256)  0           batch_normalization_9[0][0]      \n","                                                                 activation_5[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 56, 56, 128)  32768       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 56, 56, 128)  512         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 56, 56, 128)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 28, 28, 128)  147456      activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 28, 28, 512)  65536       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 28, 28, 512)  131072      activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 28, 28, 512)  2048        conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_13[0][0]     \n","                                                                 batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 28, 28, 128)  65536       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 28, 28, 128)  0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 28, 28, 128)  147456      activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 28, 28, 512)  65536       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_16[0][0]     \n","                                                                 activation_11[0][0]              \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 28, 28, 128)  65536       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 28, 28, 128)  147456      activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 28, 28, 512)  65536       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_19[0][0]     \n","                                                                 activation_14[0][0]              \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 28, 28, 128)  65536       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 28, 28, 128)  0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 28, 28, 128)  147456      activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 28, 28, 512)  65536       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 28, 28, 512)  2048        conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_22[0][0]     \n","                                                                 activation_17[0][0]              \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 28, 28, 256)  131072      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 28, 28, 256)  1024        conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 28, 28, 256)  0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 14, 14, 256)  589824      activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 14, 14, 256)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 14, 14, 1024) 262144      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 14, 14, 1024) 524288      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 14, 14, 1024) 4096        conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 14, 14, 1024) 4096        conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_26[0][0]     \n","                                                                 batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 14, 14, 256)  262144      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 14, 14, 256)  1024        conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 14, 14, 256)  0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 14, 14, 256)  589824      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 14, 14, 256)  0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 14, 14, 1024) 262144      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 14, 14, 1024) 4096        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_29[0][0]     \n","                                                                 activation_23[0][0]              \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 14, 14, 256)  262144      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 14, 14, 256)  1024        conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 14, 14, 256)  0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 14, 14, 256)  589824      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 14, 14, 256)  0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 14, 14, 1024) 262144      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 14, 14, 1024) 4096        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_32[0][0]     \n","                                                                 activation_26[0][0]              \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 14, 14, 256)  262144      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 14, 14, 256)  0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 14, 14, 256)  589824      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 14, 14, 256)  0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 14, 14, 1024) 262144      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 14, 14, 1024) 4096        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_35[0][0]     \n","                                                                 activation_29[0][0]              \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 14, 14, 256)  262144      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 14, 14, 256)  1024        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 14, 14, 256)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 14, 14, 256)  589824      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 14, 14, 256)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 14, 14, 1024) 262144      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 14, 14, 1024) 4096        conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_38[0][0]     \n","                                                                 activation_32[0][0]              \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 14, 14, 256)  262144      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 14, 14, 256)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 14, 14, 256)  589824      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 14, 14, 1024) 262144      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 14, 14, 1024) 4096        conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_41[0][0]     \n","                                                                 activation_35[0][0]              \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 14, 14, 512)  524288      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 14, 14, 512)  2048        conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 14, 14, 512)  0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 7, 7, 512)    2359296     activation_39[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 7, 7, 512)    0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 7, 7, 2048)   1048576     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 7, 7, 2048)   2097152     activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 7, 7, 2048)   8192        conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 7, 7, 2048)   8192        conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_45[0][0]     \n","                                                                 batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 7, 7, 512)    1048576     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 7, 7, 512)    2048        conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 7, 7, 512)    0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 7, 7, 512)    2359296     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 7, 7, 512)    0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 7, 7, 2048)   1048576     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 7, 7, 2048)   8192        conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_48[0][0]     \n","                                                                 activation_41[0][0]              \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 7, 7, 512)    1048576     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 7, 7, 512)    2048        conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 7, 7, 512)    0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 7, 7, 512)    2359296     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 7, 7, 512)    0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 7, 7, 2048)   1048576     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 7, 7, 2048)   8192        conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_51[0][0]     \n","                                                                 activation_44[0][0]              \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 2048)         0           activation_47[0][0]              \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 100)          204800      global_average_pooling2d[0][0]   \n","==================================================================================================\n","Total params: 23,765,696\n","Trainable params: 23,712,704\n","Non-trainable params: 52,992\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AispA2HmDSs_"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e4TEeLLw9al1"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8643H3mcjj3"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwH0Q16iRMSH"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMuhpBHjRMSN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605641154304,"user_tz":-540,"elapsed":69229804,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"aceeb1c2-d04b-4b93-b55c-142ed3ef60a9"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_5/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_6/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_7/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_8/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_9/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_10/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_12/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_13/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_14/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_11/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_15/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_16/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_17/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_18/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_19/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_20/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_21/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_22/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_23/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_25/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_26/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_27/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_24/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_28/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_29/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_30/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_31/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_32/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_33/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_34/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_35/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_36/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_37/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_38/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_39/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_40/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_41/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_42/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_44/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_45/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_46/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_43/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_47/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_48/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_49/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_50/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_51/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for conv2d_52/kernel:0\n","0.0(L1), 0.00010690450184266088(L2) weight decay set for dense/kernel:0\n","350/350 [==============================] - ETA: 0s - loss: 4.2376 - accuracy: 0.0840 - top5_acc: 0.2610 - macro_f1score: 0.0027  \n","Epoch 00001: val_loss improved from inf to 4.40148, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.07612, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/001.h5\n","350/350 [==============================] - 27065s 77s/step - loss: 4.2376 - accuracy: 0.0840 - top5_acc: 0.2610 - macro_f1score: 0.0027 - val_loss: 4.4015 - val_accuracy: 0.0761 - val_top5_acc: 0.2398 - val_macro_f1score: 0.0013\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","350/350 [==============================] - ETA: 0s - loss: 3.5357 - accuracy: 0.1624 - top5_acc: 0.4208 - macro_f1score: 0.0140\n","Epoch 00002: val_loss improved from 4.40148 to 3.68586, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/002.h5\n","\n","Epoch 00002: val_accuracy improved from 0.07612 to 0.15264, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/002.h5\n","350/350 [==============================] - 655s 2s/step - loss: 3.5357 - accuracy: 0.1624 - top5_acc: 0.4208 - macro_f1score: 0.0140 - val_loss: 3.6859 - val_accuracy: 0.1526 - val_top5_acc: 0.3986 - val_macro_f1score: 0.0229\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","350/350 [==============================] - ETA: 0s - loss: 3.1490 - accuracy: 0.2307 - top5_acc: 0.5195 - macro_f1score: 0.0415\n","Epoch 00003: val_loss improved from 3.68586 to 3.31289, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/003.h5\n","\n","Epoch 00003: val_accuracy improved from 0.15264 to 0.20633, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/003.h5\n","350/350 [==============================] - 653s 2s/step - loss: 3.1490 - accuracy: 0.2307 - top5_acc: 0.5195 - macro_f1score: 0.0415 - val_loss: 3.3129 - val_accuracy: 0.2063 - val_top5_acc: 0.4842 - val_macro_f1score: 0.0355\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","350/350 [==============================] - ETA: 0s - loss: 2.9218 - accuracy: 0.2730 - top5_acc: 0.5784 - macro_f1score: 0.0635\n","Epoch 00004: val_loss improved from 3.31289 to 3.07771, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/004.h5\n","\n","Epoch 00004: val_accuracy improved from 0.20633 to 0.26222, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/004.h5\n","350/350 [==============================] - 639s 2s/step - loss: 2.9218 - accuracy: 0.2730 - top5_acc: 0.5784 - macro_f1score: 0.0635 - val_loss: 3.0777 - val_accuracy: 0.2622 - val_top5_acc: 0.5493 - val_macro_f1score: 0.0702\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","350/350 [==============================] - ETA: 0s - loss: 2.6470 - accuracy: 0.3260 - top5_acc: 0.6433 - macro_f1score: 0.1021\n","Epoch 00005: val_loss did not improve from 3.07771\n","\n","Epoch 00005: val_accuracy did not improve from 0.26222\n","350/350 [==============================] - 641s 2s/step - loss: 2.6470 - accuracy: 0.3260 - top5_acc: 0.6433 - macro_f1score: 0.1021 - val_loss: 3.1417 - val_accuracy: 0.2524 - val_top5_acc: 0.5481 - val_macro_f1score: 0.0916\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","350/350 [==============================] - ETA: 0s - loss: 2.4053 - accuracy: 0.3732 - top5_acc: 0.6948 - macro_f1score: 0.1386\n","Epoch 00006: val_loss improved from 3.07771 to 2.47918, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/006.h5\n","\n","Epoch 00006: val_accuracy improved from 0.26222 to 0.36418, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/006.h5\n","350/350 [==============================] - 641s 2s/step - loss: 2.4053 - accuracy: 0.3732 - top5_acc: 0.6948 - macro_f1score: 0.1386 - val_loss: 2.4792 - val_accuracy: 0.3642 - val_top5_acc: 0.6887 - val_macro_f1score: 0.1420\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","350/350 [==============================] - ETA: 0s - loss: 2.2005 - accuracy: 0.4191 - top5_acc: 0.7377 - macro_f1score: 0.1756\n","Epoch 00007: val_loss did not improve from 2.47918\n","\n","Epoch 00007: val_accuracy improved from 0.36418 to 0.37400, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/007.h5\n","350/350 [==============================] - 629s 2s/step - loss: 2.2005 - accuracy: 0.4191 - top5_acc: 0.7377 - macro_f1score: 0.1756 - val_loss: 2.4819 - val_accuracy: 0.3740 - val_top5_acc: 0.6905 - val_macro_f1score: 0.1650\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","350/350 [==============================] - ETA: 0s - loss: 2.0271 - accuracy: 0.4510 - top5_acc: 0.7723 - macro_f1score: 0.2101\n","Epoch 00008: val_loss did not improve from 2.47918\n","\n","Epoch 00008: val_accuracy did not improve from 0.37400\n","350/350 [==============================] - 626s 2s/step - loss: 2.0271 - accuracy: 0.4510 - top5_acc: 0.7723 - macro_f1score: 0.2101 - val_loss: 2.8134 - val_accuracy: 0.3409 - val_top5_acc: 0.6755 - val_macro_f1score: 0.1604\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","350/350 [==============================] - ETA: 0s - loss: 1.8645 - accuracy: 0.4919 - top5_acc: 0.7999 - macro_f1score: 0.2461\n","Epoch 00009: val_loss improved from 2.47918 to 2.13800, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/009.h5\n","\n","Epoch 00009: val_accuracy improved from 0.37400 to 0.43109, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/009.h5\n","350/350 [==============================] - 630s 2s/step - loss: 1.8645 - accuracy: 0.4919 - top5_acc: 0.7999 - macro_f1score: 0.2461 - val_loss: 2.1380 - val_accuracy: 0.4311 - val_top5_acc: 0.7556 - val_macro_f1score: 0.2106\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","350/350 [==============================] - ETA: 0s - loss: 1.7258 - accuracy: 0.5242 - top5_acc: 0.8278 - macro_f1score: 0.2735\n","Epoch 00010: val_loss did not improve from 2.13800\n","\n","Epoch 00010: val_accuracy did not improve from 0.43109\n","350/350 [==============================] - 629s 2s/step - loss: 1.7258 - accuracy: 0.5242 - top5_acc: 0.8278 - macro_f1score: 0.2735 - val_loss: 2.3144 - val_accuracy: 0.4179 - val_top5_acc: 0.7358 - val_macro_f1score: 0.2182\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","350/350 [==============================] - ETA: 0s - loss: 1.6196 - accuracy: 0.5481 - top5_acc: 0.8436 - macro_f1score: 0.2997\n","Epoch 00011: val_loss improved from 2.13800 to 1.99228, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/011.h5\n","\n","Epoch 00011: val_accuracy improved from 0.43109 to 0.47216, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/011.h5\n","350/350 [==============================] - 636s 2s/step - loss: 1.6196 - accuracy: 0.5481 - top5_acc: 0.8436 - macro_f1score: 0.2997 - val_loss: 1.9923 - val_accuracy: 0.4722 - val_top5_acc: 0.7887 - val_macro_f1score: 0.2578\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","350/350 [==============================] - ETA: 0s - loss: 1.4874 - accuracy: 0.5816 - top5_acc: 0.8653 - macro_f1score: 0.3325\n","Epoch 00012: val_loss improved from 1.99228 to 1.97972, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/012.h5\n","\n","Epoch 00012: val_accuracy improved from 0.47216 to 0.48438, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/012.h5\n","350/350 [==============================] - 635s 2s/step - loss: 1.4874 - accuracy: 0.5816 - top5_acc: 0.8653 - macro_f1score: 0.3325 - val_loss: 1.9797 - val_accuracy: 0.4844 - val_top5_acc: 0.7895 - val_macro_f1score: 0.2750\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","350/350 [==============================] - ETA: 0s - loss: 1.4009 - accuracy: 0.6023 - top5_acc: 0.8791 - macro_f1score: 0.3545\n","Epoch 00013: val_loss improved from 1.97972 to 1.78050, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/013.h5\n","\n","Epoch 00013: val_accuracy improved from 0.48438 to 0.52564, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/013.h5\n","350/350 [==============================] - 635s 2s/step - loss: 1.4009 - accuracy: 0.6023 - top5_acc: 0.8791 - macro_f1score: 0.3545 - val_loss: 1.7805 - val_accuracy: 0.5256 - val_top5_acc: 0.8151 - val_macro_f1score: 0.3057\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","350/350 [==============================] - ETA: 0s - loss: 1.3085 - accuracy: 0.6256 - top5_acc: 0.8939 - macro_f1score: 0.3725\n","Epoch 00014: val_loss did not improve from 1.78050\n","\n","Epoch 00014: val_accuracy improved from 0.52564 to 0.52845, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/014.h5\n","350/350 [==============================] - 637s 2s/step - loss: 1.3085 - accuracy: 0.6256 - top5_acc: 0.8939 - macro_f1score: 0.3725 - val_loss: 1.7893 - val_accuracy: 0.5284 - val_top5_acc: 0.8195 - val_macro_f1score: 0.3073\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","350/350 [==============================] - ETA: 0s - loss: 1.2310 - accuracy: 0.6438 - top5_acc: 0.9013 - macro_f1score: 0.3901\n","Epoch 00015: val_loss improved from 1.78050 to 1.64073, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/015.h5\n","\n","Epoch 00015: val_accuracy improved from 0.52845 to 0.54968, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/015.h5\n","350/350 [==============================] - 636s 2s/step - loss: 1.2310 - accuracy: 0.6438 - top5_acc: 0.9013 - macro_f1score: 0.3901 - val_loss: 1.6407 - val_accuracy: 0.5497 - val_top5_acc: 0.8504 - val_macro_f1score: 0.3294\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","350/350 [==============================] - ETA: 0s - loss: 1.1530 - accuracy: 0.6635 - top5_acc: 0.9132 - macro_f1score: 0.4119\n","Epoch 00016: val_loss did not improve from 1.64073\n","\n","Epoch 00016: val_accuracy did not improve from 0.54968\n","350/350 [==============================] - 630s 2s/step - loss: 1.1530 - accuracy: 0.6635 - top5_acc: 0.9132 - macro_f1score: 0.4119 - val_loss: 1.7002 - val_accuracy: 0.5403 - val_top5_acc: 0.8359 - val_macro_f1score: 0.3220\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","350/350 [==============================] - ETA: 0s - loss: 1.0990 - accuracy: 0.6785 - top5_acc: 0.9199 - macro_f1score: 0.4284\n","Epoch 00017: val_loss improved from 1.64073 to 1.60038, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/017.h5\n","\n","Epoch 00017: val_accuracy improved from 0.54968 to 0.56911, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/017.h5\n","350/350 [==============================] - 632s 2s/step - loss: 1.0990 - accuracy: 0.6785 - top5_acc: 0.9199 - macro_f1score: 0.4284 - val_loss: 1.6004 - val_accuracy: 0.5691 - val_top5_acc: 0.8512 - val_macro_f1score: 0.3532\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","350/350 [==============================] - ETA: 0s - loss: 1.0317 - accuracy: 0.6949 - top5_acc: 0.9290 - macro_f1score: 0.4441\n","Epoch 00018: val_loss did not improve from 1.60038\n","\n","Epoch 00018: val_accuracy did not improve from 0.56911\n","350/350 [==============================] - 626s 2s/step - loss: 1.0317 - accuracy: 0.6949 - top5_acc: 0.9290 - macro_f1score: 0.4441 - val_loss: 1.7438 - val_accuracy: 0.5527 - val_top5_acc: 0.8325 - val_macro_f1score: 0.3384\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9801 - accuracy: 0.7094 - top5_acc: 0.9346 - macro_f1score: 0.4575\n","Epoch 00019: val_loss did not improve from 1.60038\n","\n","Epoch 00019: val_accuracy did not improve from 0.56911\n","350/350 [==============================] - 610s 2s/step - loss: 0.9801 - accuracy: 0.7094 - top5_acc: 0.9346 - macro_f1score: 0.4575 - val_loss: 1.6250 - val_accuracy: 0.5649 - val_top5_acc: 0.8516 - val_macro_f1score: 0.3571\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9316 - accuracy: 0.7203 - top5_acc: 0.9420 - macro_f1score: 0.4682\n","Epoch 00020: val_loss did not improve from 1.60038\n","\n","Epoch 00020: val_accuracy did not improve from 0.56911\n","350/350 [==============================] - 599s 2s/step - loss: 0.9316 - accuracy: 0.7203 - top5_acc: 0.9420 - macro_f1score: 0.4682 - val_loss: 1.6416 - val_accuracy: 0.5639 - val_top5_acc: 0.8530 - val_macro_f1score: 0.3407\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8730 - accuracy: 0.7385 - top5_acc: 0.9477 - macro_f1score: 0.4837\n","Epoch 00021: val_loss improved from 1.60038 to 1.51129, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/021.h5\n","\n","Epoch 00021: val_accuracy improved from 0.56911 to 0.58474, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/021.h5\n","350/350 [==============================] - 600s 2s/step - loss: 0.8730 - accuracy: 0.7385 - top5_acc: 0.9477 - macro_f1score: 0.4837 - val_loss: 1.5113 - val_accuracy: 0.5847 - val_top5_acc: 0.8712 - val_macro_f1score: 0.3704\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8285 - accuracy: 0.7487 - top5_acc: 0.9523 - macro_f1score: 0.4920\n","Epoch 00022: val_loss did not improve from 1.51129\n","\n","Epoch 00022: val_accuracy did not improve from 0.58474\n","350/350 [==============================] - 600s 2s/step - loss: 0.8285 - accuracy: 0.7487 - top5_acc: 0.9523 - macro_f1score: 0.4920 - val_loss: 1.7905 - val_accuracy: 0.5677 - val_top5_acc: 0.8397 - val_macro_f1score: 0.3657\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","350/350 [==============================] - ETA: 0s - loss: 0.7895 - accuracy: 0.7581 - top5_acc: 0.9570 - macro_f1score: 0.5041\n","Epoch 00023: val_loss improved from 1.51129 to 1.40572, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/023.h5\n","\n","Epoch 00023: val_accuracy improved from 0.58474 to 0.60938, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/023.h5\n","350/350 [==============================] - 604s 2s/step - loss: 0.7895 - accuracy: 0.7581 - top5_acc: 0.9570 - macro_f1score: 0.5041 - val_loss: 1.4057 - val_accuracy: 0.6094 - val_top5_acc: 0.8928 - val_macro_f1score: 0.3966\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","350/350 [==============================] - ETA: 0s - loss: 0.7356 - accuracy: 0.7740 - top5_acc: 0.9627 - macro_f1score: 0.5176\n","Epoch 00024: val_loss did not improve from 1.40572\n","\n","Epoch 00024: val_accuracy improved from 0.60938 to 0.61899, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/024.h5\n","350/350 [==============================] - 600s 2s/step - loss: 0.7356 - accuracy: 0.7740 - top5_acc: 0.9627 - macro_f1score: 0.5176 - val_loss: 1.4729 - val_accuracy: 0.6190 - val_top5_acc: 0.8810 - val_macro_f1score: 0.4005\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","350/350 [==============================] - ETA: 0s - loss: 0.7031 - accuracy: 0.7819 - top5_acc: 0.9654 - macro_f1score: 0.5247\n","Epoch 00025: val_loss improved from 1.40572 to 1.38421, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/025.h5\n","\n","Epoch 00025: val_accuracy improved from 0.61899 to 0.63061, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/025.h5\n","350/350 [==============================] - 601s 2s/step - loss: 0.7031 - accuracy: 0.7819 - top5_acc: 0.9654 - macro_f1score: 0.5247 - val_loss: 1.3842 - val_accuracy: 0.6306 - val_top5_acc: 0.8872 - val_macro_f1score: 0.4103\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","350/350 [==============================] - ETA: 0s - loss: 0.6522 - accuracy: 0.7959 - top5_acc: 0.9705 - macro_f1score: 0.5385\n","Epoch 00026: val_loss did not improve from 1.38421\n","\n","Epoch 00026: val_accuracy did not improve from 0.63061\n","350/350 [==============================] - 597s 2s/step - loss: 0.6522 - accuracy: 0.7959 - top5_acc: 0.9705 - macro_f1score: 0.5385 - val_loss: 1.5232 - val_accuracy: 0.6146 - val_top5_acc: 0.8802 - val_macro_f1score: 0.4100\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","350/350 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.8045 - top5_acc: 0.9736 - macro_f1score: 0.5471\n","Epoch 00027: val_loss did not improve from 1.38421\n","\n","Epoch 00027: val_accuracy did not improve from 0.63061\n","350/350 [==============================] - 597s 2s/step - loss: 0.6285 - accuracy: 0.8045 - top5_acc: 0.9736 - macro_f1score: 0.5471 - val_loss: 1.7704 - val_accuracy: 0.5974 - val_top5_acc: 0.8604 - val_macro_f1score: 0.3943\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","350/350 [==============================] - ETA: 0s - loss: 0.5942 - accuracy: 0.8134 - top5_acc: 0.9752 - macro_f1score: 0.5566\n","Epoch 00028: val_loss did not improve from 1.38421\n","\n","Epoch 00028: val_accuracy improved from 0.63061 to 0.63301, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/028.h5\n","350/350 [==============================] - 597s 2s/step - loss: 0.5942 - accuracy: 0.8134 - top5_acc: 0.9752 - macro_f1score: 0.5566 - val_loss: 1.4673 - val_accuracy: 0.6330 - val_top5_acc: 0.8854 - val_macro_f1score: 0.4177\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","350/350 [==============================] - ETA: 0s - loss: 0.5582 - accuracy: 0.8234 - top5_acc: 0.9792 - macro_f1score: 0.5656\n","Epoch 00029: val_loss did not improve from 1.38421\n","\n","Epoch 00029: val_accuracy did not improve from 0.63301\n","350/350 [==============================] - 597s 2s/step - loss: 0.5582 - accuracy: 0.8234 - top5_acc: 0.9792 - macro_f1score: 0.5656 - val_loss: 1.5781 - val_accuracy: 0.6082 - val_top5_acc: 0.8736 - val_macro_f1score: 0.4000\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","350/350 [==============================] - ETA: 0s - loss: 0.5276 - accuracy: 0.8331 - top5_acc: 0.9811 - macro_f1score: 0.5779\n","Epoch 00030: val_loss did not improve from 1.38421\n","\n","Epoch 00030: val_accuracy did not improve from 0.63301\n","350/350 [==============================] - 598s 2s/step - loss: 0.5276 - accuracy: 0.8331 - top5_acc: 0.9811 - macro_f1score: 0.5779 - val_loss: 9.9674 - val_accuracy: 0.4878 - val_top5_acc: 0.7478 - val_macro_f1score: 0.3232\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","350/350 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.9205 - top5_acc: 0.9948 - macro_f1score: 0.6521\n","Epoch 00031: val_loss improved from 1.38421 to 1.17438, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/031.h5\n","\n","Epoch 00031: val_accuracy improved from 0.63301 to 0.70513, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/031.h5\n","350/350 [==============================] - 617s 2s/step - loss: 0.2577 - accuracy: 0.9205 - top5_acc: 0.9948 - macro_f1score: 0.6521 - val_loss: 1.1744 - val_accuracy: 0.7051 - val_top5_acc: 0.9179 - val_macro_f1score: 0.4894\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","350/350 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9475 - top5_acc: 0.9977 - macro_f1score: 0.6770\n","Epoch 00032: val_loss improved from 1.17438 to 1.16826, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/032.h5\n","\n","Epoch 00032: val_accuracy improved from 0.70513 to 0.70613, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/032.h5\n","350/350 [==============================] - 605s 2s/step - loss: 0.1726 - accuracy: 0.9475 - top5_acc: 0.9977 - macro_f1score: 0.6770 - val_loss: 1.1683 - val_accuracy: 0.7061 - val_top5_acc: 0.9265 - val_macro_f1score: 0.4948\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","350/350 [==============================] - ETA: 0s - loss: 0.1460 - accuracy: 0.9559 - top5_acc: 0.9984 - macro_f1score: 0.6827\n","Epoch 00033: val_loss improved from 1.16826 to 1.14901, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/033.h5\n","\n","Epoch 00033: val_accuracy improved from 0.70613 to 0.71334, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/033.h5\n","350/350 [==============================] - 601s 2s/step - loss: 0.1460 - accuracy: 0.9559 - top5_acc: 0.9984 - macro_f1score: 0.6827 - val_loss: 1.1490 - val_accuracy: 0.7133 - val_top5_acc: 0.9273 - val_macro_f1score: 0.4946\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","350/350 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9635 - top5_acc: 0.9989 - macro_f1score: 0.6927\n","Epoch 00034: val_loss did not improve from 1.14901\n","\n","Epoch 00034: val_accuracy did not improve from 0.71334\n","350/350 [==============================] - 599s 2s/step - loss: 0.1268 - accuracy: 0.9635 - top5_acc: 0.9989 - macro_f1score: 0.6927 - val_loss: 1.1986 - val_accuracy: 0.7099 - val_top5_acc: 0.9229 - val_macro_f1score: 0.4863\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","350/350 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9669 - top5_acc: 0.9993 - macro_f1score: 0.6926\n","Epoch 00035: val_loss did not improve from 1.14901\n","\n","Epoch 00035: val_accuracy improved from 0.71334 to 0.71374, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/035.h5\n","350/350 [==============================] - 597s 2s/step - loss: 0.1175 - accuracy: 0.9669 - top5_acc: 0.9993 - macro_f1score: 0.6926 - val_loss: 1.1518 - val_accuracy: 0.7137 - val_top5_acc: 0.9255 - val_macro_f1score: 0.4899\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","350/350 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9719 - top5_acc: 0.9995 - macro_f1score: 0.6972\n","Epoch 00036: val_loss did not improve from 1.14901\n","\n","Epoch 00036: val_accuracy did not improve from 0.71374\n","350/350 [==============================] - 596s 2s/step - loss: 0.1072 - accuracy: 0.9719 - top5_acc: 0.9995 - macro_f1score: 0.6972 - val_loss: 1.1528 - val_accuracy: 0.7093 - val_top5_acc: 0.9299 - val_macro_f1score: 0.4930\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","350/350 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9730 - top5_acc: 0.9994 - macro_f1score: 0.6965\n","Epoch 00037: val_loss improved from 1.14901 to 1.13696, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/037.h5\n","\n","Epoch 00037: val_accuracy improved from 0.71374 to 0.71575, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/037.h5\n","350/350 [==============================] - 599s 2s/step - loss: 0.1036 - accuracy: 0.9730 - top5_acc: 0.9994 - macro_f1score: 0.6965 - val_loss: 1.1370 - val_accuracy: 0.7157 - val_top5_acc: 0.9275 - val_macro_f1score: 0.5000\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9756 - top5_acc: 0.9995 - macro_f1score: 0.7008\n","Epoch 00038: val_loss did not improve from 1.13696\n","\n","Epoch 00038: val_accuracy did not improve from 0.71575\n","350/350 [==============================] - 595s 2s/step - loss: 0.0980 - accuracy: 0.9756 - top5_acc: 0.9995 - macro_f1score: 0.7008 - val_loss: 1.1467 - val_accuracy: 0.7155 - val_top5_acc: 0.9269 - val_macro_f1score: 0.4878\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9772 - top5_acc: 0.9996 - macro_f1score: 0.7025\n","Epoch 00039: val_loss did not improve from 1.13696\n","\n","Epoch 00039: val_accuracy did not improve from 0.71575\n","350/350 [==============================] - 599s 2s/step - loss: 0.0932 - accuracy: 0.9772 - top5_acc: 0.9996 - macro_f1score: 0.7025 - val_loss: 1.1505 - val_accuracy: 0.7147 - val_top5_acc: 0.9241 - val_macro_f1score: 0.4903\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9786 - top5_acc: 0.9997 - macro_f1score: 0.7050\n","Epoch 00040: val_loss did not improve from 1.13696\n","\n","Epoch 00040: val_accuracy did not improve from 0.71575\n","350/350 [==============================] - 596s 2s/step - loss: 0.0906 - accuracy: 0.9786 - top5_acc: 0.9997 - macro_f1score: 0.7050 - val_loss: 1.1636 - val_accuracy: 0.7093 - val_top5_acc: 0.9251 - val_macro_f1score: 0.4889\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9811 - top5_acc: 0.9996 - macro_f1score: 0.7060\n","Epoch 00041: val_loss did not improve from 1.13696\n","\n","Epoch 00041: val_accuracy did not improve from 0.71575\n","350/350 [==============================] - 597s 2s/step - loss: 0.0835 - accuracy: 0.9811 - top5_acc: 0.9996 - macro_f1score: 0.7060 - val_loss: 1.1462 - val_accuracy: 0.7131 - val_top5_acc: 0.9243 - val_macro_f1score: 0.4965\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.9812 - top5_acc: 0.9998 - macro_f1score: 0.7089\n","Epoch 00042: val_loss did not improve from 1.13696\n","\n","Epoch 00042: val_accuracy improved from 0.71575 to 0.71815, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/042.h5\n","350/350 [==============================] - 599s 2s/step - loss: 0.0813 - accuracy: 0.9812 - top5_acc: 0.9998 - macro_f1score: 0.7089 - val_loss: 1.1482 - val_accuracy: 0.7181 - val_top5_acc: 0.9269 - val_macro_f1score: 0.4922\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9819 - top5_acc: 0.9997 - macro_f1score: 0.7092\n","Epoch 00043: val_loss did not improve from 1.13696\n","\n","Epoch 00043: val_accuracy did not improve from 0.71815\n","350/350 [==============================] - 596s 2s/step - loss: 0.0815 - accuracy: 0.9819 - top5_acc: 0.9997 - macro_f1score: 0.7092 - val_loss: 1.1618 - val_accuracy: 0.7089 - val_top5_acc: 0.9235 - val_macro_f1score: 0.4842\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9844 - top5_acc: 0.9998 - macro_f1score: 0.7100\n","Epoch 00044: val_loss did not improve from 1.13696\n","\n","Epoch 00044: val_accuracy improved from 0.71815 to 0.71875, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/044.h5\n","350/350 [==============================] - 598s 2s/step - loss: 0.0748 - accuracy: 0.9844 - top5_acc: 0.9998 - macro_f1score: 0.7100 - val_loss: 1.1403 - val_accuracy: 0.7188 - val_top5_acc: 0.9287 - val_macro_f1score: 0.5018\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9835 - top5_acc: 0.9998 - macro_f1score: 0.7090\n","Epoch 00045: val_loss did not improve from 1.13696\n","\n","Epoch 00045: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 597s 2s/step - loss: 0.0756 - accuracy: 0.9835 - top5_acc: 0.9998 - macro_f1score: 0.7090 - val_loss: 1.1596 - val_accuracy: 0.7177 - val_top5_acc: 0.9245 - val_macro_f1score: 0.4907\n","Learning rate:  0.0001\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 46/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9848 - top5_acc: 0.9998 - macro_f1score: 0.7128\n","Epoch 00046: val_loss did not improve from 1.13696\n","\n","Epoch 00046: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 600s 2s/step - loss: 0.0710 - accuracy: 0.9848 - top5_acc: 0.9998 - macro_f1score: 0.7128 - val_loss: 1.1770 - val_accuracy: 0.7119 - val_top5_acc: 0.9203 - val_macro_f1score: 0.4922\n","Learning rate:  0.0001\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 47/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9839 - top5_acc: 0.9999 - macro_f1score: 0.7074\n","Epoch 00047: val_loss did not improve from 1.13696\n","\n","Epoch 00047: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 596s 2s/step - loss: 0.0763 - accuracy: 0.9839 - top5_acc: 0.9999 - macro_f1score: 0.7074 - val_loss: 1.1991 - val_accuracy: 0.7041 - val_top5_acc: 0.9173 - val_macro_f1score: 0.4880\n","Learning rate:  0.0001\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 48/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9865 - top5_acc: 0.9999 - macro_f1score: 0.7100\n","Epoch 00048: val_loss did not improve from 1.13696\n","\n","Epoch 00048: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 593s 2s/step - loss: 0.0666 - accuracy: 0.9865 - top5_acc: 0.9999 - macro_f1score: 0.7100 - val_loss: 1.2207 - val_accuracy: 0.7085 - val_top5_acc: 0.9187 - val_macro_f1score: 0.4841\n","Learning rate:  0.0001\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 49/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9877 - top5_acc: 1.0000 - macro_f1score: 0.7156\n","Epoch 00049: val_loss did not improve from 1.13696\n","\n","Epoch 00049: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 594s 2s/step - loss: 0.0647 - accuracy: 0.9877 - top5_acc: 1.0000 - macro_f1score: 0.7156 - val_loss: 1.1594 - val_accuracy: 0.7149 - val_top5_acc: 0.9223 - val_macro_f1score: 0.4896\n","Learning rate:  0.0001\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 50/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9862 - top5_acc: 0.9999 - macro_f1score: 0.7130\n","Epoch 00050: val_loss did not improve from 1.13696\n","\n","Epoch 00050: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 593s 2s/step - loss: 0.0658 - accuracy: 0.9862 - top5_acc: 0.9999 - macro_f1score: 0.7130 - val_loss: 1.2202 - val_accuracy: 0.7101 - val_top5_acc: 0.9219 - val_macro_f1score: 0.4923\n","Learning rate:  0.0001\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 51/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9855 - top5_acc: 0.9999 - macro_f1score: 0.7083\n","Epoch 00051: val_loss did not improve from 1.13696\n","\n","Epoch 00051: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 595s 2s/step - loss: 0.0681 - accuracy: 0.9855 - top5_acc: 0.9999 - macro_f1score: 0.7083 - val_loss: 1.1838 - val_accuracy: 0.7101 - val_top5_acc: 0.9211 - val_macro_f1score: 0.4853\n","Learning rate:  0.0001\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 52/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9864 - top5_acc: 0.9998 - macro_f1score: 0.7094\n","Epoch 00052: val_loss did not improve from 1.13696\n","\n","Epoch 00052: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 594s 2s/step - loss: 0.0668 - accuracy: 0.9864 - top5_acc: 0.9998 - macro_f1score: 0.7094 - val_loss: 1.2384 - val_accuracy: 0.6999 - val_top5_acc: 0.9129 - val_macro_f1score: 0.4853\n","Learning rate:  0.0001\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 53/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9853 - top5_acc: 0.9998 - macro_f1score: 0.7119\n","Epoch 00053: val_loss did not improve from 1.13696\n","\n","Epoch 00053: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 594s 2s/step - loss: 0.0677 - accuracy: 0.9853 - top5_acc: 0.9998 - macro_f1score: 0.7119 - val_loss: 1.2404 - val_accuracy: 0.7037 - val_top5_acc: 0.9159 - val_macro_f1score: 0.4843\n","Learning rate:  0.0001\n","\n","Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 54/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9865 - top5_acc: 0.9999 - macro_f1score: 0.7142\n","Epoch 00054: val_loss did not improve from 1.13696\n","\n","Epoch 00054: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 593s 2s/step - loss: 0.0648 - accuracy: 0.9865 - top5_acc: 0.9999 - macro_f1score: 0.7142 - val_loss: 1.2455 - val_accuracy: 0.7029 - val_top5_acc: 0.9115 - val_macro_f1score: 0.4771\n","Learning rate:  0.0001\n","\n","Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 55/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9860 - top5_acc: 0.9999 - macro_f1score: 0.7122\n","Epoch 00055: val_loss did not improve from 1.13696\n","\n","Epoch 00055: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 595s 2s/step - loss: 0.0664 - accuracy: 0.9860 - top5_acc: 0.9999 - macro_f1score: 0.7122 - val_loss: 1.2104 - val_accuracy: 0.7101 - val_top5_acc: 0.9159 - val_macro_f1score: 0.4894\n","Learning rate:  0.0001\n","\n","Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 56/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9860 - top5_acc: 0.9998 - macro_f1score: 0.7104\n","Epoch 00056: val_loss did not improve from 1.13696\n","\n","Epoch 00056: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 597s 2s/step - loss: 0.0661 - accuracy: 0.9860 - top5_acc: 0.9998 - macro_f1score: 0.7104 - val_loss: 1.2343 - val_accuracy: 0.7097 - val_top5_acc: 0.9175 - val_macro_f1score: 0.4952\n","Learning rate:  0.0001\n","\n","Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 57/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9854 - top5_acc: 0.9999 - macro_f1score: 0.7118\n","Epoch 00057: val_loss did not improve from 1.13696\n","\n","Epoch 00057: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 594s 2s/step - loss: 0.0658 - accuracy: 0.9854 - top5_acc: 0.9999 - macro_f1score: 0.7118 - val_loss: 1.2344 - val_accuracy: 0.6961 - val_top5_acc: 0.9163 - val_macro_f1score: 0.4834\n","Learning rate:  0.0001\n","\n","Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 58/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9860 - top5_acc: 0.9999 - macro_f1score: 0.7104\n","Epoch 00058: val_loss did not improve from 1.13696\n","\n","Epoch 00058: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 593s 2s/step - loss: 0.0652 - accuracy: 0.9860 - top5_acc: 0.9999 - macro_f1score: 0.7104 - val_loss: 1.2603 - val_accuracy: 0.7071 - val_top5_acc: 0.9159 - val_macro_f1score: 0.4902\n","Learning rate:  0.0001\n","\n","Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 59/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9845 - top5_acc: 0.9998 - macro_f1score: 0.7099\n","Epoch 00059: val_loss did not improve from 1.13696\n","\n","Epoch 00059: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 595s 2s/step - loss: 0.0685 - accuracy: 0.9845 - top5_acc: 0.9998 - macro_f1score: 0.7099 - val_loss: 1.2580 - val_accuracy: 0.6963 - val_top5_acc: 0.9145 - val_macro_f1score: 0.4765\n","Learning rate:  0.0001\n","\n","Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 60/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9852 - top5_acc: 1.0000 - macro_f1score: 0.7114\n","Epoch 00060: val_loss did not improve from 1.13696\n","\n","Epoch 00060: val_accuracy did not improve from 0.71875\n","350/350 [==============================] - 596s 2s/step - loss: 0.0685 - accuracy: 0.9852 - top5_acc: 1.0000 - macro_f1score: 0.7114 - val_loss: 1.2239 - val_accuracy: 0.7035 - val_top5_acc: 0.9169 - val_macro_f1score: 0.4897\n","Learning rate:  1e-05\n","\n","Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 61/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9938 - top5_acc: 1.0000 - macro_f1score: 0.7163\n","Epoch 00061: val_loss improved from 1.13696 to 1.08985, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/061.h5\n","\n","Epoch 00061: val_accuracy improved from 0.71875 to 0.72636, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/061.h5\n","350/350 [==============================] - 597s 2s/step - loss: 0.0396 - accuracy: 0.9938 - top5_acc: 1.0000 - macro_f1score: 0.7163 - val_loss: 1.0899 - val_accuracy: 0.7264 - val_top5_acc: 0.9271 - val_macro_f1score: 0.5016\n","Learning rate:  1e-05\n","\n","Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 62/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9966 - top5_acc: 1.0000 - macro_f1score: 0.7193\n","Epoch 00062: val_loss improved from 1.08985 to 1.07058, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/062.h5\n","\n","Epoch 00062: val_accuracy improved from 0.72636 to 0.72676, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/062.h5\n","350/350 [==============================] - 602s 2s/step - loss: 0.0329 - accuracy: 0.9966 - top5_acc: 1.0000 - macro_f1score: 0.7193 - val_loss: 1.0706 - val_accuracy: 0.7268 - val_top5_acc: 0.9283 - val_macro_f1score: 0.5001\n","Learning rate:  1e-05\n","\n","Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 63/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9967 - top5_acc: 1.0000 - macro_f1score: 0.7222\n","Epoch 00063: val_loss improved from 1.07058 to 1.05140, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/063.h5\n","\n","Epoch 00063: val_accuracy improved from 0.72676 to 0.73037, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/063.h5\n","350/350 [==============================] - 602s 2s/step - loss: 0.0322 - accuracy: 0.9967 - top5_acc: 1.0000 - macro_f1score: 0.7222 - val_loss: 1.0514 - val_accuracy: 0.7304 - val_top5_acc: 0.9287 - val_macro_f1score: 0.5010\n","Learning rate:  1e-05\n","\n","Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 64/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9976 - top5_acc: 1.0000 - macro_f1score: 0.7247\n","Epoch 00064: val_loss improved from 1.05140 to 1.04474, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/064.h5\n","\n","Epoch 00064: val_accuracy did not improve from 0.73037\n","350/350 [==============================] - 597s 2s/step - loss: 0.0327 - accuracy: 0.9976 - top5_acc: 1.0000 - macro_f1score: 0.7247 - val_loss: 1.0447 - val_accuracy: 0.7270 - val_top5_acc: 0.9291 - val_macro_f1score: 0.5000\n","Learning rate:  1e-05\n","\n","Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 65/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.7219\n","Epoch 00065: val_loss improved from 1.04474 to 1.02137, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/065.h5\n","\n","Epoch 00065: val_accuracy improved from 0.73037 to 0.73117, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/065.h5\n","350/350 [==============================] - 596s 2s/step - loss: 0.0333 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.7219 - val_loss: 1.0214 - val_accuracy: 0.7312 - val_top5_acc: 0.9309 - val_macro_f1score: 0.4993\n","Learning rate:  1e-05\n","\n","Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 66/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.7215\n","Epoch 00066: val_loss did not improve from 1.02137\n","\n","Epoch 00066: val_accuracy improved from 0.73117 to 0.73137, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/066.h5\n","350/350 [==============================] - 593s 2s/step - loss: 0.0343 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.7215 - val_loss: 1.0231 - val_accuracy: 0.7314 - val_top5_acc: 0.9307 - val_macro_f1score: 0.4980\n","Learning rate:  1e-05\n","\n","Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 67/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.7186\n","Epoch 00067: val_loss improved from 1.02137 to 1.01324, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/067.h5\n","\n","Epoch 00067: val_accuracy did not improve from 0.73137\n","350/350 [==============================] - 595s 2s/step - loss: 0.0357 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.7186 - val_loss: 1.0132 - val_accuracy: 0.7300 - val_top5_acc: 0.9285 - val_macro_f1score: 0.4933\n","Learning rate:  1e-05\n","\n","Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 68/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9978 - top5_acc: 1.0000 - macro_f1score: 0.7231\n","Epoch 00068: val_loss improved from 1.01324 to 1.00612, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/068.h5\n","\n","Epoch 00068: val_accuracy improved from 0.73137 to 0.73277, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/068.h5\n","350/350 [==============================] - 600s 2s/step - loss: 0.0374 - accuracy: 0.9978 - top5_acc: 1.0000 - macro_f1score: 0.7231 - val_loss: 1.0061 - val_accuracy: 0.7328 - val_top5_acc: 0.9295 - val_macro_f1score: 0.5001\n","Learning rate:  1e-05\n","\n","Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 69/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.7251\n","Epoch 00069: val_loss did not improve from 1.00612\n","\n","Epoch 00069: val_accuracy improved from 0.73277 to 0.73297, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/069.h5\n","350/350 [==============================] - 598s 2s/step - loss: 0.0396 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.7251 - val_loss: 1.0109 - val_accuracy: 0.7330 - val_top5_acc: 0.9279 - val_macro_f1score: 0.4973\n","Learning rate:  1e-05\n","\n","Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 70/70\n","350/350 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.7231\n","Epoch 00070: val_loss improved from 1.00612 to 1.00253, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/ResNet50/070.h5\n","\n","Epoch 00070: val_accuracy did not improve from 0.73297\n","350/350 [==============================] - 594s 2s/step - loss: 0.0412 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.7231 - val_loss: 1.0025 - val_accuracy: 0.7328 - val_top5_acc: 0.9291 - val_macro_f1score: 0.4964\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6J7qM483RMST"},"source":["### 2) ResNet50 Evaluate"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"zg1v-zqzRMSU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd13474a-c0ae-4fd4-eafe-e5a2ad494b54"},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["38/78 [=============>................] - ETA: 47:00 - loss: 1.0246 - accuracy: 0.7303 - top5_acc: 0.9231 - macro_f1score: 0.4963"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mWbV6MR0RMSY"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_HOf2qVRMSe"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DLCKPSirRMSi"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'ResNet50.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWoU3mT7RMSn"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yovtXW4cRMSs"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IA98syIrYvyu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VbbJBDDQKVwJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0z6BwcAulnw","executionInfo":{"status":"ok","timestamp":1606103063739,"user_tz":-540,"elapsed":1464,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / ResNet50"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c","executionInfo":{"status":"ok","timestamp":1606103065170,"user_tz":-540,"elapsed":2882,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak","executionInfo":{"status":"ok","timestamp":1606103065174,"user_tz":-540,"elapsed":2876,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pFcw51AuDG4","executionInfo":{"status":"ok","timestamp":1606103074322,"user_tz":-540,"elapsed":12020,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["model=load_model(os.path.join(dir,'model_output',number,'ResNet50','070.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWlrnY9EuDG-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606108247589,"user_tz":-540,"elapsed":5185275,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"c8f5a0b7-84c9-420a-fda0-5fcd6c775f72"},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["78/78 [==============================] - 5084s 65s/step - loss: 1.0230 - accuracy: 0.7323 - top5_acc: 0.9248 - macro_f1score: 0.4973\n","[Test Loss: 1.0230 /  Test Top-1 Accuracy: 0.7323 / Test Top-5 Accuracy: 0.9248 / Test Macro f1: 0.4973]\n","\n"],"name":"stdout"}]}]}
