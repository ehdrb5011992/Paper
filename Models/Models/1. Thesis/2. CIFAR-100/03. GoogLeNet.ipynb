{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"3.GoogLeNet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [GoogLeNet]"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original GoogLeNet\n","```\n","1) Support Functions\n","2) Almost Original GoogLeNet\n","3) GoogLeNet Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606277651344,"user_tz":-540,"elapsed":51749,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"edba79a7-e090-42cc-a6ca-0761e7d41903"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606277651345,"user_tz":-540,"elapsed":51740,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"9094ecf5-8f76-4706-e7cf-a9c4353391ac"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HxNdfTtNwd9J"},"source":["from f1score import macro_f1score,weighted_f1score\n","from pool_helper import PoolHelper\n","from lrn import LRN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D\n","from tensorflow.keras.layers import add\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606277653857,"user_tz":-540,"elapsed":54239,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"8d850af8-35fe-4a95-c7a9-589b38040fc5"},"source":["os.getcwd()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"aeqQ6tagEcQi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606277660807,"user_tz":-540,"elapsed":61181,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"dc542b51-fb52-4315-cf33-c8d3c425d226"},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dskXxmkc_-fK","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606277661191,"user_tz":-540,"elapsed":61556,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"f929dae9-a342-480d-d471-2d004a935bdf"},"source":["tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"joOrR4FOMkja","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606277661192,"user_tz":-540,"elapsed":61550,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"3828434f-586e-4963-8877-a6cc1f371785"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 10026369010924853400\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 7284184234401271008\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 6443141084603106703\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15473775744\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 15952631103370002498\n","physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"UJMl9X9C3H1h"},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CIFAR100'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 224\n","super_size = 256\n","input_sizes = (size,size,3)\n","batch_sizes = 128\n","weight_decay = 1e-4\n","epochs = 70"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6"},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tW0qQsvKnGTG"},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM"},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g_JGvoqtnGTM"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"a6Ht6oZinGTM"},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf"},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kRUFnlHG8dQ0"},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FBTMwbyuJq1A"},"source":["# 매우 간단하다.\n","\n","#1. train data\n","\n","def generate_train_for_three(crop_length=size, batch_sizes = batch_sizes, super_size=super_size):\n","\n","      batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical')\n","\n","      while True:\n","          batch_x, batch_y = next(batches)\n","          batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","          for i in range(batch_x.shape[0]):\n","              batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","          yield batch_crops, [batch_y,batch_y,batch_y]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oh3RCAUaJq1E"},"source":["# 2. valid data\n","\n","def generate_valid_for_three(size=size, batch_sizes = batch_sizes):\n","\n","      batches_xy = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical')\n","\n","      while True:\n","\n","          batch_xy = batches_xy.next()\n","          yield  batch_xy[0], [ batch_xy[1],batch_xy[1],batch_xy[1] ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5IuLwjb-Jq1H"},"source":["# 3. test data\n","\n","def generate_test_for_three(size=size, batch_sizes = batch_sizes):\n","\n","      batches_xy = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical')\n","\n","      while True:\n","\n","          batch_xy = batches_xy.next()\n","          yield  batch_xy[0], [ batch_xy[1],batch_xy[1],batch_xy[1] ] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QLPktMPZJq1J"},"source":["# 위에서 쓰임\n","# train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","# train_generator= crop_generator(train_batches, size)\n","\n","# valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","# test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original GoogLeNet\n","---"]},{"cell_type":"markdown","metadata":{"id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 3e-4\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JcsJNpFIEPSR"},"source":["### 3) Almost Original GoogLeNet"]},{"cell_type":"code","metadata":{"id":"RQQSvuzfUBlZ"},"source":["# GoogLeNet를 최대한 논문에 가깝게 맞춰 모형작성.\n","\n","def googlenet(input_shape=(224,224,3), classes=1000, weight_decay = weight_decay, weights_path = None,name='Inception_v1'):\n","\n","    input = Input(input_shape)\n","\n","    conv1_7x7_s2 = Conv2D(64, (7,7), strides=(2,2), padding='same', activation='relu', name='conv1/7x7_s2', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(input)\n","    pool1_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same', name='pool1/3x3_s2')(conv1_7x7_s2)\n","    pool1_norm1 = LRN(name='pool1/norm1')(pool1_3x3_s2)\n","\n","    conv2_3x3_reduce = Conv2D(64, (1,1), padding='same', activation='relu', name='conv2/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool1_norm1)\n","    conv2_3x3 = Conv2D(192, (3,3), padding='same', activation='relu', name='conv2/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(conv2_3x3_reduce)\n","    conv2_norm2 = LRN(name='conv2/norm2')(conv2_3x3)\n","    pool2_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same', name='pool2/3x3_s2')(conv2_norm2)\n","\n","    inception_3a_1x1 = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_3a/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool2_3x3_s2)\n","    inception_3a_3x3_reduce = Conv2D(96, (1,1), padding='same', activation='relu', name='inception_3a/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool2_3x3_s2)\n","    inception_3a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3_reduce)\n","    inception_3a_3x3 = Conv2D(128, (3,3), padding='valid', activation='relu', name='inception_3a/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_3x3_pad)\n","    inception_3a_5x5_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_3a/5x5_reduce', kernel_regularizer=l2(weight_decay))(pool2_3x3_s2)\n","    inception_3a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5_reduce)\n","    inception_3a_5x5 = Conv2D(32, (5,5), padding='valid', activation='relu', name='inception_3a/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_5x5_pad)\n","    inception_3a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3a/pool')(pool2_3x3_s2)\n","    inception_3a_pool_proj = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_3a/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_pool)\n","    inception_3a_output = Concatenate(axis=-1, name='inception_3a/output')([inception_3a_1x1,inception_3a_3x3,inception_3a_5x5,inception_3a_pool_proj])\n","    # Concatenate axis 수정.\n","\n","    inception_3b_1x1 = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_3b/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_output)\n","    inception_3b_3x3_reduce = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_3b/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_output)\n","    inception_3b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3_reduce)\n","    inception_3b_3x3 = Conv2D(192, (3,3), padding='valid', activation='relu', name='inception_3b/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3b_3x3_pad)\n","    inception_3b_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_3b/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3a_output)\n","    inception_3b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5_reduce)\n","    inception_3b_5x5 = Conv2D(96, (5,5), padding='valid', activation='relu', name='inception_3b/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3b_5x5_pad)\n","    inception_3b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3b/pool')(inception_3a_output)\n","    inception_3b_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_3b/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_3b_pool)\n","    inception_3b_output = Concatenate(axis=-1, name='inception_3b/output')([inception_3b_1x1,inception_3b_3x3,inception_3b_5x5,inception_3b_pool_proj])\n","\n","    pool3_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same', name='pool3/3x3_s2')(inception_3b_output)\n","\n","    inception_4a_1x1 = Conv2D(192, (1,1), padding='same', activation='relu', name='inception_4a/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool3_3x3_s2)\n","    inception_4a_3x3_reduce = Conv2D(96, (1,1), padding='same', activation='relu', name='inception_4a/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool3_3x3_s2)\n","    inception_4a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4a_3x3_reduce)\n","    inception_4a_3x3 = Conv2D(208, (3,3), padding='valid', activation='relu', name='inception_4a/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_3x3_pad)\n","    inception_4a_5x5_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4a/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool3_3x3_s2)\n","    inception_4a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4a_5x5_reduce)\n","    inception_4a_5x5 = Conv2D(48, (5,5), padding='valid', activation='relu', name='inception_4a/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_5x5_pad)\n","    inception_4a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4a/pool')(pool3_3x3_s2)\n","    inception_4a_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4a/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_pool)\n","    inception_4a_output = Concatenate(axis=-1, name='inception_4a/output')([inception_4a_1x1,inception_4a_3x3,inception_4a_5x5,inception_4a_pool_proj])\n","\n","    loss1_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss1/ave_pool')(inception_4a_output)\n","    loss1_conv = Conv2D(128, (1,1), padding='same', activation='relu', name='loss1/conv', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(loss1_ave_pool)\n","    loss1_flat = Flatten()(loss1_conv)\n","    loss1_fc = Dense(1024, activation='relu', name='loss1/fc', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(loss1_flat)\n","    loss1_drop_fc = Dropout(rate=0.7)(loss1_fc)\n","    loss1_classifier = Dense(classes, activation='softmax', kernel_regularizer=l2(weight_decay), name='loss1/classifier')(loss1_drop_fc)\n","\n","    inception_4b_1x1 = Conv2D(160, (1,1), padding='same', activation='relu', name='inception_4b/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_output)\n","    inception_4b_3x3_reduce = Conv2D(112, (1,1), padding='same', activation='relu', name='inception_4b/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_output)\n","    inception_4b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4b_3x3_reduce)\n","    inception_4b_3x3 = Conv2D(224, (3,3), padding='valid', activation='relu', name='inception_4b/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_3x3_pad)\n","    inception_4b_5x5_reduce = Conv2D(24, (1,1), padding='same', activation='relu', name='inception_4b/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4a_output)\n","    inception_4b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4b_5x5_reduce)\n","    inception_4b_5x5 = Conv2D(64, (5,5), padding='valid', activation='relu', name='inception_4b/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_5x5_pad)\n","    inception_4b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4b/pool')(inception_4a_output)\n","    inception_4b_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4b/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_pool)\n","    inception_4b_output = Concatenate(axis=-1, name='inception_4b/output')([inception_4b_1x1,inception_4b_3x3,inception_4b_5x5,inception_4b_pool_proj])\n","\n","    inception_4c_1x1 = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_4c/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_output)\n","    inception_4c_3x3_reduce = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_4c/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_output)\n","    inception_4c_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4c_3x3_reduce)\n","    inception_4c_3x3 = Conv2D(256, (3,3), padding='valid', activation='relu', name='inception_4c/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_3x3_pad)\n","    inception_4c_5x5_reduce = Conv2D(24, (1,1), padding='same', activation='relu', name='inception_4c/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4b_output)\n","    inception_4c_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4c_5x5_reduce)\n","    inception_4c_5x5 = Conv2D(64, (5,5), padding='valid', activation='relu', name='inception_4c/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_5x5_pad)\n","    inception_4c_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4c/pool')(inception_4b_output)\n","    inception_4c_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4c/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_pool)\n","    inception_4c_output = Concatenate(axis=-1, name='inception_4c/output')([inception_4c_1x1,inception_4c_3x3,inception_4c_5x5,inception_4c_pool_proj])\n","\n","    inception_4d_1x1 = Conv2D(112, (1,1), padding='same', activation='relu', name='inception_4d/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_output)\n","    inception_4d_3x3_reduce = Conv2D(144, (1,1), padding='same', activation='relu', name='inception_4d/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_output)\n","    inception_4d_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4d_3x3_reduce)\n","    inception_4d_3x3 = Conv2D(288, (3,3), padding='valid', activation='relu', name='inception_4d/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_3x3_pad)\n","    inception_4d_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_4d/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4c_output)\n","    inception_4d_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4d_5x5_reduce)\n","    inception_4d_5x5 = Conv2D(64, (5,5), padding='valid', activation='relu', name='inception_4d/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_5x5_pad)\n","    inception_4d_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4d/pool')(inception_4c_output)\n","    inception_4d_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4d/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_pool)\n","    inception_4d_output = Concatenate(axis=-1, name='inception_4d/output')([inception_4d_1x1,inception_4d_3x3,inception_4d_5x5,inception_4d_pool_proj])\n","\n","    loss2_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss2/ave_pool')(inception_4d_output)\n","    loss2_conv = Conv2D(128, (1,1), padding='same', activation='relu', name='loss2/conv', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(loss2_ave_pool)\n","    loss2_flat = Flatten()(loss2_conv)\n","    loss2_fc = Dense(1024, activation='relu', name='loss2/fc', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(loss2_flat)\n","    loss2_drop_fc = Dropout(rate=0.7)(loss2_fc)\n","    loss2_classifier = Dense(classes, activation='softmax', kernel_regularizer=l2(weight_decay), name='loss2/classifier')(loss2_drop_fc)\n","\n","    inception_4e_1x1 = Conv2D(256, (1,1), padding='same', activation='relu', name='inception_4e/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_output)\n","    inception_4e_3x3_reduce = Conv2D(160, (1,1), padding='same', activation='relu', name='inception_4e/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_output)\n","    inception_4e_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_3x3_reduce)\n","    inception_4e_3x3 = Conv2D(320, (3,3), padding='valid', activation='relu', name='inception_4e/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4e_3x3_pad)\n","    inception_4e_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_4e/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4d_output)\n","    inception_4e_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4e_5x5_reduce)\n","    inception_4e_5x5 = Conv2D(128, (5,5), padding='valid', activation='relu', name='inception_4e/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4e_5x5_pad)\n","    inception_4e_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4e/pool')(inception_4d_output)\n","    inception_4e_pool_proj = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_4e/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_4e_pool)\n","    inception_4e_output = Concatenate(axis=-1, name='inception_4e/output')([inception_4e_1x1,inception_4e_3x3,inception_4e_5x5,inception_4e_pool_proj])\n","\n","    pool4_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same', name='pool4/3x3_s2')(inception_4e_output)\n","\n","    inception_5a_1x1 = Conv2D(256, (1,1), padding='same', activation='relu', name='inception_5a/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool4_3x3_s2)\n","    inception_5a_3x3_reduce = Conv2D(160, (1,1), padding='same', activation='relu', name='inception_5a/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool4_3x3_s2)\n","    inception_5a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5a_3x3_reduce)\n","    inception_5a_3x3 = Conv2D(320, (3,3), padding='valid', activation='relu', name='inception_5a/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_3x3_pad)\n","    inception_5a_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_5a/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(pool4_3x3_s2)\n","    inception_5a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5a_5x5_reduce)\n","    inception_5a_5x5 = Conv2D(128, (5,5), padding='valid', activation='relu', name='inception_5a/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_5x5_pad)\n","    inception_5a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5a/pool')(pool4_3x3_s2)\n","    inception_5a_pool_proj = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_5a/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_pool)\n","    inception_5a_output = Concatenate(axis=-1, name='inception_5a/output')([inception_5a_1x1,inception_5a_3x3,inception_5a_5x5,inception_5a_pool_proj])\n","\n","    inception_5b_1x1 = Conv2D(384, (1,1), padding='same', activation='relu', name='inception_5b/1x1', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_output)\n","    inception_5b_3x3_reduce = Conv2D(192, (1,1), padding='same', activation='relu', name='inception_5b/3x3_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_output)\n","    inception_5b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5b_3x3_reduce)\n","    inception_5b_3x3 = Conv2D(384, (3,3), padding='valid', activation='relu', name='inception_5b/3x3', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5b_3x3_pad)\n","    inception_5b_5x5_reduce = Conv2D(48, (1,1), padding='same', activation='relu', name='inception_5b/5x5_reduce', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5a_output)\n","    inception_5b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5b_5x5_reduce)\n","    inception_5b_5x5 = Conv2D(128, (5,5), padding='valid', activation='relu', name='inception_5b/5x5', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5b_5x5_pad)\n","    inception_5b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5b/pool')(inception_5a_output)\n","    inception_5b_pool_proj = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_5b/pool_proj', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(inception_5b_pool)\n","    inception_5b_output = Concatenate(axis=-1, name='inception_5b/output')([inception_5b_1x1,inception_5b_3x3,inception_5b_5x5,inception_5b_pool_proj])\n","\n","    pool5_7x7_s1 = AveragePooling2D(pool_size=(7,7), strides=(1,1), name='pool5/7x7_s2')(inception_5b_output)\n","\n","    loss3_flat = Flatten()(pool5_7x7_s1)\n","    pool5_drop_7x7_s1 = Dropout(rate=0.4)(loss3_flat)\n","    loss3_classifier = Dense(classes, activation='softmax', kernel_regularizer=l2(weight_decay), name='loss3/classifier')(pool5_drop_7x7_s1)\n","\n","    googlenet = Model(inputs=input, outputs=[loss1_classifier,loss2_classifier,loss3_classifier],name=name)\n","\n","    if weights_path:\n","        googlenet.load_weights(weights_path)\n","\n","    return googlenet\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"te4pinumUBle","scrolled":true},"source":["model = googlenet(input_shape=input_sizes, classes=classes, name='GoogleNet')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vmeG8i1uwd-I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606132004585,"user_tz":-540,"elapsed":45739,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"44ca2c07-0b5f-4472-953a-0d70d1aa5e04"},"source":["# auxiliary classifier 2개를 포함하기 때문에, 모수의 개수는 1000만개쯤 된다.\n","# 메인은 670만개 가량의 모수.\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"GoogleNet\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9472        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","pool1/3x3_s2 (MaxPooling2D)     (None, 56, 56, 64)   0           conv1/7x7_s2[0][0]               \n","__________________________________________________________________________________________________\n","pool1/norm1 (LRN)               (None, 56, 56, 64)   0           pool1/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","conv2/3x3_reduce (Conv2D)       (None, 56, 56, 64)   4160        pool1/norm1[0][0]                \n","__________________________________________________________________________________________________\n","conv2/3x3 (Conv2D)              (None, 56, 56, 192)  110784      conv2/3x3_reduce[0][0]           \n","__________________________________________________________________________________________________\n","conv2/norm2 (LRN)               (None, 56, 56, 192)  0           conv2/3x3[0][0]                  \n","__________________________________________________________________________________________________\n","pool2/3x3_s2 (MaxPooling2D)     (None, 28, 28, 192)  0           conv2/norm2[0][0]                \n","__________________________________________________________________________________________________\n","inception_3a/3x3_reduce (Conv2D (None, 28, 28, 96)   18528       pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_3a/5x5_reduce (Conv2D (None, 28, 28, 16)   3088        pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","zero_padding2d (ZeroPadding2D)  (None, 30, 30, 96)   0           inception_3a/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, 32, 32, 16)   0           inception_3a/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_3a/pool (MaxPooling2D (None, 28, 28, 192)  0           pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_3a/1x1 (Conv2D)       (None, 28, 28, 64)   12352       pool2/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_3a/3x3 (Conv2D)       (None, 28, 28, 128)  110720      zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","inception_3a/5x5 (Conv2D)       (None, 28, 28, 32)   12832       zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","inception_3a/pool_proj (Conv2D) (None, 28, 28, 32)   6176        inception_3a/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_3a/output (Concatenat (None, 28, 28, 256)  0           inception_3a/1x1[0][0]           \n","                                                                 inception_3a/3x3[0][0]           \n","                                                                 inception_3a/5x5[0][0]           \n","                                                                 inception_3a/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_3b/3x3_reduce (Conv2D (None, 28, 28, 128)  32896       inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_3b/5x5_reduce (Conv2D (None, 28, 28, 32)   8224        inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_2 (ZeroPadding2D (None, 30, 30, 128)  0           inception_3b/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_3 (ZeroPadding2D (None, 32, 32, 32)   0           inception_3b/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_3b/pool (MaxPooling2D (None, 28, 28, 256)  0           inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_3b/1x1 (Conv2D)       (None, 28, 28, 128)  32896       inception_3a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_3b/3x3 (Conv2D)       (None, 28, 28, 192)  221376      zero_padding2d_2[0][0]           \n","__________________________________________________________________________________________________\n","inception_3b/5x5 (Conv2D)       (None, 28, 28, 96)   76896       zero_padding2d_3[0][0]           \n","__________________________________________________________________________________________________\n","inception_3b/pool_proj (Conv2D) (None, 28, 28, 64)   16448       inception_3b/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_3b/output (Concatenat (None, 28, 28, 480)  0           inception_3b/1x1[0][0]           \n","                                                                 inception_3b/3x3[0][0]           \n","                                                                 inception_3b/5x5[0][0]           \n","                                                                 inception_3b/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","pool3/3x3_s2 (MaxPooling2D)     (None, 14, 14, 480)  0           inception_3b/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4a/3x3_reduce (Conv2D (None, 14, 14, 96)   46176       pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_4a/5x5_reduce (Conv2D (None, 14, 14, 16)   7696        pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","zero_padding2d_4 (ZeroPadding2D (None, 16, 16, 96)   0           inception_4a/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_5 (ZeroPadding2D (None, 18, 18, 16)   0           inception_4a/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4a/pool (MaxPooling2D (None, 14, 14, 480)  0           pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_4a/1x1 (Conv2D)       (None, 14, 14, 192)  92352       pool3/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_4a/3x3 (Conv2D)       (None, 14, 14, 208)  179920      zero_padding2d_4[0][0]           \n","__________________________________________________________________________________________________\n","inception_4a/5x5 (Conv2D)       (None, 14, 14, 48)   19248       zero_padding2d_5[0][0]           \n","__________________________________________________________________________________________________\n","inception_4a/pool_proj (Conv2D) (None, 14, 14, 64)   30784       inception_4a/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4a/output (Concatenat (None, 14, 14, 512)  0           inception_4a/1x1[0][0]           \n","                                                                 inception_4a/3x3[0][0]           \n","                                                                 inception_4a/5x5[0][0]           \n","                                                                 inception_4a/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4b/3x3_reduce (Conv2D (None, 14, 14, 112)  57456       inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4b/5x5_reduce (Conv2D (None, 14, 14, 24)   12312       inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_6 (ZeroPadding2D (None, 16, 16, 112)  0           inception_4b/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_7 (ZeroPadding2D (None, 18, 18, 24)   0           inception_4b/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4b/pool (MaxPooling2D (None, 14, 14, 512)  0           inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4b/1x1 (Conv2D)       (None, 14, 14, 160)  82080       inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4b/3x3 (Conv2D)       (None, 14, 14, 224)  226016      zero_padding2d_6[0][0]           \n","__________________________________________________________________________________________________\n","inception_4b/5x5 (Conv2D)       (None, 14, 14, 64)   38464       zero_padding2d_7[0][0]           \n","__________________________________________________________________________________________________\n","inception_4b/pool_proj (Conv2D) (None, 14, 14, 64)   32832       inception_4b/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4b/output (Concatenat (None, 14, 14, 512)  0           inception_4b/1x1[0][0]           \n","                                                                 inception_4b/3x3[0][0]           \n","                                                                 inception_4b/5x5[0][0]           \n","                                                                 inception_4b/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4c/3x3_reduce (Conv2D (None, 14, 14, 128)  65664       inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4c/5x5_reduce (Conv2D (None, 14, 14, 24)   12312       inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_8 (ZeroPadding2D (None, 16, 16, 128)  0           inception_4c/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_9 (ZeroPadding2D (None, 18, 18, 24)   0           inception_4c/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4c/pool (MaxPooling2D (None, 14, 14, 512)  0           inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4c/1x1 (Conv2D)       (None, 14, 14, 128)  65664       inception_4b/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4c/3x3 (Conv2D)       (None, 14, 14, 256)  295168      zero_padding2d_8[0][0]           \n","__________________________________________________________________________________________________\n","inception_4c/5x5 (Conv2D)       (None, 14, 14, 64)   38464       zero_padding2d_9[0][0]           \n","__________________________________________________________________________________________________\n","inception_4c/pool_proj (Conv2D) (None, 14, 14, 64)   32832       inception_4c/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4c/output (Concatenat (None, 14, 14, 512)  0           inception_4c/1x1[0][0]           \n","                                                                 inception_4c/3x3[0][0]           \n","                                                                 inception_4c/5x5[0][0]           \n","                                                                 inception_4c/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4d/3x3_reduce (Conv2D (None, 14, 14, 144)  73872       inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4d/5x5_reduce (Conv2D (None, 14, 14, 32)   16416       inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_10 (ZeroPadding2 (None, 16, 16, 144)  0           inception_4d/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 32)   0           inception_4d/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4d/pool (MaxPooling2D (None, 14, 14, 512)  0           inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4d/1x1 (Conv2D)       (None, 14, 14, 112)  57456       inception_4c/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4d/3x3 (Conv2D)       (None, 14, 14, 288)  373536      zero_padding2d_10[0][0]          \n","__________________________________________________________________________________________________\n","inception_4d/5x5 (Conv2D)       (None, 14, 14, 64)   51264       zero_padding2d_11[0][0]          \n","__________________________________________________________________________________________________\n","inception_4d/pool_proj (Conv2D) (None, 14, 14, 64)   32832       inception_4d/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4d/output (Concatenat (None, 14, 14, 528)  0           inception_4d/1x1[0][0]           \n","                                                                 inception_4d/3x3[0][0]           \n","                                                                 inception_4d/5x5[0][0]           \n","                                                                 inception_4d/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_4e/3x3_reduce (Conv2D (None, 14, 14, 160)  84640       inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4e/5x5_reduce (Conv2D (None, 14, 14, 32)   16928       inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_12 (ZeroPadding2 (None, 16, 16, 160)  0           inception_4e/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 32)   0           inception_4e/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_4e/pool (MaxPooling2D (None, 14, 14, 528)  0           inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4e/1x1 (Conv2D)       (None, 14, 14, 256)  135424      inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_4e/3x3 (Conv2D)       (None, 14, 14, 320)  461120      zero_padding2d_12[0][0]          \n","__________________________________________________________________________________________________\n","inception_4e/5x5 (Conv2D)       (None, 14, 14, 128)  102528      zero_padding2d_13[0][0]          \n","__________________________________________________________________________________________________\n","inception_4e/pool_proj (Conv2D) (None, 14, 14, 128)  67712       inception_4e/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_4e/output (Concatenat (None, 14, 14, 832)  0           inception_4e/1x1[0][0]           \n","                                                                 inception_4e/3x3[0][0]           \n","                                                                 inception_4e/5x5[0][0]           \n","                                                                 inception_4e/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","pool4/3x3_s2 (MaxPooling2D)     (None, 7, 7, 832)    0           inception_4e/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_5a/3x3_reduce (Conv2D (None, 7, 7, 160)    133280      pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_5a/5x5_reduce (Conv2D (None, 7, 7, 32)     26656       pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","zero_padding2d_14 (ZeroPadding2 (None, 9, 9, 160)    0           inception_5a/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_15 (ZeroPadding2 (None, 11, 11, 32)   0           inception_5a/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_5a/pool (MaxPooling2D (None, 7, 7, 832)    0           pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_5a/1x1 (Conv2D)       (None, 7, 7, 256)    213248      pool4/3x3_s2[0][0]               \n","__________________________________________________________________________________________________\n","inception_5a/3x3 (Conv2D)       (None, 7, 7, 320)    461120      zero_padding2d_14[0][0]          \n","__________________________________________________________________________________________________\n","inception_5a/5x5 (Conv2D)       (None, 7, 7, 128)    102528      zero_padding2d_15[0][0]          \n","__________________________________________________________________________________________________\n","inception_5a/pool_proj (Conv2D) (None, 7, 7, 128)    106624      inception_5a/pool[0][0]          \n","__________________________________________________________________________________________________\n","inception_5a/output (Concatenat (None, 7, 7, 832)    0           inception_5a/1x1[0][0]           \n","                                                                 inception_5a/3x3[0][0]           \n","                                                                 inception_5a/5x5[0][0]           \n","                                                                 inception_5a/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","inception_5b/3x3_reduce (Conv2D (None, 7, 7, 192)    159936      inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_5b/5x5_reduce (Conv2D (None, 7, 7, 48)     39984       inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","zero_padding2d_16 (ZeroPadding2 (None, 9, 9, 192)    0           inception_5b/3x3_reduce[0][0]    \n","__________________________________________________________________________________________________\n","zero_padding2d_17 (ZeroPadding2 (None, 11, 11, 48)   0           inception_5b/5x5_reduce[0][0]    \n","__________________________________________________________________________________________________\n","inception_5b/pool (MaxPooling2D (None, 7, 7, 832)    0           inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","loss1/ave_pool (AveragePooling2 (None, 4, 4, 512)    0           inception_4a/output[0][0]        \n","__________________________________________________________________________________________________\n","loss2/ave_pool (AveragePooling2 (None, 4, 4, 528)    0           inception_4d/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_5b/1x1 (Conv2D)       (None, 7, 7, 384)    319872      inception_5a/output[0][0]        \n","__________________________________________________________________________________________________\n","inception_5b/3x3 (Conv2D)       (None, 7, 7, 384)    663936      zero_padding2d_16[0][0]          \n","__________________________________________________________________________________________________\n","inception_5b/5x5 (Conv2D)       (None, 7, 7, 128)    153728      zero_padding2d_17[0][0]          \n","__________________________________________________________________________________________________\n","inception_5b/pool_proj (Conv2D) (None, 7, 7, 128)    106624      inception_5b/pool[0][0]          \n","__________________________________________________________________________________________________\n","loss1/conv (Conv2D)             (None, 4, 4, 128)    65664       loss1/ave_pool[0][0]             \n","__________________________________________________________________________________________________\n","loss2/conv (Conv2D)             (None, 4, 4, 128)    67712       loss2/ave_pool[0][0]             \n","__________________________________________________________________________________________________\n","inception_5b/output (Concatenat (None, 7, 7, 1024)   0           inception_5b/1x1[0][0]           \n","                                                                 inception_5b/3x3[0][0]           \n","                                                                 inception_5b/5x5[0][0]           \n","                                                                 inception_5b/pool_proj[0][0]     \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 2048)         0           loss1/conv[0][0]                 \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 2048)         0           loss2/conv[0][0]                 \n","__________________________________________________________________________________________________\n","pool5/7x7_s2 (AveragePooling2D) (None, 1, 1, 1024)   0           inception_5b/output[0][0]        \n","__________________________________________________________________________________________________\n","loss1/fc (Dense)                (None, 1024)         2098176     flatten[0][0]                    \n","__________________________________________________________________________________________________\n","loss2/fc (Dense)                (None, 1024)         2098176     flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 1024)         0           pool5/7x7_s2[0][0]               \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 1024)         0           loss1/fc[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           loss2/fc[0][0]                   \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","loss1/classifier (Dense)        (None, 100)          102500      dropout[0][0]                    \n","__________________________________________________________________________________________________\n","loss2/classifier (Dense)        (None, 100)          102500      dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","loss3/classifier (Dense)        (None, 100)          102500      dropout_2[0][0]                  \n","==================================================================================================\n","Total params: 10,610,780\n","Trainable params: 10,610,780\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8_zZtvSY4KCo"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nqg2fSkrdIMr"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2AsMQKJXUfy"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3FCbpFOcmHd"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_loss3/classifier_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]                    \t\n","\n","model.compile(optimizer, loss={'loss1/classifier' : 'categorical_crossentropy', 'loss2/classifier' : 'categorical_crossentropy', 'loss3/classifier' : 'categorical_crossentropy'},\n","              loss_weights={'loss1/classifier' : 0.3, 'loss2/classifier' : 0.3, 'loss3/classifier' : 1.0}, \n","              metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDj1YFknYC-S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606196132709,"user_tz":-540,"elapsed":64173819,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"1f50496e-c5a5-40b7-d59f-cdbb38d78c4e"},"source":["######## flow_from_directory\n","#history = model.fit_generator(generate_train_for_three(), steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = generate_valid_for_three(), epochs=epochs , verbose=1 , callbacks = callbacks_list,validation_steps=int(len(x_valid)/batch_sizes))\n","history = model.fit(generate_train_for_three(), steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = generate_valid_for_three(), epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 44923 images belonging to 100 classes.\n","Learning rate:  0.0003\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 1/70\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for conv1/7x7_s2/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for conv2/3x3_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for conv2/3x3/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3a/3x3_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3a/5x5_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3a/1x1/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3a/3x3/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3a/5x5/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3a/pool_proj/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3b/3x3_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3b/5x5_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3b/1x1/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3b/3x3/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3b/5x5/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_3b/pool_proj/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4a/3x3_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4a/5x5_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4a/1x1/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4a/3x3/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4a/5x5/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4a/pool_proj/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4b/3x3_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4b/5x5_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4b/1x1/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4b/3x3/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4b/5x5/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4b/pool_proj/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4c/3x3_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4c/5x5_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4c/1x1/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4c/3x3/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4c/5x5/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4c/pool_proj/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4d/3x3_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4d/5x5_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4d/1x1/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4d/3x3/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4d/5x5/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4d/pool_proj/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4e/3x3_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4e/5x5_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4e/1x1/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4e/3x3/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4e/5x5/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_4e/pool_proj/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5a/3x3_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5a/5x5_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5a/1x1/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5a/3x3/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5a/5x5/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5a/pool_proj/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5b/3x3_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5b/5x5_reduce/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5b/1x1/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5b/3x3/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5b/5x5/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for inception_5b/pool_proj/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for loss1/conv/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for loss2/conv/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for loss1/fc/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for loss2/fc/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for loss1/classifier/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for loss2/classifier/kernel:0\n","0.0(L1), 5.34522470321675e-06(L2) weight decay set for loss3/classifier/kernel:0\n","350/350 [==============================] - ETA: 0s - loss: 6.7647 - loss1/classifier_loss: 4.2019 - loss2/classifier_loss: 4.2477 - loss3/classifier_loss: 4.2298 - loss1/classifier_accuracy: 0.0615 - loss1/classifier_top5_acc: 0.2084 - loss1/classifier_macro_f1score: 0.0021 - loss2/classifier_accuracy: 0.0550 - loss2/classifier_top5_acc: 0.1898 - loss2/classifier_macro_f1score: 0.0016 - loss3/classifier_accuracy: 0.0510 - loss3/classifier_top5_acc: 0.1865 - loss3/classifier_macro_f1score: 9.4435e-04 Found 5077 images belonging to 100 classes.\n","\n","Epoch 00001: val_loss improved from inf to 6.16833, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/001.h5\n","\n","Epoch 00001: val_loss3/classifier_accuracy improved from -inf to 0.08754, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/001.h5\n","350/350 [==============================] - 18607s 53s/step - loss: 6.7647 - loss1/classifier_loss: 4.2019 - loss2/classifier_loss: 4.2477 - loss3/classifier_loss: 4.2298 - loss1/classifier_accuracy: 0.0615 - loss1/classifier_top5_acc: 0.2084 - loss1/classifier_macro_f1score: 0.0021 - loss2/classifier_accuracy: 0.0550 - loss2/classifier_top5_acc: 0.1898 - loss2/classifier_macro_f1score: 0.0016 - loss3/classifier_accuracy: 0.0510 - loss3/classifier_top5_acc: 0.1865 - loss3/classifier_macro_f1score: 9.4435e-04 - val_loss: 6.1683 - val_loss1/classifier_loss: 3.7227 - val_loss2/classifier_loss: 3.8246 - val_loss3/classifier_loss: 3.9041 - val_loss1/classifier_accuracy: 0.1388 - val_loss1/classifier_top5_acc: 0.3770 - val_loss1/classifier_macro_f1score: 0.0032 - val_loss2/classifier_accuracy: 0.1122 - val_loss2/classifier_top5_acc: 0.3361 - val_loss2/classifier_macro_f1score: 5.5556e-04 - val_loss3/classifier_accuracy: 0.0875 - val_loss3/classifier_top5_acc: 0.2885 - val_loss3/classifier_macro_f1score: 4.8718e-04\n","Learning rate:  0.0003\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 2/70\n","350/350 [==============================] - ETA: 0s - loss: 5.9863 - loss1/classifier_loss: 3.7134 - loss2/classifier_loss: 3.7657 - loss3/classifier_loss: 3.7426 - loss1/classifier_accuracy: 0.1291 - loss1/classifier_top5_acc: 0.3633 - loss1/classifier_macro_f1score: 0.0087 - loss2/classifier_accuracy: 0.1162 - loss2/classifier_top5_acc: 0.3433 - loss2/classifier_macro_f1score: 0.0081 - loss3/classifier_accuracy: 0.1124 - loss3/classifier_top5_acc: 0.3406 - loss3/classifier_macro_f1score: 0.0062\n","Epoch 00002: val_loss improved from 6.16833 to 5.51708, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/002.h5\n","\n","Epoch 00002: val_loss3/classifier_accuracy improved from 0.08754 to 0.15345, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/002.h5\n","350/350 [==============================] - 684s 2s/step - loss: 5.9863 - loss1/classifier_loss: 3.7134 - loss2/classifier_loss: 3.7657 - loss3/classifier_loss: 3.7426 - loss1/classifier_accuracy: 0.1291 - loss1/classifier_top5_acc: 0.3633 - loss1/classifier_macro_f1score: 0.0087 - loss2/classifier_accuracy: 0.1162 - loss2/classifier_top5_acc: 0.3433 - loss2/classifier_macro_f1score: 0.0081 - loss3/classifier_accuracy: 0.1124 - loss3/classifier_top5_acc: 0.3406 - loss3/classifier_macro_f1score: 0.0062 - val_loss: 5.5171 - val_loss1/classifier_loss: 3.3180 - val_loss2/classifier_loss: 3.4123 - val_loss3/classifier_loss: 3.4980 - val_loss1/classifier_accuracy: 0.2055 - val_loss1/classifier_top5_acc: 0.4848 - val_loss1/classifier_macro_f1score: 0.0167 - val_loss2/classifier_accuracy: 0.1801 - val_loss2/classifier_top5_acc: 0.4507 - val_loss2/classifier_macro_f1score: 0.0144 - val_loss3/classifier_accuracy: 0.1534 - val_loss3/classifier_top5_acc: 0.4179 - val_loss3/classifier_macro_f1score: 0.0129\n","Learning rate:  0.0003\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 3/70\n","350/350 [==============================] - ETA: 0s - loss: 5.4834 - loss1/classifier_loss: 3.4191 - loss2/classifier_loss: 3.4641 - loss3/classifier_loss: 3.4184 - loss1/classifier_accuracy: 0.1774 - loss1/classifier_top5_acc: 0.4495 - loss1/classifier_macro_f1score: 0.0216 - loss2/classifier_accuracy: 0.1666 - loss2/classifier_top5_acc: 0.4335 - loss2/classifier_macro_f1score: 0.0200 - loss3/classifier_accuracy: 0.1677 - loss3/classifier_top5_acc: 0.4404 - loss3/classifier_macro_f1score: 0.0190\n","Epoch 00003: val_loss improved from 5.51708 to 5.08455, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/003.h5\n","\n","Epoch 00003: val_loss3/classifier_accuracy improved from 0.15345 to 0.20773, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/003.h5\n","350/350 [==============================] - 688s 2s/step - loss: 5.4834 - loss1/classifier_loss: 3.4191 - loss2/classifier_loss: 3.4641 - loss3/classifier_loss: 3.4184 - loss1/classifier_accuracy: 0.1774 - loss1/classifier_top5_acc: 0.4495 - loss1/classifier_macro_f1score: 0.0216 - loss2/classifier_accuracy: 0.1666 - loss2/classifier_top5_acc: 0.4335 - loss2/classifier_macro_f1score: 0.0200 - loss3/classifier_accuracy: 0.1677 - loss3/classifier_top5_acc: 0.4404 - loss3/classifier_macro_f1score: 0.0190 - val_loss: 5.0845 - val_loss1/classifier_loss: 3.0767 - val_loss2/classifier_loss: 3.1352 - val_loss3/classifier_loss: 3.2210 - val_loss1/classifier_accuracy: 0.2408 - val_loss1/classifier_top5_acc: 0.5405 - val_loss1/classifier_macro_f1score: 0.0298 - val_loss2/classifier_accuracy: 0.2230 - val_loss2/classifier_top5_acc: 0.5226 - val_loss2/classifier_macro_f1score: 0.0355 - val_loss3/classifier_accuracy: 0.2077 - val_loss3/classifier_top5_acc: 0.4962 - val_loss3/classifier_macro_f1score: 0.0368\n","Learning rate:  0.0003\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 4/70\n","350/350 [==============================] - ETA: 0s - loss: 5.0503 - loss1/classifier_loss: 3.1944 - loss2/classifier_loss: 3.2127 - loss3/classifier_loss: 3.1282 - loss1/classifier_accuracy: 0.2166 - loss1/classifier_top5_acc: 0.5061 - loss1/classifier_macro_f1score: 0.0361 - loss2/classifier_accuracy: 0.2089 - loss2/classifier_top5_acc: 0.5016 - loss2/classifier_macro_f1score: 0.0382 - loss3/classifier_accuracy: 0.2205 - loss3/classifier_top5_acc: 0.5200 - loss3/classifier_macro_f1score: 0.0410\n","Epoch 00004: val_loss improved from 5.08455 to 4.79865, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/004.h5\n","\n","Epoch 00004: val_loss3/classifier_accuracy improved from 0.20773 to 0.24279, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/004.h5\n","350/350 [==============================] - 692s 2s/step - loss: 5.0503 - loss1/classifier_loss: 3.1944 - loss2/classifier_loss: 3.2127 - loss3/classifier_loss: 3.1282 - loss1/classifier_accuracy: 0.2166 - loss1/classifier_top5_acc: 0.5061 - loss1/classifier_macro_f1score: 0.0361 - loss2/classifier_accuracy: 0.2089 - loss2/classifier_top5_acc: 0.5016 - loss2/classifier_macro_f1score: 0.0382 - loss3/classifier_accuracy: 0.2205 - loss3/classifier_top5_acc: 0.5200 - loss3/classifier_macro_f1score: 0.0410 - val_loss: 4.7986 - val_loss1/classifier_loss: 2.9073 - val_loss2/classifier_loss: 2.9532 - val_loss3/classifier_loss: 3.0405 - val_loss1/classifier_accuracy: 0.2726 - val_loss1/classifier_top5_acc: 0.5721 - val_loss1/classifier_macro_f1score: 0.0551 - val_loss2/classifier_accuracy: 0.2628 - val_loss2/classifier_top5_acc: 0.5647 - val_loss2/classifier_macro_f1score: 0.0585 - val_loss3/classifier_accuracy: 0.2428 - val_loss3/classifier_top5_acc: 0.5425 - val_loss3/classifier_macro_f1score: 0.0610\n","Learning rate:  0.0003\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 5/70\n","350/350 [==============================] - ETA: 0s - loss: 4.6902 - loss1/classifier_loss: 3.0152 - loss2/classifier_loss: 2.9985 - loss3/classifier_loss: 2.8861 - loss1/classifier_accuracy: 0.2532 - loss1/classifier_top5_acc: 0.5524 - loss1/classifier_macro_f1score: 0.0543 - loss2/classifier_accuracy: 0.2505 - loss2/classifier_top5_acc: 0.5577 - loss2/classifier_macro_f1score: 0.0590 - loss3/classifier_accuracy: 0.2682 - loss3/classifier_top5_acc: 0.5814 - loss3/classifier_macro_f1score: 0.0665\n","Epoch 00005: val_loss improved from 4.79865 to 4.37665, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/005.h5\n","\n","Epoch 00005: val_loss3/classifier_accuracy improved from 0.24279 to 0.29647, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/005.h5\n","350/350 [==============================] - 665s 2s/step - loss: 4.6902 - loss1/classifier_loss: 3.0152 - loss2/classifier_loss: 2.9985 - loss3/classifier_loss: 2.8861 - loss1/classifier_accuracy: 0.2532 - loss1/classifier_top5_acc: 0.5524 - loss1/classifier_macro_f1score: 0.0543 - loss2/classifier_accuracy: 0.2505 - loss2/classifier_top5_acc: 0.5577 - loss2/classifier_macro_f1score: 0.0590 - loss3/classifier_accuracy: 0.2682 - loss3/classifier_top5_acc: 0.5814 - loss3/classifier_macro_f1score: 0.0665 - val_loss: 4.3767 - val_loss1/classifier_loss: 2.7453 - val_loss2/classifier_loss: 2.7159 - val_loss3/classifier_loss: 2.7383 - val_loss1/classifier_accuracy: 0.3097 - val_loss1/classifier_top5_acc: 0.6192 - val_loss1/classifier_macro_f1score: 0.0716 - val_loss2/classifier_accuracy: 0.3031 - val_loss2/classifier_top5_acc: 0.6252 - val_loss2/classifier_macro_f1score: 0.0901 - val_loss3/classifier_accuracy: 0.2965 - val_loss3/classifier_top5_acc: 0.6114 - val_loss3/classifier_macro_f1score: 0.0920\n","Learning rate:  0.0003\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 6/70\n","350/350 [==============================] - ETA: 0s - loss: 4.3651 - loss1/classifier_loss: 2.8527 - loss2/classifier_loss: 2.8147 - loss3/classifier_loss: 2.6649 - loss1/classifier_accuracy: 0.2800 - loss1/classifier_top5_acc: 0.5932 - loss1/classifier_macro_f1score: 0.0720 - loss2/classifier_accuracy: 0.2853 - loss2/classifier_top5_acc: 0.6010 - loss2/classifier_macro_f1score: 0.0825 - loss3/classifier_accuracy: 0.3142 - loss3/classifier_top5_acc: 0.6325 - loss3/classifier_macro_f1score: 0.0982\n","Epoch 00006: val_loss improved from 4.37665 to 4.04346, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/006.h5\n","\n","Epoch 00006: val_loss3/classifier_accuracy improved from 0.29647 to 0.34675, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/006.h5\n","350/350 [==============================] - 676s 2s/step - loss: 4.3651 - loss1/classifier_loss: 2.8527 - loss2/classifier_loss: 2.8147 - loss3/classifier_loss: 2.6649 - loss1/classifier_accuracy: 0.2800 - loss1/classifier_top5_acc: 0.5932 - loss1/classifier_macro_f1score: 0.0720 - loss2/classifier_accuracy: 0.2853 - loss2/classifier_top5_acc: 0.6010 - loss2/classifier_macro_f1score: 0.0825 - loss3/classifier_accuracy: 0.3142 - loss3/classifier_top5_acc: 0.6325 - loss3/classifier_macro_f1score: 0.0982 - val_loss: 4.0435 - val_loss1/classifier_loss: 2.5552 - val_loss2/classifier_loss: 2.5058 - val_loss3/classifier_loss: 2.5251 - val_loss1/classifier_accuracy: 0.3458 - val_loss1/classifier_top5_acc: 0.6565 - val_loss1/classifier_macro_f1score: 0.1076 - val_loss2/classifier_accuracy: 0.3522 - val_loss2/classifier_top5_acc: 0.6679 - val_loss2/classifier_macro_f1score: 0.1158 - val_loss3/classifier_accuracy: 0.3468 - val_loss3/classifier_top5_acc: 0.6679 - val_loss3/classifier_macro_f1score: 0.1254\n","Learning rate:  0.0003\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 7/70\n","350/350 [==============================] - ETA: 0s - loss: 4.0934 - loss1/classifier_loss: 2.7163 - loss2/classifier_loss: 2.6429 - loss3/classifier_loss: 2.4856 - loss1/classifier_accuracy: 0.3083 - loss1/classifier_top5_acc: 0.6234 - loss1/classifier_macro_f1score: 0.0899 - loss2/classifier_accuracy: 0.3198 - loss2/classifier_top5_acc: 0.6413 - loss2/classifier_macro_f1score: 0.1050 - loss3/classifier_accuracy: 0.3502 - loss3/classifier_top5_acc: 0.6746 - loss3/classifier_macro_f1score: 0.1260\n","Epoch 00007: val_loss improved from 4.04346 to 3.93727, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/007.h5\n","\n","Epoch 00007: val_loss3/classifier_accuracy improved from 0.34675 to 0.36218, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/007.h5\n","350/350 [==============================] - 682s 2s/step - loss: 4.0934 - loss1/classifier_loss: 2.7163 - loss2/classifier_loss: 2.6429 - loss3/classifier_loss: 2.4856 - loss1/classifier_accuracy: 0.3083 - loss1/classifier_top5_acc: 0.6234 - loss1/classifier_macro_f1score: 0.0899 - loss2/classifier_accuracy: 0.3198 - loss2/classifier_top5_acc: 0.6413 - loss2/classifier_macro_f1score: 0.1050 - loss3/classifier_accuracy: 0.3502 - loss3/classifier_top5_acc: 0.6746 - loss3/classifier_macro_f1score: 0.1260 - val_loss: 3.9373 - val_loss1/classifier_loss: 2.4287 - val_loss2/classifier_loss: 2.4456 - val_loss3/classifier_loss: 2.4750 - val_loss1/classifier_accuracy: 0.3730 - val_loss1/classifier_top5_acc: 0.6915 - val_loss1/classifier_macro_f1score: 0.1283 - val_loss2/classifier_accuracy: 0.3700 - val_loss2/classifier_top5_acc: 0.6861 - val_loss2/classifier_macro_f1score: 0.1459 - val_loss3/classifier_accuracy: 0.3622 - val_loss3/classifier_top5_acc: 0.6767 - val_loss3/classifier_macro_f1score: 0.1589\n","Learning rate:  0.0003\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 8/70\n","350/350 [==============================] - ETA: 0s - loss: 3.8698 - loss1/classifier_loss: 2.6075 - loss2/classifier_loss: 2.5098 - loss3/classifier_loss: 2.3346 - loss1/classifier_accuracy: 0.3320 - loss1/classifier_top5_acc: 0.6487 - loss1/classifier_macro_f1score: 0.1054 - loss2/classifier_accuracy: 0.3483 - loss2/classifier_top5_acc: 0.6715 - loss2/classifier_macro_f1score: 0.1245 - loss3/classifier_accuracy: 0.3842 - loss3/classifier_top5_acc: 0.7087 - loss3/classifier_macro_f1score: 0.1503\n","Epoch 00008: val_loss improved from 3.93727 to 3.69250, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/008.h5\n","\n","Epoch 00008: val_loss3/classifier_accuracy improved from 0.36218 to 0.39844, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/008.h5\n","350/350 [==============================] - 684s 2s/step - loss: 3.8698 - loss1/classifier_loss: 2.6075 - loss2/classifier_loss: 2.5098 - loss3/classifier_loss: 2.3346 - loss1/classifier_accuracy: 0.3320 - loss1/classifier_top5_acc: 0.6487 - loss1/classifier_macro_f1score: 0.1054 - loss2/classifier_accuracy: 0.3483 - loss2/classifier_top5_acc: 0.6715 - loss2/classifier_macro_f1score: 0.1245 - loss3/classifier_accuracy: 0.3842 - loss3/classifier_top5_acc: 0.7087 - loss3/classifier_macro_f1score: 0.1503 - val_loss: 3.6925 - val_loss1/classifier_loss: 2.4298 - val_loss2/classifier_loss: 2.2879 - val_loss3/classifier_loss: 2.2772 - val_loss1/classifier_accuracy: 0.3692 - val_loss1/classifier_top5_acc: 0.6899 - val_loss1/classifier_macro_f1score: 0.1358 - val_loss2/classifier_accuracy: 0.3968 - val_loss2/classifier_top5_acc: 0.7190 - val_loss2/classifier_macro_f1score: 0.1596 - val_loss3/classifier_accuracy: 0.3984 - val_loss3/classifier_top5_acc: 0.7192 - val_loss3/classifier_macro_f1score: 0.1717\n","Learning rate:  0.0003\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 9/70\n","350/350 [==============================] - ETA: 0s - loss: 3.6509 - loss1/classifier_loss: 2.4921 - loss2/classifier_loss: 2.3849 - loss3/classifier_loss: 2.1878 - loss1/classifier_accuracy: 0.3547 - loss1/classifier_top5_acc: 0.6745 - loss1/classifier_macro_f1score: 0.1229 - loss2/classifier_accuracy: 0.3737 - loss2/classifier_top5_acc: 0.6996 - loss2/classifier_macro_f1score: 0.1466 - loss3/classifier_accuracy: 0.4147 - loss3/classifier_top5_acc: 0.7381 - loss3/classifier_macro_f1score: 0.1801\n","Epoch 00009: val_loss improved from 3.69250 to 3.57974, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/009.h5\n","\n","Epoch 00009: val_loss3/classifier_accuracy improved from 0.39844 to 0.41607, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/009.h5\n","350/350 [==============================] - 656s 2s/step - loss: 3.6509 - loss1/classifier_loss: 2.4921 - loss2/classifier_loss: 2.3849 - loss3/classifier_loss: 2.1878 - loss1/classifier_accuracy: 0.3547 - loss1/classifier_top5_acc: 0.6745 - loss1/classifier_macro_f1score: 0.1229 - loss2/classifier_accuracy: 0.3737 - loss2/classifier_top5_acc: 0.6996 - loss2/classifier_macro_f1score: 0.1466 - loss3/classifier_accuracy: 0.4147 - loss3/classifier_top5_acc: 0.7381 - loss3/classifier_macro_f1score: 0.1801 - val_loss: 3.5797 - val_loss1/classifier_loss: 2.2859 - val_loss2/classifier_loss: 2.2590 - val_loss3/classifier_loss: 2.2163 - val_loss1/classifier_accuracy: 0.4008 - val_loss1/classifier_top5_acc: 0.7238 - val_loss1/classifier_macro_f1score: 0.1578 - val_loss2/classifier_accuracy: 0.4117 - val_loss2/classifier_top5_acc: 0.7276 - val_loss2/classifier_macro_f1score: 0.1775 - val_loss3/classifier_accuracy: 0.4161 - val_loss3/classifier_top5_acc: 0.7376 - val_loss3/classifier_macro_f1score: 0.1897\n","Learning rate:  0.0003\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 10/70\n","350/350 [==============================] - ETA: 0s - loss: 3.4620 - loss1/classifier_loss: 2.4071 - loss2/classifier_loss: 2.2719 - loss3/classifier_loss: 2.0583 - loss1/classifier_accuracy: 0.3733 - loss1/classifier_top5_acc: 0.6932 - loss1/classifier_macro_f1score: 0.1373 - loss2/classifier_accuracy: 0.3998 - loss2/classifier_top5_acc: 0.7207 - loss2/classifier_macro_f1score: 0.1659 - loss3/classifier_accuracy: 0.4462 - loss3/classifier_top5_acc: 0.7614 - loss3/classifier_macro_f1score: 0.2082\n","Epoch 00010: val_loss improved from 3.57974 to 3.33441, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/010.h5\n","\n","Epoch 00010: val_loss3/classifier_accuracy improved from 0.41607 to 0.45072, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/010.h5\n","350/350 [==============================] - 652s 2s/step - loss: 3.4620 - loss1/classifier_loss: 2.4071 - loss2/classifier_loss: 2.2719 - loss3/classifier_loss: 2.0583 - loss1/classifier_accuracy: 0.3733 - loss1/classifier_top5_acc: 0.6932 - loss1/classifier_macro_f1score: 0.1373 - loss2/classifier_accuracy: 0.3998 - loss2/classifier_top5_acc: 0.7207 - loss2/classifier_macro_f1score: 0.1659 - loss3/classifier_accuracy: 0.4462 - loss3/classifier_top5_acc: 0.7614 - loss3/classifier_macro_f1score: 0.2082 - val_loss: 3.3344 - val_loss1/classifier_loss: 2.1846 - val_loss2/classifier_loss: 2.0755 - val_loss3/classifier_loss: 2.0564 - val_loss1/classifier_accuracy: 0.4225 - val_loss1/classifier_top5_acc: 0.7496 - val_loss1/classifier_macro_f1score: 0.1569 - val_loss2/classifier_accuracy: 0.4421 - val_loss2/classifier_top5_acc: 0.7666 - val_loss2/classifier_macro_f1score: 0.1900 - val_loss3/classifier_accuracy: 0.4507 - val_loss3/classifier_top5_acc: 0.7712 - val_loss3/classifier_macro_f1score: 0.2022\n","Learning rate:  0.0003\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 11/70\n","350/350 [==============================] - ETA: 0s - loss: 3.3151 - loss1/classifier_loss: 2.3325 - loss2/classifier_loss: 2.1856 - loss3/classifier_loss: 1.9597 - loss1/classifier_accuracy: 0.3866 - loss1/classifier_top5_acc: 0.7068 - loss1/classifier_macro_f1score: 0.1502 - loss2/classifier_accuracy: 0.4180 - loss2/classifier_top5_acc: 0.7382 - loss2/classifier_macro_f1score: 0.1833 - loss3/classifier_accuracy: 0.4659 - loss3/classifier_top5_acc: 0.7823 - loss3/classifier_macro_f1score: 0.2266\n","Epoch 00011: val_loss improved from 3.33441 to 3.23464, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/011.h5\n","\n","Epoch 00011: val_loss3/classifier_accuracy improved from 0.45072 to 0.45974, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/011.h5\n","350/350 [==============================] - 659s 2s/step - loss: 3.3151 - loss1/classifier_loss: 2.3325 - loss2/classifier_loss: 2.1856 - loss3/classifier_loss: 1.9597 - loss1/classifier_accuracy: 0.3866 - loss1/classifier_top5_acc: 0.7068 - loss1/classifier_macro_f1score: 0.1502 - loss2/classifier_accuracy: 0.4180 - loss2/classifier_top5_acc: 0.7382 - loss2/classifier_macro_f1score: 0.1833 - loss3/classifier_accuracy: 0.4659 - loss3/classifier_top5_acc: 0.7823 - loss3/classifier_macro_f1score: 0.2266 - val_loss: 3.2346 - val_loss1/classifier_loss: 2.1104 - val_loss2/classifier_loss: 2.0301 - val_loss3/classifier_loss: 1.9925 - val_loss1/classifier_accuracy: 0.4429 - val_loss1/classifier_top5_acc: 0.7584 - val_loss1/classifier_macro_f1score: 0.1821 - val_loss2/classifier_accuracy: 0.4493 - val_loss2/classifier_top5_acc: 0.7660 - val_loss2/classifier_macro_f1score: 0.2102 - val_loss3/classifier_accuracy: 0.4597 - val_loss3/classifier_top5_acc: 0.7718 - val_loss3/classifier_macro_f1score: 0.2311\n","Learning rate:  0.0003\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 12/70\n","350/350 [==============================] - ETA: 0s - loss: 3.1719 - loss1/classifier_loss: 2.2593 - loss2/classifier_loss: 2.1061 - loss3/classifier_loss: 1.8623 - loss1/classifier_accuracy: 0.4032 - loss1/classifier_top5_acc: 0.7234 - loss1/classifier_macro_f1score: 0.1633 - loss2/classifier_accuracy: 0.4358 - loss2/classifier_top5_acc: 0.7550 - loss2/classifier_macro_f1score: 0.1985 - loss3/classifier_accuracy: 0.4902 - loss3/classifier_top5_acc: 0.7983 - loss3/classifier_macro_f1score: 0.2480\n","Epoch 00012: val_loss improved from 3.23464 to 3.18772, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/012.h5\n","\n","Epoch 00012: val_loss3/classifier_accuracy improved from 0.45974 to 0.46995, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/012.h5\n","350/350 [==============================] - 684s 2s/step - loss: 3.1719 - loss1/classifier_loss: 2.2593 - loss2/classifier_loss: 2.1061 - loss3/classifier_loss: 1.8623 - loss1/classifier_accuracy: 0.4032 - loss1/classifier_top5_acc: 0.7234 - loss1/classifier_macro_f1score: 0.1633 - loss2/classifier_accuracy: 0.4358 - loss2/classifier_top5_acc: 0.7550 - loss2/classifier_macro_f1score: 0.1985 - loss3/classifier_accuracy: 0.4902 - loss3/classifier_top5_acc: 0.7983 - loss3/classifier_macro_f1score: 0.2480 - val_loss: 3.1877 - val_loss1/classifier_loss: 2.0911 - val_loss2/classifier_loss: 2.0017 - val_loss3/classifier_loss: 1.9599 - val_loss1/classifier_accuracy: 0.4429 - val_loss1/classifier_top5_acc: 0.7644 - val_loss1/classifier_macro_f1score: 0.1806 - val_loss2/classifier_accuracy: 0.4591 - val_loss2/classifier_top5_acc: 0.7780 - val_loss2/classifier_macro_f1score: 0.2085 - val_loss3/classifier_accuracy: 0.4700 - val_loss3/classifier_top5_acc: 0.7873 - val_loss3/classifier_macro_f1score: 0.2252\n","Learning rate:  0.0003\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 13/70\n","350/350 [==============================] - ETA: 0s - loss: 3.0422 - loss1/classifier_loss: 2.1977 - loss2/classifier_loss: 2.0313 - loss3/classifier_loss: 1.7735 - loss1/classifier_accuracy: 0.4167 - loss1/classifier_top5_acc: 0.7353 - loss1/classifier_macro_f1score: 0.1747 - loss2/classifier_accuracy: 0.4543 - loss2/classifier_top5_acc: 0.7685 - loss2/classifier_macro_f1score: 0.2136 - loss3/classifier_accuracy: 0.5116 - loss3/classifier_top5_acc: 0.8145 - loss3/classifier_macro_f1score: 0.2666\n","Epoch 00013: val_loss improved from 3.18772 to 3.00842, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/013.h5\n","\n","Epoch 00013: val_loss3/classifier_accuracy improved from 0.46995 to 0.50321, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/013.h5\n","350/350 [==============================] - 696s 2s/step - loss: 3.0422 - loss1/classifier_loss: 2.1977 - loss2/classifier_loss: 2.0313 - loss3/classifier_loss: 1.7735 - loss1/classifier_accuracy: 0.4167 - loss1/classifier_top5_acc: 0.7353 - loss1/classifier_macro_f1score: 0.1747 - loss2/classifier_accuracy: 0.4543 - loss2/classifier_top5_acc: 0.7685 - loss2/classifier_macro_f1score: 0.2136 - loss3/classifier_accuracy: 0.5116 - loss3/classifier_top5_acc: 0.8145 - loss3/classifier_macro_f1score: 0.2666 - val_loss: 3.0084 - val_loss1/classifier_loss: 1.9997 - val_loss2/classifier_loss: 1.8793 - val_loss3/classifier_loss: 1.8447 - val_loss1/classifier_accuracy: 0.4561 - val_loss1/classifier_top5_acc: 0.7782 - val_loss1/classifier_macro_f1score: 0.2172 - val_loss2/classifier_accuracy: 0.4874 - val_loss2/classifier_top5_acc: 0.8021 - val_loss2/classifier_macro_f1score: 0.2501 - val_loss3/classifier_accuracy: 0.5032 - val_loss3/classifier_top5_acc: 0.8039 - val_loss3/classifier_macro_f1score: 0.2802\n","Learning rate:  0.0003\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 14/70\n","350/350 [==============================] - ETA: 0s - loss: 2.9097 - loss1/classifier_loss: 2.1404 - loss2/classifier_loss: 1.9610 - loss3/classifier_loss: 1.6793 - loss1/classifier_accuracy: 0.4303 - loss1/classifier_top5_acc: 0.7485 - loss1/classifier_macro_f1score: 0.1850 - loss2/classifier_accuracy: 0.4690 - loss2/classifier_top5_acc: 0.7820 - loss2/classifier_macro_f1score: 0.2268 - loss3/classifier_accuracy: 0.5331 - loss3/classifier_top5_acc: 0.8305 - loss3/classifier_macro_f1score: 0.2863\n","Epoch 00014: val_loss improved from 3.00842 to 2.97118, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/014.h5\n","\n","Epoch 00014: val_loss3/classifier_accuracy improved from 0.50321 to 0.51042, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/014.h5\n","350/350 [==============================] - 697s 2s/step - loss: 2.9097 - loss1/classifier_loss: 2.1404 - loss2/classifier_loss: 1.9610 - loss3/classifier_loss: 1.6793 - loss1/classifier_accuracy: 0.4303 - loss1/classifier_top5_acc: 0.7485 - loss1/classifier_macro_f1score: 0.1850 - loss2/classifier_accuracy: 0.4690 - loss2/classifier_top5_acc: 0.7820 - loss2/classifier_macro_f1score: 0.2268 - loss3/classifier_accuracy: 0.5331 - loss3/classifier_top5_acc: 0.8305 - loss3/classifier_macro_f1score: 0.2863 - val_loss: 2.9712 - val_loss1/classifier_loss: 1.9910 - val_loss2/classifier_loss: 1.8677 - val_loss3/classifier_loss: 1.8136 - val_loss1/classifier_accuracy: 0.4663 - val_loss1/classifier_top5_acc: 0.7774 - val_loss1/classifier_macro_f1score: 0.2122 - val_loss2/classifier_accuracy: 0.4924 - val_loss2/classifier_top5_acc: 0.8015 - val_loss2/classifier_macro_f1score: 0.2415 - val_loss3/classifier_accuracy: 0.5104 - val_loss3/classifier_top5_acc: 0.8127 - val_loss3/classifier_macro_f1score: 0.2766\n","Learning rate:  0.0003\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 15/70\n","350/350 [==============================] - ETA: 0s - loss: 2.7898 - loss1/classifier_loss: 2.0919 - loss2/classifier_loss: 1.8851 - loss3/classifier_loss: 1.5967 - loss1/classifier_accuracy: 0.4400 - loss1/classifier_top5_acc: 0.7574 - loss1/classifier_macro_f1score: 0.1952 - loss2/classifier_accuracy: 0.4852 - loss2/classifier_top5_acc: 0.7955 - loss2/classifier_macro_f1score: 0.2421 - loss3/classifier_accuracy: 0.5536 - loss3/classifier_top5_acc: 0.8434 - loss3/classifier_macro_f1score: 0.3053\n","Epoch 00015: val_loss improved from 2.97118 to 2.93951, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/015.h5\n","\n","Epoch 00015: val_loss3/classifier_accuracy improved from 0.51042 to 0.51502, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/015.h5\n","350/350 [==============================] - 695s 2s/step - loss: 2.7898 - loss1/classifier_loss: 2.0919 - loss2/classifier_loss: 1.8851 - loss3/classifier_loss: 1.5967 - loss1/classifier_accuracy: 0.4400 - loss1/classifier_top5_acc: 0.7574 - loss1/classifier_macro_f1score: 0.1952 - loss2/classifier_accuracy: 0.4852 - loss2/classifier_top5_acc: 0.7955 - loss2/classifier_macro_f1score: 0.2421 - loss3/classifier_accuracy: 0.5536 - loss3/classifier_top5_acc: 0.8434 - loss3/classifier_macro_f1score: 0.3053 - val_loss: 2.9395 - val_loss1/classifier_loss: 1.9689 - val_loss2/classifier_loss: 1.8428 - val_loss3/classifier_loss: 1.7960 - val_loss1/classifier_accuracy: 0.4712 - val_loss1/classifier_top5_acc: 0.7839 - val_loss1/classifier_macro_f1score: 0.2149 - val_loss2/classifier_accuracy: 0.5020 - val_loss2/classifier_top5_acc: 0.8039 - val_loss2/classifier_macro_f1score: 0.2608 - val_loss3/classifier_accuracy: 0.5150 - val_loss3/classifier_top5_acc: 0.8129 - val_loss3/classifier_macro_f1score: 0.2883\n","Learning rate:  0.0003\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 16/70\n","350/350 [==============================] - ETA: 0s - loss: 2.6936 - loss1/classifier_loss: 2.0399 - loss2/classifier_loss: 1.8321 - loss3/classifier_loss: 1.5320 - loss1/classifier_accuracy: 0.4515 - loss1/classifier_top5_acc: 0.7677 - loss1/classifier_macro_f1score: 0.2068 - loss2/classifier_accuracy: 0.4997 - loss2/classifier_top5_acc: 0.8080 - loss2/classifier_macro_f1score: 0.2539 - loss3/classifier_accuracy: 0.5698 - loss3/classifier_top5_acc: 0.8560 - loss3/classifier_macro_f1score: 0.3202\n","Epoch 00016: val_loss did not improve from 2.93951\n","\n","Epoch 00016: val_loss3/classifier_accuracy did not improve from 0.51502\n","350/350 [==============================] - 700s 2s/step - loss: 2.6936 - loss1/classifier_loss: 2.0399 - loss2/classifier_loss: 1.8321 - loss3/classifier_loss: 1.5320 - loss1/classifier_accuracy: 0.4515 - loss1/classifier_top5_acc: 0.7677 - loss1/classifier_macro_f1score: 0.2068 - loss2/classifier_accuracy: 0.4997 - loss2/classifier_top5_acc: 0.8080 - loss2/classifier_macro_f1score: 0.2539 - loss3/classifier_accuracy: 0.5698 - loss3/classifier_top5_acc: 0.8560 - loss3/classifier_macro_f1score: 0.3202 - val_loss: 2.9659 - val_loss1/classifier_loss: 1.9617 - val_loss2/classifier_loss: 1.8597 - val_loss3/classifier_loss: 1.8194 - val_loss1/classifier_accuracy: 0.4698 - val_loss1/classifier_top5_acc: 0.7887 - val_loss1/classifier_macro_f1score: 0.2209 - val_loss2/classifier_accuracy: 0.5004 - val_loss2/classifier_top5_acc: 0.8005 - val_loss2/classifier_macro_f1score: 0.2476 - val_loss3/classifier_accuracy: 0.5100 - val_loss3/classifier_top5_acc: 0.8119 - val_loss3/classifier_macro_f1score: 0.2749\n","Learning rate:  0.0003\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 17/70\n","350/350 [==============================] - ETA: 0s - loss: 2.6009 - loss1/classifier_loss: 1.9946 - loss2/classifier_loss: 1.7747 - loss3/classifier_loss: 1.4701 - loss1/classifier_accuracy: 0.4600 - loss1/classifier_top5_acc: 0.7748 - loss1/classifier_macro_f1score: 0.2146 - loss2/classifier_accuracy: 0.5103 - loss2/classifier_top5_acc: 0.8159 - loss2/classifier_macro_f1score: 0.2671 - loss3/classifier_accuracy: 0.5849 - loss3/classifier_top5_acc: 0.8640 - loss3/classifier_macro_f1score: 0.3342\n","Epoch 00017: val_loss improved from 2.93951 to 2.85010, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/017.h5\n","\n","Epoch 00017: val_loss3/classifier_accuracy improved from 0.51502 to 0.52404, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/017.h5\n","350/350 [==============================] - 703s 2s/step - loss: 2.6009 - loss1/classifier_loss: 1.9946 - loss2/classifier_loss: 1.7747 - loss3/classifier_loss: 1.4701 - loss1/classifier_accuracy: 0.4600 - loss1/classifier_top5_acc: 0.7748 - loss1/classifier_macro_f1score: 0.2146 - loss2/classifier_accuracy: 0.5103 - loss2/classifier_top5_acc: 0.8159 - loss2/classifier_macro_f1score: 0.2671 - loss3/classifier_accuracy: 0.5849 - loss3/classifier_top5_acc: 0.8640 - loss3/classifier_macro_f1score: 0.3342 - val_loss: 2.8501 - val_loss1/classifier_loss: 1.8633 - val_loss2/classifier_loss: 1.7785 - val_loss3/classifier_loss: 1.7576 - val_loss1/classifier_accuracy: 0.4958 - val_loss1/classifier_top5_acc: 0.8029 - val_loss1/classifier_macro_f1score: 0.2499 - val_loss2/classifier_accuracy: 0.5164 - val_loss2/classifier_top5_acc: 0.8169 - val_loss2/classifier_macro_f1score: 0.2891 - val_loss3/classifier_accuracy: 0.5240 - val_loss3/classifier_top5_acc: 0.8227 - val_loss3/classifier_macro_f1score: 0.3146\n","Learning rate:  0.0003\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 18/70\n","350/350 [==============================] - ETA: 0s - loss: 2.4864 - loss1/classifier_loss: 1.9501 - loss2/classifier_loss: 1.7161 - loss3/classifier_loss: 1.3866 - loss1/classifier_accuracy: 0.4721 - loss1/classifier_top5_acc: 0.7830 - loss1/classifier_macro_f1score: 0.2236 - loss2/classifier_accuracy: 0.5262 - loss2/classifier_top5_acc: 0.8240 - loss2/classifier_macro_f1score: 0.2782 - loss3/classifier_accuracy: 0.6034 - loss3/classifier_top5_acc: 0.8770 - loss3/classifier_macro_f1score: 0.3524\n","Epoch 00018: val_loss improved from 2.85010 to 2.77270, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/018.h5\n","\n","Epoch 00018: val_loss3/classifier_accuracy improved from 0.52404 to 0.54888, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/018.h5\n","350/350 [==============================] - 704s 2s/step - loss: 2.4864 - loss1/classifier_loss: 1.9501 - loss2/classifier_loss: 1.7161 - loss3/classifier_loss: 1.3866 - loss1/classifier_accuracy: 0.4721 - loss1/classifier_top5_acc: 0.7830 - loss1/classifier_macro_f1score: 0.2236 - loss2/classifier_accuracy: 0.5262 - loss2/classifier_top5_acc: 0.8240 - loss2/classifier_macro_f1score: 0.2782 - loss3/classifier_accuracy: 0.6034 - loss3/classifier_top5_acc: 0.8770 - loss3/classifier_macro_f1score: 0.3524 - val_loss: 2.7727 - val_loss1/classifier_loss: 1.8862 - val_loss2/classifier_loss: 1.7582 - val_loss3/classifier_loss: 1.6794 - val_loss1/classifier_accuracy: 0.4948 - val_loss1/classifier_top5_acc: 0.7945 - val_loss1/classifier_macro_f1score: 0.2437 - val_loss2/classifier_accuracy: 0.5246 - val_loss2/classifier_top5_acc: 0.8221 - val_loss2/classifier_macro_f1score: 0.2904 - val_loss3/classifier_accuracy: 0.5489 - val_loss3/classifier_top5_acc: 0.8303 - val_loss3/classifier_macro_f1score: 0.3249\n","Learning rate:  0.0003\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 19/70\n","350/350 [==============================] - ETA: 0s - loss: 2.3971 - loss1/classifier_loss: 1.9079 - loss2/classifier_loss: 1.6667 - loss3/classifier_loss: 1.3247 - loss1/classifier_accuracy: 0.4792 - loss1/classifier_top5_acc: 0.7937 - loss1/classifier_macro_f1score: 0.2327 - loss2/classifier_accuracy: 0.5374 - loss2/classifier_top5_acc: 0.8361 - loss2/classifier_macro_f1score: 0.2922 - loss3/classifier_accuracy: 0.6210 - loss3/classifier_top5_acc: 0.8859 - loss3/classifier_macro_f1score: 0.3685\n","Epoch 00019: val_loss improved from 2.77270 to 2.73778, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/019.h5\n","\n","Epoch 00019: val_loss3/classifier_accuracy did not improve from 0.54888\n","350/350 [==============================] - 702s 2s/step - loss: 2.3971 - loss1/classifier_loss: 1.9079 - loss2/classifier_loss: 1.6667 - loss3/classifier_loss: 1.3247 - loss1/classifier_accuracy: 0.4792 - loss1/classifier_top5_acc: 0.7937 - loss1/classifier_macro_f1score: 0.2327 - loss2/classifier_accuracy: 0.5374 - loss2/classifier_top5_acc: 0.8361 - loss2/classifier_macro_f1score: 0.2922 - loss3/classifier_accuracy: 0.6210 - loss3/classifier_top5_acc: 0.8859 - loss3/classifier_macro_f1score: 0.3685 - val_loss: 2.7378 - val_loss1/classifier_loss: 1.8790 - val_loss2/classifier_loss: 1.7065 - val_loss3/classifier_loss: 1.6621 - val_loss1/classifier_accuracy: 0.4878 - val_loss1/classifier_top5_acc: 0.7973 - val_loss1/classifier_macro_f1score: 0.2405 - val_loss2/classifier_accuracy: 0.5357 - val_loss2/classifier_top5_acc: 0.8303 - val_loss2/classifier_macro_f1score: 0.2833 - val_loss3/classifier_accuracy: 0.5477 - val_loss3/classifier_top5_acc: 0.8403 - val_loss3/classifier_macro_f1score: 0.3206\n","Learning rate:  0.0003\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 20/70\n","350/350 [==============================] - ETA: 0s - loss: 2.3363 - loss1/classifier_loss: 1.8885 - loss2/classifier_loss: 1.6326 - loss3/classifier_loss: 1.2800 - loss1/classifier_accuracy: 0.4866 - loss1/classifier_top5_acc: 0.7944 - loss1/classifier_macro_f1score: 0.2392 - loss2/classifier_accuracy: 0.5456 - loss2/classifier_top5_acc: 0.8391 - loss2/classifier_macro_f1score: 0.3003 - loss3/classifier_accuracy: 0.6283 - loss3/classifier_top5_acc: 0.8920 - loss3/classifier_macro_f1score: 0.3803\n","Epoch 00020: val_loss improved from 2.73778 to 2.73056, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/020.h5\n","\n","Epoch 00020: val_loss3/classifier_accuracy improved from 0.54888 to 0.55329, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/020.h5\n","350/350 [==============================] - 699s 2s/step - loss: 2.3363 - loss1/classifier_loss: 1.8885 - loss2/classifier_loss: 1.6326 - loss3/classifier_loss: 1.2800 - loss1/classifier_accuracy: 0.4866 - loss1/classifier_top5_acc: 0.7944 - loss1/classifier_macro_f1score: 0.2392 - loss2/classifier_accuracy: 0.5456 - loss2/classifier_top5_acc: 0.8391 - loss2/classifier_macro_f1score: 0.3003 - loss3/classifier_accuracy: 0.6283 - loss3/classifier_top5_acc: 0.8920 - loss3/classifier_macro_f1score: 0.3803 - val_loss: 2.7306 - val_loss1/classifier_loss: 1.8506 - val_loss2/classifier_loss: 1.7139 - val_loss3/classifier_loss: 1.6612 - val_loss1/classifier_accuracy: 0.5004 - val_loss1/classifier_top5_acc: 0.8047 - val_loss1/classifier_macro_f1score: 0.2463 - val_loss2/classifier_accuracy: 0.5329 - val_loss2/classifier_top5_acc: 0.8217 - val_loss2/classifier_macro_f1score: 0.2924 - val_loss3/classifier_accuracy: 0.5533 - val_loss3/classifier_top5_acc: 0.8389 - val_loss3/classifier_macro_f1score: 0.3187\n","Learning rate:  0.0003\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 21/70\n","350/350 [==============================] - ETA: 0s - loss: 2.2620 - loss1/classifier_loss: 1.8521 - loss2/classifier_loss: 1.5867 - loss3/classifier_loss: 1.2304 - loss1/classifier_accuracy: 0.4931 - loss1/classifier_top5_acc: 0.8020 - loss1/classifier_macro_f1score: 0.2434 - loss2/classifier_accuracy: 0.5558 - loss2/classifier_top5_acc: 0.8477 - loss2/classifier_macro_f1score: 0.3068 - loss3/classifier_accuracy: 0.6431 - loss3/classifier_top5_acc: 0.8989 - loss3/classifier_macro_f1score: 0.3882\n","Epoch 00021: val_loss improved from 2.73056 to 2.63239, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/021.h5\n","\n","Epoch 00021: val_loss3/classifier_accuracy improved from 0.55329 to 0.56530, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/021.h5\n","350/350 [==============================] - 695s 2s/step - loss: 2.2620 - loss1/classifier_loss: 1.8521 - loss2/classifier_loss: 1.5867 - loss3/classifier_loss: 1.2304 - loss1/classifier_accuracy: 0.4931 - loss1/classifier_top5_acc: 0.8020 - loss1/classifier_macro_f1score: 0.2434 - loss2/classifier_accuracy: 0.5558 - loss2/classifier_top5_acc: 0.8477 - loss2/classifier_macro_f1score: 0.3068 - loss3/classifier_accuracy: 0.6431 - loss3/classifier_top5_acc: 0.8989 - loss3/classifier_macro_f1score: 0.3882 - val_loss: 2.6324 - val_loss1/classifier_loss: 1.7521 - val_loss2/classifier_loss: 1.6414 - val_loss3/classifier_loss: 1.6143 - val_loss1/classifier_accuracy: 0.5144 - val_loss1/classifier_top5_acc: 0.8215 - val_loss1/classifier_macro_f1score: 0.2671 - val_loss2/classifier_accuracy: 0.5497 - val_loss2/classifier_top5_acc: 0.8359 - val_loss2/classifier_macro_f1score: 0.3131 - val_loss3/classifier_accuracy: 0.5653 - val_loss3/classifier_top5_acc: 0.8413 - val_loss3/classifier_macro_f1score: 0.3546\n","Learning rate:  0.0003\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 22/70\n","350/350 [==============================] - ETA: 0s - loss: 2.1832 - loss1/classifier_loss: 1.8168 - loss2/classifier_loss: 1.5406 - loss3/classifier_loss: 1.1759 - loss1/classifier_accuracy: 0.5026 - loss1/classifier_top5_acc: 0.8063 - loss1/classifier_macro_f1score: 0.2560 - loss2/classifier_accuracy: 0.5679 - loss2/classifier_top5_acc: 0.8550 - loss2/classifier_macro_f1score: 0.3213 - loss3/classifier_accuracy: 0.6578 - loss3/classifier_top5_acc: 0.9071 - loss3/classifier_macro_f1score: 0.4063\n","Epoch 00022: val_loss improved from 2.63239 to 2.57588, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/022.h5\n","\n","Epoch 00022: val_loss3/classifier_accuracy improved from 0.56530 to 0.57672, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/022.h5\n","350/350 [==============================] - 698s 2s/step - loss: 2.1832 - loss1/classifier_loss: 1.8168 - loss2/classifier_loss: 1.5406 - loss3/classifier_loss: 1.1759 - loss1/classifier_accuracy: 0.5026 - loss1/classifier_top5_acc: 0.8063 - loss1/classifier_macro_f1score: 0.2560 - loss2/classifier_accuracy: 0.5679 - loss2/classifier_top5_acc: 0.8550 - loss2/classifier_macro_f1score: 0.3213 - loss3/classifier_accuracy: 0.6578 - loss3/classifier_top5_acc: 0.9071 - loss3/classifier_macro_f1score: 0.4063 - val_loss: 2.5759 - val_loss1/classifier_loss: 1.7398 - val_loss2/classifier_loss: 1.6343 - val_loss3/classifier_loss: 1.5636 - val_loss1/classifier_accuracy: 0.5180 - val_loss1/classifier_top5_acc: 0.8245 - val_loss1/classifier_macro_f1score: 0.2724 - val_loss2/classifier_accuracy: 0.5555 - val_loss2/classifier_top5_acc: 0.8413 - val_loss2/classifier_macro_f1score: 0.3253 - val_loss3/classifier_accuracy: 0.5767 - val_loss3/classifier_top5_acc: 0.8530 - val_loss3/classifier_macro_f1score: 0.3579\n","Learning rate:  0.0003\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 23/70\n","350/350 [==============================] - ETA: 0s - loss: 2.0808 - loss1/classifier_loss: 1.7737 - loss2/classifier_loss: 1.4817 - loss3/classifier_loss: 1.1042 - loss1/classifier_accuracy: 0.5141 - loss1/classifier_top5_acc: 0.8157 - loss1/classifier_macro_f1score: 0.2648 - loss2/classifier_accuracy: 0.5850 - loss2/classifier_top5_acc: 0.8636 - loss2/classifier_macro_f1score: 0.3327 - loss3/classifier_accuracy: 0.6755 - loss3/classifier_top5_acc: 0.9177 - loss3/classifier_macro_f1score: 0.4212\n","Epoch 00023: val_loss improved from 2.57588 to 2.53142, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/023.h5\n","\n","Epoch 00023: val_loss3/classifier_accuracy improved from 0.57672 to 0.58574, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/023.h5\n","350/350 [==============================] - 698s 2s/step - loss: 2.0808 - loss1/classifier_loss: 1.7737 - loss2/classifier_loss: 1.4817 - loss3/classifier_loss: 1.1042 - loss1/classifier_accuracy: 0.5141 - loss1/classifier_top5_acc: 0.8157 - loss1/classifier_macro_f1score: 0.2648 - loss2/classifier_accuracy: 0.5850 - loss2/classifier_top5_acc: 0.8636 - loss2/classifier_macro_f1score: 0.3327 - loss3/classifier_accuracy: 0.6755 - loss3/classifier_top5_acc: 0.9177 - loss3/classifier_macro_f1score: 0.4212 - val_loss: 2.5314 - val_loss1/classifier_loss: 1.7208 - val_loss2/classifier_loss: 1.5950 - val_loss3/classifier_loss: 1.5367 - val_loss1/classifier_accuracy: 0.5300 - val_loss1/classifier_top5_acc: 0.8249 - val_loss1/classifier_macro_f1score: 0.2809 - val_loss2/classifier_accuracy: 0.5679 - val_loss2/classifier_top5_acc: 0.8458 - val_loss2/classifier_macro_f1score: 0.3332 - val_loss3/classifier_accuracy: 0.5857 - val_loss3/classifier_top5_acc: 0.8598 - val_loss3/classifier_macro_f1score: 0.3664\n","Learning rate:  0.0003\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 24/70\n","350/350 [==============================] - ETA: 0s - loss: 2.0026 - loss1/classifier_loss: 1.7392 - loss2/classifier_loss: 1.4383 - loss3/classifier_loss: 1.0494 - loss1/classifier_accuracy: 0.5187 - loss1/classifier_top5_acc: 0.8216 - loss1/classifier_macro_f1score: 0.2694 - loss2/classifier_accuracy: 0.5927 - loss2/classifier_top5_acc: 0.8694 - loss2/classifier_macro_f1score: 0.3445 - loss3/classifier_accuracy: 0.6883 - loss3/classifier_top5_acc: 0.9244 - loss3/classifier_macro_f1score: 0.4331\n","Epoch 00024: val_loss did not improve from 2.53142\n","\n","Epoch 00024: val_loss3/classifier_accuracy did not improve from 0.58574\n","350/350 [==============================] - 678s 2s/step - loss: 2.0026 - loss1/classifier_loss: 1.7392 - loss2/classifier_loss: 1.4383 - loss3/classifier_loss: 1.0494 - loss1/classifier_accuracy: 0.5187 - loss1/classifier_top5_acc: 0.8216 - loss1/classifier_macro_f1score: 0.2694 - loss2/classifier_accuracy: 0.5927 - loss2/classifier_top5_acc: 0.8694 - loss2/classifier_macro_f1score: 0.3445 - loss3/classifier_accuracy: 0.6883 - loss3/classifier_top5_acc: 0.9244 - loss3/classifier_macro_f1score: 0.4331 - val_loss: 2.6701 - val_loss1/classifier_loss: 1.7585 - val_loss2/classifier_loss: 1.6827 - val_loss3/classifier_loss: 1.6377 - val_loss1/classifier_accuracy: 0.5184 - val_loss1/classifier_top5_acc: 0.8157 - val_loss1/classifier_macro_f1score: 0.2838 - val_loss2/classifier_accuracy: 0.5549 - val_loss2/classifier_top5_acc: 0.8359 - val_loss2/classifier_macro_f1score: 0.3289 - val_loss3/classifier_accuracy: 0.5797 - val_loss3/classifier_top5_acc: 0.8472 - val_loss3/classifier_macro_f1score: 0.3643\n","Learning rate:  0.0003\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 25/70\n","350/350 [==============================] - ETA: 0s - loss: 1.9689 - loss1/classifier_loss: 1.7245 - loss2/classifier_loss: 1.4315 - loss3/classifier_loss: 1.0221 - loss1/classifier_accuracy: 0.5238 - loss1/classifier_top5_acc: 0.8246 - loss1/classifier_macro_f1score: 0.2739 - loss2/classifier_accuracy: 0.5950 - loss2/classifier_top5_acc: 0.8728 - loss2/classifier_macro_f1score: 0.3449 - loss3/classifier_accuracy: 0.6968 - loss3/classifier_top5_acc: 0.9279 - loss3/classifier_macro_f1score: 0.4405\n","Epoch 00025: val_loss did not improve from 2.53142\n","\n","Epoch 00025: val_loss3/classifier_accuracy did not improve from 0.58574\n","350/350 [==============================] - 695s 2s/step - loss: 1.9689 - loss1/classifier_loss: 1.7245 - loss2/classifier_loss: 1.4315 - loss3/classifier_loss: 1.0221 - loss1/classifier_accuracy: 0.5238 - loss1/classifier_top5_acc: 0.8246 - loss1/classifier_macro_f1score: 0.2739 - loss2/classifier_accuracy: 0.5950 - loss2/classifier_top5_acc: 0.8728 - loss2/classifier_macro_f1score: 0.3449 - loss3/classifier_accuracy: 0.6968 - loss3/classifier_top5_acc: 0.9279 - loss3/classifier_macro_f1score: 0.4405 - val_loss: 2.6373 - val_loss1/classifier_loss: 1.7173 - val_loss2/classifier_loss: 1.6099 - val_loss3/classifier_loss: 1.6391 - val_loss1/classifier_accuracy: 0.5274 - val_loss1/classifier_top5_acc: 0.8289 - val_loss1/classifier_macro_f1score: 0.2820 - val_loss2/classifier_accuracy: 0.5647 - val_loss2/classifier_top5_acc: 0.8429 - val_loss2/classifier_macro_f1score: 0.3308 - val_loss3/classifier_accuracy: 0.5777 - val_loss3/classifier_top5_acc: 0.8528 - val_loss3/classifier_macro_f1score: 0.3657\n","Learning rate:  0.0003\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 26/70\n","350/350 [==============================] - ETA: 0s - loss: 1.9143 - loss1/classifier_loss: 1.7095 - loss2/classifier_loss: 1.3941 - loss3/classifier_loss: 0.9832 - loss1/classifier_accuracy: 0.5266 - loss1/classifier_top5_acc: 0.8289 - loss1/classifier_macro_f1score: 0.2747 - loss2/classifier_accuracy: 0.6032 - loss2/classifier_top5_acc: 0.8768 - loss2/classifier_macro_f1score: 0.3519 - loss3/classifier_accuracy: 0.7060 - loss3/classifier_top5_acc: 0.9337 - loss3/classifier_macro_f1score: 0.4489\n","Epoch 00026: val_loss did not improve from 2.53142\n","\n","Epoch 00026: val_loss3/classifier_accuracy did not improve from 0.58574\n","350/350 [==============================] - 683s 2s/step - loss: 1.9143 - loss1/classifier_loss: 1.7095 - loss2/classifier_loss: 1.3941 - loss3/classifier_loss: 0.9832 - loss1/classifier_accuracy: 0.5266 - loss1/classifier_top5_acc: 0.8289 - loss1/classifier_macro_f1score: 0.2747 - loss2/classifier_accuracy: 0.6032 - loss2/classifier_top5_acc: 0.8768 - loss2/classifier_macro_f1score: 0.3519 - loss3/classifier_accuracy: 0.7060 - loss3/classifier_top5_acc: 0.9337 - loss3/classifier_macro_f1score: 0.4489 - val_loss: 2.6372 - val_loss1/classifier_loss: 1.7372 - val_loss2/classifier_loss: 1.6402 - val_loss3/classifier_loss: 1.6240 - val_loss1/classifier_accuracy: 0.5262 - val_loss1/classifier_top5_acc: 0.8173 - val_loss1/classifier_macro_f1score: 0.2880 - val_loss2/classifier_accuracy: 0.5607 - val_loss2/classifier_top5_acc: 0.8393 - val_loss2/classifier_macro_f1score: 0.3331 - val_loss3/classifier_accuracy: 0.5761 - val_loss3/classifier_top5_acc: 0.8492 - val_loss3/classifier_macro_f1score: 0.3688\n","Learning rate:  0.0003\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 27/70\n","350/350 [==============================] - ETA: 0s - loss: 1.8431 - loss1/classifier_loss: 1.6677 - loss2/classifier_loss: 1.3614 - loss3/classifier_loss: 0.9343 - loss1/classifier_accuracy: 0.5360 - loss1/classifier_top5_acc: 0.8351 - loss1/classifier_macro_f1score: 0.2882 - loss2/classifier_accuracy: 0.6102 - loss2/classifier_top5_acc: 0.8815 - loss2/classifier_macro_f1score: 0.3624 - loss3/classifier_accuracy: 0.7206 - loss3/classifier_top5_acc: 0.9385 - loss3/classifier_macro_f1score: 0.4624\n","Epoch 00027: val_loss did not improve from 2.53142\n","\n","Epoch 00027: val_loss3/classifier_accuracy did not improve from 0.58574\n","350/350 [==============================] - 675s 2s/step - loss: 1.8431 - loss1/classifier_loss: 1.6677 - loss2/classifier_loss: 1.3614 - loss3/classifier_loss: 0.9343 - loss1/classifier_accuracy: 0.5360 - loss1/classifier_top5_acc: 0.8351 - loss1/classifier_macro_f1score: 0.2882 - loss2/classifier_accuracy: 0.6102 - loss2/classifier_top5_acc: 0.8815 - loss2/classifier_macro_f1score: 0.3624 - loss3/classifier_accuracy: 0.7206 - loss3/classifier_top5_acc: 0.9385 - loss3/classifier_macro_f1score: 0.4624 - val_loss: 2.5841 - val_loss1/classifier_loss: 1.7242 - val_loss2/classifier_loss: 1.6110 - val_loss3/classifier_loss: 1.5835 - val_loss1/classifier_accuracy: 0.5286 - val_loss1/classifier_top5_acc: 0.8257 - val_loss1/classifier_macro_f1score: 0.2846 - val_loss2/classifier_accuracy: 0.5603 - val_loss2/classifier_top5_acc: 0.8450 - val_loss2/classifier_macro_f1score: 0.3302 - val_loss3/classifier_accuracy: 0.5847 - val_loss3/classifier_top5_acc: 0.8580 - val_loss3/classifier_macro_f1score: 0.3742\n","Learning rate:  0.0003\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 28/70\n","350/350 [==============================] - ETA: 0s - loss: 1.7862 - loss1/classifier_loss: 1.6489 - loss2/classifier_loss: 1.3394 - loss3/classifier_loss: 0.8897 - loss1/classifier_accuracy: 0.5389 - loss1/classifier_top5_acc: 0.8372 - loss1/classifier_macro_f1score: 0.2913 - loss2/classifier_accuracy: 0.6176 - loss2/classifier_top5_acc: 0.8846 - loss2/classifier_macro_f1score: 0.3694 - loss3/classifier_accuracy: 0.7342 - loss3/classifier_top5_acc: 0.9428 - loss3/classifier_macro_f1score: 0.4767\n","Epoch 00028: val_loss did not improve from 2.53142\n","\n","Epoch 00028: val_loss3/classifier_accuracy did not improve from 0.58574\n","350/350 [==============================] - 662s 2s/step - loss: 1.7862 - loss1/classifier_loss: 1.6489 - loss2/classifier_loss: 1.3394 - loss3/classifier_loss: 0.8897 - loss1/classifier_accuracy: 0.5389 - loss1/classifier_top5_acc: 0.8372 - loss1/classifier_macro_f1score: 0.2913 - loss2/classifier_accuracy: 0.6176 - loss2/classifier_top5_acc: 0.8846 - loss2/classifier_macro_f1score: 0.3694 - loss3/classifier_accuracy: 0.7342 - loss3/classifier_top5_acc: 0.9428 - loss3/classifier_macro_f1score: 0.4767 - val_loss: 2.6413 - val_loss1/classifier_loss: 1.7125 - val_loss2/classifier_loss: 1.6129 - val_loss3/classifier_loss: 1.6437 - val_loss1/classifier_accuracy: 0.5298 - val_loss1/classifier_top5_acc: 0.8269 - val_loss1/classifier_macro_f1score: 0.2818 - val_loss2/classifier_accuracy: 0.5725 - val_loss2/classifier_top5_acc: 0.8413 - val_loss2/classifier_macro_f1score: 0.3376 - val_loss3/classifier_accuracy: 0.5785 - val_loss3/classifier_top5_acc: 0.8534 - val_loss3/classifier_macro_f1score: 0.3696\n","Learning rate:  0.0003\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 29/70\n","350/350 [==============================] - ETA: 0s - loss: 1.7212 - loss1/classifier_loss: 1.6252 - loss2/classifier_loss: 1.2970 - loss3/classifier_loss: 0.8446 - loss1/classifier_accuracy: 0.5457 - loss1/classifier_top5_acc: 0.8409 - loss1/classifier_macro_f1score: 0.2955 - loss2/classifier_accuracy: 0.6259 - loss2/classifier_top5_acc: 0.8914 - loss2/classifier_macro_f1score: 0.3765 - loss3/classifier_accuracy: 0.7439 - loss3/classifier_top5_acc: 0.9486 - loss3/classifier_macro_f1score: 0.4846\n","Epoch 00029: val_loss did not improve from 2.53142\n","\n","Epoch 00029: val_loss3/classifier_accuracy did not improve from 0.58574\n","350/350 [==============================] - 661s 2s/step - loss: 1.7212 - loss1/classifier_loss: 1.6252 - loss2/classifier_loss: 1.2970 - loss3/classifier_loss: 0.8446 - loss1/classifier_accuracy: 0.5457 - loss1/classifier_top5_acc: 0.8409 - loss1/classifier_macro_f1score: 0.2955 - loss2/classifier_accuracy: 0.6259 - loss2/classifier_top5_acc: 0.8914 - loss2/classifier_macro_f1score: 0.3765 - loss3/classifier_accuracy: 0.7439 - loss3/classifier_top5_acc: 0.9486 - loss3/classifier_macro_f1score: 0.4846 - val_loss: 2.6407 - val_loss1/classifier_loss: 1.6543 - val_loss2/classifier_loss: 1.6256 - val_loss3/classifier_loss: 1.6567 - val_loss1/classifier_accuracy: 0.5453 - val_loss1/classifier_top5_acc: 0.8367 - val_loss1/classifier_macro_f1score: 0.3037 - val_loss2/classifier_accuracy: 0.5711 - val_loss2/classifier_top5_acc: 0.8476 - val_loss2/classifier_macro_f1score: 0.3573 - val_loss3/classifier_accuracy: 0.5841 - val_loss3/classifier_top5_acc: 0.8540 - val_loss3/classifier_macro_f1score: 0.3873\n","Learning rate:  0.0003\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.0003.\n","Epoch 30/70\n","350/350 [==============================] - ETA: 0s - loss: 1.6789 - loss1/classifier_loss: 1.6009 - loss2/classifier_loss: 1.2761 - loss3/classifier_loss: 0.8158 - loss1/classifier_accuracy: 0.5525 - loss1/classifier_top5_acc: 0.8444 - loss1/classifier_macro_f1score: 0.3012 - loss2/classifier_accuracy: 0.6326 - loss2/classifier_top5_acc: 0.8939 - loss2/classifier_macro_f1score: 0.3839 - loss3/classifier_accuracy: 0.7541 - loss3/classifier_top5_acc: 0.9524 - loss3/classifier_macro_f1score: 0.4941\n","Epoch 00030: val_loss did not improve from 2.53142\n","\n","Epoch 00030: val_loss3/classifier_accuracy improved from 0.58574 to 0.59315, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/030.h5\n","350/350 [==============================] - 638s 2s/step - loss: 1.6789 - loss1/classifier_loss: 1.6009 - loss2/classifier_loss: 1.2761 - loss3/classifier_loss: 0.8158 - loss1/classifier_accuracy: 0.5525 - loss1/classifier_top5_acc: 0.8444 - loss1/classifier_macro_f1score: 0.3012 - loss2/classifier_accuracy: 0.6326 - loss2/classifier_top5_acc: 0.8939 - loss2/classifier_macro_f1score: 0.3839 - loss3/classifier_accuracy: 0.7541 - loss3/classifier_top5_acc: 0.9524 - loss3/classifier_macro_f1score: 0.4941 - val_loss: 2.5402 - val_loss1/classifier_loss: 1.6593 - val_loss2/classifier_loss: 1.5728 - val_loss3/classifier_loss: 1.5706 - val_loss1/classifier_accuracy: 0.5423 - val_loss1/classifier_top5_acc: 0.8373 - val_loss1/classifier_macro_f1score: 0.3062 - val_loss2/classifier_accuracy: 0.5725 - val_loss2/classifier_top5_acc: 0.8566 - val_loss2/classifier_macro_f1score: 0.3439 - val_loss3/classifier_accuracy: 0.5931 - val_loss3/classifier_top5_acc: 0.8574 - val_loss3/classifier_macro_f1score: 0.3817\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 31/70\n","350/350 [==============================] - ETA: 0s - loss: 1.3315 - loss1/classifier_loss: 1.4570 - loss2/classifier_loss: 1.0789 - loss3/classifier_loss: 0.5708 - loss1/classifier_accuracy: 0.5869 - loss1/classifier_top5_acc: 0.8669 - loss1/classifier_macro_f1score: 0.3330 - loss2/classifier_accuracy: 0.6831 - loss2/classifier_top5_acc: 0.9191 - loss2/classifier_macro_f1score: 0.4290 - loss3/classifier_accuracy: 0.8234 - loss3/classifier_top5_acc: 0.9724 - loss3/classifier_macro_f1score: 0.5601\n","Epoch 00031: val_loss improved from 2.53142 to 2.49745, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/031.h5\n","\n","Epoch 00031: val_loss3/classifier_accuracy improved from 0.59315 to 0.62720, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/031.h5\n","350/350 [==============================] - 637s 2s/step - loss: 1.3315 - loss1/classifier_loss: 1.4570 - loss2/classifier_loss: 1.0789 - loss3/classifier_loss: 0.5708 - loss1/classifier_accuracy: 0.5869 - loss1/classifier_top5_acc: 0.8669 - loss1/classifier_macro_f1score: 0.3330 - loss2/classifier_accuracy: 0.6831 - loss2/classifier_top5_acc: 0.9191 - loss2/classifier_macro_f1score: 0.4290 - loss3/classifier_accuracy: 0.8234 - loss3/classifier_top5_acc: 0.9724 - loss3/classifier_macro_f1score: 0.5601 - val_loss: 2.4975 - val_loss1/classifier_loss: 1.5924 - val_loss2/classifier_loss: 1.5100 - val_loss3/classifier_loss: 1.5667 - val_loss1/classifier_accuracy: 0.5645 - val_loss1/classifier_top5_acc: 0.8474 - val_loss1/classifier_macro_f1score: 0.3209 - val_loss2/classifier_accuracy: 0.6036 - val_loss2/classifier_top5_acc: 0.8678 - val_loss2/classifier_macro_f1score: 0.3754 - val_loss3/classifier_accuracy: 0.6272 - val_loss3/classifier_top5_acc: 0.8774 - val_loss3/classifier_macro_f1score: 0.4196\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 32/70\n","350/350 [==============================] - ETA: 0s - loss: 1.2393 - loss1/classifier_loss: 1.4319 - loss2/classifier_loss: 1.0284 - loss3/classifier_loss: 0.5012 - loss1/classifier_accuracy: 0.5913 - loss1/classifier_top5_acc: 0.8717 - loss1/classifier_macro_f1score: 0.3383 - loss2/classifier_accuracy: 0.6964 - loss2/classifier_top5_acc: 0.9246 - loss2/classifier_macro_f1score: 0.4424 - loss3/classifier_accuracy: 0.8444 - loss3/classifier_top5_acc: 0.9768 - loss3/classifier_macro_f1score: 0.5824\n","Epoch 00032: val_loss did not improve from 2.49745\n","\n","Epoch 00032: val_loss3/classifier_accuracy improved from 0.62720 to 0.62881, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/032.h5\n","350/350 [==============================] - 638s 2s/step - loss: 1.2393 - loss1/classifier_loss: 1.4319 - loss2/classifier_loss: 1.0284 - loss3/classifier_loss: 0.5012 - loss1/classifier_accuracy: 0.5913 - loss1/classifier_top5_acc: 0.8717 - loss1/classifier_macro_f1score: 0.3383 - loss2/classifier_accuracy: 0.6964 - loss2/classifier_top5_acc: 0.9246 - loss2/classifier_macro_f1score: 0.4424 - loss3/classifier_accuracy: 0.8444 - loss3/classifier_top5_acc: 0.9768 - loss3/classifier_macro_f1score: 0.5824 - val_loss: 2.5000 - val_loss1/classifier_loss: 1.5762 - val_loss2/classifier_loss: 1.5005 - val_loss3/classifier_loss: 1.5770 - val_loss1/classifier_accuracy: 0.5673 - val_loss1/classifier_top5_acc: 0.8514 - val_loss1/classifier_macro_f1score: 0.3346 - val_loss2/classifier_accuracy: 0.6016 - val_loss2/classifier_top5_acc: 0.8702 - val_loss2/classifier_macro_f1score: 0.3904 - val_loss3/classifier_accuracy: 0.6288 - val_loss3/classifier_top5_acc: 0.8800 - val_loss3/classifier_macro_f1score: 0.4341\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 33/70\n","350/350 [==============================] - ETA: 0s - loss: 1.2127 - loss1/classifier_loss: 1.4205 - loss2/classifier_loss: 1.0107 - loss3/classifier_loss: 0.4834 - loss1/classifier_accuracy: 0.5941 - loss1/classifier_top5_acc: 0.8718 - loss1/classifier_macro_f1score: 0.3424 - loss2/classifier_accuracy: 0.6997 - loss2/classifier_top5_acc: 0.9274 - loss2/classifier_macro_f1score: 0.4465 - loss3/classifier_accuracy: 0.8484 - loss3/classifier_top5_acc: 0.9784 - loss3/classifier_macro_f1score: 0.5869\n","Epoch 00033: val_loss did not improve from 2.49745\n","\n","Epoch 00033: val_loss3/classifier_accuracy did not improve from 0.62881\n","350/350 [==============================] - 638s 2s/step - loss: 1.2127 - loss1/classifier_loss: 1.4205 - loss2/classifier_loss: 1.0107 - loss3/classifier_loss: 0.4834 - loss1/classifier_accuracy: 0.5941 - loss1/classifier_top5_acc: 0.8718 - loss1/classifier_macro_f1score: 0.3424 - loss2/classifier_accuracy: 0.6997 - loss2/classifier_top5_acc: 0.9274 - loss2/classifier_macro_f1score: 0.4465 - loss3/classifier_accuracy: 0.8484 - loss3/classifier_top5_acc: 0.9784 - loss3/classifier_macro_f1score: 0.5869 - val_loss: 2.5278 - val_loss1/classifier_loss: 1.5792 - val_loss2/classifier_loss: 1.5177 - val_loss3/classifier_loss: 1.5987 - val_loss1/classifier_accuracy: 0.5643 - val_loss1/classifier_top5_acc: 0.8518 - val_loss1/classifier_macro_f1score: 0.3294 - val_loss2/classifier_accuracy: 0.6010 - val_loss2/classifier_top5_acc: 0.8724 - val_loss2/classifier_macro_f1score: 0.3824 - val_loss3/classifier_accuracy: 0.6274 - val_loss3/classifier_top5_acc: 0.8780 - val_loss3/classifier_macro_f1score: 0.4270\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 34/70\n","350/350 [==============================] - ETA: 0s - loss: 1.1779 - loss1/classifier_loss: 1.3994 - loss2/classifier_loss: 0.9910 - loss3/classifier_loss: 0.4608 - loss1/classifier_accuracy: 0.5982 - loss1/classifier_top5_acc: 0.8755 - loss1/classifier_macro_f1score: 0.3493 - loss2/classifier_accuracy: 0.7056 - loss2/classifier_top5_acc: 0.9287 - loss2/classifier_macro_f1score: 0.4553 - loss3/classifier_accuracy: 0.8553 - loss3/classifier_top5_acc: 0.9798 - loss3/classifier_macro_f1score: 0.5941\n","Epoch 00034: val_loss did not improve from 2.49745\n","\n","Epoch 00034: val_loss3/classifier_accuracy improved from 0.62881 to 0.63301, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/034.h5\n","350/350 [==============================] - 636s 2s/step - loss: 1.1779 - loss1/classifier_loss: 1.3994 - loss2/classifier_loss: 0.9910 - loss3/classifier_loss: 0.4608 - loss1/classifier_accuracy: 0.5982 - loss1/classifier_top5_acc: 0.8755 - loss1/classifier_macro_f1score: 0.3493 - loss2/classifier_accuracy: 0.7056 - loss2/classifier_top5_acc: 0.9287 - loss2/classifier_macro_f1score: 0.4553 - loss3/classifier_accuracy: 0.8553 - loss3/classifier_top5_acc: 0.9798 - loss3/classifier_macro_f1score: 0.5941 - val_loss: 2.5268 - val_loss1/classifier_loss: 1.5634 - val_loss2/classifier_loss: 1.5090 - val_loss3/classifier_loss: 1.6050 - val_loss1/classifier_accuracy: 0.5687 - val_loss1/classifier_top5_acc: 0.8542 - val_loss1/classifier_macro_f1score: 0.3321 - val_loss2/classifier_accuracy: 0.6052 - val_loss2/classifier_top5_acc: 0.8742 - val_loss2/classifier_macro_f1score: 0.3823 - val_loss3/classifier_accuracy: 0.6330 - val_loss3/classifier_top5_acc: 0.8774 - val_loss3/classifier_macro_f1score: 0.4247\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 35/70\n","350/350 [==============================] - ETA: 0s - loss: 1.1555 - loss1/classifier_loss: 1.3837 - loss2/classifier_loss: 0.9796 - loss3/classifier_loss: 0.4465 - loss1/classifier_accuracy: 0.6052 - loss1/classifier_top5_acc: 0.8764 - loss1/classifier_macro_f1score: 0.3481 - loss2/classifier_accuracy: 0.7098 - loss2/classifier_top5_acc: 0.9307 - loss2/classifier_macro_f1score: 0.4565 - loss3/classifier_accuracy: 0.8618 - loss3/classifier_top5_acc: 0.9803 - loss3/classifier_macro_f1score: 0.5970\n","Epoch 00035: val_loss did not improve from 2.49745\n","\n","Epoch 00035: val_loss3/classifier_accuracy improved from 0.63301 to 0.63321, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/035.h5\n","350/350 [==============================] - 631s 2s/step - loss: 1.1555 - loss1/classifier_loss: 1.3837 - loss2/classifier_loss: 0.9796 - loss3/classifier_loss: 0.4465 - loss1/classifier_accuracy: 0.6052 - loss1/classifier_top5_acc: 0.8764 - loss1/classifier_macro_f1score: 0.3481 - loss2/classifier_accuracy: 0.7098 - loss2/classifier_top5_acc: 0.9307 - loss2/classifier_macro_f1score: 0.4565 - loss3/classifier_accuracy: 0.8618 - loss3/classifier_top5_acc: 0.9803 - loss3/classifier_macro_f1score: 0.5970 - val_loss: 2.5481 - val_loss1/classifier_loss: 1.5580 - val_loss2/classifier_loss: 1.5035 - val_loss3/classifier_loss: 1.6296 - val_loss1/classifier_accuracy: 0.5715 - val_loss1/classifier_top5_acc: 0.8566 - val_loss1/classifier_macro_f1score: 0.3422 - val_loss2/classifier_accuracy: 0.6082 - val_loss2/classifier_top5_acc: 0.8712 - val_loss2/classifier_macro_f1score: 0.3924 - val_loss3/classifier_accuracy: 0.6332 - val_loss3/classifier_top5_acc: 0.8800 - val_loss3/classifier_macro_f1score: 0.4285\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 36/70\n","350/350 [==============================] - ETA: 0s - loss: 1.1350 - loss1/classifier_loss: 1.3876 - loss2/classifier_loss: 0.9620 - loss3/classifier_loss: 0.4301 - loss1/classifier_accuracy: 0.6019 - loss1/classifier_top5_acc: 0.8796 - loss1/classifier_macro_f1score: 0.3512 - loss2/classifier_accuracy: 0.7136 - loss2/classifier_top5_acc: 0.9326 - loss2/classifier_macro_f1score: 0.4603 - loss3/classifier_accuracy: 0.8628 - loss3/classifier_top5_acc: 0.9825 - loss3/classifier_macro_f1score: 0.5996\n","Epoch 00036: val_loss did not improve from 2.49745\n","\n","Epoch 00036: val_loss3/classifier_accuracy did not improve from 0.63321\n","350/350 [==============================] - 623s 2s/step - loss: 1.1350 - loss1/classifier_loss: 1.3876 - loss2/classifier_loss: 0.9620 - loss3/classifier_loss: 0.4301 - loss1/classifier_accuracy: 0.6019 - loss1/classifier_top5_acc: 0.8796 - loss1/classifier_macro_f1score: 0.3512 - loss2/classifier_accuracy: 0.7136 - loss2/classifier_top5_acc: 0.9326 - loss2/classifier_macro_f1score: 0.4603 - loss3/classifier_accuracy: 0.8628 - loss3/classifier_top5_acc: 0.9825 - loss3/classifier_macro_f1score: 0.5996 - val_loss: 2.5935 - val_loss1/classifier_loss: 1.5783 - val_loss2/classifier_loss: 1.5421 - val_loss3/classifier_loss: 1.6574 - val_loss1/classifier_accuracy: 0.5665 - val_loss1/classifier_top5_acc: 0.8534 - val_loss1/classifier_macro_f1score: 0.3318 - val_loss2/classifier_accuracy: 0.6020 - val_loss2/classifier_top5_acc: 0.8670 - val_loss2/classifier_macro_f1score: 0.3845 - val_loss3/classifier_accuracy: 0.6280 - val_loss3/classifier_top5_acc: 0.8782 - val_loss3/classifier_macro_f1score: 0.4225\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 37/70\n","350/350 [==============================] - ETA: 0s - loss: 1.1296 - loss1/classifier_loss: 1.3812 - loss2/classifier_loss: 0.9672 - loss3/classifier_loss: 0.4251 - loss1/classifier_accuracy: 0.6086 - loss1/classifier_top5_acc: 0.8791 - loss1/classifier_macro_f1score: 0.3497 - loss2/classifier_accuracy: 0.7131 - loss2/classifier_top5_acc: 0.9319 - loss2/classifier_macro_f1score: 0.4584 - loss3/classifier_accuracy: 0.8653 - loss3/classifier_top5_acc: 0.9824 - loss3/classifier_macro_f1score: 0.5996\n","Epoch 00037: val_loss did not improve from 2.49745\n","\n","Epoch 00037: val_loss3/classifier_accuracy did not improve from 0.63321\n","350/350 [==============================] - 626s 2s/step - loss: 1.1296 - loss1/classifier_loss: 1.3812 - loss2/classifier_loss: 0.9672 - loss3/classifier_loss: 0.4251 - loss1/classifier_accuracy: 0.6086 - loss1/classifier_top5_acc: 0.8791 - loss1/classifier_macro_f1score: 0.3497 - loss2/classifier_accuracy: 0.7131 - loss2/classifier_top5_acc: 0.9319 - loss2/classifier_macro_f1score: 0.4584 - loss3/classifier_accuracy: 0.8653 - loss3/classifier_top5_acc: 0.9824 - loss3/classifier_macro_f1score: 0.5996 - val_loss: 2.5756 - val_loss1/classifier_loss: 1.5836 - val_loss2/classifier_loss: 1.5253 - val_loss3/classifier_loss: 1.6430 - val_loss1/classifier_accuracy: 0.5627 - val_loss1/classifier_top5_acc: 0.8502 - val_loss1/classifier_macro_f1score: 0.3396 - val_loss2/classifier_accuracy: 0.6052 - val_loss2/classifier_top5_acc: 0.8666 - val_loss2/classifier_macro_f1score: 0.3902 - val_loss3/classifier_accuracy: 0.6258 - val_loss3/classifier_top5_acc: 0.8768 - val_loss3/classifier_macro_f1score: 0.4276\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 38/70\n","350/350 [==============================] - ETA: 0s - loss: 1.1125 - loss1/classifier_loss: 1.3759 - loss2/classifier_loss: 0.9601 - loss3/classifier_loss: 0.4117 - loss1/classifier_accuracy: 0.6069 - loss1/classifier_top5_acc: 0.8797 - loss1/classifier_macro_f1score: 0.3530 - loss2/classifier_accuracy: 0.7147 - loss2/classifier_top5_acc: 0.9341 - loss2/classifier_macro_f1score: 0.4612 - loss3/classifier_accuracy: 0.8703 - loss3/classifier_top5_acc: 0.9831 - loss3/classifier_macro_f1score: 0.6079\n","Epoch 00038: val_loss did not improve from 2.49745\n","\n","Epoch 00038: val_loss3/classifier_accuracy did not improve from 0.63321\n","350/350 [==============================] - 630s 2s/step - loss: 1.1125 - loss1/classifier_loss: 1.3759 - loss2/classifier_loss: 0.9601 - loss3/classifier_loss: 0.4117 - loss1/classifier_accuracy: 0.6069 - loss1/classifier_top5_acc: 0.8797 - loss1/classifier_macro_f1score: 0.3530 - loss2/classifier_accuracy: 0.7147 - loss2/classifier_top5_acc: 0.9341 - loss2/classifier_macro_f1score: 0.4612 - loss3/classifier_accuracy: 0.8703 - loss3/classifier_top5_acc: 0.9831 - loss3/classifier_macro_f1score: 0.6079 - val_loss: 2.5755 - val_loss1/classifier_loss: 1.5609 - val_loss2/classifier_loss: 1.5150 - val_loss3/classifier_loss: 1.6527 - val_loss1/classifier_accuracy: 0.5657 - val_loss1/classifier_top5_acc: 0.8562 - val_loss1/classifier_macro_f1score: 0.3327 - val_loss2/classifier_accuracy: 0.6040 - val_loss2/classifier_top5_acc: 0.8688 - val_loss2/classifier_macro_f1score: 0.3904 - val_loss3/classifier_accuracy: 0.6310 - val_loss3/classifier_top5_acc: 0.8768 - val_loss3/classifier_macro_f1score: 0.4288\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 39/70\n","350/350 [==============================] - ETA: 0s - loss: 1.0982 - loss1/classifier_loss: 1.3786 - loss2/classifier_loss: 0.9478 - loss3/classifier_loss: 0.4003 - loss1/classifier_accuracy: 0.6052 - loss1/classifier_top5_acc: 0.8785 - loss1/classifier_macro_f1score: 0.3516 - loss2/classifier_accuracy: 0.7182 - loss2/classifier_top5_acc: 0.9346 - loss2/classifier_macro_f1score: 0.4659 - loss3/classifier_accuracy: 0.8719 - loss3/classifier_top5_acc: 0.9836 - loss3/classifier_macro_f1score: 0.6090\n","Epoch 00039: val_loss did not improve from 2.49745\n","\n","Epoch 00039: val_loss3/classifier_accuracy did not improve from 0.63321\n","350/350 [==============================] - 648s 2s/step - loss: 1.0982 - loss1/classifier_loss: 1.3786 - loss2/classifier_loss: 0.9478 - loss3/classifier_loss: 0.4003 - loss1/classifier_accuracy: 0.6052 - loss1/classifier_top5_acc: 0.8785 - loss1/classifier_macro_f1score: 0.3516 - loss2/classifier_accuracy: 0.7182 - loss2/classifier_top5_acc: 0.9346 - loss2/classifier_macro_f1score: 0.4659 - loss3/classifier_accuracy: 0.8719 - loss3/classifier_top5_acc: 0.9836 - loss3/classifier_macro_f1score: 0.6090 - val_loss: 2.6002 - val_loss1/classifier_loss: 1.5661 - val_loss2/classifier_loss: 1.5205 - val_loss3/classifier_loss: 1.6742 - val_loss1/classifier_accuracy: 0.5709 - val_loss1/classifier_top5_acc: 0.8540 - val_loss1/classifier_macro_f1score: 0.3329 - val_loss2/classifier_accuracy: 0.6062 - val_loss2/classifier_top5_acc: 0.8690 - val_loss2/classifier_macro_f1score: 0.3901 - val_loss3/classifier_accuracy: 0.6242 - val_loss3/classifier_top5_acc: 0.8782 - val_loss3/classifier_macro_f1score: 0.4260\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 40/70\n","350/350 [==============================] - ETA: 0s - loss: 1.0885 - loss1/classifier_loss: 1.3617 - loss2/classifier_loss: 0.9470 - loss3/classifier_loss: 0.3959 - loss1/classifier_accuracy: 0.6103 - loss1/classifier_top5_acc: 0.8818 - loss1/classifier_macro_f1score: 0.3579 - loss2/classifier_accuracy: 0.7170 - loss2/classifier_top5_acc: 0.9326 - loss2/classifier_macro_f1score: 0.4646 - loss3/classifier_accuracy: 0.8748 - loss3/classifier_top5_acc: 0.9842 - loss3/classifier_macro_f1score: 0.6129\n","Epoch 00040: val_loss did not improve from 2.49745\n","\n","Epoch 00040: val_loss3/classifier_accuracy did not improve from 0.63321\n","350/350 [==============================] - 668s 2s/step - loss: 1.0885 - loss1/classifier_loss: 1.3617 - loss2/classifier_loss: 0.9470 - loss3/classifier_loss: 0.3959 - loss1/classifier_accuracy: 0.6103 - loss1/classifier_top5_acc: 0.8818 - loss1/classifier_macro_f1score: 0.3579 - loss2/classifier_accuracy: 0.7170 - loss2/classifier_top5_acc: 0.9326 - loss2/classifier_macro_f1score: 0.4646 - loss3/classifier_accuracy: 0.8748 - loss3/classifier_top5_acc: 0.9842 - loss3/classifier_macro_f1score: 0.6129 - val_loss: 2.6019 - val_loss1/classifier_loss: 1.5558 - val_loss2/classifier_loss: 1.5249 - val_loss3/classifier_loss: 1.6777 - val_loss1/classifier_accuracy: 0.5673 - val_loss1/classifier_top5_acc: 0.8548 - val_loss1/classifier_macro_f1score: 0.3402 - val_loss2/classifier_accuracy: 0.6044 - val_loss2/classifier_top5_acc: 0.8680 - val_loss2/classifier_macro_f1score: 0.3918 - val_loss3/classifier_accuracy: 0.6282 - val_loss3/classifier_top5_acc: 0.8764 - val_loss3/classifier_macro_f1score: 0.4294\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 41/70\n","350/350 [==============================] - ETA: 0s - loss: 1.0764 - loss1/classifier_loss: 1.3639 - loss2/classifier_loss: 0.9462 - loss3/classifier_loss: 0.3834 - loss1/classifier_accuracy: 0.6086 - loss1/classifier_top5_acc: 0.8823 - loss1/classifier_macro_f1score: 0.3537 - loss2/classifier_accuracy: 0.7171 - loss2/classifier_top5_acc: 0.9349 - loss2/classifier_macro_f1score: 0.4643 - loss3/classifier_accuracy: 0.8778 - loss3/classifier_top5_acc: 0.9857 - loss3/classifier_macro_f1score: 0.6118\n","Epoch 00041: val_loss did not improve from 2.49745\n","\n","Epoch 00041: val_loss3/classifier_accuracy did not improve from 0.63321\n","350/350 [==============================] - 669s 2s/step - loss: 1.0764 - loss1/classifier_loss: 1.3639 - loss2/classifier_loss: 0.9462 - loss3/classifier_loss: 0.3834 - loss1/classifier_accuracy: 0.6086 - loss1/classifier_top5_acc: 0.8823 - loss1/classifier_macro_f1score: 0.3537 - loss2/classifier_accuracy: 0.7171 - loss2/classifier_top5_acc: 0.9349 - loss2/classifier_macro_f1score: 0.4643 - loss3/classifier_accuracy: 0.8778 - loss3/classifier_top5_acc: 0.9857 - loss3/classifier_macro_f1score: 0.6118 - val_loss: 2.6484 - val_loss1/classifier_loss: 1.5696 - val_loss2/classifier_loss: 1.5297 - val_loss3/classifier_loss: 1.7186 - val_loss1/classifier_accuracy: 0.5661 - val_loss1/classifier_top5_acc: 0.8538 - val_loss1/classifier_macro_f1score: 0.3352 - val_loss2/classifier_accuracy: 0.6032 - val_loss2/classifier_top5_acc: 0.8674 - val_loss2/classifier_macro_f1score: 0.3897 - val_loss3/classifier_accuracy: 0.6276 - val_loss3/classifier_top5_acc: 0.8772 - val_loss3/classifier_macro_f1score: 0.4230\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 42/70\n","350/350 [==============================] - ETA: 0s - loss: 1.0581 - loss1/classifier_loss: 1.3371 - loss2/classifier_loss: 0.9227 - loss3/classifier_loss: 0.3802 - loss1/classifier_accuracy: 0.6172 - loss1/classifier_top5_acc: 0.8843 - loss1/classifier_macro_f1score: 0.3631 - loss2/classifier_accuracy: 0.7261 - loss2/classifier_top5_acc: 0.9358 - loss2/classifier_macro_f1score: 0.4699 - loss3/classifier_accuracy: 0.8799 - loss3/classifier_top5_acc: 0.9856 - loss3/classifier_macro_f1score: 0.6144\n","Epoch 00042: val_loss did not improve from 2.49745\n","\n","Epoch 00042: val_loss3/classifier_accuracy improved from 0.63321 to 0.63341, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/042.h5\n","350/350 [==============================] - 661s 2s/step - loss: 1.0581 - loss1/classifier_loss: 1.3371 - loss2/classifier_loss: 0.9227 - loss3/classifier_loss: 0.3802 - loss1/classifier_accuracy: 0.6172 - loss1/classifier_top5_acc: 0.8843 - loss1/classifier_macro_f1score: 0.3631 - loss2/classifier_accuracy: 0.7261 - loss2/classifier_top5_acc: 0.9358 - loss2/classifier_macro_f1score: 0.4699 - loss3/classifier_accuracy: 0.8799 - loss3/classifier_top5_acc: 0.9856 - loss3/classifier_macro_f1score: 0.6144 - val_loss: 2.6026 - val_loss1/classifier_loss: 1.5561 - val_loss2/classifier_loss: 1.5160 - val_loss3/classifier_loss: 1.6810 - val_loss1/classifier_accuracy: 0.5723 - val_loss1/classifier_top5_acc: 0.8576 - val_loss1/classifier_macro_f1score: 0.3375 - val_loss2/classifier_accuracy: 0.6108 - val_loss2/classifier_top5_acc: 0.8700 - val_loss2/classifier_macro_f1score: 0.3873 - val_loss3/classifier_accuracy: 0.6334 - val_loss3/classifier_top5_acc: 0.8756 - val_loss3/classifier_macro_f1score: 0.4255\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 43/70\n","350/350 [==============================] - ETA: 0s - loss: 1.0521 - loss1/classifier_loss: 1.3452 - loss2/classifier_loss: 0.9236 - loss3/classifier_loss: 0.3715 - loss1/classifier_accuracy: 0.6129 - loss1/classifier_top5_acc: 0.8859 - loss1/classifier_macro_f1score: 0.3610 - loss2/classifier_accuracy: 0.7252 - loss2/classifier_top5_acc: 0.9370 - loss2/classifier_macro_f1score: 0.4708 - loss3/classifier_accuracy: 0.8821 - loss3/classifier_top5_acc: 0.9861 - loss3/classifier_macro_f1score: 0.6188\n","Epoch 00043: val_loss did not improve from 2.49745\n","\n","Epoch 00043: val_loss3/classifier_accuracy did not improve from 0.63341\n","350/350 [==============================] - 653s 2s/step - loss: 1.0521 - loss1/classifier_loss: 1.3452 - loss2/classifier_loss: 0.9236 - loss3/classifier_loss: 0.3715 - loss1/classifier_accuracy: 0.6129 - loss1/classifier_top5_acc: 0.8859 - loss1/classifier_macro_f1score: 0.3610 - loss2/classifier_accuracy: 0.7252 - loss2/classifier_top5_acc: 0.9370 - loss2/classifier_macro_f1score: 0.4708 - loss3/classifier_accuracy: 0.8821 - loss3/classifier_top5_acc: 0.9861 - loss3/classifier_macro_f1score: 0.6188 - val_loss: 2.6203 - val_loss1/classifier_loss: 1.5551 - val_loss2/classifier_loss: 1.5259 - val_loss3/classifier_loss: 1.6960 - val_loss1/classifier_accuracy: 0.5709 - val_loss1/classifier_top5_acc: 0.8562 - val_loss1/classifier_macro_f1score: 0.3350 - val_loss2/classifier_accuracy: 0.6038 - val_loss2/classifier_top5_acc: 0.8732 - val_loss2/classifier_macro_f1score: 0.3826 - val_loss3/classifier_accuracy: 0.6256 - val_loss3/classifier_top5_acc: 0.8784 - val_loss3/classifier_macro_f1score: 0.4215\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 44/70\n","350/350 [==============================] - ETA: 0s - loss: 1.0388 - loss1/classifier_loss: 1.3462 - loss2/classifier_loss: 0.9133 - loss3/classifier_loss: 0.3610 - loss1/classifier_accuracy: 0.6136 - loss1/classifier_top5_acc: 0.8843 - loss1/classifier_macro_f1score: 0.3606 - loss2/classifier_accuracy: 0.7257 - loss2/classifier_top5_acc: 0.9371 - loss2/classifier_macro_f1score: 0.4712 - loss3/classifier_accuracy: 0.8844 - loss3/classifier_top5_acc: 0.9870 - loss3/classifier_macro_f1score: 0.6177\n","Epoch 00044: val_loss did not improve from 2.49745\n","\n","Epoch 00044: val_loss3/classifier_accuracy did not improve from 0.63341\n","350/350 [==============================] - 655s 2s/step - loss: 1.0388 - loss1/classifier_loss: 1.3462 - loss2/classifier_loss: 0.9133 - loss3/classifier_loss: 0.3610 - loss1/classifier_accuracy: 0.6136 - loss1/classifier_top5_acc: 0.8843 - loss1/classifier_macro_f1score: 0.3606 - loss2/classifier_accuracy: 0.7257 - loss2/classifier_top5_acc: 0.9371 - loss2/classifier_macro_f1score: 0.4712 - loss3/classifier_accuracy: 0.8844 - loss3/classifier_top5_acc: 0.9870 - loss3/classifier_macro_f1score: 0.6177 - val_loss: 2.6654 - val_loss1/classifier_loss: 1.5647 - val_loss2/classifier_loss: 1.5407 - val_loss3/classifier_loss: 1.7337 - val_loss1/classifier_accuracy: 0.5727 - val_loss1/classifier_top5_acc: 0.8522 - val_loss1/classifier_macro_f1score: 0.3388 - val_loss2/classifier_accuracy: 0.6076 - val_loss2/classifier_top5_acc: 0.8730 - val_loss2/classifier_macro_f1score: 0.3916 - val_loss3/classifier_accuracy: 0.6310 - val_loss3/classifier_top5_acc: 0.8782 - val_loss3/classifier_macro_f1score: 0.4264\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 45/70\n","350/350 [==============================] - ETA: 0s - loss: 1.0367 - loss1/classifier_loss: 1.3414 - loss2/classifier_loss: 0.9165 - loss3/classifier_loss: 0.3594 - loss1/classifier_accuracy: 0.6166 - loss1/classifier_top5_acc: 0.8850 - loss1/classifier_macro_f1score: 0.3639 - loss2/classifier_accuracy: 0.7243 - loss2/classifier_top5_acc: 0.9379 - loss2/classifier_macro_f1score: 0.4740 - loss3/classifier_accuracy: 0.8851 - loss3/classifier_top5_acc: 0.9865 - loss3/classifier_macro_f1score: 0.6229\n","Epoch 00045: val_loss did not improve from 2.49745\n","\n","Epoch 00045: val_loss3/classifier_accuracy did not improve from 0.63341\n","350/350 [==============================] - 640s 2s/step - loss: 1.0367 - loss1/classifier_loss: 1.3414 - loss2/classifier_loss: 0.9165 - loss3/classifier_loss: 0.3594 - loss1/classifier_accuracy: 0.6166 - loss1/classifier_top5_acc: 0.8850 - loss1/classifier_macro_f1score: 0.3639 - loss2/classifier_accuracy: 0.7243 - loss2/classifier_top5_acc: 0.9379 - loss2/classifier_macro_f1score: 0.4740 - loss3/classifier_accuracy: 0.8851 - loss3/classifier_top5_acc: 0.9865 - loss3/classifier_macro_f1score: 0.6229 - val_loss: 2.6534 - val_loss1/classifier_loss: 1.5611 - val_loss2/classifier_loss: 1.5289 - val_loss3/classifier_loss: 1.7264 - val_loss1/classifier_accuracy: 0.5705 - val_loss1/classifier_top5_acc: 0.8546 - val_loss1/classifier_macro_f1score: 0.3373 - val_loss2/classifier_accuracy: 0.6090 - val_loss2/classifier_top5_acc: 0.8696 - val_loss2/classifier_macro_f1score: 0.3885 - val_loss3/classifier_accuracy: 0.6288 - val_loss3/classifier_top5_acc: 0.8760 - val_loss3/classifier_macro_f1score: 0.4231\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 46/70\n","350/350 [==============================] - ETA: 0s - loss: 1.0267 - loss1/classifier_loss: 1.3382 - loss2/classifier_loss: 0.9180 - loss3/classifier_loss: 0.3499 - loss1/classifier_accuracy: 0.6179 - loss1/classifier_top5_acc: 0.8852 - loss1/classifier_macro_f1score: 0.3620 - loss2/classifier_accuracy: 0.7248 - loss2/classifier_top5_acc: 0.9359 - loss2/classifier_macro_f1score: 0.4709 - loss3/classifier_accuracy: 0.8880 - loss3/classifier_top5_acc: 0.9879 - loss3/classifier_macro_f1score: 0.6226\n","Epoch 00046: val_loss did not improve from 2.49745\n","\n","Epoch 00046: val_loss3/classifier_accuracy did not improve from 0.63341\n","350/350 [==============================] - 642s 2s/step - loss: 1.0267 - loss1/classifier_loss: 1.3382 - loss2/classifier_loss: 0.9180 - loss3/classifier_loss: 0.3499 - loss1/classifier_accuracy: 0.6179 - loss1/classifier_top5_acc: 0.8852 - loss1/classifier_macro_f1score: 0.3620 - loss2/classifier_accuracy: 0.7248 - loss2/classifier_top5_acc: 0.9359 - loss2/classifier_macro_f1score: 0.4709 - loss3/classifier_accuracy: 0.8880 - loss3/classifier_top5_acc: 0.9879 - loss3/classifier_macro_f1score: 0.6226 - val_loss: 2.6150 - val_loss1/classifier_loss: 1.5475 - val_loss2/classifier_loss: 1.5070 - val_loss3/classifier_loss: 1.6986 - val_loss1/classifier_accuracy: 0.5737 - val_loss1/classifier_top5_acc: 0.8554 - val_loss1/classifier_macro_f1score: 0.3416 - val_loss2/classifier_accuracy: 0.6084 - val_loss2/classifier_top5_acc: 0.8762 - val_loss2/classifier_macro_f1score: 0.3934 - val_loss3/classifier_accuracy: 0.6310 - val_loss3/classifier_top5_acc: 0.8786 - val_loss3/classifier_macro_f1score: 0.4344\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 47/70\n","350/350 [==============================] - ETA: 0s - loss: 1.0103 - loss1/classifier_loss: 1.3284 - loss2/classifier_loss: 0.8973 - loss3/classifier_loss: 0.3426 - loss1/classifier_accuracy: 0.6175 - loss1/classifier_top5_acc: 0.8876 - loss1/classifier_macro_f1score: 0.3615 - loss2/classifier_accuracy: 0.7305 - loss2/classifier_top5_acc: 0.9390 - loss2/classifier_macro_f1score: 0.4758 - loss3/classifier_accuracy: 0.8897 - loss3/classifier_top5_acc: 0.9885 - loss3/classifier_macro_f1score: 0.6241\n","Epoch 00047: val_loss did not improve from 2.49745\n","\n","Epoch 00047: val_loss3/classifier_accuracy did not improve from 0.63341\n","350/350 [==============================] - 642s 2s/step - loss: 1.0103 - loss1/classifier_loss: 1.3284 - loss2/classifier_loss: 0.8973 - loss3/classifier_loss: 0.3426 - loss1/classifier_accuracy: 0.6175 - loss1/classifier_top5_acc: 0.8876 - loss1/classifier_macro_f1score: 0.3615 - loss2/classifier_accuracy: 0.7305 - loss2/classifier_top5_acc: 0.9390 - loss2/classifier_macro_f1score: 0.4758 - loss3/classifier_accuracy: 0.8897 - loss3/classifier_top5_acc: 0.9885 - loss3/classifier_macro_f1score: 0.6241 - val_loss: 2.6704 - val_loss1/classifier_loss: 1.5506 - val_loss2/classifier_loss: 1.5368 - val_loss3/classifier_loss: 1.7442 - val_loss1/classifier_accuracy: 0.5735 - val_loss1/classifier_top5_acc: 0.8574 - val_loss1/classifier_macro_f1score: 0.3457 - val_loss2/classifier_accuracy: 0.6108 - val_loss2/classifier_top5_acc: 0.8708 - val_loss2/classifier_macro_f1score: 0.3959 - val_loss3/classifier_accuracy: 0.6280 - val_loss3/classifier_top5_acc: 0.8772 - val_loss3/classifier_macro_f1score: 0.4329\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 48/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9972 - loss1/classifier_loss: 1.3237 - loss2/classifier_loss: 0.8883 - loss3/classifier_loss: 0.3336 - loss1/classifier_accuracy: 0.6204 - loss1/classifier_top5_acc: 0.8875 - loss1/classifier_macro_f1score: 0.3641 - loss2/classifier_accuracy: 0.7329 - loss2/classifier_top5_acc: 0.9430 - loss2/classifier_macro_f1score: 0.4782 - loss3/classifier_accuracy: 0.8916 - loss3/classifier_top5_acc: 0.9885 - loss3/classifier_macro_f1score: 0.6266\n","Epoch 00048: val_loss did not improve from 2.49745\n","\n","Epoch 00048: val_loss3/classifier_accuracy did not improve from 0.63341\n","350/350 [==============================] - 634s 2s/step - loss: 0.9972 - loss1/classifier_loss: 1.3237 - loss2/classifier_loss: 0.8883 - loss3/classifier_loss: 0.3336 - loss1/classifier_accuracy: 0.6204 - loss1/classifier_top5_acc: 0.8875 - loss1/classifier_macro_f1score: 0.3641 - loss2/classifier_accuracy: 0.7329 - loss2/classifier_top5_acc: 0.9430 - loss2/classifier_macro_f1score: 0.4782 - loss3/classifier_accuracy: 0.8916 - loss3/classifier_top5_acc: 0.9885 - loss3/classifier_macro_f1score: 0.6266 - val_loss: 2.7001 - val_loss1/classifier_loss: 1.5611 - val_loss2/classifier_loss: 1.5498 - val_loss3/classifier_loss: 1.7668 - val_loss1/classifier_accuracy: 0.5709 - val_loss1/classifier_top5_acc: 0.8530 - val_loss1/classifier_macro_f1score: 0.3423 - val_loss2/classifier_accuracy: 0.6052 - val_loss2/classifier_top5_acc: 0.8692 - val_loss2/classifier_macro_f1score: 0.3928 - val_loss3/classifier_accuracy: 0.6292 - val_loss3/classifier_top5_acc: 0.8766 - val_loss3/classifier_macro_f1score: 0.4305\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 49/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9972 - loss1/classifier_loss: 1.3249 - loss2/classifier_loss: 0.8962 - loss3/classifier_loss: 0.3309 - loss1/classifier_accuracy: 0.6202 - loss1/classifier_top5_acc: 0.8848 - loss1/classifier_macro_f1score: 0.3662 - loss2/classifier_accuracy: 0.7299 - loss2/classifier_top5_acc: 0.9398 - loss2/classifier_macro_f1score: 0.4759 - loss3/classifier_accuracy: 0.8935 - loss3/classifier_top5_acc: 0.9887 - loss3/classifier_macro_f1score: 0.6273\n","Epoch 00049: val_loss did not improve from 2.49745\n","\n","Epoch 00049: val_loss3/classifier_accuracy did not improve from 0.63341\n","350/350 [==============================] - 635s 2s/step - loss: 0.9972 - loss1/classifier_loss: 1.3249 - loss2/classifier_loss: 0.8962 - loss3/classifier_loss: 0.3309 - loss1/classifier_accuracy: 0.6202 - loss1/classifier_top5_acc: 0.8848 - loss1/classifier_macro_f1score: 0.3662 - loss2/classifier_accuracy: 0.7299 - loss2/classifier_top5_acc: 0.9398 - loss2/classifier_macro_f1score: 0.4759 - loss3/classifier_accuracy: 0.8935 - loss3/classifier_top5_acc: 0.9887 - loss3/classifier_macro_f1score: 0.6273 - val_loss: 2.6847 - val_loss1/classifier_loss: 1.5482 - val_loss2/classifier_loss: 1.5281 - val_loss3/classifier_loss: 1.7618 - val_loss1/classifier_accuracy: 0.5693 - val_loss1/classifier_top5_acc: 0.8552 - val_loss1/classifier_macro_f1score: 0.3433 - val_loss2/classifier_accuracy: 0.6114 - val_loss2/classifier_top5_acc: 0.8740 - val_loss2/classifier_macro_f1score: 0.3976 - val_loss3/classifier_accuracy: 0.6282 - val_loss3/classifier_top5_acc: 0.8766 - val_loss3/classifier_macro_f1score: 0.4313\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 50/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9905 - loss1/classifier_loss: 1.3279 - loss2/classifier_loss: 0.8940 - loss3/classifier_loss: 0.3240 - loss1/classifier_accuracy: 0.6199 - loss1/classifier_top5_acc: 0.8885 - loss1/classifier_macro_f1score: 0.3636 - loss2/classifier_accuracy: 0.7308 - loss2/classifier_top5_acc: 0.9408 - loss2/classifier_macro_f1score: 0.4754 - loss3/classifier_accuracy: 0.8970 - loss3/classifier_top5_acc: 0.9892 - loss3/classifier_macro_f1score: 0.6281\n","Epoch 00050: val_loss did not improve from 2.49745\n","\n","Epoch 00050: val_loss3/classifier_accuracy improved from 0.63341 to 0.63482, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/050.h5\n","350/350 [==============================] - 632s 2s/step - loss: 0.9905 - loss1/classifier_loss: 1.3279 - loss2/classifier_loss: 0.8940 - loss3/classifier_loss: 0.3240 - loss1/classifier_accuracy: 0.6199 - loss1/classifier_top5_acc: 0.8885 - loss1/classifier_macro_f1score: 0.3636 - loss2/classifier_accuracy: 0.7308 - loss2/classifier_top5_acc: 0.9408 - loss2/classifier_macro_f1score: 0.4754 - loss3/classifier_accuracy: 0.8970 - loss3/classifier_top5_acc: 0.9892 - loss3/classifier_macro_f1score: 0.6281 - val_loss: 2.6696 - val_loss1/classifier_loss: 1.5440 - val_loss2/classifier_loss: 1.5158 - val_loss3/classifier_loss: 1.7517 - val_loss1/classifier_accuracy: 0.5743 - val_loss1/classifier_top5_acc: 0.8566 - val_loss1/classifier_macro_f1score: 0.3420 - val_loss2/classifier_accuracy: 0.6090 - val_loss2/classifier_top5_acc: 0.8764 - val_loss2/classifier_macro_f1score: 0.3936 - val_loss3/classifier_accuracy: 0.6348 - val_loss3/classifier_top5_acc: 0.8786 - val_loss3/classifier_macro_f1score: 0.4307\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 51/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9748 - loss1/classifier_loss: 1.3154 - loss2/classifier_loss: 0.8822 - loss3/classifier_loss: 0.3155 - loss1/classifier_accuracy: 0.6217 - loss1/classifier_top5_acc: 0.8877 - loss1/classifier_macro_f1score: 0.3677 - loss2/classifier_accuracy: 0.7342 - loss2/classifier_top5_acc: 0.9426 - loss2/classifier_macro_f1score: 0.4790 - loss3/classifier_accuracy: 0.8981 - loss3/classifier_top5_acc: 0.9896 - loss3/classifier_macro_f1score: 0.6320\n","Epoch 00051: val_loss did not improve from 2.49745\n","\n","Epoch 00051: val_loss3/classifier_accuracy did not improve from 0.63482\n","350/350 [==============================] - 631s 2s/step - loss: 0.9748 - loss1/classifier_loss: 1.3154 - loss2/classifier_loss: 0.8822 - loss3/classifier_loss: 0.3155 - loss1/classifier_accuracy: 0.6217 - loss1/classifier_top5_acc: 0.8877 - loss1/classifier_macro_f1score: 0.3677 - loss2/classifier_accuracy: 0.7342 - loss2/classifier_top5_acc: 0.9426 - loss2/classifier_macro_f1score: 0.4790 - loss3/classifier_accuracy: 0.8981 - loss3/classifier_top5_acc: 0.9896 - loss3/classifier_macro_f1score: 0.6320 - val_loss: 2.7419 - val_loss1/classifier_loss: 1.5446 - val_loss2/classifier_loss: 1.5527 - val_loss3/classifier_loss: 1.8127 - val_loss1/classifier_accuracy: 0.5733 - val_loss1/classifier_top5_acc: 0.8582 - val_loss1/classifier_macro_f1score: 0.3382 - val_loss2/classifier_accuracy: 0.6078 - val_loss2/classifier_top5_acc: 0.8738 - val_loss2/classifier_macro_f1score: 0.3862 - val_loss3/classifier_accuracy: 0.6272 - val_loss3/classifier_top5_acc: 0.8754 - val_loss3/classifier_macro_f1score: 0.4230\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 52/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9727 - loss1/classifier_loss: 1.3183 - loss2/classifier_loss: 0.8764 - loss3/classifier_loss: 0.3143 - loss1/classifier_accuracy: 0.6222 - loss1/classifier_top5_acc: 0.8863 - loss1/classifier_macro_f1score: 0.3667 - loss2/classifier_accuracy: 0.7341 - loss2/classifier_top5_acc: 0.9437 - loss2/classifier_macro_f1score: 0.4804 - loss3/classifier_accuracy: 0.8979 - loss3/classifier_top5_acc: 0.9904 - loss3/classifier_macro_f1score: 0.6331\n","Epoch 00052: val_loss did not improve from 2.49745\n","\n","Epoch 00052: val_loss3/classifier_accuracy did not improve from 0.63482\n","350/350 [==============================] - 635s 2s/step - loss: 0.9727 - loss1/classifier_loss: 1.3183 - loss2/classifier_loss: 0.8764 - loss3/classifier_loss: 0.3143 - loss1/classifier_accuracy: 0.6222 - loss1/classifier_top5_acc: 0.8863 - loss1/classifier_macro_f1score: 0.3667 - loss2/classifier_accuracy: 0.7341 - loss2/classifier_top5_acc: 0.9437 - loss2/classifier_macro_f1score: 0.4804 - loss3/classifier_accuracy: 0.8979 - loss3/classifier_top5_acc: 0.9904 - loss3/classifier_macro_f1score: 0.6331 - val_loss: 2.7195 - val_loss1/classifier_loss: 1.5355 - val_loss2/classifier_loss: 1.5396 - val_loss3/classifier_loss: 1.7970 - val_loss1/classifier_accuracy: 0.5755 - val_loss1/classifier_top5_acc: 0.8602 - val_loss1/classifier_macro_f1score: 0.3471 - val_loss2/classifier_accuracy: 0.6098 - val_loss2/classifier_top5_acc: 0.8748 - val_loss2/classifier_macro_f1score: 0.3988 - val_loss3/classifier_accuracy: 0.6326 - val_loss3/classifier_top5_acc: 0.8780 - val_loss3/classifier_macro_f1score: 0.4313\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 53/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9460 - loss1/classifier_loss: 1.2934 - loss2/classifier_loss: 0.8593 - loss3/classifier_loss: 0.3002 - loss1/classifier_accuracy: 0.6262 - loss1/classifier_top5_acc: 0.8931 - loss1/classifier_macro_f1score: 0.3703 - loss2/classifier_accuracy: 0.7418 - loss2/classifier_top5_acc: 0.9442 - loss2/classifier_macro_f1score: 0.4878 - loss3/classifier_accuracy: 0.9051 - loss3/classifier_top5_acc: 0.9915 - loss3/classifier_macro_f1score: 0.6376\n","Epoch 00053: val_loss did not improve from 2.49745\n","\n","Epoch 00053: val_loss3/classifier_accuracy did not improve from 0.63482\n","350/350 [==============================] - 632s 2s/step - loss: 0.9460 - loss1/classifier_loss: 1.2934 - loss2/classifier_loss: 0.8593 - loss3/classifier_loss: 0.3002 - loss1/classifier_accuracy: 0.6262 - loss1/classifier_top5_acc: 0.8931 - loss1/classifier_macro_f1score: 0.3703 - loss2/classifier_accuracy: 0.7418 - loss2/classifier_top5_acc: 0.9442 - loss2/classifier_macro_f1score: 0.4878 - loss3/classifier_accuracy: 0.9051 - loss3/classifier_top5_acc: 0.9915 - loss3/classifier_macro_f1score: 0.6376 - val_loss: 2.6758 - val_loss1/classifier_loss: 1.5266 - val_loss2/classifier_loss: 1.5231 - val_loss3/classifier_loss: 1.7609 - val_loss1/classifier_accuracy: 0.5779 - val_loss1/classifier_top5_acc: 0.8598 - val_loss1/classifier_macro_f1score: 0.3522 - val_loss2/classifier_accuracy: 0.6088 - val_loss2/classifier_top5_acc: 0.8730 - val_loss2/classifier_macro_f1score: 0.4012 - val_loss3/classifier_accuracy: 0.6348 - val_loss3/classifier_top5_acc: 0.8782 - val_loss3/classifier_macro_f1score: 0.4369\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00054: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 54/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9507 - loss1/classifier_loss: 1.3002 - loss2/classifier_loss: 0.8679 - loss3/classifier_loss: 0.3003 - loss1/classifier_accuracy: 0.6241 - loss1/classifier_top5_acc: 0.8895 - loss1/classifier_macro_f1score: 0.3691 - loss2/classifier_accuracy: 0.7369 - loss2/classifier_top5_acc: 0.9424 - loss2/classifier_macro_f1score: 0.4844 - loss3/classifier_accuracy: 0.9031 - loss3/classifier_top5_acc: 0.9913 - loss3/classifier_macro_f1score: 0.6370\n","Epoch 00054: val_loss did not improve from 2.49745\n","\n","Epoch 00054: val_loss3/classifier_accuracy did not improve from 0.63482\n","350/350 [==============================] - 625s 2s/step - loss: 0.9507 - loss1/classifier_loss: 1.3002 - loss2/classifier_loss: 0.8679 - loss3/classifier_loss: 0.3003 - loss1/classifier_accuracy: 0.6241 - loss1/classifier_top5_acc: 0.8895 - loss1/classifier_macro_f1score: 0.3691 - loss2/classifier_accuracy: 0.7369 - loss2/classifier_top5_acc: 0.9424 - loss2/classifier_macro_f1score: 0.4844 - loss3/classifier_accuracy: 0.9031 - loss3/classifier_top5_acc: 0.9913 - loss3/classifier_macro_f1score: 0.6370 - val_loss: 2.7620 - val_loss1/classifier_loss: 1.5456 - val_loss2/classifier_loss: 1.5518 - val_loss3/classifier_loss: 1.8328 - val_loss1/classifier_accuracy: 0.5749 - val_loss1/classifier_top5_acc: 0.8610 - val_loss1/classifier_macro_f1score: 0.3492 - val_loss2/classifier_accuracy: 0.6064 - val_loss2/classifier_top5_acc: 0.8760 - val_loss2/classifier_macro_f1score: 0.3993 - val_loss3/classifier_accuracy: 0.6290 - val_loss3/classifier_top5_acc: 0.8758 - val_loss3/classifier_macro_f1score: 0.4334\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00055: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 55/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9406 - loss1/classifier_loss: 1.2883 - loss2/classifier_loss: 0.8550 - loss3/classifier_loss: 0.2976 - loss1/classifier_accuracy: 0.6275 - loss1/classifier_top5_acc: 0.8920 - loss1/classifier_macro_f1score: 0.3700 - loss2/classifier_accuracy: 0.7405 - loss2/classifier_top5_acc: 0.9445 - loss2/classifier_macro_f1score: 0.4837 - loss3/classifier_accuracy: 0.9031 - loss3/classifier_top5_acc: 0.9912 - loss3/classifier_macro_f1score: 0.6354\n","Epoch 00055: val_loss did not improve from 2.49745\n","\n","Epoch 00055: val_loss3/classifier_accuracy did not improve from 0.63482\n","350/350 [==============================] - 629s 2s/step - loss: 0.9406 - loss1/classifier_loss: 1.2883 - loss2/classifier_loss: 0.8550 - loss3/classifier_loss: 0.2976 - loss1/classifier_accuracy: 0.6275 - loss1/classifier_top5_acc: 0.8920 - loss1/classifier_macro_f1score: 0.3700 - loss2/classifier_accuracy: 0.7405 - loss2/classifier_top5_acc: 0.9445 - loss2/classifier_macro_f1score: 0.4837 - loss3/classifier_accuracy: 0.9031 - loss3/classifier_top5_acc: 0.9912 - loss3/classifier_macro_f1score: 0.6354 - val_loss: 2.7341 - val_loss1/classifier_loss: 1.5331 - val_loss2/classifier_loss: 1.5284 - val_loss3/classifier_loss: 1.8157 - val_loss1/classifier_accuracy: 0.5783 - val_loss1/classifier_top5_acc: 0.8638 - val_loss1/classifier_macro_f1score: 0.3495 - val_loss2/classifier_accuracy: 0.6138 - val_loss2/classifier_top5_acc: 0.8766 - val_loss2/classifier_macro_f1score: 0.3985 - val_loss3/classifier_accuracy: 0.6342 - val_loss3/classifier_top5_acc: 0.8792 - val_loss3/classifier_macro_f1score: 0.4344\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00056: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 56/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9374 - loss1/classifier_loss: 1.3025 - loss2/classifier_loss: 0.8632 - loss3/classifier_loss: 0.2877 - loss1/classifier_accuracy: 0.6278 - loss1/classifier_top5_acc: 0.8903 - loss1/classifier_macro_f1score: 0.3722 - loss2/classifier_accuracy: 0.7397 - loss2/classifier_top5_acc: 0.9439 - loss2/classifier_macro_f1score: 0.4850 - loss3/classifier_accuracy: 0.9084 - loss3/classifier_top5_acc: 0.9913 - loss3/classifier_macro_f1score: 0.6405\n","Epoch 00056: val_loss did not improve from 2.49745\n","\n","Epoch 00056: val_loss3/classifier_accuracy did not improve from 0.63482\n","350/350 [==============================] - 632s 2s/step - loss: 0.9374 - loss1/classifier_loss: 1.3025 - loss2/classifier_loss: 0.8632 - loss3/classifier_loss: 0.2877 - loss1/classifier_accuracy: 0.6278 - loss1/classifier_top5_acc: 0.8903 - loss1/classifier_macro_f1score: 0.3722 - loss2/classifier_accuracy: 0.7397 - loss2/classifier_top5_acc: 0.9439 - loss2/classifier_macro_f1score: 0.4850 - loss3/classifier_accuracy: 0.9084 - loss3/classifier_top5_acc: 0.9913 - loss3/classifier_macro_f1score: 0.6405 - val_loss: 2.7846 - val_loss1/classifier_loss: 1.5460 - val_loss2/classifier_loss: 1.5485 - val_loss3/classifier_loss: 1.8563 - val_loss1/classifier_accuracy: 0.5773 - val_loss1/classifier_top5_acc: 0.8578 - val_loss1/classifier_macro_f1score: 0.3458 - val_loss2/classifier_accuracy: 0.6102 - val_loss2/classifier_top5_acc: 0.8716 - val_loss2/classifier_macro_f1score: 0.3956 - val_loss3/classifier_accuracy: 0.6248 - val_loss3/classifier_top5_acc: 0.8768 - val_loss3/classifier_macro_f1score: 0.4262\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00057: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 57/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9286 - loss1/classifier_loss: 1.2899 - loss2/classifier_loss: 0.8477 - loss3/classifier_loss: 0.2873 - loss1/classifier_accuracy: 0.6277 - loss1/classifier_top5_acc: 0.8921 - loss1/classifier_macro_f1score: 0.3710 - loss2/classifier_accuracy: 0.7447 - loss2/classifier_top5_acc: 0.9456 - loss2/classifier_macro_f1score: 0.4897 - loss3/classifier_accuracy: 0.9071 - loss3/classifier_top5_acc: 0.9911 - loss3/classifier_macro_f1score: 0.6400\n","Epoch 00057: val_loss did not improve from 2.49745\n","\n","Epoch 00057: val_loss3/classifier_accuracy did not improve from 0.63482\n","350/350 [==============================] - 630s 2s/step - loss: 0.9286 - loss1/classifier_loss: 1.2899 - loss2/classifier_loss: 0.8477 - loss3/classifier_loss: 0.2873 - loss1/classifier_accuracy: 0.6277 - loss1/classifier_top5_acc: 0.8921 - loss1/classifier_macro_f1score: 0.3710 - loss2/classifier_accuracy: 0.7447 - loss2/classifier_top5_acc: 0.9456 - loss2/classifier_macro_f1score: 0.4897 - loss3/classifier_accuracy: 0.9071 - loss3/classifier_top5_acc: 0.9911 - loss3/classifier_macro_f1score: 0.6400 - val_loss: 2.6946 - val_loss1/classifier_loss: 1.5284 - val_loss2/classifier_loss: 1.5204 - val_loss3/classifier_loss: 1.7799 - val_loss1/classifier_accuracy: 0.5759 - val_loss1/classifier_top5_acc: 0.8598 - val_loss1/classifier_macro_f1score: 0.3475 - val_loss2/classifier_accuracy: 0.6088 - val_loss2/classifier_top5_acc: 0.8766 - val_loss2/classifier_macro_f1score: 0.3946 - val_loss3/classifier_accuracy: 0.6336 - val_loss3/classifier_top5_acc: 0.8772 - val_loss3/classifier_macro_f1score: 0.4307\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00058: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 58/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9295 - loss1/classifier_loss: 1.2895 - loss2/classifier_loss: 0.8553 - loss3/classifier_loss: 0.2861 - loss1/classifier_accuracy: 0.6293 - loss1/classifier_top5_acc: 0.8904 - loss1/classifier_macro_f1score: 0.3730 - loss2/classifier_accuracy: 0.7411 - loss2/classifier_top5_acc: 0.9439 - loss2/classifier_macro_f1score: 0.4869 - loss3/classifier_accuracy: 0.9068 - loss3/classifier_top5_acc: 0.9914 - loss3/classifier_macro_f1score: 0.6411\n","Epoch 00058: val_loss did not improve from 2.49745\n","\n","Epoch 00058: val_loss3/classifier_accuracy did not improve from 0.63482\n","350/350 [==============================] - 627s 2s/step - loss: 0.9295 - loss1/classifier_loss: 1.2895 - loss2/classifier_loss: 0.8553 - loss3/classifier_loss: 0.2861 - loss1/classifier_accuracy: 0.6293 - loss1/classifier_top5_acc: 0.8904 - loss1/classifier_macro_f1score: 0.3730 - loss2/classifier_accuracy: 0.7411 - loss2/classifier_top5_acc: 0.9439 - loss2/classifier_macro_f1score: 0.4869 - loss3/classifier_accuracy: 0.9068 - loss3/classifier_top5_acc: 0.9914 - loss3/classifier_macro_f1score: 0.6411 - val_loss: 2.7430 - val_loss1/classifier_loss: 1.5432 - val_loss2/classifier_loss: 1.5390 - val_loss3/classifier_loss: 1.8184 - val_loss1/classifier_accuracy: 0.5739 - val_loss1/classifier_top5_acc: 0.8568 - val_loss1/classifier_macro_f1score: 0.3367 - val_loss2/classifier_accuracy: 0.6042 - val_loss2/classifier_top5_acc: 0.8724 - val_loss2/classifier_macro_f1score: 0.3920 - val_loss3/classifier_accuracy: 0.6288 - val_loss3/classifier_top5_acc: 0.8764 - val_loss3/classifier_macro_f1score: 0.4268\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00059: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 59/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9105 - loss1/classifier_loss: 1.2810 - loss2/classifier_loss: 0.8405 - loss3/classifier_loss: 0.2741 - loss1/classifier_accuracy: 0.6282 - loss1/classifier_top5_acc: 0.8938 - loss1/classifier_macro_f1score: 0.3754 - loss2/classifier_accuracy: 0.7459 - loss2/classifier_top5_acc: 0.9459 - loss2/classifier_macro_f1score: 0.4922 - loss3/classifier_accuracy: 0.9101 - loss3/classifier_top5_acc: 0.9927 - loss3/classifier_macro_f1score: 0.6456\n","Epoch 00059: val_loss did not improve from 2.49745\n","\n","Epoch 00059: val_loss3/classifier_accuracy did not improve from 0.63482\n","350/350 [==============================] - 624s 2s/step - loss: 0.9105 - loss1/classifier_loss: 1.2810 - loss2/classifier_loss: 0.8405 - loss3/classifier_loss: 0.2741 - loss1/classifier_accuracy: 0.6282 - loss1/classifier_top5_acc: 0.8938 - loss1/classifier_macro_f1score: 0.3754 - loss2/classifier_accuracy: 0.7459 - loss2/classifier_top5_acc: 0.9459 - loss2/classifier_macro_f1score: 0.4922 - loss3/classifier_accuracy: 0.9101 - loss3/classifier_top5_acc: 0.9927 - loss3/classifier_macro_f1score: 0.6456 - val_loss: 2.7522 - val_loss1/classifier_loss: 1.5191 - val_loss2/classifier_loss: 1.5261 - val_loss3/classifier_loss: 1.8386 - val_loss1/classifier_accuracy: 0.5821 - val_loss1/classifier_top5_acc: 0.8630 - val_loss1/classifier_macro_f1score: 0.3526 - val_loss2/classifier_accuracy: 0.6134 - val_loss2/classifier_top5_acc: 0.8810 - val_loss2/classifier_macro_f1score: 0.3995 - val_loss3/classifier_accuracy: 0.6334 - val_loss3/classifier_top5_acc: 0.8808 - val_loss3/classifier_macro_f1score: 0.4334\n","Learning rate:  2.9999999999999997e-05\n","\n","Epoch 00060: LearningRateScheduler reducing learning rate to 2.9999999999999997e-05.\n","Epoch 60/70\n","350/350 [==============================] - ETA: 0s - loss: 0.9146 - loss1/classifier_loss: 1.2902 - loss2/classifier_loss: 0.8425 - loss3/classifier_loss: 0.2747 - loss1/classifier_accuracy: 0.6265 - loss1/classifier_top5_acc: 0.8923 - loss1/classifier_macro_f1score: 0.3692 - loss2/classifier_accuracy: 0.7435 - loss2/classifier_top5_acc: 0.9468 - loss2/classifier_macro_f1score: 0.4902 - loss3/classifier_accuracy: 0.9122 - loss3/classifier_top5_acc: 0.9925 - loss3/classifier_macro_f1score: 0.6450\n","Epoch 00060: val_loss did not improve from 2.49745\n","\n","Epoch 00060: val_loss3/classifier_accuracy did not improve from 0.63482\n","350/350 [==============================] - 623s 2s/step - loss: 0.9146 - loss1/classifier_loss: 1.2902 - loss2/classifier_loss: 0.8425 - loss3/classifier_loss: 0.2747 - loss1/classifier_accuracy: 0.6265 - loss1/classifier_top5_acc: 0.8923 - loss1/classifier_macro_f1score: 0.3692 - loss2/classifier_accuracy: 0.7435 - loss2/classifier_top5_acc: 0.9468 - loss2/classifier_macro_f1score: 0.4902 - loss3/classifier_accuracy: 0.9122 - loss3/classifier_top5_acc: 0.9925 - loss3/classifier_macro_f1score: 0.6450 - val_loss: 2.7930 - val_loss1/classifier_loss: 1.5319 - val_loss2/classifier_loss: 1.5570 - val_loss3/classifier_loss: 1.8663 - val_loss1/classifier_accuracy: 0.5775 - val_loss1/classifier_top5_acc: 0.8574 - val_loss1/classifier_macro_f1score: 0.3513 - val_loss2/classifier_accuracy: 0.6098 - val_loss2/classifier_top5_acc: 0.8726 - val_loss2/classifier_macro_f1score: 0.3994 - val_loss3/classifier_accuracy: 0.6294 - val_loss3/classifier_top5_acc: 0.8786 - val_loss3/classifier_macro_f1score: 0.4321\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00061: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 61/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8667 - loss1/classifier_loss: 1.2598 - loss2/classifier_loss: 0.8141 - loss3/classifier_loss: 0.2445 - loss1/classifier_accuracy: 0.6361 - loss1/classifier_top5_acc: 0.8959 - loss1/classifier_macro_f1score: 0.3742 - loss2/classifier_accuracy: 0.7523 - loss2/classifier_top5_acc: 0.9492 - loss2/classifier_macro_f1score: 0.4943 - loss3/classifier_accuracy: 0.9220 - loss3/classifier_top5_acc: 0.9940 - loss3/classifier_macro_f1score: 0.6516\n","Epoch 00061: val_loss did not improve from 2.49745\n","\n","Epoch 00061: val_loss3/classifier_accuracy improved from 0.63482 to 0.63642, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/GoogleNet/061.h5\n","350/350 [==============================] - 629s 2s/step - loss: 0.8667 - loss1/classifier_loss: 1.2598 - loss2/classifier_loss: 0.8141 - loss3/classifier_loss: 0.2445 - loss1/classifier_accuracy: 0.6361 - loss1/classifier_top5_acc: 0.8959 - loss1/classifier_macro_f1score: 0.3742 - loss2/classifier_accuracy: 0.7523 - loss2/classifier_top5_acc: 0.9492 - loss2/classifier_macro_f1score: 0.4943 - loss3/classifier_accuracy: 0.9220 - loss3/classifier_top5_acc: 0.9940 - loss3/classifier_macro_f1score: 0.6516 - val_loss: 2.7318 - val_loss1/classifier_loss: 1.5196 - val_loss2/classifier_loss: 1.5241 - val_loss3/classifier_loss: 1.8187 - val_loss1/classifier_accuracy: 0.5817 - val_loss1/classifier_top5_acc: 0.8628 - val_loss1/classifier_macro_f1score: 0.3499 - val_loss2/classifier_accuracy: 0.6126 - val_loss2/classifier_top5_acc: 0.8764 - val_loss2/classifier_macro_f1score: 0.4016 - val_loss3/classifier_accuracy: 0.6364 - val_loss3/classifier_top5_acc: 0.8796 - val_loss3/classifier_macro_f1score: 0.4385\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00062: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 62/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8658 - loss1/classifier_loss: 1.2534 - loss2/classifier_loss: 0.8105 - loss3/classifier_loss: 0.2467 - loss1/classifier_accuracy: 0.6366 - loss1/classifier_top5_acc: 0.8973 - loss1/classifier_macro_f1score: 0.3778 - loss2/classifier_accuracy: 0.7541 - loss2/classifier_top5_acc: 0.9501 - loss2/classifier_macro_f1score: 0.4945 - loss3/classifier_accuracy: 0.9214 - loss3/classifier_top5_acc: 0.9934 - loss3/classifier_macro_f1score: 0.6501\n","Epoch 00062: val_loss did not improve from 2.49745\n","\n","Epoch 00062: val_loss3/classifier_accuracy did not improve from 0.63642\n","350/350 [==============================] - 625s 2s/step - loss: 0.8658 - loss1/classifier_loss: 1.2534 - loss2/classifier_loss: 0.8105 - loss3/classifier_loss: 0.2467 - loss1/classifier_accuracy: 0.6366 - loss1/classifier_top5_acc: 0.8973 - loss1/classifier_macro_f1score: 0.3778 - loss2/classifier_accuracy: 0.7541 - loss2/classifier_top5_acc: 0.9501 - loss2/classifier_macro_f1score: 0.4945 - loss3/classifier_accuracy: 0.9214 - loss3/classifier_top5_acc: 0.9934 - loss3/classifier_macro_f1score: 0.6501 - val_loss: 2.7359 - val_loss1/classifier_loss: 1.5263 - val_loss2/classifier_loss: 1.5308 - val_loss3/classifier_loss: 1.8188 - val_loss1/classifier_accuracy: 0.5809 - val_loss1/classifier_top5_acc: 0.8622 - val_loss1/classifier_macro_f1score: 0.3536 - val_loss2/classifier_accuracy: 0.6126 - val_loss2/classifier_top5_acc: 0.8744 - val_loss2/classifier_macro_f1score: 0.4027 - val_loss3/classifier_accuracy: 0.6316 - val_loss3/classifier_top5_acc: 0.8786 - val_loss3/classifier_macro_f1score: 0.4413\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00063: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 63/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8675 - loss1/classifier_loss: 1.2610 - loss2/classifier_loss: 0.8046 - loss3/classifier_loss: 0.2479 - loss1/classifier_accuracy: 0.6330 - loss1/classifier_top5_acc: 0.8968 - loss1/classifier_macro_f1score: 0.3753 - loss2/classifier_accuracy: 0.7544 - loss2/classifier_top5_acc: 0.9500 - loss2/classifier_macro_f1score: 0.4974 - loss3/classifier_accuracy: 0.9207 - loss3/classifier_top5_acc: 0.9937 - loss3/classifier_macro_f1score: 0.6525\n","Epoch 00063: val_loss did not improve from 2.49745\n","\n","Epoch 00063: val_loss3/classifier_accuracy did not improve from 0.63642\n","350/350 [==============================] - 630s 2s/step - loss: 0.8675 - loss1/classifier_loss: 1.2610 - loss2/classifier_loss: 0.8046 - loss3/classifier_loss: 0.2479 - loss1/classifier_accuracy: 0.6330 - loss1/classifier_top5_acc: 0.8968 - loss1/classifier_macro_f1score: 0.3753 - loss2/classifier_accuracy: 0.7544 - loss2/classifier_top5_acc: 0.9500 - loss2/classifier_macro_f1score: 0.4974 - loss3/classifier_accuracy: 0.9207 - loss3/classifier_top5_acc: 0.9937 - loss3/classifier_macro_f1score: 0.6525 - val_loss: 2.7011 - val_loss1/classifier_loss: 1.5154 - val_loss2/classifier_loss: 1.5158 - val_loss3/classifier_loss: 1.7918 - val_loss1/classifier_accuracy: 0.5815 - val_loss1/classifier_top5_acc: 0.8616 - val_loss1/classifier_macro_f1score: 0.3516 - val_loss2/classifier_accuracy: 0.6116 - val_loss2/classifier_top5_acc: 0.8760 - val_loss2/classifier_macro_f1score: 0.4001 - val_loss3/classifier_accuracy: 0.6318 - val_loss3/classifier_top5_acc: 0.8816 - val_loss3/classifier_macro_f1score: 0.4339\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00064: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 64/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8618 - loss1/classifier_loss: 1.2589 - loss2/classifier_loss: 0.8055 - loss3/classifier_loss: 0.2425 - loss1/classifier_accuracy: 0.6346 - loss1/classifier_top5_acc: 0.8984 - loss1/classifier_macro_f1score: 0.3733 - loss2/classifier_accuracy: 0.7549 - loss2/classifier_top5_acc: 0.9507 - loss2/classifier_macro_f1score: 0.4953 - loss3/classifier_accuracy: 0.9240 - loss3/classifier_top5_acc: 0.9938 - loss3/classifier_macro_f1score: 0.6531\n","Epoch 00064: val_loss did not improve from 2.49745\n","\n","Epoch 00064: val_loss3/classifier_accuracy did not improve from 0.63642\n","350/350 [==============================] - 633s 2s/step - loss: 0.8618 - loss1/classifier_loss: 1.2589 - loss2/classifier_loss: 0.8055 - loss3/classifier_loss: 0.2425 - loss1/classifier_accuracy: 0.6346 - loss1/classifier_top5_acc: 0.8984 - loss1/classifier_macro_f1score: 0.3733 - loss2/classifier_accuracy: 0.7549 - loss2/classifier_top5_acc: 0.9507 - loss2/classifier_macro_f1score: 0.4953 - loss3/classifier_accuracy: 0.9240 - loss3/classifier_top5_acc: 0.9938 - loss3/classifier_macro_f1score: 0.6531 - val_loss: 2.6867 - val_loss1/classifier_loss: 1.5141 - val_loss2/classifier_loss: 1.5030 - val_loss3/classifier_loss: 1.7816 - val_loss1/classifier_accuracy: 0.5821 - val_loss1/classifier_top5_acc: 0.8632 - val_loss1/classifier_macro_f1score: 0.3453 - val_loss2/classifier_accuracy: 0.6166 - val_loss2/classifier_top5_acc: 0.8772 - val_loss2/classifier_macro_f1score: 0.3961 - val_loss3/classifier_accuracy: 0.6350 - val_loss3/classifier_top5_acc: 0.8812 - val_loss3/classifier_macro_f1score: 0.4321\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00065: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 65/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8628 - loss1/classifier_loss: 1.2631 - loss2/classifier_loss: 0.8048 - loss3/classifier_loss: 0.2424 - loss1/classifier_accuracy: 0.6376 - loss1/classifier_top5_acc: 0.8945 - loss1/classifier_macro_f1score: 0.3773 - loss2/classifier_accuracy: 0.7550 - loss2/classifier_top5_acc: 0.9499 - loss2/classifier_macro_f1score: 0.4951 - loss3/classifier_accuracy: 0.9238 - loss3/classifier_top5_acc: 0.9940 - loss3/classifier_macro_f1score: 0.6554\n","Epoch 00065: val_loss did not improve from 2.49745\n","\n","Epoch 00065: val_loss3/classifier_accuracy did not improve from 0.63642\n","350/350 [==============================] - 646s 2s/step - loss: 0.8628 - loss1/classifier_loss: 1.2631 - loss2/classifier_loss: 0.8048 - loss3/classifier_loss: 0.2424 - loss1/classifier_accuracy: 0.6376 - loss1/classifier_top5_acc: 0.8945 - loss1/classifier_macro_f1score: 0.3773 - loss2/classifier_accuracy: 0.7550 - loss2/classifier_top5_acc: 0.9499 - loss2/classifier_macro_f1score: 0.4951 - loss3/classifier_accuracy: 0.9238 - loss3/classifier_top5_acc: 0.9940 - loss3/classifier_macro_f1score: 0.6554 - val_loss: 2.6972 - val_loss1/classifier_loss: 1.5158 - val_loss2/classifier_loss: 1.5073 - val_loss3/classifier_loss: 1.7903 - val_loss1/classifier_accuracy: 0.5809 - val_loss1/classifier_top5_acc: 0.8622 - val_loss1/classifier_macro_f1score: 0.3428 - val_loss2/classifier_accuracy: 0.6126 - val_loss2/classifier_top5_acc: 0.8772 - val_loss2/classifier_macro_f1score: 0.3987 - val_loss3/classifier_accuracy: 0.6322 - val_loss3/classifier_top5_acc: 0.8800 - val_loss3/classifier_macro_f1score: 0.4300\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00066: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 66/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8525 - loss1/classifier_loss: 1.2551 - loss2/classifier_loss: 0.8024 - loss3/classifier_loss: 0.2353 - loss1/classifier_accuracy: 0.6334 - loss1/classifier_top5_acc: 0.8974 - loss1/classifier_macro_f1score: 0.3763 - loss2/classifier_accuracy: 0.7565 - loss2/classifier_top5_acc: 0.9504 - loss2/classifier_macro_f1score: 0.4958 - loss3/classifier_accuracy: 0.9260 - loss3/classifier_top5_acc: 0.9944 - loss3/classifier_macro_f1score: 0.6549\n","Epoch 00066: val_loss did not improve from 2.49745\n","\n","Epoch 00066: val_loss3/classifier_accuracy did not improve from 0.63642\n","350/350 [==============================] - 633s 2s/step - loss: 0.8525 - loss1/classifier_loss: 1.2551 - loss2/classifier_loss: 0.8024 - loss3/classifier_loss: 0.2353 - loss1/classifier_accuracy: 0.6334 - loss1/classifier_top5_acc: 0.8974 - loss1/classifier_macro_f1score: 0.3763 - loss2/classifier_accuracy: 0.7565 - loss2/classifier_top5_acc: 0.9504 - loss2/classifier_macro_f1score: 0.4958 - loss3/classifier_accuracy: 0.9260 - loss3/classifier_top5_acc: 0.9944 - loss3/classifier_macro_f1score: 0.6549 - val_loss: 2.6983 - val_loss1/classifier_loss: 1.5214 - val_loss2/classifier_loss: 1.5074 - val_loss3/classifier_loss: 1.7897 - val_loss1/classifier_accuracy: 0.5799 - val_loss1/classifier_top5_acc: 0.8620 - val_loss1/classifier_macro_f1score: 0.3493 - val_loss2/classifier_accuracy: 0.6160 - val_loss2/classifier_top5_acc: 0.8782 - val_loss2/classifier_macro_f1score: 0.4033 - val_loss3/classifier_accuracy: 0.6314 - val_loss3/classifier_top5_acc: 0.8794 - val_loss3/classifier_macro_f1score: 0.4349\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00067: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 67/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8627 - loss1/classifier_loss: 1.2614 - loss2/classifier_loss: 0.8118 - loss3/classifier_loss: 0.2408 - loss1/classifier_accuracy: 0.6344 - loss1/classifier_top5_acc: 0.8969 - loss1/classifier_macro_f1score: 0.3751 - loss2/classifier_accuracy: 0.7508 - loss2/classifier_top5_acc: 0.9496 - loss2/classifier_macro_f1score: 0.4947 - loss3/classifier_accuracy: 0.9236 - loss3/classifier_top5_acc: 0.9943 - loss3/classifier_macro_f1score: 0.6554\n","Epoch 00067: val_loss did not improve from 2.49745\n","\n","Epoch 00067: val_loss3/classifier_accuracy did not improve from 0.63642\n","350/350 [==============================] - 637s 2s/step - loss: 0.8627 - loss1/classifier_loss: 1.2614 - loss2/classifier_loss: 0.8118 - loss3/classifier_loss: 0.2408 - loss1/classifier_accuracy: 0.6344 - loss1/classifier_top5_acc: 0.8969 - loss1/classifier_macro_f1score: 0.3751 - loss2/classifier_accuracy: 0.7508 - loss2/classifier_top5_acc: 0.9496 - loss2/classifier_macro_f1score: 0.4947 - loss3/classifier_accuracy: 0.9236 - loss3/classifier_top5_acc: 0.9943 - loss3/classifier_macro_f1score: 0.6554 - val_loss: 2.6792 - val_loss1/classifier_loss: 1.5146 - val_loss2/classifier_loss: 1.5036 - val_loss3/classifier_loss: 1.7737 - val_loss1/classifier_accuracy: 0.5825 - val_loss1/classifier_top5_acc: 0.8640 - val_loss1/classifier_macro_f1score: 0.3483 - val_loss2/classifier_accuracy: 0.6142 - val_loss2/classifier_top5_acc: 0.8778 - val_loss2/classifier_macro_f1score: 0.4006 - val_loss3/classifier_accuracy: 0.6334 - val_loss3/classifier_top5_acc: 0.8820 - val_loss3/classifier_macro_f1score: 0.4364\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00068: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 68/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8573 - loss1/classifier_loss: 1.2468 - loss2/classifier_loss: 0.8086 - loss3/classifier_loss: 0.2407 - loss1/classifier_accuracy: 0.6387 - loss1/classifier_top5_acc: 0.8979 - loss1/classifier_macro_f1score: 0.3795 - loss2/classifier_accuracy: 0.7512 - loss2/classifier_top5_acc: 0.9506 - loss2/classifier_macro_f1score: 0.4955 - loss3/classifier_accuracy: 0.9237 - loss3/classifier_top5_acc: 0.9942 - loss3/classifier_macro_f1score: 0.6558\n","Epoch 00068: val_loss did not improve from 2.49745\n","\n","Epoch 00068: val_loss3/classifier_accuracy did not improve from 0.63642\n","350/350 [==============================] - 652s 2s/step - loss: 0.8573 - loss1/classifier_loss: 1.2468 - loss2/classifier_loss: 0.8086 - loss3/classifier_loss: 0.2407 - loss1/classifier_accuracy: 0.6387 - loss1/classifier_top5_acc: 0.8979 - loss1/classifier_macro_f1score: 0.3795 - loss2/classifier_accuracy: 0.7512 - loss2/classifier_top5_acc: 0.9506 - loss2/classifier_macro_f1score: 0.4955 - loss3/classifier_accuracy: 0.9237 - loss3/classifier_top5_acc: 0.9942 - loss3/classifier_macro_f1score: 0.6558 - val_loss: 2.6721 - val_loss1/classifier_loss: 1.5139 - val_loss2/classifier_loss: 1.5020 - val_loss3/classifier_loss: 1.7673 - val_loss1/classifier_accuracy: 0.5821 - val_loss1/classifier_top5_acc: 0.8622 - val_loss1/classifier_macro_f1score: 0.3444 - val_loss2/classifier_accuracy: 0.6150 - val_loss2/classifier_top5_acc: 0.8768 - val_loss2/classifier_macro_f1score: 0.4011 - val_loss3/classifier_accuracy: 0.6330 - val_loss3/classifier_top5_acc: 0.8814 - val_loss3/classifier_macro_f1score: 0.4372\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00069: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 69/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8649 - loss1/classifier_loss: 1.2698 - loss2/classifier_loss: 0.8096 - loss3/classifier_loss: 0.2411 - loss1/classifier_accuracy: 0.6333 - loss1/classifier_top5_acc: 0.8949 - loss1/classifier_macro_f1score: 0.3736 - loss2/classifier_accuracy: 0.7539 - loss2/classifier_top5_acc: 0.9496 - loss2/classifier_macro_f1score: 0.4959 - loss3/classifier_accuracy: 0.9236 - loss3/classifier_top5_acc: 0.9943 - loss3/classifier_macro_f1score: 0.6536\n","Epoch 00069: val_loss did not improve from 2.49745\n","\n","Epoch 00069: val_loss3/classifier_accuracy did not improve from 0.63642\n","350/350 [==============================] - 678s 2s/step - loss: 0.8649 - loss1/classifier_loss: 1.2698 - loss2/classifier_loss: 0.8096 - loss3/classifier_loss: 0.2411 - loss1/classifier_accuracy: 0.6333 - loss1/classifier_top5_acc: 0.8949 - loss1/classifier_macro_f1score: 0.3736 - loss2/classifier_accuracy: 0.7539 - loss2/classifier_top5_acc: 0.9496 - loss2/classifier_macro_f1score: 0.4959 - loss3/classifier_accuracy: 0.9236 - loss3/classifier_top5_acc: 0.9943 - loss3/classifier_macro_f1score: 0.6536 - val_loss: 2.6949 - val_loss1/classifier_loss: 1.5165 - val_loss2/classifier_loss: 1.5089 - val_loss3/classifier_loss: 1.7873 - val_loss1/classifier_accuracy: 0.5797 - val_loss1/classifier_top5_acc: 0.8620 - val_loss1/classifier_macro_f1score: 0.3438 - val_loss2/classifier_accuracy: 0.6144 - val_loss2/classifier_top5_acc: 0.8768 - val_loss2/classifier_macro_f1score: 0.3965 - val_loss3/classifier_accuracy: 0.6326 - val_loss3/classifier_top5_acc: 0.8800 - val_loss3/classifier_macro_f1score: 0.4329\n","Learning rate:  2.9999999999999997e-06\n","\n","Epoch 00070: LearningRateScheduler reducing learning rate to 2.9999999999999997e-06.\n","Epoch 70/70\n","350/350 [==============================] - ETA: 0s - loss: 0.8700 - loss1/classifier_loss: 1.2655 - loss2/classifier_loss: 0.8080 - loss3/classifier_loss: 0.2479 - loss1/classifier_accuracy: 0.6333 - loss1/classifier_top5_acc: 0.8952 - loss1/classifier_macro_f1score: 0.3721 - loss2/classifier_accuracy: 0.7548 - loss2/classifier_top5_acc: 0.9500 - loss2/classifier_macro_f1score: 0.4951 - loss3/classifier_accuracy: 0.9205 - loss3/classifier_top5_acc: 0.9939 - loss3/classifier_macro_f1score: 0.6534\n","Epoch 00070: val_loss did not improve from 2.49745\n","\n","Epoch 00070: val_loss3/classifier_accuracy did not improve from 0.63642\n","350/350 [==============================] - 663s 2s/step - loss: 0.8700 - loss1/classifier_loss: 1.2655 - loss2/classifier_loss: 0.8080 - loss3/classifier_loss: 0.2479 - loss1/classifier_accuracy: 0.6333 - loss1/classifier_top5_acc: 0.8952 - loss1/classifier_macro_f1score: 0.3721 - loss2/classifier_accuracy: 0.7548 - loss2/classifier_top5_acc: 0.9500 - loss2/classifier_macro_f1score: 0.4951 - loss3/classifier_accuracy: 0.9205 - loss3/classifier_top5_acc: 0.9939 - loss3/classifier_macro_f1score: 0.6534 - val_loss: 2.6507 - val_loss1/classifier_loss: 1.5061 - val_loss2/classifier_loss: 1.4892 - val_loss3/classifier_loss: 1.7521 - val_loss1/classifier_accuracy: 0.5821 - val_loss1/classifier_top5_acc: 0.8638 - val_loss1/classifier_macro_f1score: 0.3434 - val_loss2/classifier_accuracy: 0.6164 - val_loss2/classifier_top5_acc: 0.8772 - val_loss2/classifier_macro_f1score: 0.3971 - val_loss3/classifier_accuracy: 0.6328 - val_loss3/classifier_top5_acc: 0.8816 - val_loss3/classifier_macro_f1score: 0.4345\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W3hAqJFKvqie"},"source":["### 3) GoogLeNet Evaluate\n"]},{"cell_type":"code","metadata":{"id":"UNop2cYdMkkH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606199628461,"user_tz":-540,"elapsed":67669544,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"2992aa8d-bd33-4200-e052-0642e179508e"},"source":["# 1. epoch=maximum\n","#var = model.evaluate_generator(generate_test_for_three(),steps=int(len(x_test)/batch_sizes))\n","var = model.evaluate(generate_test_for_three(),steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (var[0],var[-3],var[-2],var[-1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 10000 images belonging to 100 classes.\n","78/78 [==============================] - 3416s 44s/step - loss: 2.6386 - loss1/classifier_loss: 1.4823 - loss2/classifier_loss: 1.4721 - loss3/classifier_loss: 1.7523 - loss1/classifier_accuracy: 0.5917 - loss1/classifier_top5_acc: 0.8591 - loss1/classifier_macro_f1score: 0.3604 - loss2/classifier_accuracy: 0.6249 - loss2/classifier_top5_acc: 0.8739 - loss2/classifier_macro_f1score: 0.4081 - loss3/classifier_accuracy: 0.6349 - loss3/classifier_top5_acc: 0.8803 - loss3/classifier_macro_f1score: 0.4351\n","[Test Loss: 2.6386 /  Test Top-1 Accuracy: 0.6349 / Test Top-5 Accuracy: 0.8803 / Test Macro f1: 0.4351]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gHMaAEJbMkkJ"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['loss3/classifier_accuracy']\n","val_acc=history.history['val_loss3/classifier_accuracy']\n","top5_acc=history.history['loss3/classifier_top5_acc']\n","val_top5_acc=history.history['val_loss3/classifier_top5_acc']\n","f1=history.history['loss3/classifier_macro_f1score']\n","val_f1=history.history['val_loss3/classifier_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_J63NZRjMkkM"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vE5-Vi6O4del"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pAQKONLzMkkP"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'GoogleNet.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RFy1r9jVMkkS"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTSL86SdMkkU","colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"status":"ok","timestamp":1606199629902,"user_tz":-540,"elapsed":67670964,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"006a3461-ca71-4a0e-a72a-30927d957127"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfbA8e8JCTUBpHeDBRApoSo2wIoN1gKCoKJrw44iuq4KP13XhqIsi2VFWRVFV10WBURBBOwUQUEBEREp0pQAUpOc3x9nQkJIyCSZ5GYm5/M898nMrefezJx573vf+15RVZxzzkW/uKADcM45Fxme0J1zLkZ4QnfOuRjhCd0552KEJ3TnnIsRntCdcy5GeEJ3BxCRqSJyRaTnDZKIrBKR04thvR+LyNWh1/1F5INw5i3EdpqIyA4RKVfYWF3Z4Ak9BoS+7JlDhojsyva+f0HWpapnq+q/Iz1vaSQid4vI7FzG1xKRvSLSKtx1qep4VT0zQnEd8AOkqqtVNVFV0yOx/hzbUhE5KtLrdcHwhB4DQl/2RFVNBFYD52cbNz5zPhGJDy7KUulV4AQRaZpjfF/gW1VdHEBMzhWaJ/QYJiLdRGSNiNwlIr8CL4nIYSLynohsEpHfQ68bZVsmezXCQBH5RERGhOb9SUTOLuS8TUVktohsF5HpIvJPEXk1j7jDifFBEfk0tL4PRKRWtumXicjPIrJFRP6a1/FR1TXAR8BlOSZdDrycXxw5Yh4oIp9ke3+GiCwVkVQRGQ1ItmlHishHofg2i8h4EakemvYK0AR4N3SGNVREkkMl6fjQPA1EZJKI/CYiK0TkmmzrHi4ib4rIy6Fjs0REOuZ1DPIiItVC69gUOpb3ikhcaNpRIjIrtG+bReSN0HgRkZEislFEtonItwU5y3FF5wk99tUDagCHA9di//OXQu+bALuA0YdY/jhgGVALeAwYKyJSiHlfA74CagLDOTiJZhdOjJcCVwJ1gPLAEAARaQk8E1p/g9D2ck3CIf/OHouINAdSQvEW9FhlrqMW8A5wL3YsfgROzD4L8HAovmOAxtgxQVUv48CzrMdy2cQEYE1o+YuBv4vIqdmm9wzNUx2YFE7MufgHUA04AuiK/chdGZr2IPABcBh2bP8RGn8mcArQLLRsH2BLIbbtCktVfYihAVgFnB563Q3YC1Q8xPwpwO/Z3n8MXB16PRBYkW1aZUCBegWZF0uGaUDlbNNfBV4Nc59yi/HebO9vAN4Pvb4fmJBtWpXQMTg9j3VXBrYBJ4TePwT8r5DH6pPQ68uBL7LNJ1gCvjqP9f4J+Dq3/2HofXLoWMZjyT8dSMo2/WFgXOj1cGB6tmktgV2HOLYKHJVjXLnQMWuZbdx1wMeh1y8DzwONcix3KrAcOB6IC/q7UBYHL6HHvk2qujvzjYhUFpHnQqfR24DZQHXJuwXFr5kvVHVn6GViAedtAPyWbRzAL3kFHGaMv2Z7vTNbTA2yr1tV/+AQpcRQTP8BLg+dTfTHElZhjlWmnDFo9vciUldEJojI2tB6X8VK8uHIPJbbs437GWiY7X3OY1NRCnb9pBaQEFpvbtsYiv1IfRWq0rkKQFU/ws4G/glsFJHnRaRqAbbrisgTeuzL2Z3mHUBz4DhVrYqdIkO2Ot5isB6oISKVs41rfIj5ixLj+uzrDm2zZj7L/BurHjgDSALeLWIcOWMQDtzfv2P/l9ah9Q7Isc5DdYG6DjuWSdnGNQHW5hNTQWwG9mFVTQdtQ1V/VdVrVLUBVnIfI6GWMqo6SlU7YGcGzYA7IxiXy4cn9LInCasL3ioiNYBhxb1BVf0ZmAcMF5HyItIFOL+YYnwLOE9EThKR8sAD5P85nwNsxaoRJqjq3iLGMRk4VkQuDJWMb8GqnjIlATuAVBFpyMFJbwNWd30QVf0F+Ax4WEQqikgb4M9YKb+wyofWVVFEKobGvQk8JCJJInI4cHvmNkSkd7aLw79jP0AZItJJRI4TkQTgD2A3kFGEuFwBeUIve54CKmGlsC+A90tou/2BLlj1x9+AN4A9ecxb6BhVdQlwI3ZRcz2WcNbks4xi1SyHh/4WKQ5V3Qz0Bh7B9vdo4NNss/wf0B5IxZL/OzlW8TBwr4hsFZEhuWyiH1avvg74LzBMVaeHE1selmA/XJnDlcDNWFJeCXyCHc8XQ/N3Ar4UkR3YRddbVXUlUBX4F3bMf8b2/fEixOUKSEIXM5wrUaGmbktVtdjPEJwrK7yE7kpE6HT8SBGJE5EeQC9gYtBxORdL/M5BV1LqYVULNbEqkEGq+nWwITkXW7zKxTnnYoRXuTjnXIwIrMqlVq1ampycHNTmnXMuKs2fP3+zqtbObVpgCT05OZl58+YFtXnnnItKIvJzXtO8ysU552KEJ3TnnIsRntCdcy5GeDt052Lcvn37WLNmDbt3785/ZldqVKxYkUaNGpGQkBD2Mp7QnYtxa9asISkpieTkZPJ+NokrTVSVLVu2sGbNGpo2zfmExLx5lYtzMW737t3UrFnTk3kUERFq1qxZ4LMqT+jOlQGezKNPYf5nUZfQly+HwYNh376gI3HOudIl6hL6Dz/AU0/Bm28GHYlzLhxbtmwhJSWFlJQU6tWrR8OGDfe/37t37yGXnTdvHrfccku+2zjhhBMiEuvHH3/MeeedF5F1BSHqLoqefTa0aAFPPAGXXgp+Julc6VazZk0WLlwIwPDhw0lMTGTIkKzndqSlpREfn3sq6tixIx07dsx3G5999llkgo1yUVdCj4uD22+Hr7+Gjz8OOhrnXGEMHDiQ66+/nuOOO46hQ4fy1Vdf0aVLF9q1a8cJJ5zAsmXLgANLzMOHD+eqq66iW7duHHHEEYwaNWr/+hITE/fP361bNy6++GJatGhB//79yexRdsqUKbRo0YIOHTpwyy23FKgk/vrrr9O6dWtatWrFXXfdBUB6ejoDBw6kVatWtG7dmpEjRwIwatQoWrZsSZs2bejbt2/RD1YBRF0JHWDAAPjrX62U3r170NE4Fz1uuw1CheWISUmxatCCWrNmDZ999hnlypVj27ZtzJkzh/j4eKZPn84999zD22+/fdAyS5cuZebMmWzfvp3mzZszaNCgg9ppf/311yxZsoQGDRpw4okn8umnn9KxY0euu+46Zs+eTdOmTenXr1/Yca5bt4677rqL+fPnc9hhh3HmmWcyceJEGjduzNq1a1m8eDEAW7duBeCRRx7hp59+okKFCvvHlZSoK6EDVKoEN9wAkyfD0qVBR+OcK4zevXtTrlw5AFJTU+nduzetWrVi8ODBLFmyJNdlzj33XCpUqECtWrWoU6cOGzZsOGiezp0706hRI+Li4khJSWHVqlUsXbqUI444Yn+b7oIk9Llz59KtWzdq165NfHw8/fv3Z/bs2RxxxBGsXLmSm2++mffff5+qVasC0KZNG/r378+rr76aZ1VScYnKEjqrVnHDDck88giMHAnPPRd0QM5Fh8KUpItLlSpV9r++77776N69O//9739ZtWoV3bp1y3WZChUq7H9drlw50tLSCjVPJBx22GEsWrSIadOm8eyzz/Lmm2/y4osvMnnyZGbPns27777LQw89xLfffltiiT36SugTJkDz5tR57Skuv0x5+WXYtCnooJxzRZGamkrDhg0BGDduXMTX37x5c1auXMmqVasAeOONN8JetnPnzsyaNYvNmzeTnp7O66+/TteuXdm8eTMZGRlcdNFF/O1vf2PBggVkZGTwyy+/0L17dx599FFSU1PZsWNHxPcnL9GX0E8/Hc46CwYP5skfzidx9ybGjAk6KOdcUQwdOpS//OUvtGvXrlhK1JUqVWLMmDH06NGDDh06kJSURLVq1XKdd8aMGTRq1Gj/sGrVKh555BG6d+9O27Zt6dChA7169WLt2rV069aNlJQUBgwYwMMPP0x6ejoDBgygdevWtGvXjltuuYXq1atHfH/yEtgzRTt27KiFfsCFKoweDUOGsEVqcnXF8by2vjuVKkU2Rudiwffff88xxxwTdBiB27FjB4mJiagqN954I0cffTSDBw8OOqxDyu1/JyLzVTXXtpzRV0IHa3x+883w5ZdUrFOVt1NPY+nF90J6etCROedKqX/961+kpKRw7LHHkpqaynXXXRd0SBEXnRdFM6WkUPm7+Uw6/GZ6TXmIjH8fRdxVA4OOyjlXCg0ePLjUl8iLKjpL6NlIYhV2PD2W5RzNlqdfCToc55wLTNQndIA+lwhTqven5jcz0V/WBB2Oc84FIiYSekICNLizP3Eoy4a/HnQ4zjkXiJhI6AB/GnIUC8ofT7kJrxJQwx3nnAtUzCT08uVh54UDOHrnN3z23LdBh+OcC+nevTvTpk07YNxTTz3FoEGD8lymW7duZDZrPuecc3LtE2X48OGMGDHikNueOHEi33333f73999/P9OnTy9I+Lkqrd3sxkxCB+g8og/7iGflg+O9lO5cKdGvXz8mTJhwwLgJEyaE3Z/KlClTCn1zTs6E/sADD3D66acXal3RIKYSevmGtVnb6iy6rRvPjA8zgg7HOQdcfPHFTJ48ef/DLFatWsW6des4+eSTGTRoEB07duTYY49l2LBhuS6fnJzM5s2bAXjooYdo1qwZJ5100v4udsHamHfq1Im2bdty0UUXsXPnTj777DMmTZrEnXfeSUpKCj/++CMDBw7krbfeAuyO0Hbt2tG6dWuuuuoq9uzZs397w4YNo3379rRu3ZqlBegBMOhudqO7HXouGg4dQMLlk3nsjtmc9k03fwCGc9kF0H9ujRo16Ny5M1OnTqVXr15MmDCBPn36ICI89NBD1KhRg/T0dE477TS++eYb2rRpk+t65s+fz4QJE1i4cCFpaWm0b9+eDh06AHDhhRdyzTXXAHDvvfcyduxYbr75Znr27Ml5553HxRdffMC6du/ezcCBA5kxYwbNmjXj8ssv55lnnuG2224DoFatWixYsIAxY8YwYsQIXnjhhXwPQ2noZjemSugACRf1ZG+FRNosHs/MmUFH45yDA6tdsle3vPnmm7Rv35527dqxZMmSA6pHcpozZw4XXHABlStXpmrVqvTs2XP/tMWLF3PyySfTunVrxo8fn2f3u5mWLVtG06ZNadasGQBXXHEFs2fP3j/9wgsvBKBDhw77O/TKT2noZjfmSuhUrky53hfRZ/x/uHjYPzj11IpBR+Rc6RFQ/7m9evVi8ODBLFiwgJ07d9KhQwd++uknRowYwdy5cznssMMYOHAgu3fvLtT6Bw4cyMSJE2nbti3jxo3j4yI+ziyzC95IdL9bkt3sxlwJHaDc5f2ppqlU/WSyP6bOuVIgMTGR7t27c9VVV+0vnW/bto0qVapQrVo1NmzYwNSpUw+5jlNOOYWJEyeya9cutm/fzrvvvrt/2vbt26lfvz779u1j/Pjx+8cnJSWxffv2g9bVvHlzVq1axYoVKwB45ZVX6Nq1a5H2sTR0s5vvz4GIVARmAxVC87+lqsNyzFMBeBnoAGwBLlHVVUWOrrBOPRWtW4+rt77K3/52EXn0le+cK0H9+vXjggsu2F/10rZtW9q1a0eLFi1o3LgxJ5544iGXb9++PZdccglt27alTp06dOrUaf+0Bx98kOOOO47atWtz3HHH7U/iffv25ZprrmHUqFH7L4YCVKxYkZdeeonevXuTlpZGp06duP766wu0P5nd7Gb6z3/+s7+bXVXl3HPPpVevXixatIgrr7ySjAxrqJG9m93U1FRUNWLd7Obbfa6ICFBFVXeISALwCXCrqn6RbZ4bgDaqer2I9AUuUNVLDrXeInWfG4477iDt6dHUSV/P5M9q0KVL8W3KudLMu8+NXhHvPldN5rlAQmjI+SvQC/h36PVbwGmhH4LgDBhAfPpexlQYzFPDfg80FOecKwlh1aGLSDkRWQhsBD5U1S9zzNIQ+AVAVdOAVKBmJAMtsJQUGDyYS/a+wugPm7H6r895f+nOuZgWVkJX1XRVTQEaAZ1FpFVhNiYi14rIPBGZt6m4HwQqAk8+yY5ZC1heriVN/n49dOgAs2YV73adK4WCejKZK7zC/M8K1MpFVbcCM4EeOSatBRoDiEg8UA27OJpz+edVtaOqdqxdu3aBgy2MpJNTmPaXj+nNm+zd+Dt06wa9esH8+XkvpAqzZ0O2q+jORauKFSuyZcsWT+pRRFXZsmULFSsWrNl1OK1cagP7VHWriFQCzgAezTHbJOAK4HPgYuAjLUWfnltvE5Kf6s11J5/LS62fhCeegI4d4bzz4L77oHNnmzE1FV55BZ55BjJvcJg/H9q3Dy5454qoUaNGrFmzhmI/K3YRVbFixQNa0YQjnFYubbALnuWwEv2bqvqAiDwAzFPVSaGmja8A7YDfgL6quvJQ6y32Vi453HUXjBgBS5fC0XVS7SHTTz4Jv/0GPXpA48bw2mvwxx+W7K+5Bv76V2jVCj76CO9DwDlXGhyqlUu+Cb24lHRC37ABkpOhXz948cXQyO3bYcwYy/R//GETBw2yhA7wz3/CTTfBpElw/vklFqtzzuXFE3rIrbda/v7hB0vu++3ZYy1gKlc+cIF9+6B1a3v97bf2aCTnnAtQkdqhx5I777Sak4cfzjGhQoWDkzlYAn/sMVi2DMLobc0554JUphJ6o0Zw7bUwdqyV0sNy/vnQtSsMGwbbthVrfM45VxRlKqGDNWqpWBHuvTfMBUSsjn3TJng0Z+Me55wrPcpcQq9bF26/Hd58E8Kuwu/YEfr3t1Yxv/xSrPE551xhlbmEDjBkCNSqBXffXYCFHnrIbjgKu2jvnHMlq0wm9KpVLS/PmAEffhjmQocfbo/vevlleO+9Yo3POecKo0w1W8xuzx5o0QJq1IC5cyEunJ+2nTvh5JNh+XL4/HO76cg550qQN1vMRYUK8MADsGCB1aeHpXJl+N//ICkJevaE0JPInXOuNCizCR3g0kvtvqF774W9e8NcqFEjmDgR1q2Diy4qwILOOVe8ynRCL1fObjL68ccC3jfUubP1HzB7Ntxwg10sdc4Vj6lTYeRICD3CzeWtTCd0gHPOsfuG7rvP+nsJ26WXWuddY8fC008XW3zORZV337XT3kg8d+DXX+GSS+xLevvtcOWVkJZW9PXGsDKf0EXg2Wetb65BgwpY2H7gAbjgArjjDmsL+dtvxRanc4FStUYBeUlPt1JRz56wZIndt7HloEcihL+tsWPhmGOsevPBB2H4cGth1revV3MeiqoGMnTo0EFLk8ceUwXV114r4II7dqgOHKgqolq9uq1o165iidG5wNx0k2r58qqXX646f/6B07ZsUT3rLPsCXXWV6qefqiYkqF54oWpGRnjrT09X/eUX1enTVbt2tXWdcorq0qVZ8zz5pI0/+2zVnTsjtmvRBuu2PNe86gk9JC1N9fjjVWvUUF2/vhArWLTIPmig2rix6rhxqps2hf+Bdq44ZWSojh+vOnWq6t69BVv2jTfsc33iiaqJifb6pJNU//Mf1blzVZOTLdk//3zW5z2zhPTCC7mvMy1N9emnVf/0J9VWrVQrVbL5wQpG//qXJfmcnn/eCk/duqlu25b7fsY4T+hh+v571QoV7DNW6M/FRx+pduyY9eGsWFH1qKNUu3e30s3cuRGN2bmwPP541meyVi3VQYNUZ8/OPWlm98MPqklJql262A/B1q2qI0eqHnFE1voaNVL98ssDl0tPVz31VNXKlVWXLTtw2q+/qp5+ui3brJlqz56qt9+uOmaM6ocfqv7226FjGj9etVw5W/bkk+0HoVEj1SpV7Idl0CDbRow6VEIvszcW5WXECOtmd/x4u+5ZKBkZMH06fP+99f2SOXz3nbVl/+47qF49onE7l6fXXrM67T597EP9+uv20JZdu6wZ7q23wuDB1uwruz174IQT4KefYOFCaNIka1p6OkyebB0i3XQT1Klz8HbXroU2baBpU/jsMyhf3i6W9usHv/8O//gH/PnPhXsa2KRJ1kStYkU47DD7PlWvbut95RUbn3ltKymp4OsvxQ51Y5GX0HMoctXLocybZyWLq66K8IpdmZCerrp5c8GWmTHD6rO7dVPdvTtr/PbtVtI94wwrKXfporp8+YHL3nSTTfvf/wof8zvv2DqGDlX9+99V4+JUjz7aqiiLy7JlqhdfbNutU0d19GjV338vvu2VMLzKpWAyq1569iyGKrm//MUO+7RpEV6xi1m7d1tddPPm9tlJTrbqu3/9y5JXXh/ShQtVq1a1Kom8ElpGhrUEOOwwq8ceNcp+ON56y7Y1eHDR47/mmqzqmb59c6/7Lg5ffGEXVjO33bKl6p//rDp2rOqSJapff20/avfeaxdwW7Sw6qjq1e1aQYUKVgCrU0f1iivsmKSmhrft1FTVl15Svewyu24RQYdK6F7lkocnnrCztZdegoEDI7ji3buhXTs73f3225g7HXQRlJpqbWqfesraZLdrZ3cnf/213dS2aZPNV6cOnHRS1pCSYncyd+li1Siff25VK4eybh1cfbXdxNO1q1WxNG8Oc+ZYVUlR/PGHtSE/7TR7wkxJPnBdFT79FD7+2I7D559btUx25crBUUdZM8n69e1JZfHxNiQkWJXT1Km2XEKCHZ8zzrCqpEaNbKhf36pap061+tp337XveqVK9l2//np4/HFITCzyLnmVSyGkpVnrqaQk1Z9+ivDKP/3UrtTfeGPR1rNunZUAJk0qE1f3o0pGhl0g/+qrgjexy8iwC49JSVayPOMMu1iY/X+ckWGnks8/rzpggGrTplkl0cqVVWvXVq1WTfXbbwu23RdesNJptWqqK1cWLO5okJ5ux23cOGu98+23B1ZF5WXfPruIPHSo6jHHZB3rzCEuLqulTq1a9t3+7DP73w8ZYt/3I49U/eSTIu8CXuVSOKtW2Xfq5JMtwUfUbbfZ4Z81q/DruPnmrA9Up052aueJPXjr16uec86BX/ZjjlHt10/10UdVf/wx72X37VO97jpb7pxzVBcsCH+7a9ZYkrrlFtUePVTnzClc/OvWHTpGZ1VY33yjOmWK/ajed58d98mTc28WOmuW/ejGxanefXd4PyJ58IReBOPG2VF67LEIr3jHDmv6ddRRqn/8UfDlN22yEkH//laqOvxwC/SEE1Q/+MCSSubw66+qGzeGl+yXL7fmY888Yx/UF15QffHFiJQsosqWLap9+ljTuILs+8SJVkKrWNFK2W+/bV/288+3+xPA6mbvu+/g//u2bZaIwb70+TUpdNFl27as6wmDBhV6NZ7QiyAjQ/WCC6x5a8QvzM+YYf+C668veMl6+HBbdvFie79njyXhhg31oNPBzKFHj0Nf7Z8+Pes0P7fh448Lv6/RZNYsa9ccH29/4+JU77/fSs952b5d9eqr7TilpNhFt9z8/LOV1MF+hP/7X/vf//KLaps2dhHu+eeLZbdcKfHee/Y5KCRP6EW0caNq3bqqrVsX6Uwpd0OG2L9hwABLyuHYsUO1Zk3V8847eNquXdZq4ZlnDhzuv9+arzVvfvCNHqp2tT8hwVpEfPedlezXrlVdvVp1xQo7mzj66Nju1mDfPis5x8XZmdPcudZa4Yor7H90/PF2LDKlpdkNNQ8+aMdHxErW4fwfZ85UPfZYW++ZZ6o2aGAtUj74oLj2zsUIT+gR8N57drTuvDPCK87IUP3b32zlp51md+LlZ9Qom7+gdaSzZmU1y8pMHBkZWbdpd+2adwn+ww9tnnvuKdg2S6Nt2+wOyCVLrI76889t/044wfbxiisOblo3YYJdKExMtB/HPn3sZgWwRN65c8Gvh+zda/2TJCVZdUxBLmC6MssTeoRce619d3P2TRQRL79sp/itW9vpd1727bNT9RNOKNx2fvrJtlGunPWlccst9jHo0yf/04+BAy3GhQsLt+1I+e471WHDrHXP9u3hLZOebkm7Xz+rw86tSqlqVTtTycvPP9sVcrAS9cCBdja0cWPR9uf330uubbaLeodK6N4OvQBSU625aqtW8NFHxdCcdvp0uPBCe4r1lCl223ROmbdxT5wIvXoVbjvbt8OAAXb7NNht3yNG5P9g1S1boGVLe2D2558ffKt4cVOFf/7T+mbYvdvGJSTAiSfCWWdZO+fsXSqIWBvgt9+GcePg55/tNvH+/aFTJ3sOYfbh2GOhbt1Dx5CRYW22GzYs2fbUzoV4O/QIGjPGCmgTJxbTBhYtsgublStb3XfOtsdt21oTuKK2gEhPt6qWgl6Ae/11OwAjRxZt+wW1fn1Wb5Znn22l5RkzrA6sTZvcS9yZg4jVU0+YENvXAFyZgJfQIyctzQrOaWmweHHRb6LL1bp1dmfdBx/A2WdbZ//168P779v7F1+06UFQhfPPh5kz7UEGycnFv81337VOnLZvtzOJG244uHS8fr3dEbhnT1acYPOddJKdVTgXA7yEHmGTJ1vB7+mni3EjGRnWqVClSnbx7c03rQveBg2KoalNAf38s10cPOus4msrvWGDnaGceqrm2xTQuTIEL6FHlqpV2c6bBytWQI0axbixZcvgsstg7lx7//jj1slM0EaPhptvhm7d7IyhadOCLf/NN7B6dVafGZnDt9/Cm29aXyUZGdafyOWXW1eoFSoUy644F02KVEIHGgMzge+AJcCtuczTDUgFFoaG+/NbbzSX0FWtqlskMp3R5WvvXruR6OSTw+/trbhlZFhvf0lJ9mCB0aPzL63v3Wu3pmc2D8xraNHC2oN/8413ZeBcDhSlhC4i9YH6qrpARJKA+cCfVPW7bPN0A4ao6nnh/spEcwk90zXXwL//bc+rOOqooKMJyOrVdiA++ODg0rqq1Wlv2WIP+B0zBtasgSOPtNL9iSfaxYjsQ4MG1uudtyBxLleHKqHH57ewqq4H1odebxeR74GGWIm9THvwQXv4y113Wcu4MqlJE7tY++KLcPvtloyrVbMnxO/cadUmmU4/HZ55xi7slnSTR+fKgHwTenYikgy0A77MZXIXEVkErMNK60tyWf5a4FqAJtkfZxWl6tWDu++G++6DadOsXr1MErFWKGeeaa1Q9uyBKlXscXuVK9vr006zdt7OuWIT9kVREUkEZgEPqeo7OaZVBTJUdYeInAM8rapHH2p9scm4tWcAABUeSURBVFDlAnbfSseO8Ntvdp2vdu2gI3LOxbJDVbnkc2vg/hUkAG8D43MmcwBV3aaqO0KvpwAJIlKrCDFHjUqVrNrl99/hqquymj8751xJyzehi4gAY4HvVfXJPOapF5oPEekcWu+WSAZamrVpA489Bu+9Z9f9nHMuCOHUoZ8IXAZ8KyILQ+PuAZoAqOqzwMXAIBFJA3YBfTXcupwYcfPNdm3wjjvskYOtWgUdkXOurPEbiyJo40YrrdeuDV99ZdUxzjkXSUWuQ3fhqVPHOvVbvBiGDg06GudcWeMJPcJ69LDeaEePtp5unXOupBSoHboLz8MPw/z51uX4rl3WRNs554qbl9CLQYUKMHWq3Wdz9dXw1FNBR+ScKws8oReTypXhf/+Diy6yKpgHHvA26s654uUJvRhVqAATJsAVV8CwYfbkNE/qzrni4nXoxSw+3vqtSkqCJ56A9HQYOTLoqJxzscgTegmIi4NRo6yDwaeesqe23Xpr0FE552KNJ/QSImIl9NWrrU49ORl69Qo6KudcLPE69BJUrhy8+ip06gT9+mU9Vc455yLBE3oJq1wZJk2CunXh/PNh1aqgI3LOxQpP6AGoWxemTLHnQJx7LmzdGnREzrlY4Ak9IMccA++8Az/8AL172+M0nXOuKDyhB6h7d3juOZg+HYYMCToa51y081YuAbvySli0CJ5+Gtq2tffOOVcYXkIvBUaMgNNPh+uvh88/Dzoa51y08oReCsTHwxtvQOPGcOGFsHZt0BE556KRJ/RSokYN68xrxw7405+s213nnCsIT+ilyLHH2o1H8+ZZ9YtzzhWEJ/RSplcvuP9+ePllePfdoKNxzkUTT+il0F//aqX1m26yKhjnnAuHJ/RSqHx5eP5568jr/vuDjsY5Fy08oZdSJ5wA111n7dMXLAg6GudcNPCEXoo98gjUrg3XXutdAzjn8ucJvRSrXt1K6PPnw+jRQUfjnCvtPKGXcn36wNlnw733Wp26c87lxRN6KScCY8ZARoa1evGHTDvn8uIJPQokJ8ODD1q79KeeCjoa51xp5Qk9SgweDBdcYN3sTpsWdDTOudLIE3qUiIuzu0dbtYJLLoHly4OOyDlX2nhCjyKJidaBV0KCPY/UH13nnMsu34QuIo1FZKaIfCciS0Tk1lzmEREZJSIrROQbEWlfPOG65GR4+21YuRL69oX09KAjcs6VFuGU0NOAO1S1JXA8cKOItMwxz9nA0aHhWuCZiEbpDnDKKdbyZdo0GDo06Gicc6VFvgldVder6oLQ6+3A90DDHLP1Al5W8wVQXUTqRzxat98111gzxiefhB49vHsA51wB69BFJBloB3yZY1JD4Jds79dwcNJHRK4VkXkiMm/Tpk0Fi9QdZORIePxxmDsXOnSA3r1h6dKgo3LOBSXshC4iicDbwG2quq0wG1PV51W1o6p2rF27dmFW4bKJj7dmjCtXWq+M779v3e5edRX476VzZU9YCV1EErBkPl5V38lllrVA42zvG4XGuRJQrRr83/9ZYr/tNhg/Ho47Dr77LujInHMlKZxWLgKMBb5X1SfzmG0ScHmotcvxQKqqro9gnC4MtWvDE0/AnDmwc6d1wTt9etBROedKSjgl9BOBy4BTRWRhaDhHRK4XkcwnX04BVgIrgH8BNxRPuC4cnTvDV19BkyZ2wfS554KOyDlXEuLzm0FVPwEkn3kUuDFSQbmia9IEPvnE2qpff73dWfrYY1CuXNCROeeKi98pGsOqVoVJk7KaN155pfXa6JyLTfmW0F10i4+Hf/zD6teHDYN69ayk7pyLPZ7Qy4j77oONG63dev361nujcy62eEIvI0TscXYbNsDtt0PdunDppUFH5ZyLJE/oZUi5cvDKK7B5MwwcaNUwZ5wRdFTOuUjxi6JlTMWKMHEitGwJF14I8+YFHZFzLlI8oZdB1arB1KlQqxacdhp89FHQETnnIsETehlVvz7Mng2NG9vNR6+9FnREzrmi8oRehjVubDcfnXgi9O8Pjz4KqkFH5ZwrLE/oZVz16tZLY9++cPfdcPPN/hQk56KVt3JxVKhgPTQ2agQjRsD69fD661C+fNCROecKwkvoDoC4OLvpaORIeOcdK7Hv2xd0VM65gvCE7g5w2212A9J//wv9+nlSdy6aeEJ3B7nlFiupv/22XSxNSws6IudcOLwO3eXqttvs4uiQIVl3mMb7p8W5Us2/oi5Pd9xhSf2uu6w549ixUKVK0FE55/LiVS7ukIYOtfbpb7wBrVvDzJlBR+Scy4sndJevoUNh1iyrejn1VBg0CLZtCzoq51xOntBdWE45BRYtsq53n3sOWrWCadOCjso5l50ndBe2ypXhiSfg00+tLv2cc+xZpc650sETuiuwLl2sSWNGBnzxRdDROOcyeUJ3hdKsmfWtvmhR0JE45zJ5QneFEh9v9eie0J0rPTyhu0Jr2xYWLvQud50rLTyhu0JLSYEtW2DduqAjcc6BJ3RXBG3b2l+vdnGudPCE7gqtTRv7u3BhsHE454wndFdo1apB06ZeQneutPCE7ook88Kocy54ntBdkaSkwA8/wB9/BB2Jc84TuiuStm2t2eLixUFH4pzLN6GLyIsislFEcv3Kikg3EUkVkYWh4f7Ih+lKq8yWLl7t4lzwwnnAxThgNPDyIeaZo6rnRSQiF1WSk6FqVb8w6lxpkG8JXVVnA7+VQCwuColYKd0TunPBi1QdehcRWSQiU0Xk2LxmEpFrRWSeiMzbtGlThDbtgpaZ0DMygo7EubItEgl9AXC4qrYF/gFMzGtGVX1eVTuqasfatWtHYNOuNEhJsVYuK1cGHYlzZVuRE7qqblPVHaHXU4AEEalV5Mhc1PAuAJwrHYqc0EWknohI6HXn0Dq3FHW9Lnoce6w9b9RbujgXrHxbuYjI60A3oJaIrAGGAQkAqvoscDEwSETSgF1AX1XvULUsqVQJmjf3ErpzQcs3oatqv3ymj8aaNboyrG1b+OSToKNwrmzzO0VdRKSkwC+/wG/ewNW5wHhCdxGReWH0m2+CjcO5sswTuosI7wLAueB5QncRUa8e1K3rF0adC5IndBcx3gWAc8HyhO4iJiUFliyBffuCjsS5sskTuouYtm1h715YujToSJwrmzyhu4jp2NH+vvJKsHE4V1Z5QncR06wZXH01jBgBc+YEHY1zZY8ndBdRI0dC06Zw2WWwbVvQ0ThXtnhCdxGVmAivvmp3jd56a9DROFe2eEJ3EdelC9xzD4wbB++8E3Q0zpUdntBdsbj/fujQAa69FtavDzoa58oGT+iuWCQkWNXLH3/An/8M3qGyc8XPE7orNi1awOOPw9Sp0LcvfPGFJ3bnipMndFesbrwR7rrLknqXLlYN88ILVnJ3zkWWJ3RXrETgkUdg7Vp49llIS4NrroGGDeEvf4GtW4OO0LnY4QndlYikJLjuOuu8a84cOOssePRROOIIeOIJ2L076Aidi36e0F2JEoGTToI33oAFC6BzZxgyxJ5J+sorkJ4edITORS9P6C4wKSnw/vswfTrUqgWXXw7HHAPDh8OyZUFH51z08YTuAnfaaTB3LkyYAI0awQMPWAuZ9u2tlczq1UFH6Fx08ITuSoW4OLjkEvjoI1izxvqESUiAoUPh8MOtauaRR2D58qAjda70Eg2oYXDHjh113rx5gWzbRY8VK+Dtt60Lga++snHHHgvnngtNmkDt2lCnjv2tVw9q1gw2XueKm4jMV9WOuU7zhO6ixS+/wMSJltxnz4aMjIPnadYMTj/dhu7doXr1ko/TueLkCd3FnLQ02LIFNm2CjRvt7+rV8PHHMGuW3bgUFwedOsHJJ9tNTV26QP36QUfuXNF4Qndlyt691s3A9Ok2zJ9v48Cqabp0sRY2zZpZc8mjjoIKFYKN2blweUJ3ZdqePfD11/D55zZ88YVV32SKi4PkZKubb9vWkn1Kij2oI86bDbhSxhO6czls22YtZpYvtzbvy5bB4sX2gOvMm5uSkuw5qWedBWefDa1b241RzgXJE7pzYdq9G5YsgYULbZgzx7orAOt/pkcPOPVUq7qpV8+GxMRgY3Zly6ESenxJB+NcaVaxovUI2aFD1rh16+yO1qlT4a23YOzYA5epUgUaNLDqmk6dbOjQAapWLdnYnfMSunMFsG+fVcv8+uuBw+rVdvH1p59sPhG76Fq7tv1IVKpkfytWtLthW7SwoXlzqFYt2H1y0aVIJXQReRE4D9ioqq1ymS7A08A5wE5goKouKFrIzpVOCQlWl966de7TN2+GefOsK4Ovv4bUVNi505pY7t5tr9eutWaXmerVs24Oune36py2baFcuZLZHxdbwqlyGQeMBl7OY/rZwNGh4TjgmdBf58qcWrWsnr1Hj7zn2bcPVq60C7FLl8L331vLmylTbHr16tCtG5xyilXfpKR4Pb0LT74JXVVni0jyIWbpBbysVnfzhYhUF5H6quqPBnYuFwkJVtXSvDn07Jk1ft06uzHqo49smDjRxsfFWS+UHTpAy5YHl97LlbNSfsOGVpffsKFV8biyJxIXRRsC2Vr1siY07qCELiLXAtcCNGnSJAKbdi52NGgAl15qA1jd/Pz5VoUzbx5MmwYv53WenEONGla679o1q6Rfvnzxxe5KhxJt5aKqzwPPg10ULcltOxdt6tWzTsjOPdfeq+b+LNZ9+yz5r12bNaxaBZ99BvfcY/NUqgTHHw+NGx98kbZ9ezjnHIj3Nm9RLxL/wrVA42zvG4XGOeciSCTvuvTDDrNqmZw2b7a29LNmwSefWKdmu3fDrl32d88em69JE3tE4NVXW++VLjqF1WwxVIf+Xh6tXM4FbsJauRwHjFLVzvmt05stOhe8ffvgvffgn/+EGTOsfr93b3voyNat1jonc0hPt6aYxxyT1ezSm1yWvCLdKSoirwPdgFrABmAYkACgqs+Gmi2OBnpgzRavVNV8M7UndOdKl6VL4ZlnYNw46xoB7IJrjRpZ/cz/+KP9CGSqXdta5SQmWlcJiYl2Q9Xhh8ORR2YNjRodeDFX1QbvK6fg/NZ/51zYdu60OvmaNS05Z++/Zt8+u3lq6VIbfvzRkv+OHbB9u/3dutVutMqe+OPj7aJsWpqV9DP7y2naFM47z64TdO1qdfru0DyhO+dKVHq6PUpwxQpL+j/9ZAk+Pt5K6vHx9kMxb55V9ezebV0onH66VemkptoPQ+ZQrx6MGmUl/bLOE7pzrtTauRNmzoTJk21Yt86qcTKHatXgyy+tz/qXX7YWOWWZd87lnCu1Klc+uHlmzm6Kly+HPn1snjvvhIcesgu47kB+ScI5V6rk1ud8s2b2cJLrr4fHH7ebpX7+Of91padbdU5AFRH7qVrV0YoV1s3DypXFsx0voTvnokKlStYKp3t3ay9/xBFWDZO9Xj4uzh43uHevtbHPvPhaoYK1r69bN+tv9ou0aWk2VK9udfiZQ8OG9gOzdav1uZPZ907mReM6dbKGqlWtumj1avux+flnezLWxo3W7DN7h2x33QWPPBL5Y+QJ3TkXVfr0sX5txo2z0ndmQs5sPVO+vCXwzL8JCZaQN2ywYf16e3hJWpr9CGQO5crZw8a3bs3aVmKiXazdsCFrXPnydpH2t9+sVU9uatSwm7WSk+0O3Vq1DhxatCieY+MJ3TkXdY48Eh58MPLrVbXk/f33WSXyP/6wjtQyS+3JyVndJOzaZT8CGzday5z69a17haSkyMcWDk/ozjkXIpL1aMHu3fOfv1IlK4mXlr4G/aKoc87FCE/ozjkXIzyhO+dcjPCE7pxzMcITunPOxQhP6M45FyM8oTvnXIzwhO6cczEisO5zRWQTEEb3OtQCNhdzOCUplvYnlvYFfH9Ks1jaFyja/hyuqrVzmxBYQg+XiMzLq+/faBRL+xNL+wK+P6VZLO0LFN/+eJWLc87FCE/ozjkXI6IhoT8fdAARFkv7E0v7Ar4/pVks7QsU0/6U+jp055xz4YmGErpzzrkweEJ3zrkYUaoSuoi8KCIbRWRxtnE1RORDEfkh9PewIGMMl4g0FpGZIvKdiCwRkVtD46N1fyqKyFcisii0P/8XGt9URL4UkRUi8oaIlA861nCJSDkR+VpE3gu9j+Z9WSUi34rIQhGZFxoXlZ81ABGpLiJvichSEfleRLpE4/6ISPPQ/yRz2CYitxXXvpSqhA6MA3rkGHc3MENVjwZmhN5HgzTgDlVtCRwP3CgiLYne/dkDnKqqbYEUoIeIHA88CoxU1aOA34E/BxhjQd0KfJ/tfTTvC0B3VU3J1r45Wj9rAE8D76tqC6At9n+Kuv1R1WWh/0kK0AHYCfyX4toXVS1VA5AMLM72fhlQP/S6PrAs6BgLuV//A86Ihf0BKgMLgOOwu93iQ+O7ANOCji/MfWgU+iKdCrwHSLTuSyjeVUCtHOOi8rMGVAN+ItRoI9r3J1v8ZwKfFue+lLYSem7qqur60OtfgbpBBlMYIpIMtAO+JIr3J1RFsRDYCHwI/AhsVdW00CxrgIZBxVdATwFDgYzQ+5pE774AKPCBiMwXkWtD46L1s9YU2AS8FKoSe0FEqhC9+5OpL/B66HWx7Es0JPT91H7OoqqdpYgkAm8Dt6nqtuzTom1/VDVd7dSxEdAZaBFwSIUiIucBG1V1ftCxRNBJqtoeOBur3jsl+8Qo+6zFA+2BZ1S1HfAHOaokomx/CF2P6Qn8J+e0SO5LNCT0DSJSHyD0d2PA8YRNRBKwZD5eVd8JjY7a/cmkqluBmVi1RHURiQ9NagSsDSyw8J0I9BSRVcAErNrlaaJzXwBQ1bWhvxuxOtrORO9nbQ2wRlW/DL1/C0vw0bo/YD+0C1R1Q+h9sexLNCT0ScAVoddXYHXRpZ6ICDAW+F5Vn8w2KVr3p7aIVA+9roRdD/geS+wXh2aLiv1R1b+oaiNVTcZOgz9S1f5E4b4AiEgVEUnKfI3V1S4mSj9rqvor8IuINA+NOg34jijdn5B+ZFW3QHHtS9AXCnJcNHgdWA/sw36l/4zVbc4AfgCmAzWCjjPMfTkJO436BlgYGs6J4v1pA3wd2p/FwP2h8UcAXwErsNPJCkHHWsD96ga8F837Eop7UWhYAvw1ND4qP2uh2FOAeaHP20TgsGjdH6AKsAWolm1cseyL3/rvnHMxIhqqXJxzzoXBE7pzzsUIT+jOORcjPKE751yM8ITunHMxwhO6c87FCE/ozjkXI/4fc9Ma9Ye0oxwAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Ts4qdfNV4uOW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5sQBZnFSKEb4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0z6BwcAulnw"},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / Inception-V1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pFcw51AuDG4"},"source":["model=load_model(os.path.join(dir,'model_output',number,'GoogleNet','061.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc,\"LRN\":LRN,\"PoolHelper\":PoolHelper, \"AdamW\":AdamW})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWlrnY9EuDG-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606283365101,"user_tz":-540,"elapsed":669884,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"f7d1b652-841d-46be-82d3-754a6860afd5"},"source":["# 2. epoch=?\n","var = model.evaluate(generate_test_for_three(),steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (var[0],var[-3],var[-2],var[-1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 10000 images belonging to 100 classes.\n","78/78 [==============================] - 5589s 72s/step - loss: 2.7180 - loss1/classifier_loss: 1.4923 - loss2/classifier_loss: 1.4992 - loss3/classifier_loss: 1.8205 - loss1/classifier_accuracy: 0.5917 - loss1/classifier_top5_acc: 0.8585 - loss1/classifier_macro_f1score: 0.3602 - loss2/classifier_accuracy: 0.6236 - loss2/classifier_top5_acc: 0.8736 - loss2/classifier_macro_f1score: 0.4066 - loss3/classifier_accuracy: 0.6347 - loss3/classifier_top5_acc: 0.8792 - loss3/classifier_macro_f1score: 0.4328\n","[Test Loss: 2.7180 /  Test Top-1 Accuracy: 0.6347 / Test Top-5 Accuracy: 0.8792 / Test Macro f1: 0.4328]\n","\n"],"name":"stdout"}]}]}
