{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12.Xception.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"E-OCKgEwJfTn","executionInfo":{"status":"ok","timestamp":1606103350320,"user_tz":-540,"elapsed":1105,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["### 참고 : https://github.com/fchollet/deep-learning-models/blob/master/xception.py"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [Xception]"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original Xception\n","```\n","1) Support Functions\n","2) Almost Original Xception\n","```\n","3. Xception\n","```\n","1) Xception\n","2) Xception Evaluate\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages\n"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103514542,"user_tz":-540,"elapsed":165309,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"e40582e9-080f-45a7-c589-a245e1ab1d0d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103514543,"user_tz":-540,"elapsed":165299,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"d38f9d4a-d6fd-4fde-c1bd-049d9e50c60f"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1606103517083,"user_tz":-540,"elapsed":167837,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1606103517084,"user_tz":-540,"elapsed":167836,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606103517085,"user_tz":-540,"elapsed":167824,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"2cfb27e3-c0cc-45ec-9b9e-cc9f9497c9fd"},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103520220,"user_tz":-540,"elapsed":170947,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"00b1e719-1b96-4898-bbbf-82906cf51de2"},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606103521224,"user_tz":-540,"elapsed":171941,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"e1bf5f56-f83c-4e1b-bc42-5194e6ca758b"},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Kf057Rw2yigs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103521226,"user_tz":-540,"elapsed":171931,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"49b015bb-9c29-4bf5-c891-f6e88483151b"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 4984620507216051753\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 8543644969446583331\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 7425369543340974041\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15695549568\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 13148709706924144665\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k5ubMy33cQZV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103521229,"user_tz":-540,"elapsed":171923,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"f997dd1b-b327-4cd6-f3c7-f6f1996d4148"},"source":["!cat /proc/cpuinfo"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.186\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.37\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.186\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.37\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.186\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.37\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.186\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.37\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"BeJ7UtuOEgWY","executionInfo":{"status":"ok","timestamp":1606103521229,"user_tz":-540,"elapsed":171921,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CIFAR100'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 299 # sizes after cropping\n","super_size = 330 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 32\n","weight_decay = 1e-6\n","epochs = 70"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1606103521230,"user_tz":-540,"elapsed":171917,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4wDCqXKpNBz","executionInfo":{"status":"ok","timestamp":1606103521231,"user_tz":-540,"elapsed":171913,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1606103521231,"user_tz":-540,"elapsed":171910,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ayj6GUEvpNB4"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"UVHXXOYqpNB4","executionInfo":{"status":"ok","timestamp":1606103521232,"user_tz":-540,"elapsed":171909,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1606103521233,"user_tz":-540,"elapsed":171908,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_6Z9x0vpNB8","executionInfo":{"status":"ok","timestamp":1606103521235,"user_tz":-540,"elapsed":171906,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qeao4HympNB9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103573076,"user_tz":-540,"elapsed":223739,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"fd634f5c-5ddc-4c12-ef7f-30148b920215"},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Found 44923 images belonging to 100 classes.\n","Found 5077 images belonging to 100 classes.\n","Found 10000 images belonging to 100 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original Xception\n","---"]},{"cell_type":"markdown","metadata":{"id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vJixgnY7Z6j7"},"source":["### 2) Almost Original Xception\n"]},{"cell_type":"code","metadata":{"id":"xpAHo3rnaJKw"},"source":["def Xception(input_shape=None, classes=1000, name = \"Xception\", weight_decay = weight_decay):\n","\n","\n","    img_input = Input(shape=input_shape)\n","\n","\n","    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay), name='block1_conv1')(img_input)\n","    x = BatchNormalization(name='block1_conv1_bn')(x)\n","    x = Activation('relu', name='block1_conv1_act')(x)\n","    x = Conv2D(64, (3, 3), use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay), name='block1_conv2')(x)\n","    x = BatchNormalization(name='block1_conv2_bn')(x)\n","    x = Activation('relu', name='block1_conv2_act')(x)\n","\n","    residual = Conv2D(128, (1, 1), strides=(2, 2),\n","                      padding='same', use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    residual = BatchNormalization()(residual)\n","\n","    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block2_sepconv1')(x)\n","    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n","    x = Activation('relu', name='block2_sepconv2_act')(x)\n","    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block2_sepconv2')(x)\n","    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n","\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block2_pool')(x)\n","    x = add([x, residual])\n","\n","    residual = Conv2D(256, (1, 1), strides=(2, 2),\n","                      padding='same', use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    residual = BatchNormalization()(residual)\n","\n","    x = Activation('relu', name='block3_sepconv1_act')(x)\n","    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block3_sepconv1')(x)\n","    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n","    x = Activation('relu', name='block3_sepconv2_act')(x)\n","    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block3_sepconv2')(x)\n","    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n","\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block3_pool')(x)\n","    x = add([x, residual])\n","\n","    residual = Conv2D(728, (1, 1), strides=(2, 2),\n","                      padding='same', use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    residual = BatchNormalization()(residual)\n","\n","    x = Activation('relu', name='block4_sepconv1_act')(x)\n","    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block4_sepconv1')(x)\n","    x = BatchNormalization(name='block4_sepconv1_bn')(x)\n","    x = Activation('relu', name='block4_sepconv2_act')(x)\n","    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block4_sepconv2')(x)\n","    x = BatchNormalization(name='block4_sepconv2_bn')(x)\n","\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block4_pool')(x)\n","    x = add([x, residual])\n","\n","    for i in range(8):\n","        residual = x\n","        prefix = 'block' + str(i + 5)\n","\n","        x = Activation('relu', name=prefix + '_sepconv1_act')(x)\n","        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name=prefix + '_sepconv1')(x)\n","        x = BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n","        x = Activation('relu', name=prefix + '_sepconv2_act')(x)\n","        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name=prefix + '_sepconv2')(x)\n","        x = BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n","        x = Activation('relu', name=prefix + '_sepconv3_act')(x)\n","        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name=prefix + '_sepconv3')(x)\n","        x = BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n","\n","        x = add([x, residual])\n","\n","    residual = Conv2D(1024, (1, 1), strides=(2, 2),\n","                      padding='same', use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    residual = BatchNormalization()(residual)\n","\n","    x = Activation('relu', name='block13_sepconv1_act')(x)\n","    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block13_sepconv1')(x)\n","    x = BatchNormalization(name='block13_sepconv1_bn')(x)\n","    x = Activation('relu', name='block13_sepconv2_act')(x)\n","    x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block13_sepconv2')(x)\n","    x = BatchNormalization(name='block13_sepconv2_bn')(x)\n","\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block13_pool')(x)\n","    x = add([x, residual])\n","\n","    x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block14_sepconv1')(x)\n","    x = BatchNormalization(name='block14_sepconv1_bn')(x)\n","    x = Activation('relu', name='block14_sepconv1_act')(x)\n","\n","    x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block14_sepconv2')(x)\n","    x = BatchNormalization(name='block14_sepconv2_bn')(x)\n","    x = Activation('relu', name='block14_sepconv2_act')(x)\n","\n","\n","    x = GlobalAveragePooling2D(name='avg_pool')(x)\n","    x = Dropout(0.5)(x)\n","    x = Dense(classes, activation='softmax', kernel_regularizer=l2(weight_decay), name='predictions')(x)\n","\n","\n","    inputs = img_input\n","\n","    # Create model.\n","    model = Model(inputs, x, name=name)\n","\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOAp8LsWRMR6"},"source":["## 3. Xception\n","---"]},{"cell_type":"markdown","metadata":{"id":"18V3G5o-RMR7"},"source":["### 1) Xception"]},{"cell_type":"code","metadata":{"id":"5YOrZ2rhneyq"},"source":["model = Xception(input_sizes, classes=classes, name='Xception')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HuelUizNJWz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605698405376,"user_tz":-540,"elapsed":130813,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"232e137e-973a-4b5a-dff7-c4123176be28"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"Xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n","                                                                 add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n","                                                                 add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n","                                                                 add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n","                                                                 add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n","                                                                 add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n","                                                                 add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n","                                                                 batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 2048)         0           avg_pool[0][0]                   \n","__________________________________________________________________________________________________\n","predictions (Dense)             (None, 100)          204900      dropout[0][0]                    \n","==================================================================================================\n","Total params: 21,066,380\n","Trainable params: 21,011,852\n","Non-trainable params: 54,528\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yNCT3g8eE6vT"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0hcwfHt4efG"},"source":["# AdamW 시작 / AdamWR은 epoch을 500번은 돌려야 될 것 같아 힘듦.\n","# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWz2b3riipUA"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoWLeggG6dBf"},"source":["optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=False, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=False, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9pnv0cw6dBm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4ba9a76-cfd9-49fe-cc7f-8cdbc0265445"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs, verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 2.669753492949904e-08(L2) weight decay set for block1_conv1/kernel:0\n","0.0(L1), 2.669753492949904e-08(L2) weight decay set for block1_conv2/kernel:0\n","0.0(L1), 2.669753492949904e-08(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 2.669753492949904e-08(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 2.669753492949904e-08(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 2.669753492949904e-08(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 2.669753492949904e-08(L2) weight decay set for predictions/kernel:0\n","1403/1403 [==============================] - ETA: 0s - loss: 3.9768 - accuracy: 0.0979 - top5_acc: 0.3029 - macro_f1score: 0.0020\n","Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/001.h5\n","\n","Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/001.h5\n","1403/1403 [==============================] - 12438s 9s/step - loss: 3.9768 - accuracy: 0.0979 - top5_acc: 0.3029 - macro_f1score: 0.0020 - val_loss: 4.4823 - val_accuracy: 0.0987 - val_top5_acc: 0.3121 - val_macro_f1score: 0.0074\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","1403/1403 [==============================] - ETA: 0s - loss: 3.0735 - accuracy: 0.2427 - top5_acc: 0.5483 - macro_f1score: 0.0191\n","Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/002.h5\n","\n","Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/002.h5\n","1403/1403 [==============================] - 1155s 823ms/step - loss: 3.0735 - accuracy: 0.2427 - top5_acc: 0.5483 - macro_f1score: 0.0191 - val_loss: 3.2887 - val_accuracy: 0.2421 - val_top5_acc: 0.5400 - val_macro_f1score: 0.0313\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","1403/1403 [==============================] - ETA: 0s - loss: 2.4866 - accuracy: 0.3622 - top5_acc: 0.6893 - macro_f1score: 0.0486\n","Epoch 00003: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/003.h5\n","\n","Epoch 00003: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/003.h5\n","1403/1403 [==============================] - 1157s 825ms/step - loss: 2.4866 - accuracy: 0.3622 - top5_acc: 0.6893 - macro_f1score: 0.0486 - val_loss: 3.0444 - val_accuracy: 0.2979 - val_top5_acc: 0.6143 - val_macro_f1score: 0.0503\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","1403/1403 [==============================] - ETA: 0s - loss: 2.1303 - accuracy: 0.4427 - top5_acc: 0.7651 - macro_f1score: 0.0739\n","Epoch 00004: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/004.h5\n","\n","Epoch 00004: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/004.h5\n","1403/1403 [==============================] - 1144s 816ms/step - loss: 2.1303 - accuracy: 0.4427 - top5_acc: 0.7651 - macro_f1score: 0.0739 - val_loss: 2.3056 - val_accuracy: 0.4320 - val_top5_acc: 0.7369 - val_macro_f1score: 0.0834\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.8681 - accuracy: 0.5059 - top5_acc: 0.8119 - macro_f1score: 0.0957\n","Epoch 00005: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/005.h5\n","\n","Epoch 00005: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/005.h5\n","1403/1403 [==============================] - 1146s 817ms/step - loss: 1.8681 - accuracy: 0.5059 - top5_acc: 0.8119 - macro_f1score: 0.0957 - val_loss: 1.8780 - val_accuracy: 0.5024 - val_top5_acc: 0.8117 - val_macro_f1score: 0.0988\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.6815 - accuracy: 0.5495 - top5_acc: 0.8450 - macro_f1score: 0.1111\n","Epoch 00006: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/006.h5\n","\n","Epoch 00006: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/006.h5\n","1403/1403 [==============================] - 1148s 818ms/step - loss: 1.6815 - accuracy: 0.5495 - top5_acc: 0.8450 - macro_f1score: 0.1111 - val_loss: 2.0853 - val_accuracy: 0.4903 - val_top5_acc: 0.8038 - val_macro_f1score: 0.1073\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.5364 - accuracy: 0.5877 - top5_acc: 0.8705 - macro_f1score: 0.1256\n","Epoch 00007: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/007.h5\n","\n","Epoch 00007: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/007.h5\n","1403/1403 [==============================] - 1160s 827ms/step - loss: 1.5364 - accuracy: 0.5877 - top5_acc: 0.8705 - macro_f1score: 0.1256 - val_loss: 1.8036 - val_accuracy: 0.5374 - val_top5_acc: 0.8291 - val_macro_f1score: 0.1161\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.3976 - accuracy: 0.6236 - top5_acc: 0.8896 - macro_f1score: 0.1392\n","Epoch 00008: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/008.h5\n","\n","Epoch 00008: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/008.h5\n","1403/1403 [==============================] - 1159s 826ms/step - loss: 1.3976 - accuracy: 0.6236 - top5_acc: 0.8896 - macro_f1score: 0.1392 - val_loss: 1.8609 - val_accuracy: 0.5473 - val_top5_acc: 0.8212 - val_macro_f1score: 0.1242\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.3059 - accuracy: 0.6498 - top5_acc: 0.9034 - macro_f1score: 0.1486\n","Epoch 00009: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/009.h5\n","\n","Epoch 00009: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/009.h5\n","1403/1403 [==============================] - 1144s 816ms/step - loss: 1.3059 - accuracy: 0.6498 - top5_acc: 0.9034 - macro_f1score: 0.1486 - val_loss: 1.7119 - val_accuracy: 0.5789 - val_top5_acc: 0.8430 - val_macro_f1score: 0.1314\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.2035 - accuracy: 0.6774 - top5_acc: 0.9182 - macro_f1score: 0.1598\n","Epoch 00010: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/010.h5\n","\n","Epoch 00010: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/010.h5\n","1403/1403 [==============================] - 1139s 812ms/step - loss: 1.2035 - accuracy: 0.6774 - top5_acc: 0.9182 - macro_f1score: 0.1598 - val_loss: 1.6007 - val_accuracy: 0.5991 - val_top5_acc: 0.8708 - val_macro_f1score: 0.1421\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.1165 - accuracy: 0.7030 - top5_acc: 0.9302 - macro_f1score: 0.1676\n","Epoch 00011: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/011.h5\n","\n","Epoch 00011: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/011.h5\n","1403/1403 [==============================] - 1143s 815ms/step - loss: 1.1165 - accuracy: 0.7030 - top5_acc: 0.9302 - macro_f1score: 0.1676 - val_loss: 1.5074 - val_accuracy: 0.6205 - val_top5_acc: 0.8764 - val_macro_f1score: 0.1467\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.0468 - accuracy: 0.7207 - top5_acc: 0.9370 - macro_f1score: 0.1753\n","Epoch 00012: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/012.h5\n","\n","Epoch 00012: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/012.h5\n","1403/1403 [==============================] - 1157s 825ms/step - loss: 1.0468 - accuracy: 0.7207 - top5_acc: 0.9370 - macro_f1score: 0.1753 - val_loss: 1.5013 - val_accuracy: 0.6341 - val_top5_acc: 0.8857 - val_macro_f1score: 0.1533\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.9740 - accuracy: 0.7401 - top5_acc: 0.9481 - macro_f1score: 0.1827\n","Epoch 00013: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/013.h5\n","\n","Epoch 00013: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/013.h5\n","1403/1403 [==============================] - 1172s 835ms/step - loss: 0.9740 - accuracy: 0.7401 - top5_acc: 0.9481 - macro_f1score: 0.1827 - val_loss: 1.4760 - val_accuracy: 0.6337 - val_top5_acc: 0.8956 - val_macro_f1score: 0.1581\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.9126 - accuracy: 0.7593 - top5_acc: 0.9538 - macro_f1score: 0.1907\n","Epoch 00014: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/014.h5\n","\n","Epoch 00014: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/014.h5\n","1403/1403 [==============================] - 1153s 822ms/step - loss: 0.9126 - accuracy: 0.7593 - top5_acc: 0.9538 - macro_f1score: 0.1907 - val_loss: 1.4574 - val_accuracy: 0.6400 - val_top5_acc: 0.8916 - val_macro_f1score: 0.1582\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.8501 - accuracy: 0.7790 - top5_acc: 0.9624 - macro_f1score: 0.1972\n","Epoch 00015: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/015.h5\n","\n","Epoch 00015: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/015.h5\n","1403/1403 [==============================] - 1148s 818ms/step - loss: 0.8501 - accuracy: 0.7790 - top5_acc: 0.9624 - macro_f1score: 0.1972 - val_loss: 1.3928 - val_accuracy: 0.6705 - val_top5_acc: 0.9064 - val_macro_f1score: 0.1695\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.7921 - accuracy: 0.7945 - top5_acc: 0.9667 - macro_f1score: 0.2033\n","Epoch 00016: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/016.h5\n","\n","Epoch 00016: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/016.h5\n","1403/1403 [==============================] - 1135s 809ms/step - loss: 0.7921 - accuracy: 0.7945 - top5_acc: 0.9667 - macro_f1score: 0.2033 - val_loss: 1.3737 - val_accuracy: 0.6723 - val_top5_acc: 0.9047 - val_macro_f1score: 0.1697\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.7438 - accuracy: 0.8109 - top5_acc: 0.9722 - macro_f1score: 0.2089\n","Epoch 00017: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/017.h5\n","\n","Epoch 00017: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/017.h5\n","1403/1403 [==============================] - 1152s 821ms/step - loss: 0.7438 - accuracy: 0.8109 - top5_acc: 0.9722 - macro_f1score: 0.2089 - val_loss: 1.4931 - val_accuracy: 0.6570 - val_top5_acc: 0.8952 - val_macro_f1score: 0.1666\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.7052 - accuracy: 0.8218 - top5_acc: 0.9770 - macro_f1score: 0.2141\n","Epoch 00018: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/018.h5\n","\n","Epoch 00018: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/018.h5\n","1403/1403 [==============================] - 1158s 825ms/step - loss: 0.7052 - accuracy: 0.8218 - top5_acc: 0.9770 - macro_f1score: 0.2141 - val_loss: 1.6255 - val_accuracy: 0.6539 - val_top5_acc: 0.8956 - val_macro_f1score: 0.1670\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.6684 - accuracy: 0.8352 - top5_acc: 0.9798 - macro_f1score: 0.2187\n","Epoch 00019: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/019.h5\n","\n","Epoch 00019: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/019.h5\n","1403/1403 [==============================] - 1136s 810ms/step - loss: 0.6684 - accuracy: 0.8352 - top5_acc: 0.9798 - macro_f1score: 0.2187 - val_loss: 1.4766 - val_accuracy: 0.6711 - val_top5_acc: 0.9011 - val_macro_f1score: 0.1706\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.8466 - top5_acc: 0.9840 - macro_f1score: 0.2226\n","Epoch 00020: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/020.h5\n","\n","Epoch 00020: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/020.h5\n","1403/1403 [==============================] - 1160s 827ms/step - loss: 0.6285 - accuracy: 0.8466 - top5_acc: 0.9840 - macro_f1score: 0.2226 - val_loss: 1.4495 - val_accuracy: 0.6841 - val_top5_acc: 0.9053 - val_macro_f1score: 0.1779\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.8582 - top5_acc: 0.9862 - macro_f1score: 0.2266\n","Epoch 00021: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/021.h5\n","\n","Epoch 00021: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/021.h5\n","1403/1403 [==============================] - 1170s 834ms/step - loss: 0.6003 - accuracy: 0.8582 - top5_acc: 0.9862 - macro_f1score: 0.2266 - val_loss: 1.6673 - val_accuracy: 0.6543 - val_top5_acc: 0.8847 - val_macro_f1score: 0.1692\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.5808 - accuracy: 0.8665 - top5_acc: 0.9877 - macro_f1score: 0.2295\n","Epoch 00022: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/022.h5\n","\n","Epoch 00022: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/022.h5\n","1403/1403 [==============================] - 1183s 843ms/step - loss: 0.5808 - accuracy: 0.8665 - top5_acc: 0.9877 - macro_f1score: 0.2295 - val_loss: 1.5482 - val_accuracy: 0.6790 - val_top5_acc: 0.9080 - val_macro_f1score: 0.1747\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.5483 - accuracy: 0.8737 - top5_acc: 0.9901 - macro_f1score: 0.2329\n","Epoch 00023: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/023.h5\n","\n","Epoch 00023: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/023.h5\n","1403/1403 [==============================] - 1176s 838ms/step - loss: 0.5483 - accuracy: 0.8737 - top5_acc: 0.9901 - macro_f1score: 0.2329 - val_loss: 1.5173 - val_accuracy: 0.6741 - val_top5_acc: 0.9102 - val_macro_f1score: 0.1748\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.5314 - accuracy: 0.8844 - top5_acc: 0.9913 - macro_f1score: 0.2368\n","Epoch 00024: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/024.h5\n","\n","Epoch 00024: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/024.h5\n","1403/1403 [==============================] - 1173s 836ms/step - loss: 0.5314 - accuracy: 0.8844 - top5_acc: 0.9913 - macro_f1score: 0.2368 - val_loss: 1.5775 - val_accuracy: 0.6758 - val_top5_acc: 0.9049 - val_macro_f1score: 0.1777\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.5082 - accuracy: 0.8929 - top5_acc: 0.9917 - macro_f1score: 0.2388\n","Epoch 00025: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/025.h5\n","\n","Epoch 00025: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/025.h5\n","1403/1403 [==============================] - 1175s 838ms/step - loss: 0.5082 - accuracy: 0.8929 - top5_acc: 0.9917 - macro_f1score: 0.2388 - val_loss: 1.6460 - val_accuracy: 0.6746 - val_top5_acc: 0.9011 - val_macro_f1score: 0.1767\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.8947 - top5_acc: 0.9932 - macro_f1score: 0.2413\n","Epoch 00026: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/026.h5\n","\n","Epoch 00026: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/026.h5\n","1403/1403 [==============================] - 1181s 842ms/step - loss: 0.5015 - accuracy: 0.8947 - top5_acc: 0.9932 - macro_f1score: 0.2413 - val_loss: 1.7072 - val_accuracy: 0.6705 - val_top5_acc: 0.8997 - val_macro_f1score: 0.1761\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.4818 - accuracy: 0.9036 - top5_acc: 0.9937 - macro_f1score: 0.2427\n","Epoch 00027: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/027.h5\n","\n","Epoch 00027: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/027.h5\n","1403/1403 [==============================] - 1167s 831ms/step - loss: 0.4818 - accuracy: 0.9036 - top5_acc: 0.9937 - macro_f1score: 0.2427 - val_loss: 1.5774 - val_accuracy: 0.6958 - val_top5_acc: 0.9140 - val_macro_f1score: 0.1832\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.9069 - top5_acc: 0.9947 - macro_f1score: 0.2446\n","Epoch 00028: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/028.h5\n","\n","Epoch 00028: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/028.h5\n","1403/1403 [==============================] - 1170s 834ms/step - loss: 0.4716 - accuracy: 0.9069 - top5_acc: 0.9947 - macro_f1score: 0.2446 - val_loss: 1.7941 - val_accuracy: 0.6752 - val_top5_acc: 0.9051 - val_macro_f1score: 0.1772\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.4673 - accuracy: 0.9096 - top5_acc: 0.9949 - macro_f1score: 0.2461\n","Epoch 00029: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/029.h5\n","\n","Epoch 00029: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/029.h5\n","1403/1403 [==============================] - 1176s 838ms/step - loss: 0.4673 - accuracy: 0.9096 - top5_acc: 0.9949 - macro_f1score: 0.2461 - val_loss: 1.5863 - val_accuracy: 0.7008 - val_top5_acc: 0.9066 - val_macro_f1score: 0.1850\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.4570 - accuracy: 0.9140 - top5_acc: 0.9951 - macro_f1score: 0.2470\n","Epoch 00030: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/030.h5\n","\n","Epoch 00030: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/030.h5\n","1403/1403 [==============================] - 1181s 841ms/step - loss: 0.4570 - accuracy: 0.9140 - top5_acc: 0.9951 - macro_f1score: 0.2470 - val_loss: 1.6514 - val_accuracy: 0.6879 - val_top5_acc: 0.9106 - val_macro_f1score: 0.1835\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.9554 - top5_acc: 0.9986 - macro_f1score: 0.2604\n","Epoch 00031: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/031.h5\n","\n","Epoch 00031: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/031.h5\n","1403/1403 [==============================] - 1182s 842ms/step - loss: 0.3388 - accuracy: 0.9554 - top5_acc: 0.9986 - macro_f1score: 0.2604 - val_loss: 1.4248 - val_accuracy: 0.7358 - val_top5_acc: 0.9268 - val_macro_f1score: 0.1947\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.9690 - top5_acc: 0.9993 - macro_f1score: 0.2650\n","Epoch 00032: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/032.h5\n","\n","Epoch 00032: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/032.h5\n","1403/1403 [==============================] - 1171s 834ms/step - loss: 0.2943 - accuracy: 0.9690 - top5_acc: 0.9993 - macro_f1score: 0.2650 - val_loss: 1.4494 - val_accuracy: 0.7375 - val_top5_acc: 0.9328 - val_macro_f1score: 0.1981\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2797 - accuracy: 0.9733 - top5_acc: 0.9994 - macro_f1score: 0.2665\n","Epoch 00033: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/033.h5\n","\n","Epoch 00033: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/033.h5\n","1403/1403 [==============================] - 1155s 823ms/step - loss: 0.2797 - accuracy: 0.9733 - top5_acc: 0.9994 - macro_f1score: 0.2665 - val_loss: 1.4561 - val_accuracy: 0.7381 - val_top5_acc: 0.9320 - val_macro_f1score: 0.1952\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.9774 - top5_acc: 0.9996 - macro_f1score: 0.2682\n","Epoch 00034: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/034.h5\n","\n","Epoch 00034: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/034.h5\n","1403/1403 [==============================] - 1154s 823ms/step - loss: 0.2656 - accuracy: 0.9774 - top5_acc: 0.9996 - macro_f1score: 0.2682 - val_loss: 1.4593 - val_accuracy: 0.7330 - val_top5_acc: 0.9331 - val_macro_f1score: 0.1952\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2575 - accuracy: 0.9808 - top5_acc: 0.9998 - macro_f1score: 0.2687\n","Epoch 00035: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/035.h5\n","\n","Epoch 00035: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/035.h5\n","1403/1403 [==============================] - 1162s 828ms/step - loss: 0.2575 - accuracy: 0.9808 - top5_acc: 0.9998 - macro_f1score: 0.2687 - val_loss: 1.4455 - val_accuracy: 0.7391 - val_top5_acc: 0.9337 - val_macro_f1score: 0.1982\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.9817 - top5_acc: 0.9996 - macro_f1score: 0.2698\n","Epoch 00036: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/036.h5\n","\n","Epoch 00036: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/036.h5\n","1403/1403 [==============================] - 1156s 824ms/step - loss: 0.2522 - accuracy: 0.9817 - top5_acc: 0.9996 - macro_f1score: 0.2698 - val_loss: 1.4639 - val_accuracy: 0.7395 - val_top5_acc: 0.9318 - val_macro_f1score: 0.1963\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2459 - accuracy: 0.9833 - top5_acc: 0.9999 - macro_f1score: 0.2702\n","Epoch 00037: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/037.h5\n","\n","Epoch 00037: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/037.h5\n","1403/1403 [==============================] - 1153s 821ms/step - loss: 0.2459 - accuracy: 0.9833 - top5_acc: 0.9999 - macro_f1score: 0.2702 - val_loss: 1.5037 - val_accuracy: 0.7401 - val_top5_acc: 0.9324 - val_macro_f1score: 0.1997\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2426 - accuracy: 0.9843 - top5_acc: 0.9997 - macro_f1score: 0.2705\n","Epoch 00038: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/038.h5\n","\n","Epoch 00038: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/038.h5\n","1403/1403 [==============================] - 1150s 820ms/step - loss: 0.2426 - accuracy: 0.9843 - top5_acc: 0.9997 - macro_f1score: 0.2705 - val_loss: 1.5068 - val_accuracy: 0.7407 - val_top5_acc: 0.9324 - val_macro_f1score: 0.1997\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9859 - top5_acc: 0.9998 - macro_f1score: 0.2699\n","Epoch 00039: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/039.h5\n","\n","Epoch 00039: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/039.h5\n","1403/1403 [==============================] - 1157s 825ms/step - loss: 0.2362 - accuracy: 0.9859 - top5_acc: 0.9998 - macro_f1score: 0.2699 - val_loss: 1.4879 - val_accuracy: 0.7421 - val_top5_acc: 0.9333 - val_macro_f1score: 0.1985\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.9864 - top5_acc: 0.9998 - macro_f1score: 0.2716\n","Epoch 00040: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/040.h5\n","\n","Epoch 00040: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/040.h5\n","1403/1403 [==============================] - 1144s 816ms/step - loss: 0.2323 - accuracy: 0.9864 - top5_acc: 0.9998 - macro_f1score: 0.2716 - val_loss: 1.5088 - val_accuracy: 0.7389 - val_top5_acc: 0.9335 - val_macro_f1score: 0.1973\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.9857 - top5_acc: 0.9999 - macro_f1score: 0.2714\n","Epoch 00041: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/041.h5\n","\n","Epoch 00041: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/041.h5\n","1403/1403 [==============================] - 1136s 810ms/step - loss: 0.2322 - accuracy: 0.9857 - top5_acc: 0.9999 - macro_f1score: 0.2714 - val_loss: 1.5132 - val_accuracy: 0.7369 - val_top5_acc: 0.9326 - val_macro_f1score: 0.1985\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.9877 - top5_acc: 0.9999 - macro_f1score: 0.2705\n","Epoch 00042: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/042.h5\n","\n","Epoch 00042: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/042.h5\n","1403/1403 [==============================] - 1120s 798ms/step - loss: 0.2273 - accuracy: 0.9877 - top5_acc: 0.9999 - macro_f1score: 0.2705 - val_loss: 1.5001 - val_accuracy: 0.7385 - val_top5_acc: 0.9331 - val_macro_f1score: 0.1969\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.9885 - top5_acc: 0.9999 - macro_f1score: 0.2716\n","Epoch 00043: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/043.h5\n","\n","Epoch 00043: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/043.h5\n","1403/1403 [==============================] - 1127s 803ms/step - loss: 0.2242 - accuracy: 0.9885 - top5_acc: 0.9999 - macro_f1score: 0.2716 - val_loss: 1.5396 - val_accuracy: 0.7421 - val_top5_acc: 0.9347 - val_macro_f1score: 0.2000\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9883 - top5_acc: 0.9999 - macro_f1score: 0.2722\n","Epoch 00044: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/044.h5\n","\n","Epoch 00044: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/044.h5\n","1403/1403 [==============================] - 1133s 807ms/step - loss: 0.2228 - accuracy: 0.9883 - top5_acc: 0.9999 - macro_f1score: 0.2722 - val_loss: 1.5169 - val_accuracy: 0.7417 - val_top5_acc: 0.9320 - val_macro_f1score: 0.1984\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.9897 - top5_acc: 1.0000 - macro_f1score: 0.2715\n","Epoch 00045: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/045.h5\n","\n","Epoch 00045: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/045.h5\n","1403/1403 [==============================] - 1144s 815ms/step - loss: 0.2181 - accuracy: 0.9897 - top5_acc: 1.0000 - macro_f1score: 0.2715 - val_loss: 1.5373 - val_accuracy: 0.7423 - val_top5_acc: 0.9318 - val_macro_f1score: 0.2009\n","Learning rate:  0.0001\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 46/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9891 - top5_acc: 0.9999 - macro_f1score: 0.2724\n","Epoch 00046: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/046.h5\n","\n","Epoch 00046: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/046.h5\n","1403/1403 [==============================] - 1133s 807ms/step - loss: 0.2175 - accuracy: 0.9891 - top5_acc: 0.9999 - macro_f1score: 0.2724 - val_loss: 1.5584 - val_accuracy: 0.7427 - val_top5_acc: 0.9312 - val_macro_f1score: 0.1993\n","Learning rate:  0.0001\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 47/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.9902 - top5_acc: 0.9999 - macro_f1score: 0.2722\n","Epoch 00047: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/047.h5\n","\n","Epoch 00047: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/047.h5\n","1403/1403 [==============================] - 1190s 848ms/step - loss: 0.2146 - accuracy: 0.9902 - top5_acc: 0.9999 - macro_f1score: 0.2722 - val_loss: 1.5376 - val_accuracy: 0.7460 - val_top5_acc: 0.9318 - val_macro_f1score: 0.1997\n","Learning rate:  0.0001\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 48/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.9912 - top5_acc: 0.9998 - macro_f1score: 0.2721\n","Epoch 00048: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/048.h5\n","\n","Epoch 00048: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/048.h5\n","1403/1403 [==============================] - 1190s 848ms/step - loss: 0.2113 - accuracy: 0.9912 - top5_acc: 0.9998 - macro_f1score: 0.2721 - val_loss: 1.5792 - val_accuracy: 0.7407 - val_top5_acc: 0.9314 - val_macro_f1score: 0.1961\n","Learning rate:  0.0001\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 49/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.9915 - top5_acc: 1.0000 - macro_f1score: 0.2731\n","Epoch 00049: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/049.h5\n","\n","Epoch 00049: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/049.h5\n","1403/1403 [==============================] - 1207s 860ms/step - loss: 0.2098 - accuracy: 0.9915 - top5_acc: 1.0000 - macro_f1score: 0.2731 - val_loss: 1.5669 - val_accuracy: 0.7439 - val_top5_acc: 0.9312 - val_macro_f1score: 0.2012\n","Learning rate:  0.0001\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 50/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9920 - top5_acc: 1.0000 - macro_f1score: 0.2727\n","Epoch 00050: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/050.h5\n","\n","Epoch 00050: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/050.h5\n","1403/1403 [==============================] - 1208s 861ms/step - loss: 0.2066 - accuracy: 0.9920 - top5_acc: 1.0000 - macro_f1score: 0.2727 - val_loss: 1.5907 - val_accuracy: 0.7371 - val_top5_acc: 0.9302 - val_macro_f1score: 0.1988\n","Learning rate:  0.0001\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 51/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2053 - accuracy: 0.9919 - top5_acc: 0.9999 - macro_f1score: 0.2732\n","Epoch 00051: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/051.h5\n","\n","Epoch 00051: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/051.h5\n","1403/1403 [==============================] - 1194s 851ms/step - loss: 0.2053 - accuracy: 0.9919 - top5_acc: 0.9999 - macro_f1score: 0.2732 - val_loss: 1.5757 - val_accuracy: 0.7407 - val_top5_acc: 0.9302 - val_macro_f1score: 0.2004\n","Learning rate:  0.0001\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 52/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.9916 - top5_acc: 0.9999 - macro_f1score: 0.2727\n","Epoch 00052: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/052.h5\n","\n","Epoch 00052: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Xception/052.h5\n","1403/1403 [==============================] - 1223s 872ms/step - loss: 0.2048 - accuracy: 0.9916 - top5_acc: 0.9999 - macro_f1score: 0.2727 - val_loss: 1.5914 - val_accuracy: 0.7407 - val_top5_acc: 0.9314 - val_macro_f1score: 0.1983\n","Learning rate:  0.0001\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 53/70\n"," 242/1403 [====>.........................] - ETA: 16:20 - loss: 0.2045 - accuracy: 0.9910 - top5_acc: 1.0000 - macro_f1score: 0.2716"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-UfCUKfdEJnF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qE5DXS9PEJpv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMKlqQh24hcq"},"source":["# colab pro가 최대 24시간 돌아가므로, 그 한계로 인해 두번 나눠서 학습을봄."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5JqngK2zwLmH"},"source":["model=load_model(os.path.join(dir,'model_output',number,'Xception','051.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgavL2IxsJ9m"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-4\n","    if epoch < 10:\n","        lr = lr\n","    else :\n","        lr = lr * 0.1\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WmA0zyNQvEGl"},"source":["os.makedirs(os.path.join(dir,'model_output',number,'SUB',model.name), exist_ok=True) # 모델을 위에서 정의해야함"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTbhbLyX8L6F"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,'SUB',model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d_8Yy1A48KLO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605871225524,"user_tz":-540,"elapsed":34613384,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"7a8c6001-e9c4-48c7-affc-d8a1b6368893"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=20 , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.0001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 1/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.9933 - top5_acc: 0.9999 - macro_f1score: 0.2730\n","Epoch 00001: val_loss improved from inf to 1.59048, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Xception/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.74308, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Xception/001.h5\n","1403/1403 [==============================] - 11944s 9s/step - loss: 0.1985 - accuracy: 0.9933 - top5_acc: 0.9999 - macro_f1score: 0.2730 - val_loss: 1.5905 - val_accuracy: 0.7431 - val_top5_acc: 0.9341 - val_macro_f1score: 0.2005\n","Learning rate:  0.0001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 2/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2042 - accuracy: 0.9917 - top5_acc: 1.0000 - macro_f1score: 0.2722\n","Epoch 00002: val_loss did not improve from 1.59048\n","\n","Epoch 00002: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1215s 866ms/step - loss: 0.2042 - accuracy: 0.9917 - top5_acc: 1.0000 - macro_f1score: 0.2722 - val_loss: 1.5970 - val_accuracy: 0.7417 - val_top5_acc: 0.9306 - val_macro_f1score: 0.1997\n","Learning rate:  0.0001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 3/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.9917 - top5_acc: 1.0000 - macro_f1score: 0.2729\n","Epoch 00003: val_loss did not improve from 1.59048\n","\n","Epoch 00003: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1194s 851ms/step - loss: 0.2030 - accuracy: 0.9917 - top5_acc: 1.0000 - macro_f1score: 0.2729 - val_loss: 1.6012 - val_accuracy: 0.7429 - val_top5_acc: 0.9286 - val_macro_f1score: 0.1992\n","Learning rate:  0.0001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 4/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.9925 - top5_acc: 0.9999 - macro_f1score: 0.2723\n","Epoch 00004: val_loss did not improve from 1.59048\n","\n","Epoch 00004: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1192s 850ms/step - loss: 0.1989 - accuracy: 0.9925 - top5_acc: 0.9999 - macro_f1score: 0.2723 - val_loss: 1.5932 - val_accuracy: 0.7385 - val_top5_acc: 0.9320 - val_macro_f1score: 0.1984\n","Learning rate:  0.0001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 5/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1988 - accuracy: 0.9925 - top5_acc: 1.0000 - macro_f1score: 0.2726\n","Epoch 00005: val_loss did not improve from 1.59048\n","\n","Epoch 00005: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1193s 850ms/step - loss: 0.1988 - accuracy: 0.9925 - top5_acc: 1.0000 - macro_f1score: 0.2726 - val_loss: 1.6138 - val_accuracy: 0.7405 - val_top5_acc: 0.9318 - val_macro_f1score: 0.1988\n","Learning rate:  0.0001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 6/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1958 - accuracy: 0.9931 - top5_acc: 1.0000 - macro_f1score: 0.2724\n","Epoch 00006: val_loss did not improve from 1.59048\n","\n","Epoch 00006: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1189s 848ms/step - loss: 0.1958 - accuracy: 0.9931 - top5_acc: 1.0000 - macro_f1score: 0.2724 - val_loss: 1.6031 - val_accuracy: 0.7367 - val_top5_acc: 0.9306 - val_macro_f1score: 0.2001\n","Learning rate:  0.0001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 7/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.9932 - top5_acc: 0.9999 - macro_f1score: 0.2728\n","Epoch 00007: val_loss did not improve from 1.59048\n","\n","Epoch 00007: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1187s 846ms/step - loss: 0.1946 - accuracy: 0.9932 - top5_acc: 0.9999 - macro_f1score: 0.2728 - val_loss: 1.5949 - val_accuracy: 0.7389 - val_top5_acc: 0.9320 - val_macro_f1score: 0.1988\n","Learning rate:  0.0001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 8/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1943 - accuracy: 0.9931 - top5_acc: 1.0000 - macro_f1score: 0.2732\n","Epoch 00008: val_loss did not improve from 1.59048\n","\n","Epoch 00008: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1193s 850ms/step - loss: 0.1943 - accuracy: 0.9931 - top5_acc: 1.0000 - macro_f1score: 0.2732 - val_loss: 1.6010 - val_accuracy: 0.7391 - val_top5_acc: 0.9296 - val_macro_f1score: 0.1984\n","Learning rate:  0.0001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 9/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1915 - accuracy: 0.9939 - top5_acc: 1.0000 - macro_f1score: 0.2733\n","Epoch 00009: val_loss did not improve from 1.59048\n","\n","Epoch 00009: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1194s 851ms/step - loss: 0.1915 - accuracy: 0.9939 - top5_acc: 1.0000 - macro_f1score: 0.2733 - val_loss: 1.6250 - val_accuracy: 0.7421 - val_top5_acc: 0.9304 - val_macro_f1score: 0.2011\n","Learning rate:  0.0001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 10/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9931 - top5_acc: 1.0000 - macro_f1score: 0.2735\n","Epoch 00010: val_loss did not improve from 1.59048\n","\n","Epoch 00010: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1185s 845ms/step - loss: 0.1907 - accuracy: 0.9931 - top5_acc: 1.0000 - macro_f1score: 0.2735 - val_loss: 1.6230 - val_accuracy: 0.7393 - val_top5_acc: 0.9318 - val_macro_f1score: 0.1974\n","Learning rate:  1e-05\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 11/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9944 - top5_acc: 1.0000 - macro_f1score: 0.2727\n","Epoch 00011: val_loss did not improve from 1.59048\n","\n","Epoch 00011: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1188s 847ms/step - loss: 0.1886 - accuracy: 0.9944 - top5_acc: 1.0000 - macro_f1score: 0.2727 - val_loss: 1.6061 - val_accuracy: 0.7411 - val_top5_acc: 0.9312 - val_macro_f1score: 0.2004\n","Learning rate:  1e-05\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 12/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9946 - top5_acc: 1.0000 - macro_f1score: 0.2740\n","Epoch 00012: val_loss did not improve from 1.59048\n","\n","Epoch 00012: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1192s 850ms/step - loss: 0.1874 - accuracy: 0.9946 - top5_acc: 1.0000 - macro_f1score: 0.2740 - val_loss: 1.5952 - val_accuracy: 0.7417 - val_top5_acc: 0.9322 - val_macro_f1score: 0.2004\n","Learning rate:  1e-05\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 13/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1868 - accuracy: 0.9947 - top5_acc: 1.0000 - macro_f1score: 0.2740\n","Epoch 00013: val_loss did not improve from 1.59048\n","\n","Epoch 00013: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1184s 844ms/step - loss: 0.1868 - accuracy: 0.9947 - top5_acc: 1.0000 - macro_f1score: 0.2740 - val_loss: 1.6050 - val_accuracy: 0.7417 - val_top5_acc: 0.9314 - val_macro_f1score: 0.2007\n","Learning rate:  1e-05\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 14/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.9956 - top5_acc: 1.0000 - macro_f1score: 0.2740\n","Epoch 00014: val_loss did not improve from 1.59048\n","\n","Epoch 00014: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1185s 845ms/step - loss: 0.1845 - accuracy: 0.9956 - top5_acc: 1.0000 - macro_f1score: 0.2740 - val_loss: 1.5944 - val_accuracy: 0.7431 - val_top5_acc: 0.9333 - val_macro_f1score: 0.2015\n","Learning rate:  1e-05\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 15/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1855 - accuracy: 0.9952 - top5_acc: 1.0000 - macro_f1score: 0.2736\n","Epoch 00015: val_loss did not improve from 1.59048\n","\n","Epoch 00015: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1175s 838ms/step - loss: 0.1855 - accuracy: 0.9952 - top5_acc: 1.0000 - macro_f1score: 0.2736 - val_loss: 1.6089 - val_accuracy: 0.7389 - val_top5_acc: 0.9333 - val_macro_f1score: 0.2006\n","Learning rate:  1e-05\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 16/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.9951 - top5_acc: 1.0000 - macro_f1score: 0.2733\n","Epoch 00016: val_loss did not improve from 1.59048\n","\n","Epoch 00016: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1183s 843ms/step - loss: 0.1857 - accuracy: 0.9951 - top5_acc: 1.0000 - macro_f1score: 0.2733 - val_loss: 1.6023 - val_accuracy: 0.7413 - val_top5_acc: 0.9314 - val_macro_f1score: 0.1994\n","Learning rate:  1e-05\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 17/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9947 - top5_acc: 1.0000 - macro_f1score: 0.2734\n","Epoch 00017: val_loss improved from 1.59048 to 1.59030, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Xception/017.h5\n","\n","Epoch 00017: val_accuracy did not improve from 0.74308\n","1403/1403 [==============================] - 1179s 840ms/step - loss: 0.1861 - accuracy: 0.9947 - top5_acc: 1.0000 - macro_f1score: 0.2734 - val_loss: 1.5903 - val_accuracy: 0.7417 - val_top5_acc: 0.9318 - val_macro_f1score: 0.2006\n","Learning rate:  1e-05\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 18/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1852 - accuracy: 0.9954 - top5_acc: 1.0000 - macro_f1score: 0.2736\n","Epoch 00018: val_loss did not improve from 1.59030\n","\n","Epoch 00018: val_accuracy improved from 0.74308 to 0.74347, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Xception/018.h5\n","1403/1403 [==============================] - 1198s 854ms/step - loss: 0.1852 - accuracy: 0.9954 - top5_acc: 1.0000 - macro_f1score: 0.2736 - val_loss: 1.5931 - val_accuracy: 0.7435 - val_top5_acc: 0.9312 - val_macro_f1score: 0.1986\n","Learning rate:  1e-05\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 19/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.9957 - top5_acc: 1.0000 - macro_f1score: 0.2736\n","Epoch 00019: val_loss did not improve from 1.59030\n","\n","Epoch 00019: val_accuracy did not improve from 0.74347\n","1403/1403 [==============================] - 1196s 853ms/step - loss: 0.1831 - accuracy: 0.9957 - top5_acc: 1.0000 - macro_f1score: 0.2736 - val_loss: 1.6056 - val_accuracy: 0.7419 - val_top5_acc: 0.9312 - val_macro_f1score: 0.2010\n","Learning rate:  1e-05\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 20/20\n","1403/1403 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.9956 - top5_acc: 1.0000 - macro_f1score: 0.2738\n","Epoch 00020: val_loss did not improve from 1.59030\n","\n","Epoch 00020: val_accuracy did not improve from 0.74347\n","1403/1403 [==============================] - 1196s 853ms/step - loss: 0.1836 - accuracy: 0.9956 - top5_acc: 1.0000 - macro_f1score: 0.2738 - val_loss: 1.6049 - val_accuracy: 0.7415 - val_top5_acc: 0.9312 - val_macro_f1score: 0.2023\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RJnD6E3lEJsu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zb7V2o7cEKRn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRiw3ebD-FhC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605872885951,"user_tz":-540,"elapsed":36273796,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"8fd46372-e8bc-4fd7-9606-80451ed58875"},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["312/312 [==============================] - 1652s 5s/step - loss: 1.5981 - accuracy: 0.7482 - top5_acc: 0.9315 - macro_f1score: 0.2018\n","[Test Loss: 1.5981 /  Test Top-1 Accuracy: 0.7482 / Test Top-5 Accuracy: 0.9315 / Test Macro f1: 0.2018]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zWPdDUWI-FhG"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jhTx3Gm8-FhB"},"source":["### 2) Xception Evaluate\n"]},{"cell_type":"code","metadata":{"id":"yp2_HCXHyihu"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PpEXLWpmyihx"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'Xception.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1UoLe1oyihz"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ITeu5vTyih3","colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"status":"ok","timestamp":1605872886841,"user_tz":-540,"elapsed":36274663,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"c4b60ea1-f0a7-423e-d6ad-a1fef7360bd1"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgV5Zn38e9PFlEBF0BFEAGjKCprA4obxmjQcVwQo2iMhBiXifGN8xJHk4w6RMaJkryZGLMYNS4xoolRSaLjFhmIxEgjoCKgiK00IEGQxQUVvN8/qrr70JzuPnSf3srf57rq6jr1PFV1V53qu57zVJ06igjMzCy7dmjuAMzMrHE50ZuZZZwTvZlZxjnRm5llnBO9mVnGOdGbmWWcE30rIukxSRcUu25zklQm6QuNsNzpki5Mx8+T9EQhdeuxnl6S3pPUpr6xmjU2J/pGliaBiuFTSR/mvD5ve5YVESdFxF3FrtsSSbpK0ow807tK+ljSoYUuKyLujYgTixTXViemiHgrIjpGxJZiLD9dR69qx01Iej/n9dFFWs+o9JjMXVetjQMllkp6pRgxWNNo29wBZF1EdKwYl1QGXBgRT1WvJ6ltRGxuythauN8A10vqExFv5Ew/B3gpIl5uprgaXUS8BeQeNwEMjIgljbC6FRHRczvqHwPsCbSVNCwiZjdCTHn5f6T+3KJvJmlrqlzSv0l6G/i1pN0l/UnSaknvpuM9c+bJ7Y4YL+mvkqakdd+QdFI96/aRNEPSRklPSbpF0m9qiLuQGL8v6dl0eU9I6ppTfr6kNyWtkfTdmvZPRJQDfwHOr1b0FeDuuuKoFvN4SX/NeX2CpEWS1kv6KaCcsv0l/SWN7x1J90raLS27B+gF/DFt/V4pqXfa4m6b1tlH0jRJayUtkfT1nGVfJ+kBSXen+2aBpJKa9kEN27JrOv/qdD9+T9IOOdv5rKSfptu2SNLx27P8AlwAPAI8mo7nxnaIpCfTbV8l6Tvp9DaSviPp9XS750jat/q+S+tWP26flfT/JK0Brqvt/Unn2VfSH9L9sybdF+3TmA7LqbenpA8kdSvy/mmRnOib197AHsB+wEUk78ev09e9gA+Bn9Yy/whgMdAVuBG4XZLqUfe3wPNAF+A6tk2uuQqJ8VzgqyQtv/bARABJ/YGfp8vfJ11fba3Ju3JjkdQPGJTGu737qmIZXYE/AN8j2RevA0fmVgFuSOM7GNiXZJ8QEecDbwH/nHbX3JhnFVOB8nT+scB/Svp8TvmpaZ3dgGmFxFzNzcCuQF/gWJIT31dzykek29QVuBb4g6Q9alnenmlSfiNNqLvUVFHSzuk23ZsO50hqn5Z1Ap4C/odk2z8HPJ3O+q/AOOBkoDMwAfigwO0dASwF9gImU8v7o+Q6yZ+AN4HeQA9gakR8TLLPv5yz3HHA0xGxusA4WreI8NBEA1AGfCEdHwV8DHSopf4g4N2c19NJun4AxgNLcsp2BgLYe3vqkiTJzcDOOeW/AX5T4Dbli/F7Oa//BfifdPwakn+8irJd0n3whRqWvTOwARiZvp4MPFLPffXXdPwrwHM59USSmC+sYbmnA3PzvYfp697pvmxLknS2AJ1yym8A7kzHrwOeyinrD3xYwD4OksTZJt1f/XPKLgam52znCkA55c8D59ew3L3TGHYA+gAzgF/WEseXgdXptnYA1gNnpGXjcvdTtfkWA6flmV6572p5396qY99Uvj/AERXx5ak3guQkrfR1KfCl+vwft8bBLfrmtToiNlW8kLSzpF+mH8k3kPzj7aaa7+h4u2IkIipaSB23s+4+wNqcaQDLagq4wBjfzhn/ICemfXKXHRHvA2tqWlca0++Ar6SfPs4D7t6OOPKpHkPkvpa0l6Spkpany/0NSeu4EBX7cmPOtDdJWpYVqu+bDrldF3XoCrRLl1nT8pen25Rbvo+ko1V1wXUBQES8HRGvRMSnkVwHuRI4s5b1XwA8EBGb0+P2Qaq6b/Yl+SSRT21lddnqWKzj/dkXeDPy9ONHxN9J9vcoSQeRnDin1TOmVseJvnlVf3To/wX6ASMiojPJhS/I6UNuBCuBPdKP5RX2raV+Q2JcmbvsdJ1d6pjnLuBLwAlAJ+CPDYyjegxi6+39T5L35bB0uV+utszaHve6gmRfdsqZ1gtYXkdMhXoH+ISku6qm5feo1n3Xi+SC68xIups6RsQhNSw/qCEnKLn+8Xngy5LeVnJdaSxwctodtoykOymfZcD+eaa/n/7NPfb2zhNTrtren2VAr1pOnHel9c8Hfp/byMo6J/qWpRNJX/O6tF/12sZeYUS8SfIx9rr0otURwD83Uoy/B06RdFTatzuJuo/BmcA64Faq+lsbEsefgUMkjUkTwuVsnVw6Ae8B6yX1AL5dbf5V1JDQImIZMAu4QVIHSQOAr5G0Ohsskls4HwAmS+okaT+S/u/c5e8JXC6pnaSzSPqxH823PEnHSdpPiX2B/yK50JrP+cCrJCfXQelwIEm31ziSvvHukr4lacc0vhHpvLcB35d0QLquAZK6RNI/vpzk5NFG0gTynxBy1fb+PE9yIv8vSbuk70Hu9ZffAGeQJPu761hPpjjRtyw/BnYiabk9R3JhqymcR9K/uQa4Hrgf+KiGuvWOMSIWAN8guZi6EniXJFHUNk+Q/FPux9b/nPWKIyLeAc4iSWprgAOAZ3Oq/AcwhKT/+c8kF25z3QB8T9I6SRPzrGIcSd/zCuAh4NrIczttA3yTpCW8FPgryb68I6f87yTb9A7JNY2xEVFT99hgkhPT++nfl0hOfPlcAPws7e6pHIBfABek3VUnkDQS3gZeA45L5/0RyQnqCZJrLreTvHcAXydJ1muAQ9I4alPj+5OeCP+ZpFvmLZJj6+yc8mXACySfCGbWsZ5MqbgwYVZJ0v3Aooho9E8UVjySxpNcyDyquWNpqSTdQdKV9b3mjqUp+QtThqRhwFrgDeBE4DSSFq9ZZkjqDYwh+STzmeKuG4Okj3o6Sd/nT4BLI2Jus0ZkVkSSvg+8DNwUW3/T+jPBXTdmZhnnFr2ZWca1uD76rl27Ru/evZs7DDOzVmXOnDnvRETeZ/e0uETfu3dvSktLmzsMM7NWRdKbNZW568bMLOOc6M3MMs6J3sws45zozcwyzonezCzj6kz0ku6Q9A9JeX+jM30a3U+U/Gzai5KG5JRdIOm1dKj1R4fNzKxxFNKivxMYXUv5SSRPyzuA5Ofwfg6Q8+jYEcBw4FpJuzckWDMz23513kcfETPShwHV5DTg7vRxss9J2k1Sd5KfynsyItYCSHqS5IRxX0ODzuf99+EHP0jGpcKGmuq2aZMMO+xQNZ47FDI9Aj79tO6hpnrFejLFDjskg1Q1XttQvR7Ali1JTFu2bDsUMr2YT9ko9L3NN1TEEVG/oZgKPRZr25btOZ7y1avtmCjkeKmIo5D91hT7tCEackzkjm/vfqxevueecOqpxd++Ynxhqgdb/9xXeTqtpunbkHQRyacBevXqVa8g3n8frr++ZR08ZmbbY8SIlpvoGywibiX5BSFKSkrqlar33DNpqVQts/6tjIa2YLdsqV/ruXpZQ1VsT31ae7njDf2EU/HJoFjbU9+hvq3n6i3vYm9Hfbatvq3w6sdWbcdEIcdLQz89F2ufFkMxjonq/3OF7Mfc8raNlJGLsdjlbP2bmz3TactJum9yp08vwvoK0tIOIrOWKLer0hquIu8Uq3FTLMUIZxrwlfTum8OB9RGxEngcOFHS7ulF2BPTaWZm1oTqbNFLuo+kZd5VUjnJnTTtACLiFyQ/PHwysAT4APhqWrY2fdj/7HRRkyouzJqZWdMp5K6bcXWUB8kPPucru4Otf7jYzMyaWAvrSTIzs2JzojczyzgnejOzjHOiNzPLOCd6M7OMc6I3M8s4J3ozs4xzojczyzgnejOzjHOiNzPLOCd6M7OMc6I3M8s4J3ozs4xzojczyzgnejOzjHOiNzPLOCd6M7OMc6I3M8s4J3ozs4wrKNFLGi1psaQlkq7KU76fpKclvShpuqSeOWU/kPRyOpxdzODNzKxudSZ6SW2AW4CTgP7AOEn9q1WbAtwdEQOAScAN6bz/BAwBBgEjgImSOhcvfDMzq0shLfrhwJKIWBoRHwNTgdOq1ekP/CUdfyanvD8wIyI2R8T7wIvA6IaHbWZmhSok0fcAluW8Lk+n5ZoPjEnHzwA6SeqSTh8taWdJXYHjgH2rr0DSRZJKJZWuXr16e7fBzMxqUayLsROBYyXNBY4FlgNbIuIJ4FFgFnAf8DdgS/WZI+LWiCiJiJJu3boVKSQzM4PCEv1ytm6F90ynVYqIFRExJiIGA99Np61L/06OiEERcQIg4NWiRG5mZgUpJNHPBg6Q1EdSe+AcYFpuBUldJVUs62rgjnR6m7QLB0kDgAHAE8UK3szM6ta2rgoRsVnSZcDjQBvgjohYIGkSUBoR04BRwA2SApgBfCOdvR0wUxLABuDLEbG5+JthZmY1UUQ0dwxbKSkpidLS0uYOw8ysVZE0JyJK8pX5m7FmZhnnRG9mlnFO9GZmGedEb2aWcU70ZmYZ50RvZpZxTvRmZhnnRG9mlnFO9GZmGedEb2aWcU70ZmYZ50RvZpZxTvRmZhnnRG9mlnFO9GZmGedEb2aWcU70ZmYZ50RvZpZxBSV6SaMlLZa0RNJVecr3k/S0pBclTZfUM6fsRkkLJC2U9BOlPyBrZmZNo85EL6kNcAtwEtAfGCepf7VqU4C7I2IAMAm4IZ13JHAkMAA4FBgGHFu06M3MrE6FtOiHA0siYmlEfAxMBU6rVqc/8Jd0/Jmc8gA6AO2BHYF2wKqGBm1mZoUrJNH3AJblvC5Pp+WaD4xJx88AOknqEhF/I0n8K9Ph8YhY2LCQzcxsexTrYuxE4FhJc0m6ZpYDWyR9DjgY6Elycvi8pKOrzyzpIkmlkkpXr15dpJDMzAwKS/TLgX1zXvdMp1WKiBURMSYiBgPfTaetI2ndPxcR70XEe8BjwBHVVxARt0ZESUSUdOvWrZ6bYmZm+RSS6GcDB0jqI6k9cA4wLbeCpK6SKpZ1NXBHOv4WSUu/raR2JK19d92YmTWhOhN9RGwGLgMeJ0nSD0TEAkmTJJ2aVhsFLJb0KrAXMDmd/nvgdeAlkn78+RHxx+JugpmZ1UYR0dwxbKWkpCRKS0ubOwwzs1ZF0pyIKMlX5m/GmpllnBO9mVnGOdGbmWWcE72ZWcY50ZuZZZwTvZlZxjnRm5llnBO9mVnGOdGbmWWcE72ZWcY50ZuZZZwTvZlZxjnRm5llnBO9mVnGOdGbmWWcE72ZWcY50ZuZZZwTvZlZxjnRm5llXEGJXtJoSYslLZF0VZ7y/SQ9LelFSdMl9UynHydpXs6wSdLpxd4IMzOrWZ2JXlIb4BbgJKA/ME5S/2rVpgB3R8QAYBJwA0BEPBMRgyJiEPB54APgiSLGb2ZmdSikRT8cWBIRSyPiY2AqcFq1Ov2Bv6Tjz+QpBxgLPBYRH9Q3WDMz235tC6jTA1iW87ocGFGtznxgDPDfwBlAJ0ldImJNTp1zgB/lW4Gki4CLAHr16lVY5GZWsE8++YTy8nI2bdrU3KFYA3Xo0IGePXvSrl27gucpJNEXYiLwU0njgRnAcmBLRaGk7sBhwOP5Zo6IW4FbAUpKSqJIMZlZqry8nE6dOtG7d28kNXc4Vk8RwZo1aygvL6dPnz4Fz1dIol8O7Jvzumc6LXflK0ha9EjqCJwZEetyqnwJeCgiPik4MjMrmk2bNjnJZ4AkunTpwurVq7drvkL66GcDB0jqI6k9SRfMtGor7yqpYllXA3dUW8Y44L7tiszMispJPhvq8z7WmegjYjNwGUm3y0LggYhYIGmSpFPTaqOAxZJeBfYCJucE1ZvkE8H/bnd0ZpYJa9asYdCgQQwaNIi9996bHj16VL7++OOPa523tLSUyy+/vM51jBw5siixlpWVsdNOO1XGd8kll9Raf9CgQZxzzjlFWXdjKaiPPiIeBR6tNu2anPHfA7+vYd4ykgu6ZvYZ1aVLF+bNmwfAddddR8eOHZk4cWJl+ebNm2nbNn86KikpoaSkpM51zJo1qzjBAvvvv39lvLVZuHAhW7ZsYebMmbz//vvssssuRYuhmPzNWDNrFuPHj+eSSy5hxIgRXHnllTz//PMcccQRDB48mJEjR7J48WIApk+fzimnnAIkJ4kJEyYwatQo+vbty09+8pPK5XXs2LGy/qhRoxg7diwHHXQQ5513HhHJPR6PPvooBx10EEOHDuXyyy+vXG593XfffZx//vmceOKJPPLII5XTZ8+ezciRIxk4cCDDhw9n48aNbNmyhYkTJ3LooYcyYMAAbr755gate3sU664bM2slvvUtKKCxul0GDYIf/3j75ysvL2fWrFm0adOGDRs2MHPmTNq2bctTTz3Fd77zHR588MFt5lm0aBHPPPMMGzdupF+/flx66aXb3Go4d+5cFixYwD777MORRx7Js88+S0lJCRdffDEzZsygT58+jBs3rsa43njjDQYPHkznzp25/vrrOfroo/PWu//++3nyySdZtGgRN998M+eeey4ff/wxZ599Nvfffz/Dhg1jw4YN7LTTTtx6662UlZUxb9482rZty9q1a7d/h9WTE72ZNZuzzjqLNm3aALB+/XouuOACXnvtNSTxySf5b9L7p3/6J3bccUd23HFH9txzT1atWkXPnj23qjN8+PDKaYMGDaKsrIyOHTvSt2/fytsSx40bx6233rrN8rt3785bb71Fly5dmDNnDqeffjoLFiygc+fOW9UrLS2la9eu9OrVix49ejBhwgTWrl3L8uXL6d69O8OGDQOonO+pp57ikksuqeyi2mOPPeq727abE73ZZ0x9Wt6NJbdP+9///d857rjjeOihhygrK2PUqFF559lxxx0rx9u0acPmzZvrVacmFScRgKFDh7L//vvz6quvsmzZMv7jP/4DgNtuu4377ruPRYsW0bt3bwA2bNjAgw8+yOGHH17wupqK++jNrEVYv349PXok923ceeedRV9+v379WLp0KWVlZUDS7ZLP6tWr2bIl+b7n0qVLee211+jbty9nnHEG8+bNY968eQwZMoQHHniAl156ibKyMsrKynjkkUe477776NevHytXrmT27NkAbNy4kc2bN3PCCSfwy1/+svKk05RdN070ZtYiXHnllVx99dUMHjx4u1rghdppp5342c9+xujRoxk6dCidOnVi11133abejBkzGDBgAIMGDWLs2LH84he/2KabZebMmfTo0YN99tmnctoxxxzDK6+8wpo1a7j//vv55je/ycCBAznhhBPYtGkTF154Ib169WLAgAEMHDiQ3/72t0Xfxpqo4mp0S1FSUhKlpaXNHYZZpixcuJCDDz64ucNodu+99x4dO3YkIvjGN77BAQccwBVXXNHcYW23fO+npDkRkfc+VLfozewz41e/+hWDBg3ikEMOYf369Vx88cXNHVKT8MVYM/vMuOKKK1plC76h3KI3M8s4J3ozs4xzojczyzgnejOzjHOiN7NGd9xxx/H441v/wNyPf/xjLr300hrnGTVqFBW3Wp988smsW7dumzrXXXcdU6ZMqXXdDz/8MK+88krl62uuuYannnpqe8LPqzU9zth33ZhZoxs3bhxTp07li1/8YuW0qVOncuONNxY0/6OPPlp3pRo8/PDDnHLKKfTv3x+ASZMm1XtZ1bWWxxm7RW9mjW7s2LH8+c9/rvyRkbKyMlasWMHRRx/NpZdeSklJCYcccgjXXntt3vl79+7NO++8A8DkyZM58MADOeqooyofZQzJPfLDhg1j4MCBnHnmmXzwwQfMmjWLadOm8e1vf5tBgwbx+uuvM378eH7/++TnM55++mkGDx7MYYcdxoQJE/joo48q13fttdcyZMgQDjvsMBYtWtSg7W/uxxm7RW/2WdMMzyneY489GD58OI899hinnXYaU6dO5Utf+hKSmDx5MnvssQdbtmzh+OOP58UXX2TAgAF5lzNnzhymTp3KvHnz2Lx5M0OGDGHo0KEAjBkzhq9//esAfO973+P222/nm9/8JqeeeiqnnHIKY8eO3WpZmzZtYvz48Tz99NMceOCBfOUrX+HnP/853/rWtwDo2rUrL7zwAj/72c+YMmUKt9122zbxtJbHGbtFb2ZNoqL7BpJum4rnwT/wwAMMGTKEwYMHs2DBgq3606ubOXMmZ5xxBjvvvDOdO3fm1FNPrSx7+eWXOfrooznssMO49957WbBgQa3xLF68mD59+nDggQcCcMEFFzBjxozK8jFjxgDJEywrHoSWq+JxxnPnzuVHP/oR5557Lhs2bNimXu7jjI8//njmzp3L2rVrWbx48TaPM654Fv/FF19c1McZu0Vv9lnTTM8pPu2007jiiit44YUX+OCDDxg6dChvvPEGU6ZMYfbs2ey+++6MHz+eTZs21Wv548eP5+GHH2bgwIHceeedTJ8+vUHxVjyquLZHIbeWxxkX1KKXNFrSYklLJF2Vp3w/SU9LelHSdEk9c8p6SXpC0kJJr6Q/Fm5mnzEdO3bkuOOOY8KECZWt+Q0bNrDLLruw6667smrVKh577LFal3HMMcfw8MMP8+GHH7Jx40b++Mc/VpZt3LiR7t2788knn3DvvfdWTu/UqRMbN27cZln9+vWjrKyMJUuWAHDPPfdw7LHHFrw9relxxnUmekltgFuAk4D+wDhJ/atVmwLcHREDgEnADTlldwM3RcTBwHDgHw2O2sxapXHjxjF//vzKRD9w4EAGDx7MQQcdxLnnnsuRRx5Z6/xDhgzh7LPPZuDAgZx00kmV3R4A3//+9xkxYgRHHnkkBx10UOX0c845h5tuuonBgwfz+uuvV07v0KEDv/71rznrrLM47LDD2GGHHeq8RTJXa3qccZ2PKZZ0BHBdRHwxfX01QETckFNnATA6IpZJErA+IjqnJ4RbI+KoQgPyY4rNis+PKc6WxnhMcQ9gWc7r8nRarvnAmHT8DKCTpC7AgcA6SX+QNFfSTeknhOoBXiSpVFLp6tWrCwjJzMwKVay7biYCx0qaCxwLLAe2kFzsPTotHwb0BcZXnzkibo2Ikogo6datW5FCMjMzKCzRLwf2zXndM51WKSJWRMSYiBgMfDedto6k9T8vIpZGxGbgYWBIUSI3M7OCFJLoZwMHSOojqT1wDjAtt4KkrpIqlnU1cEfOvLtJqmimfx6o+SZZM2s0Le1nQ61+6vM+1pno05b4ZcDjwELggYhYIGmSpIpvK4wCFkt6FdgLmJzOu4Wk2+ZpSS8BAn613VGaWYN06NCBNWvWONm3chHBmjVr6NChw3bN5x8HN/sM+OSTTygvL6/3l5Gs5ejQoQM9e/akXbt2W02v7a4bfzPW7DOgXbt29OnTp7nDsGbiZ92YmWWcE72ZWcY50ZuZZZwTvZlZxjnRm5llnBO9mVnGOdGbmWWcE72ZWcY50ZuZZZwTvZlZxjnRm5llnBO9mVnGOdGbmWWcE72ZWcY50ZuZZZwTvZlZxjnRm5llnBO9mVnGFZToJY2WtFjSEklX5SnfT9LTkl6UNF1Sz5yyLZLmpcO0YgZvZmZ1q/M3YyW1AW4BTgDKgdmSpkXEKznVpgB3R8Rdkj4P3ACcn5Z9GBGDihy3mZkVqJAW/XBgSUQsjYiPganAadXq9Af+ko4/k6fczMyaSSGJvgewLOd1eTot13xgTDp+BtBJUpf0dQdJpZKek3R6vhVIuiitU7p69ertCN/MzOpSrIuxE4FjJc0FjgWWA1vSsv0iogQ4F/ixpP2rzxwRt0ZESUSUdOvWrUghmZkZFNBHT5K098153TOdVikiVpC26CV1BM6MiHVp2fL071JJ04HBwOsNjtzMzApSSIt+NnCApD6S2gPnAFvdPSOpq6SKZV0N3JFO313SjhV1gCOB3Iu4ZmbWyOpM9BGxGbgMeBxYCDwQEQskTZJ0alptFLBY0qvAXsDkdPrBQKmk+SQXaf+r2t06ZmbWyBQRzR3DVkpKSqK0tLS5wzAza1UkzUmvh27D34w1M8s4J3ozs4xzojczyzgnejOzjHOiNzPLOCd6M7OMc6I3M8s4J3ozs4xzojczyzgnejOzjHOiNzPLOCd6M7OMc6I3M8s4J3ozs4xzojczyzgnejOzjHOiNzPLOCd6M7OMKyjRSxotabGkJZKuylO+n6SnJb0oabqkntXKO0sql/TTYgVuZmaFqTPRS2oD3AKcBPQHxknqX63aFODuiBgATAJuqFb+fWBGw8M1M7PtVUiLfjiwJCKWRsTHwFTgtGp1+gN/ScefyS2XNBTYC3ii4eGamdn2KiTR9wCW5bwuT6flmg+MScfPADpJ6iJpB+CHwMTaViDpIkmlkkpXr15dWORmZlaQYl2MnQgcK2kucCywHNgC/AvwaESU1zZzRNwaESURUdKtW7cihWRmZgBtC6izHNg353XPdFqliFhB2qKX1BE4MyLWSToCOFrSvwAdgfaS3ouIbS7omplZ4ygk0c8GDpDUhyTBnwOcm1tBUldgbUR8ClwN3AEQEefl1BkPlDjJm5k1rTq7biJiM3AZ8DiwEHggIhZImiTp1LTaKGCxpFdJLrxObqR4zcxsOykimjuGrZSUlERpaWlzh2Fm1qpImhMRJfnK/M1YM7OMc6I3M8s4J3ozs4xzojczyzgnejOzjHOiNzPLOCd6M7OMc6I3M8s4J3ozs4xzojczyzgnejOzjHOiNzPLOCd6s8+KjRth6lQ46yzYdVdo375hQ6dOcPrpcM89sG5dc2+d1aKQ59GbWWu1di388Y/w4IPwxBPw0Uew995w9tnQtWvDlv3uu/CnP8Ejj0C7dnD88XDmmXDaaeBfimtR/Jhis6xZtQoefjhJ7s88A5s3Q69eMGZMkoiPOALatCnOuj79FGbPTtb14IOwdCnssAMcc0yyrjPOgB7Vf2LaGkNtjyl2om8My5dDBHToUDW0bYUfnjZtgg8/hN13b+5IWq+PPoJXX4WFC+GVV5LxXXaBvn2hT5+qoVs3kOq/nvJy+MMfkmQ7c2Zy/H3uc0myPfNMKClp2PILEQHz51cl/YULk+lHHAIe9TgAAAvDSURBVJHEMGZMsq3WKJzom8rLL8OVV8Jjj21b1rZtVdLfaaetTwL5XnfqBIcdBkOGwKGHJtMb28qVMGtW1TBnDmzZAiefDBdemPxt167x4yimtWvhb39Lhk2boHv3bYfOnRueBN97DxYtqkroFX9ffz1p9UKyjt694f334R//2Hr+XXZJyqqfACqGTp22Xefrr1cl1eefT6YdemhVcj/00MZP7rVZuLDq5DN3bjJtyJCqpH/QQXUvY9OmpP//3Xer/uaOr1uXnEz32qvq/dx77+TvnnsW75NLK+BE39hWrIBrroFf/zpJGv/6r8mBtmlT1fDhh/nHaypbuza5eAbJSeKQQ2Dw4OQfZcgQGDgQOnasf8ybNycnpoqk/uyzUFaWlO24Y9ICHDkySRT33JOcBPbaC8aPhwkT4MADG7rXiu/TT5MWc+42LVqUlLVpk5ykNm3adr6ddqpKDtWH3OnduiWJpXoyX7gQ3nqrannt2sEBB0D//nDwwVV/DzwwWRckJ4ayMnjjja2HpUuTv++9t3WMXbpUnQT23hv+93+T1jPA0KFVyb0lvi+QbFdF0n/uuWRa//5w4onwySfbJvOKv/ner1w775xcGM53MXiHHZJkn++9rP4eN0VDqpE50TeWjRvhppvghz9MDtbLLoPvfjf5p2yoiOQf/oUXktbQCy8kQ0VLUIJ+/bZO/oMH19zNsm5d8g9WkQT//veqZNK9Oxx5ZJLYR46EQYOSZF9h8+bkU8ptt8Gf/5y08o85Br72NRg7Nvlnaw7vv5/0D1ds09/+lpwgIdkPFdszciQMG5bEuX49vP12cuKqPuROrylxVLTOIUnaBx20bULff/+GffKJgDVrtk78uUN5+dYt496967+u5lBeDg89lCT9WbOSBstuuyXv2e67V43nm1a9vH37ZJkffbT1+1fTe7xq1dbvYYWdd27eTz8Vhg1LrqvUQ4MTvaTRwH8DbYDbIuK/qpXvB9wBdAPWAl+OiPJ0+kMkt3G2A26OiF/Utq4GJfr77oPjjkvO0I1p8+Yk6V17bZJ4zz4b/vM/kxZXY4pIDtaKpF9xEshtTfbuXZX499yzKhG+8koy/w47JIk8Nwn26lX4Qb5yJdx1F9x+OyxZknyCOffcpGtnyJDG/WdZtqyqpT5rFsybl5x0IEmwudt04IHJttbXhx9WJYvcpLHbblUJfb/9GrYOa3pbtsDq1dueCN59t7kjS/TqBZdfXq9ZG5ToJbUBXgVOAMqB2cC4iHglp87vgD9FxF2SPg98NSLOl9Q+XcdHkjoCLwMjI2JFTeurd6JfujRpSUlw1FFVrZ19993+ZdUkAqZNg3/7N1i8GI4+GqZMgeHDi7eO+njnnapWf8Xf115LynbbLbkYVpEAhw9vWJdPhQiYMSNJ+L/7XfIRe+DAJOGfd179L+Bu2JC/O2P+/KQlCEnra8SIqm06/HDYY4+Gb5NZK9bQRH8EcF1EfDF9fTVARNyQU2cBMDoilkkSsD4iOldbThdgLnB4oyT6iKTPuaIf8KWXkunDhlX1X37uc9u/3ArPPw/f/naS3Pr1gx/8AE49tWV83Mtnw4bk00bfvo3f6ly3Lvk0dfvtyQXcHXdM9vfXvgajRm29/o8+gjffzN8v/cYbVV0vFTp3Tvql+/evSuwDBrTOu5jMGlFDE/1YkiR+Yfr6fGBERFyWU+e3wN8j4r8ljQEeBLpGxBpJ+wJ/Bj4HfDsibsmzjouAiwB69eo19M0336zPdm7t1Verkn7FiWPAgKqk379/YUl66VL4znfg/vuTrpDrrktara3t7pOmMm9ekvB/85vkBNC3b/KJoiK5r1iRnJQrtG+fdDfl3mGSe+fJ7ru33JOpWQvSFIl+H+CnQB9gBnAmcGhErKtW52HgnyNiVU3ra5SLsW++WZX0Z81KEk2/flVJf/DgbZPJ2rVw/fXw058mrceJE5MWfb7b3GxbH36YXHC77bakLz/fLYN9+sA++7if26wIGr3rplr9jsCiiOiZp+wO4NGI+H1N62v0u25Wrqz61uD06cnFmd69q741OHgw3HILTJ6cdH989aswaVKSkMzMWqiGJvq2JBdjjweWk1yMPTciFuTU6QqsjYhPJU0GtkTENZJ6Amsi4kNJuwN/B86MiJdqWl+T3l75zjvJxdUHH4Qnn0xukWzXLvk7ejTceGPypSUzsxautkRf5xWtiNgs6TLgcZLbK++IiAWSJgGlETENGAXcIClIum6+kc5+MPDDdLqAKbUl+SbXtWvy5Z8JE5L7q//0J/jrX5OW/Re+0NzRmZkVhb8wZWaWAbW16H0VzMws45zozcwyzonezCzjnOjNzDLOid7MLOOc6M3MMs6J3sws45zozcwyrsV9YUrSaqAIj6+sUVfgnUZcfrG0ljih9cTqOIurtcQJrSfWhsS5X0R0y1fQ4hJ9Y5NUWtO3x1qS1hIntJ5YHWdxtZY4ofXE2lhxuuvGzCzjnOjNzDLus5job23uAArUWuKE1hOr4yyu1hIntJ5YGyXOz1wfvZnZZ81nsUVvZvaZ4kRvZpZxmUz0kvaV9IykVyQtkPR/8tQZJWm9pHnpcE0zxVom6aU0hm1+cUWJn0haIulFSUOaIcZ+OftpnqQNkr5VrU6z7U9Jd0j6h6SXc6btIelJSa+lf3evYd4L0jqvSbqgGeK8SdKi9L19SNJuNcxb63HSBHFeJ2l5zvt7cg3zjpa0OD1er2rMOGuJ9f6cOMskzath3qbcp3lzUpMdpxGRuQHoDgxJxzuR/OZt/2p1RgF/agGxlgFdayk/GXiM5KcYDwf+3szxtgHeJvlyRovYn8AxwBDg5ZxpNwJXpeNXAT/IM98ewNL07+7p+O5NHOeJQNt0/Af54izkOGmCOK8DJhZwbLwO9AXaA/Or/981RazVyn8IXNMC9mnenNRUx2kmW/QRsTIiXkjHNwILgR7NG1W9nQbcHYnngN0kdW/GeI4HXo+Ixvz28naJiBnA2mqTTwPuSsfvAk7PM+sXgScjYm1EvAs8CYxuyjgj4omI2Jy+fA7o2VjrL1QN+7MQw4ElEbE0Ij4GppK8D42mtlglCfgScF9jxlCIWnJSkxynmUz0uST1BgYDf89TfISk+ZIek3RIkwZWJYAnJM2RdFGe8h7AspzX5TTvSescav7HaQn7s8JeEbEyHX8b2CtPnZa2byeQfHrLp67jpClclnYx3VFDF0NL259HA6si4rUayptln1bLSU1ynGY60UvqCDwIfCsiNlQrfoGk+2EgcDPwcFPHlzoqIoYAJwHfkHRMM8VRJ0ntgVOB3+Upbin7cxuRfP5t0fcRS/ousBm4t4YqzX2c/BzYHxgErCTpEmnpxlF7a77J92ltOakxj9PMJnpJ7Uh26L0R8Yfq5RGxISLeS8cfBdpJ6trEYRIRy9O//wAeIvn4m2s5sG/O657ptOZwEvBCRKyqXtBS9meOVRVdXOnff+Sp0yL2raTxwCnAeek/+zYKOE4aVUSsiogtEfEp8Ksa1t8i9ieApLbAGOD+muo09T6tISc1yXGayUSf9s3dDiyMiB/VUGfvtB6ShpPsizVNFyVI2kVSp4pxkgtzL1erNg34Snr3zeHA+pyPek2txhZSS9if1UwDKu5OuAB4JE+dx4ETJe2edkWcmE5rMpJGA1cCp0bEBzXUKeQ4aVTVrgudUcP6ZwMHSOqTfvo7h+R9aA5fABZFRHm+wqbep7XkpKY5TpviinNTD8BRJB+BXgTmpcPJwCXAJWmdy4AFJHcGPAeMbIY4+6brn5/G8t10em6cAm4huZvhJaCkmfbpLiSJe9ecaS1if5KcfFYCn5D0X34N6AI8DbwGPAXskdYtAW7LmXcCsCQdvtoMcS4h6X+tOE5/kdbdB3i0tuOkieO8Jz3+XiRJTt2rx5m+PpnkjpLXGzvOmmJNp99ZcWzm1G3OfVpTTmqS49SPQDAzy7hMdt2YmVkVJ3ozs4xzojczyzgnejOzjHOiNzPLOCd6M7OMc6I3M8u4/w8UmkpuxeDtigAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"_RmXQw95FFrY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dFr5uSSK7eN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-opNS8oXFHdB","executionInfo":{"status":"ok","timestamp":1606103574740,"user_tz":-540,"elapsed":1659,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / Xception"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c","executionInfo":{"status":"ok","timestamp":1606103575306,"user_tz":-540,"elapsed":2220,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak","executionInfo":{"status":"ok","timestamp":1606103575307,"user_tz":-540,"elapsed":2215,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-38Ov61FHdE","executionInfo":{"status":"ok","timestamp":1606103588494,"user_tz":-540,"elapsed":15334,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["model=load_model(os.path.join(dir,'model_output',number,'SUB','Xception','018.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"hxpCFriTFHdG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606109117810,"user_tz":-540,"elapsed":5544614,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"c287dcb2-762d-4358-ee57-8c838c34817e"},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["312/312 [==============================] - 5498s 18s/step - loss: 1.5947 - accuracy: 0.7480 - top5_acc: 0.9314 - macro_f1score: 0.1998\n","[Test Loss: 1.5947 /  Test Top-1 Accuracy: 0.7480 / Test Top-5 Accuracy: 0.9314 / Test Macro f1: 0.1998]\n","\n"],"name":"stdout"}]}]}
