{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11.DenseNet121.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ucbQyskZRiX_","executionInfo":{"status":"ok","timestamp":1606103342526,"user_tz":-540,"elapsed":1260,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["#모형 출처 : https://github.com/titu1994/keras-squeeze-excite-network"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [DenseNet121]\n"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original DenseNet121\n","```\n","1) Support Functions\n","2) Almost orginal DenseNet121\n","```\n","3. DenseNet121\n","```\n","1) DenseNet121\n","2) DenseNet121 Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages\n"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103386704,"user_tz":-540,"elapsed":18056,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"8f8d86e4-105f-4270-a8ff-20da885f5254"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103386705,"user_tz":-540,"elapsed":18046,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"640eca1a-5374-440b-f82b-198d89d845ed"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1606103389274,"user_tz":-540,"elapsed":20610,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1606103389276,"user_tz":-540,"elapsed":20608,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606103389866,"user_tz":-540,"elapsed":21191,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"0ce9afbf-0a6a-4197-94d7-3998ae32411a"},"source":["os.getcwd()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606103389867,"user_tz":-540,"elapsed":21187,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"1c3f3c26-1038-4995-c7e7-310af5c4f2ba"},"source":["tf.__version__"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.3.0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606103393365,"user_tz":-540,"elapsed":24680,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"e1b0a976-150b-4113-ea59-334363d4a0f8"},"source":["tf.test.gpu_device_name()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"Kf057Rw2yigs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103393368,"user_tz":-540,"elapsed":24678,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"32daf07f-4a81-4e03-b743-06ce57f36813"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 5907243733293426163\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 7722372754785323714\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 17778981779805448702\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15473775744\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 8036306165658551023\n","physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EpLlsyj3hxeJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103393370,"user_tz":-540,"elapsed":24672,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"d519640c-5b12-4eeb-9e72-f7ebee542af5"},"source":["!cat /proc/cpuinfo"],"execution_count":11,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.160\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.32\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.160\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.32\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.160\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.32\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.160\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.32\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"BeJ7UtuOEgWY","executionInfo":{"status":"ok","timestamp":1606103393371,"user_tz":-540,"elapsed":24668,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CIFAR100'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 224 # sizes after cropping\n","super_size = 256 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 64\n","weight_decay = 1e-3\n","epochs = 70"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1606103393372,"user_tz":-540,"elapsed":24665,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbP99pIGoIUp","executionInfo":{"status":"ok","timestamp":1606103393375,"user_tz":-540,"elapsed":24663,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1606103393376,"user_tz":-540,"elapsed":24659,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wzhKX9OVoIUw"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"Iz9u1paNoIUx","executionInfo":{"status":"ok","timestamp":1606103393377,"user_tz":-540,"elapsed":24655,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1606103393377,"user_tz":-540,"elapsed":24650,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"c2IcuMY2oIU3","executionInfo":{"status":"ok","timestamp":1606103393378,"user_tz":-540,"elapsed":24646,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"4t6c_JewoIU7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103447020,"user_tz":-540,"elapsed":78283,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"2c445245-4297-4704-99ce-3afbe6ebd952"},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Found 44923 images belonging to 100 classes.\n","Found 5077 images belonging to 100 classes.\n","Found 10000 images belonging to 100 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gn_DwVVV1qmT"},"source":["## 2. Support Functions & Almost Original DenseNet121\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"GrcgSgWh1qmT"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aBovAVC3gVsB"},"source":["def __conv_block(ip, nb_filter, bottleneck=False, dropout_rate=None, weight_decay=weight_decay):\n","\n","    concat_axis = -1\n","\n","    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n","    x = Activation('relu')(x)\n","\n","    if bottleneck:\n","        inter_channel = nb_filter * 4  # Obtained from https://github.com/liuzhuang13/DenseNet/blob/master/densenet.lua\n","\n","        x = Conv2D(inter_channel, (1, 1), kernel_initializer='he_uniform', padding='same', use_bias=False,\n","                   kernel_regularizer=l2(weight_decay))(x)\n","        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","        x = Activation('relu')(x)\n","\n","    x = Conv2D(nb_filter, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False, kernel_regularizer=l2(weight_decay))(x)\n","    if dropout_rate:\n","        x = Dropout(dropout_rate)(x)\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEOp1A-0gdee"},"source":["def __dense_block(x, nb_layers, nb_filter, growth_rate, bottleneck=False, dropout_rate=None, weight_decay=weight_decay,\n","                  grow_nb_filters=True, return_concat_list=False):\n","\n","    concat_axis = -1\n","\n","    x_list = [x]\n","\n","    for i in range(nb_layers):\n","        cb = __conv_block(x, growth_rate, bottleneck, dropout_rate, weight_decay)\n","        x_list.append(cb)\n","\n","        x = concatenate([x, cb], axis=concat_axis)\n","\n","        if grow_nb_filters:\n","            nb_filter += growth_rate\n","\n","    if return_concat_list:\n","        return x, nb_filter, x_list\n","    else:\n","        return x, nb_filter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-K3RzQuCgdc_"},"source":["def __transition_block(ip, nb_filter, compression=1.0, weight_decay=weight_decay):\n","\n","    concat_axis = -1\n","\n","    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n","    x = Activation('relu')(x)\n","    x = Conv2D(int(nb_filter * compression), (1, 1), kernel_initializer='he_uniform', padding='same', use_bias=False,\n","               kernel_regularizer=l2(weight_decay))(x)\n","    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n","\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2HhTzaFgdbi"},"source":["def __create_dense_net(nb_classes, img_input, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1,\n","                       nb_layers_per_block=-1, bottleneck=False, reduction=0.0, dropout_rate=None, weight_decay=weight_decay,\n","                       subsample_initial_block=False, activation='softmax'):\n","\n","    concat_axis = -1\n","\n","    if reduction != 0.0:\n","        assert 1.0 >= reduction > 0.0, 'reduction value must lie between 0.0 and 1.0'\n","\n","    # layers in each dense block\n","    if type(nb_layers_per_block) is list or type(nb_layers_per_block) is tuple:\n","        nb_layers = list(nb_layers_per_block)  # Convert tuple to list\n","\n","        assert len(nb_layers) == nb_dense_block, 'If list, nb_layer is used as provided. ' \\\n","                                                 'Note that list size must be (nb_dense_block)'\n","        final_nb_layer = nb_layers[-1]\n","        nb_layers = nb_layers[:-1]\n","    else:\n","        if nb_layers_per_block == -1:\n","            assert (depth - 4) % 3 == 0, 'Depth must be 3 N + 4 if nb_layers_per_block == -1'\n","            count = int((depth - 4) / 3)\n","            nb_layers = [count for _ in range(nb_dense_block)]\n","            final_nb_layer = count\n","        else:\n","            final_nb_layer = nb_layers_per_block\n","            nb_layers = [nb_layers_per_block] * nb_dense_block\n","\n","    # compute initial nb_filter if -1, else accept users initial nb_filter\n","    if nb_filter <= 0:\n","        nb_filter = 2 * growth_rate\n","\n","    # compute compression factor\n","    compression = 1.0 - reduction\n","\n","    # Initial convolution\n","    if subsample_initial_block:\n","        initial_kernel = (7, 7)\n","        initial_strides = (2, 2)\n","    else:\n","        initial_kernel = (3, 3)\n","        initial_strides = (1, 1)\n","\n","    x = Conv2D(nb_filter, initial_kernel, kernel_initializer='he_uniform', padding='same',\n","               strides=initial_strides, use_bias=False, kernel_regularizer=l2(weight_decay))(img_input)\n","\n","    if subsample_initial_block:\n","        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","        x = Activation('relu')(x)\n","        x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","\n","    # Add dense blocks\n","    for block_idx in range(nb_dense_block - 1):\n","        x, nb_filter = __dense_block(x, nb_layers[block_idx], nb_filter, growth_rate, bottleneck=bottleneck,\n","                                     dropout_rate=dropout_rate, weight_decay=weight_decay)\n","        # add transition_block\n","        x = __transition_block(x, nb_filter, compression=compression, weight_decay=weight_decay)\n","        nb_filter = int(nb_filter * compression)\n","\n","    # The last dense_block does not have a transition_block\n","    x, nb_filter = __dense_block(x, final_nb_layer, nb_filter, growth_rate, bottleneck=bottleneck,\n","                                 dropout_rate=dropout_rate, weight_decay=weight_decay)\n","\n","    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","    x = Activation('relu')(x)\n","    x = GlobalAveragePooling2D()(x)\n","\n","    x = Dense(nb_classes, kernel_regularizer=l2(weight_decay),  activation=activation)(x)\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Lho4zoe1qmc"},"source":["### 2) Almost Orginial DenseNet121\n","\n"]},{"cell_type":"code","metadata":{"id":"7focbQW_gdZq"},"source":["def DenseNet(input_shape=None, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1, nb_layers_per_block=-1, bottleneck=False,\n","               reduction=0.0, dropout_rate=0.0, weight_decay=weight_decay, subsample_initial_block=False,\n","               weights=None, classes=classes, activation='softmax', name=None):\n","\n","\n","    if activation not in ['softmax', 'sigmoid']:\n","        raise ValueError('activation must be one of \"softmax\" or \"sigmoid\"')\n","\n","    if activation == 'sigmoid' and classes != 1:\n","        raise ValueError('sigmoid activation can only be used when classes = 1')\n","\n","    img_input = Input(shape=input_shape)\n","\n","    x = __create_dense_net(classes, img_input, depth, nb_dense_block,\n","                           growth_rate, nb_filter, nb_layers_per_block, bottleneck, reduction,\n","                           dropout_rate, weight_decay, subsample_initial_block, activation)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","\n","    inputs = img_input\n","\n","    # Create model.\n","    model = Model(inputs, x, name= name )\n","\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cCqpFfbZgdWF"},"source":["def DenseNet121(input_shape=None, bottleneck=True, reduction=0.5, growth_rate = 32, dropout_rate=0.0, weight_decay=weight_decay, classes=classes, activation='softmax', name = None):\n","\n","    return DenseNet(input_shape, depth=121, nb_dense_block=4, growth_rate=growth_rate, nb_filter=64,\n","                      nb_layers_per_block=[6, 12, 24, 16], bottleneck=bottleneck, reduction=reduction,\n","                      dropout_rate=dropout_rate, weight_decay=weight_decay, subsample_initial_block=True,\n","                      classes=classes, activation=activation , name = name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Y24Va7X1qmf"},"source":["## 3. DenseNet121\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"Wiva9k1w1qmg"},"source":["### 1) DenseNet121\n"]},{"cell_type":"code","metadata":{"id":"IA-KMy4xgdUD"},"source":["# densenet\n","\n","model = DenseNet121(input_shape=input_sizes, classes = classes, dropout_rate = 0.2, growth_rate = 32, name = 'DenseNet121')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YaOtPgAcgdRx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605698414368,"user_tz":-540,"elapsed":140156,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"6f64c64c-68ce-420a-9da1-e5a1935d20e4"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"DenseNet121\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 112, 112, 64) 9408        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 56, 56, 128)  8192        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 56, 56, 128)  512         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 56, 56, 128)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 56, 56, 32)   36864       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 56, 56, 32)   0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 56, 56, 96)   0           max_pooling2d[0][0]              \n","                                                                 dropout[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 56, 56, 96)   384         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 56, 56, 96)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 56, 56, 128)  12288       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 56, 56, 128)  512         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 56, 56, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 56, 56, 32)   36864       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 56, 56, 32)   0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 56, 56, 128)  0           concatenate[0][0]                \n","                                                                 dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 56, 56, 128)  512         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 56, 56, 128)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 56, 56, 128)  16384       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 56, 56, 128)  512         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 56, 56, 128)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 56, 56, 32)   36864       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 56, 56, 32)   0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 56, 56, 160)  0           concatenate_1[0][0]              \n","                                                                 dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 56, 56, 160)  640         concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 56, 56, 160)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 56, 56, 128)  20480       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 56, 56, 128)  512         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 56, 56, 128)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 56, 56, 32)   36864       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 56, 56, 32)   0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 56, 56, 192)  0           concatenate_2[0][0]              \n","                                                                 dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 56, 56, 192)  768         concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 56, 56, 192)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 56, 56, 128)  24576       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 56, 56, 128)  512         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 56, 56, 128)  0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 56, 56, 32)   36864       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 56, 56, 32)   0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 56, 56, 224)  0           concatenate_3[0][0]              \n","                                                                 dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 56, 56, 224)  896         concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 56, 56, 224)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 56, 56, 128)  28672       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 56, 56, 128)  512         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 56, 56, 128)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 56, 56, 32)   36864       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 56, 56, 32)   0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 56, 56, 256)  0           concatenate_4[0][0]              \n","                                                                 dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 56, 56, 256)  1024        concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 56, 56, 256)  0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 56, 56, 128)  32768       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 28, 28, 128)  0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 28, 28, 128)  16384       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 28, 28, 32)   36864       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 28, 28, 32)   0           conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 28, 28, 160)  0           average_pooling2d[0][0]          \n","                                                                 dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 28, 28, 160)  640         concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 28, 28, 160)  0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 28, 28, 128)  20480       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 28, 28, 32)   36864       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 28, 28, 32)   0           conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 28, 28, 192)  0           concatenate_6[0][0]              \n","                                                                 dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 28, 28, 192)  768         concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 28, 28, 192)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 28, 28, 128)  24576       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 28, 28, 32)   36864       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 28, 28, 32)   0           conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 28, 28, 224)  0           concatenate_7[0][0]              \n","                                                                 dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 28, 28, 224)  896         concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 28, 28, 224)  0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 28, 28, 128)  28672       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 28, 28, 32)   36864       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 28, 28, 32)   0           conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 28, 28, 256)  0           concatenate_8[0][0]              \n","                                                                 dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 28, 28, 256)  1024        concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 28, 28, 256)  0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 28, 28, 128)  32768       activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 28, 28, 128)  0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 28, 28, 32)   36864       activation_23[0][0]              \n","__________________________________________________________________________________________________\n","dropout_10 (Dropout)            (None, 28, 28, 32)   0           conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_10 (Concatenate)    (None, 28, 28, 288)  0           concatenate_9[0][0]              \n","                                                                 dropout_10[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 28, 28, 288)  1152        concatenate_10[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 28, 28, 288)  0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 28, 28, 128)  36864       activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 28, 28, 128)  512         conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 28, 28, 128)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 28, 28, 32)   36864       activation_25[0][0]              \n","__________________________________________________________________________________________________\n","dropout_11 (Dropout)            (None, 28, 28, 32)   0           conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_11 (Concatenate)    (None, 28, 28, 320)  0           concatenate_10[0][0]             \n","                                                                 dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 28, 28, 320)  1280        concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 28, 28, 320)  0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 28, 28, 128)  40960       activation_26[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 28, 28, 128)  512         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 28, 28, 128)  0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 28, 28, 32)   36864       activation_27[0][0]              \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 28, 28, 32)   0           conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_12 (Concatenate)    (None, 28, 28, 352)  0           concatenate_11[0][0]             \n","                                                                 dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 28, 28, 352)  1408        concatenate_12[0][0]             \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 28, 28, 352)  0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 28, 28, 128)  45056       activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 28, 28, 128)  512         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 28, 28, 128)  0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 28, 28, 32)   36864       activation_29[0][0]              \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 28, 28, 32)   0           conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_13 (Concatenate)    (None, 28, 28, 384)  0           concatenate_12[0][0]             \n","                                                                 dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 28, 28, 384)  1536        concatenate_13[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 28, 28, 384)  0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 28, 28, 128)  49152       activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 28, 28, 128)  512         conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 28, 28, 128)  0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 28, 28, 32)   36864       activation_31[0][0]              \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 28, 28, 32)   0           conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 28, 28, 416)  0           concatenate_13[0][0]             \n","                                                                 dropout_14[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 28, 28, 416)  1664        concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 28, 28, 416)  0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 28, 28, 128)  53248       activation_32[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 28, 28, 128)  512         conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 28, 28, 128)  0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 28, 28, 32)   36864       activation_33[0][0]              \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 28, 28, 32)   0           conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 28, 28, 448)  0           concatenate_14[0][0]             \n","                                                                 dropout_15[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 28, 28, 448)  1792        concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 28, 28, 448)  0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 28, 28, 128)  57344       activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 28, 28, 128)  512         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 28, 28, 128)  0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 28, 28, 32)   36864       activation_35[0][0]              \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 28, 28, 32)   0           conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 28, 28, 480)  0           concatenate_15[0][0]             \n","                                                                 dropout_16[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 28, 28, 480)  1920        concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 28, 28, 480)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 28, 28, 128)  61440       activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 28, 28, 128)  512         conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 28, 28, 128)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 28, 28, 32)   36864       activation_37[0][0]              \n","__________________________________________________________________________________________________\n","dropout_17 (Dropout)            (None, 28, 28, 32)   0           conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 28, 28, 512)  0           concatenate_16[0][0]             \n","                                                                 dropout_17[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 28, 28, 512)  2048        concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 28, 28, 512)  0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 28, 28, 256)  131072      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 14, 14, 256)  0           conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 14, 14, 256)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 14, 14, 128)  32768       activation_39[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 14, 14, 128)  512         conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 14, 14, 128)  0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 14, 14, 32)   36864       activation_40[0][0]              \n","__________________________________________________________________________________________________\n","dropout_18 (Dropout)            (None, 14, 14, 32)   0           conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 14, 14, 288)  0           average_pooling2d_1[0][0]        \n","                                                                 dropout_18[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 14, 14, 288)  1152        concatenate_18[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 14, 14, 288)  0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 14, 14, 128)  36864       activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 14, 14, 128)  512         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 14, 14, 128)  0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 14, 14, 32)   36864       activation_42[0][0]              \n","__________________________________________________________________________________________________\n","dropout_19 (Dropout)            (None, 14, 14, 32)   0           conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_19 (Concatenate)    (None, 14, 14, 320)  0           concatenate_18[0][0]             \n","                                                                 dropout_19[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 14, 14, 320)  1280        concatenate_19[0][0]             \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 14, 14, 320)  0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 14, 14, 128)  40960       activation_43[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 14, 14, 128)  512         conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 14, 14, 128)  0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 14, 14, 32)   36864       activation_44[0][0]              \n","__________________________________________________________________________________________________\n","dropout_20 (Dropout)            (None, 14, 14, 32)   0           conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_20 (Concatenate)    (None, 14, 14, 352)  0           concatenate_19[0][0]             \n","                                                                 dropout_20[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 14, 14, 352)  1408        concatenate_20[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 14, 14, 352)  0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 14, 14, 128)  45056       activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 14, 14, 128)  512         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 14, 14, 128)  0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 14, 14, 32)   36864       activation_46[0][0]              \n","__________________________________________________________________________________________________\n","dropout_21 (Dropout)            (None, 14, 14, 32)   0           conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_21 (Concatenate)    (None, 14, 14, 384)  0           concatenate_20[0][0]             \n","                                                                 dropout_21[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 14, 14, 384)  1536        concatenate_21[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 14, 14, 384)  0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 14, 14, 128)  49152       activation_47[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 14, 14, 128)  512         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 14, 14, 128)  0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 14, 14, 32)   36864       activation_48[0][0]              \n","__________________________________________________________________________________________________\n","dropout_22 (Dropout)            (None, 14, 14, 32)   0           conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_22 (Concatenate)    (None, 14, 14, 416)  0           concatenate_21[0][0]             \n","                                                                 dropout_22[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 14, 14, 416)  1664        concatenate_22[0][0]             \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 14, 14, 416)  0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 14, 14, 128)  53248       activation_49[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 14, 14, 128)  512         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 14, 14, 128)  0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 14, 14, 32)   36864       activation_50[0][0]              \n","__________________________________________________________________________________________________\n","dropout_23 (Dropout)            (None, 14, 14, 32)   0           conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_23 (Concatenate)    (None, 14, 14, 448)  0           concatenate_22[0][0]             \n","                                                                 dropout_23[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 14, 14, 448)  1792        concatenate_23[0][0]             \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 14, 14, 448)  0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 14, 14, 128)  57344       activation_51[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 14, 14, 128)  512         conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 14, 14, 128)  0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 14, 14, 32)   36864       activation_52[0][0]              \n","__________________________________________________________________________________________________\n","dropout_24 (Dropout)            (None, 14, 14, 32)   0           conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_24 (Concatenate)    (None, 14, 14, 480)  0           concatenate_23[0][0]             \n","                                                                 dropout_24[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 14, 14, 480)  1920        concatenate_24[0][0]             \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 14, 14, 480)  0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 14, 14, 128)  61440       activation_53[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 14, 14, 128)  512         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","activation_54 (Activation)      (None, 14, 14, 128)  0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 14, 14, 32)   36864       activation_54[0][0]              \n","__________________________________________________________________________________________________\n","dropout_25 (Dropout)            (None, 14, 14, 32)   0           conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_25 (Concatenate)    (None, 14, 14, 512)  0           concatenate_24[0][0]             \n","                                                                 dropout_25[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 14, 14, 512)  2048        concatenate_25[0][0]             \n","__________________________________________________________________________________________________\n","activation_55 (Activation)      (None, 14, 14, 512)  0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 14, 14, 128)  65536       activation_55[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 14, 14, 128)  512         conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","activation_56 (Activation)      (None, 14, 14, 128)  0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 14, 14, 32)   36864       activation_56[0][0]              \n","__________________________________________________________________________________________________\n","dropout_26 (Dropout)            (None, 14, 14, 32)   0           conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_26 (Concatenate)    (None, 14, 14, 544)  0           concatenate_25[0][0]             \n","                                                                 dropout_26[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 14, 14, 544)  2176        concatenate_26[0][0]             \n","__________________________________________________________________________________________________\n","activation_57 (Activation)      (None, 14, 14, 544)  0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 14, 14, 128)  69632       activation_57[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 14, 14, 128)  512         conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","activation_58 (Activation)      (None, 14, 14, 128)  0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 14, 14, 32)   36864       activation_58[0][0]              \n","__________________________________________________________________________________________________\n","dropout_27 (Dropout)            (None, 14, 14, 32)   0           conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_27 (Concatenate)    (None, 14, 14, 576)  0           concatenate_26[0][0]             \n","                                                                 dropout_27[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 14, 14, 576)  2304        concatenate_27[0][0]             \n","__________________________________________________________________________________________________\n","activation_59 (Activation)      (None, 14, 14, 576)  0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, 14, 14, 128)  73728       activation_59[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 14, 14, 128)  512         conv2d_59[0][0]                  \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 14, 14, 128)  0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 14, 14, 32)   36864       activation_60[0][0]              \n","__________________________________________________________________________________________________\n","dropout_28 (Dropout)            (None, 14, 14, 32)   0           conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_28 (Concatenate)    (None, 14, 14, 608)  0           concatenate_27[0][0]             \n","                                                                 dropout_28[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 14, 14, 608)  2432        concatenate_28[0][0]             \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 14, 14, 608)  0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 14, 14, 128)  77824       activation_61[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 14, 14, 128)  512         conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 14, 14, 128)  0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, 14, 14, 32)   36864       activation_62[0][0]              \n","__________________________________________________________________________________________________\n","dropout_29 (Dropout)            (None, 14, 14, 32)   0           conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_29 (Concatenate)    (None, 14, 14, 640)  0           concatenate_28[0][0]             \n","                                                                 dropout_29[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 14, 14, 640)  2560        concatenate_29[0][0]             \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 14, 14, 640)  0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, 14, 14, 128)  81920       activation_63[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 14, 14, 128)  512         conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 14, 14, 128)  0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_64 (Conv2D)              (None, 14, 14, 32)   36864       activation_64[0][0]              \n","__________________________________________________________________________________________________\n","dropout_30 (Dropout)            (None, 14, 14, 32)   0           conv2d_64[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_30 (Concatenate)    (None, 14, 14, 672)  0           concatenate_29[0][0]             \n","                                                                 dropout_30[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 14, 14, 672)  2688        concatenate_30[0][0]             \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 14, 14, 672)  0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_65 (Conv2D)              (None, 14, 14, 128)  86016       activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 14, 14, 128)  512         conv2d_65[0][0]                  \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 14, 14, 128)  0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_66 (Conv2D)              (None, 14, 14, 32)   36864       activation_66[0][0]              \n","__________________________________________________________________________________________________\n","dropout_31 (Dropout)            (None, 14, 14, 32)   0           conv2d_66[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_31 (Concatenate)    (None, 14, 14, 704)  0           concatenate_30[0][0]             \n","                                                                 dropout_31[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 14, 14, 704)  2816        concatenate_31[0][0]             \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 14, 14, 704)  0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_67 (Conv2D)              (None, 14, 14, 128)  90112       activation_67[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 14, 14, 128)  512         conv2d_67[0][0]                  \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 14, 14, 128)  0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_68 (Conv2D)              (None, 14, 14, 32)   36864       activation_68[0][0]              \n","__________________________________________________________________________________________________\n","dropout_32 (Dropout)            (None, 14, 14, 32)   0           conv2d_68[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_32 (Concatenate)    (None, 14, 14, 736)  0           concatenate_31[0][0]             \n","                                                                 dropout_32[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 14, 14, 736)  2944        concatenate_32[0][0]             \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 14, 14, 736)  0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_69 (Conv2D)              (None, 14, 14, 128)  94208       activation_69[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 14, 14, 128)  512         conv2d_69[0][0]                  \n","__________________________________________________________________________________________________\n","activation_70 (Activation)      (None, 14, 14, 128)  0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_70 (Conv2D)              (None, 14, 14, 32)   36864       activation_70[0][0]              \n","__________________________________________________________________________________________________\n","dropout_33 (Dropout)            (None, 14, 14, 32)   0           conv2d_70[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_33 (Concatenate)    (None, 14, 14, 768)  0           concatenate_32[0][0]             \n","                                                                 dropout_33[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 14, 14, 768)  3072        concatenate_33[0][0]             \n","__________________________________________________________________________________________________\n","activation_71 (Activation)      (None, 14, 14, 768)  0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_71 (Conv2D)              (None, 14, 14, 128)  98304       activation_71[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 14, 14, 128)  512         conv2d_71[0][0]                  \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 14, 14, 128)  0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_72 (Conv2D)              (None, 14, 14, 32)   36864       activation_72[0][0]              \n","__________________________________________________________________________________________________\n","dropout_34 (Dropout)            (None, 14, 14, 32)   0           conv2d_72[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_34 (Concatenate)    (None, 14, 14, 800)  0           concatenate_33[0][0]             \n","                                                                 dropout_34[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 14, 14, 800)  3200        concatenate_34[0][0]             \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 14, 14, 800)  0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_73 (Conv2D)              (None, 14, 14, 128)  102400      activation_73[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 14, 14, 128)  512         conv2d_73[0][0]                  \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 14, 14, 128)  0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_74 (Conv2D)              (None, 14, 14, 32)   36864       activation_74[0][0]              \n","__________________________________________________________________________________________________\n","dropout_35 (Dropout)            (None, 14, 14, 32)   0           conv2d_74[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_35 (Concatenate)    (None, 14, 14, 832)  0           concatenate_34[0][0]             \n","                                                                 dropout_35[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 14, 14, 832)  3328        concatenate_35[0][0]             \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 14, 14, 832)  0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_75 (Conv2D)              (None, 14, 14, 128)  106496      activation_75[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 14, 14, 128)  512         conv2d_75[0][0]                  \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 14, 14, 128)  0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_76 (Conv2D)              (None, 14, 14, 32)   36864       activation_76[0][0]              \n","__________________________________________________________________________________________________\n","dropout_36 (Dropout)            (None, 14, 14, 32)   0           conv2d_76[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_36 (Concatenate)    (None, 14, 14, 864)  0           concatenate_35[0][0]             \n","                                                                 dropout_36[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 14, 14, 864)  3456        concatenate_36[0][0]             \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 14, 14, 864)  0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_77 (Conv2D)              (None, 14, 14, 128)  110592      activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 14, 14, 128)  512         conv2d_77[0][0]                  \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 14, 14, 128)  0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_78 (Conv2D)              (None, 14, 14, 32)   36864       activation_78[0][0]              \n","__________________________________________________________________________________________________\n","dropout_37 (Dropout)            (None, 14, 14, 32)   0           conv2d_78[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_37 (Concatenate)    (None, 14, 14, 896)  0           concatenate_36[0][0]             \n","                                                                 dropout_37[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 14, 14, 896)  3584        concatenate_37[0][0]             \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 14, 14, 896)  0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_79 (Conv2D)              (None, 14, 14, 128)  114688      activation_79[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 14, 14, 128)  512         conv2d_79[0][0]                  \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 14, 14, 128)  0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_80 (Conv2D)              (None, 14, 14, 32)   36864       activation_80[0][0]              \n","__________________________________________________________________________________________________\n","dropout_38 (Dropout)            (None, 14, 14, 32)   0           conv2d_80[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_38 (Concatenate)    (None, 14, 14, 928)  0           concatenate_37[0][0]             \n","                                                                 dropout_38[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 14, 14, 928)  3712        concatenate_38[0][0]             \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 14, 14, 928)  0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_81 (Conv2D)              (None, 14, 14, 128)  118784      activation_81[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 14, 14, 128)  512         conv2d_81[0][0]                  \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 14, 14, 128)  0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_82 (Conv2D)              (None, 14, 14, 32)   36864       activation_82[0][0]              \n","__________________________________________________________________________________________________\n","dropout_39 (Dropout)            (None, 14, 14, 32)   0           conv2d_82[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_39 (Concatenate)    (None, 14, 14, 960)  0           concatenate_38[0][0]             \n","                                                                 dropout_39[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 14, 14, 960)  3840        concatenate_39[0][0]             \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 14, 14, 960)  0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_83 (Conv2D)              (None, 14, 14, 128)  122880      activation_83[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 14, 14, 128)  512         conv2d_83[0][0]                  \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 14, 14, 128)  0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_84 (Conv2D)              (None, 14, 14, 32)   36864       activation_84[0][0]              \n","__________________________________________________________________________________________________\n","dropout_40 (Dropout)            (None, 14, 14, 32)   0           conv2d_84[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_40 (Concatenate)    (None, 14, 14, 992)  0           concatenate_39[0][0]             \n","                                                                 dropout_40[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 14, 14, 992)  3968        concatenate_40[0][0]             \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 14, 14, 992)  0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_85 (Conv2D)              (None, 14, 14, 128)  126976      activation_85[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 14, 14, 128)  512         conv2d_85[0][0]                  \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 14, 14, 128)  0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_86 (Conv2D)              (None, 14, 14, 32)   36864       activation_86[0][0]              \n","__________________________________________________________________________________________________\n","dropout_41 (Dropout)            (None, 14, 14, 32)   0           conv2d_86[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_41 (Concatenate)    (None, 14, 14, 1024) 0           concatenate_40[0][0]             \n","                                                                 dropout_41[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 14, 14, 1024) 4096        concatenate_41[0][0]             \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_87 (Conv2D)              (None, 14, 14, 512)  524288      activation_87[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling2d_2 (AveragePoo (None, 7, 7, 512)    0           conv2d_87[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 7, 7, 512)    2048        average_pooling2d_2[0][0]        \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 7, 7, 512)    0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 7, 7, 128)    65536       activation_88[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 7, 7, 128)    512         conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 7, 7, 128)    0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 7, 7, 32)     36864       activation_89[0][0]              \n","__________________________________________________________________________________________________\n","dropout_42 (Dropout)            (None, 7, 7, 32)     0           conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_42 (Concatenate)    (None, 7, 7, 544)    0           average_pooling2d_2[0][0]        \n","                                                                 dropout_42[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 7, 7, 544)    2176        concatenate_42[0][0]             \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 7, 7, 544)    0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 7, 7, 128)    69632       activation_90[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 7, 7, 128)    512         conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 7, 7, 128)    0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 7, 7, 32)     36864       activation_91[0][0]              \n","__________________________________________________________________________________________________\n","dropout_43 (Dropout)            (None, 7, 7, 32)     0           conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_43 (Concatenate)    (None, 7, 7, 576)    0           concatenate_42[0][0]             \n","                                                                 dropout_43[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 7, 7, 576)    2304        concatenate_43[0][0]             \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 7, 7, 576)    0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 7, 7, 128)    73728       activation_92[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 7, 7, 128)    512         conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 7, 7, 128)    0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 7, 7, 32)     36864       activation_93[0][0]              \n","__________________________________________________________________________________________________\n","dropout_44 (Dropout)            (None, 7, 7, 32)     0           conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_44 (Concatenate)    (None, 7, 7, 608)    0           concatenate_43[0][0]             \n","                                                                 dropout_44[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 7, 7, 608)    2432        concatenate_44[0][0]             \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 7, 7, 608)    0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 7, 7, 128)    77824       activation_94[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 7, 7, 128)    512         conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 7, 7, 128)    0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 7, 7, 32)     36864       activation_95[0][0]              \n","__________________________________________________________________________________________________\n","dropout_45 (Dropout)            (None, 7, 7, 32)     0           conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_45 (Concatenate)    (None, 7, 7, 640)    0           concatenate_44[0][0]             \n","                                                                 dropout_45[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 7, 7, 640)    2560        concatenate_45[0][0]             \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 7, 7, 640)    0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 7, 7, 128)    81920       activation_96[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 7, 7, 128)    512         conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 7, 7, 128)    0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 7, 7, 32)     36864       activation_97[0][0]              \n","__________________________________________________________________________________________________\n","dropout_46 (Dropout)            (None, 7, 7, 32)     0           conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_46 (Concatenate)    (None, 7, 7, 672)    0           concatenate_45[0][0]             \n","                                                                 dropout_46[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 7, 7, 672)    2688        concatenate_46[0][0]             \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 7, 7, 672)    0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 7, 7, 128)    86016       activation_98[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 7, 7, 128)    512         conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 7, 7, 128)    0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 7, 7, 32)     36864       activation_99[0][0]              \n","__________________________________________________________________________________________________\n","dropout_47 (Dropout)            (None, 7, 7, 32)     0           conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_47 (Concatenate)    (None, 7, 7, 704)    0           concatenate_46[0][0]             \n","                                                                 dropout_47[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 7, 7, 704)    2816        concatenate_47[0][0]             \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 7, 7, 704)    0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 7, 7, 128)    90112       activation_100[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 7, 7, 128)    512         conv2d_100[0][0]                 \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 7, 7, 128)    0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 7, 7, 32)     36864       activation_101[0][0]             \n","__________________________________________________________________________________________________\n","dropout_48 (Dropout)            (None, 7, 7, 32)     0           conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_48 (Concatenate)    (None, 7, 7, 736)    0           concatenate_47[0][0]             \n","                                                                 dropout_48[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 7, 7, 736)    2944        concatenate_48[0][0]             \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 7, 7, 736)    0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 7, 7, 128)    94208       activation_102[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 7, 7, 128)    512         conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 7, 7, 128)    0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 7, 7, 32)     36864       activation_103[0][0]             \n","__________________________________________________________________________________________________\n","dropout_49 (Dropout)            (None, 7, 7, 32)     0           conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_49 (Concatenate)    (None, 7, 7, 768)    0           concatenate_48[0][0]             \n","                                                                 dropout_49[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 7, 7, 768)    3072        concatenate_49[0][0]             \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 7, 7, 768)    0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 7, 7, 128)    98304       activation_104[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_105 (BatchN (None, 7, 7, 128)    512         conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","activation_105 (Activation)     (None, 7, 7, 128)    0           batch_normalization_105[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_105 (Conv2D)             (None, 7, 7, 32)     36864       activation_105[0][0]             \n","__________________________________________________________________________________________________\n","dropout_50 (Dropout)            (None, 7, 7, 32)     0           conv2d_105[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_50 (Concatenate)    (None, 7, 7, 800)    0           concatenate_49[0][0]             \n","                                                                 dropout_50[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_106 (BatchN (None, 7, 7, 800)    3200        concatenate_50[0][0]             \n","__________________________________________________________________________________________________\n","activation_106 (Activation)     (None, 7, 7, 800)    0           batch_normalization_106[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_106 (Conv2D)             (None, 7, 7, 128)    102400      activation_106[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_107 (BatchN (None, 7, 7, 128)    512         conv2d_106[0][0]                 \n","__________________________________________________________________________________________________\n","activation_107 (Activation)     (None, 7, 7, 128)    0           batch_normalization_107[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_107 (Conv2D)             (None, 7, 7, 32)     36864       activation_107[0][0]             \n","__________________________________________________________________________________________________\n","dropout_51 (Dropout)            (None, 7, 7, 32)     0           conv2d_107[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_51 (Concatenate)    (None, 7, 7, 832)    0           concatenate_50[0][0]             \n","                                                                 dropout_51[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_108 (BatchN (None, 7, 7, 832)    3328        concatenate_51[0][0]             \n","__________________________________________________________________________________________________\n","activation_108 (Activation)     (None, 7, 7, 832)    0           batch_normalization_108[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_108 (Conv2D)             (None, 7, 7, 128)    106496      activation_108[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_109 (BatchN (None, 7, 7, 128)    512         conv2d_108[0][0]                 \n","__________________________________________________________________________________________________\n","activation_109 (Activation)     (None, 7, 7, 128)    0           batch_normalization_109[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_109 (Conv2D)             (None, 7, 7, 32)     36864       activation_109[0][0]             \n","__________________________________________________________________________________________________\n","dropout_52 (Dropout)            (None, 7, 7, 32)     0           conv2d_109[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_52 (Concatenate)    (None, 7, 7, 864)    0           concatenate_51[0][0]             \n","                                                                 dropout_52[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_110 (BatchN (None, 7, 7, 864)    3456        concatenate_52[0][0]             \n","__________________________________________________________________________________________________\n","activation_110 (Activation)     (None, 7, 7, 864)    0           batch_normalization_110[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_110 (Conv2D)             (None, 7, 7, 128)    110592      activation_110[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_111 (BatchN (None, 7, 7, 128)    512         conv2d_110[0][0]                 \n","__________________________________________________________________________________________________\n","activation_111 (Activation)     (None, 7, 7, 128)    0           batch_normalization_111[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_111 (Conv2D)             (None, 7, 7, 32)     36864       activation_111[0][0]             \n","__________________________________________________________________________________________________\n","dropout_53 (Dropout)            (None, 7, 7, 32)     0           conv2d_111[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_53 (Concatenate)    (None, 7, 7, 896)    0           concatenate_52[0][0]             \n","                                                                 dropout_53[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_112 (BatchN (None, 7, 7, 896)    3584        concatenate_53[0][0]             \n","__________________________________________________________________________________________________\n","activation_112 (Activation)     (None, 7, 7, 896)    0           batch_normalization_112[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_112 (Conv2D)             (None, 7, 7, 128)    114688      activation_112[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_113 (BatchN (None, 7, 7, 128)    512         conv2d_112[0][0]                 \n","__________________________________________________________________________________________________\n","activation_113 (Activation)     (None, 7, 7, 128)    0           batch_normalization_113[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_113 (Conv2D)             (None, 7, 7, 32)     36864       activation_113[0][0]             \n","__________________________________________________________________________________________________\n","dropout_54 (Dropout)            (None, 7, 7, 32)     0           conv2d_113[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_54 (Concatenate)    (None, 7, 7, 928)    0           concatenate_53[0][0]             \n","                                                                 dropout_54[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_114 (BatchN (None, 7, 7, 928)    3712        concatenate_54[0][0]             \n","__________________________________________________________________________________________________\n","activation_114 (Activation)     (None, 7, 7, 928)    0           batch_normalization_114[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_114 (Conv2D)             (None, 7, 7, 128)    118784      activation_114[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_115 (BatchN (None, 7, 7, 128)    512         conv2d_114[0][0]                 \n","__________________________________________________________________________________________________\n","activation_115 (Activation)     (None, 7, 7, 128)    0           batch_normalization_115[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_115 (Conv2D)             (None, 7, 7, 32)     36864       activation_115[0][0]             \n","__________________________________________________________________________________________________\n","dropout_55 (Dropout)            (None, 7, 7, 32)     0           conv2d_115[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_55 (Concatenate)    (None, 7, 7, 960)    0           concatenate_54[0][0]             \n","                                                                 dropout_55[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_116 (BatchN (None, 7, 7, 960)    3840        concatenate_55[0][0]             \n","__________________________________________________________________________________________________\n","activation_116 (Activation)     (None, 7, 7, 960)    0           batch_normalization_116[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_116 (Conv2D)             (None, 7, 7, 128)    122880      activation_116[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_117 (BatchN (None, 7, 7, 128)    512         conv2d_116[0][0]                 \n","__________________________________________________________________________________________________\n","activation_117 (Activation)     (None, 7, 7, 128)    0           batch_normalization_117[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_117 (Conv2D)             (None, 7, 7, 32)     36864       activation_117[0][0]             \n","__________________________________________________________________________________________________\n","dropout_56 (Dropout)            (None, 7, 7, 32)     0           conv2d_117[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_56 (Concatenate)    (None, 7, 7, 992)    0           concatenate_55[0][0]             \n","                                                                 dropout_56[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_118 (BatchN (None, 7, 7, 992)    3968        concatenate_56[0][0]             \n","__________________________________________________________________________________________________\n","activation_118 (Activation)     (None, 7, 7, 992)    0           batch_normalization_118[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_118 (Conv2D)             (None, 7, 7, 128)    126976      activation_118[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_119 (BatchN (None, 7, 7, 128)    512         conv2d_118[0][0]                 \n","__________________________________________________________________________________________________\n","activation_119 (Activation)     (None, 7, 7, 128)    0           batch_normalization_119[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_119 (Conv2D)             (None, 7, 7, 32)     36864       activation_119[0][0]             \n","__________________________________________________________________________________________________\n","dropout_57 (Dropout)            (None, 7, 7, 32)     0           conv2d_119[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_57 (Concatenate)    (None, 7, 7, 1024)   0           concatenate_56[0][0]             \n","                                                                 dropout_57[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_120 (BatchN (None, 7, 7, 1024)   4096        concatenate_57[0][0]             \n","__________________________________________________________________________________________________\n","activation_120 (Activation)     (None, 7, 7, 1024)   0           batch_normalization_120[0][0]    \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 1024)         0           activation_120[0][0]             \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 100)          102500      global_average_pooling2d[0][0]   \n","==================================================================================================\n","Total params: 7,140,004\n","Trainable params: 7,056,356\n","Non-trainable params: 83,648\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pwRlyWzi1qmm"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6K-e9yii3Qh"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8UHl5yto6_fc"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wgOtwPW1qmp"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=False, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=False, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VmS0d9OS1qmr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b59bde5-f76c-4a29-db13-43d31fed752a"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_5/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_6/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_7/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_8/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_9/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_10/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_11/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_12/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_13/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_14/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_15/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_16/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_17/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_18/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_19/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_20/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_21/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_22/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_23/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_24/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_25/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_26/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_27/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_28/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_29/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_30/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_31/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_32/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_33/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_34/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_35/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_36/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_37/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_38/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_39/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_40/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_41/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_42/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_43/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_44/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_45/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_46/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_47/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_48/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_49/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_50/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_51/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_52/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_53/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_54/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_55/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_56/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_57/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_58/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_59/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_60/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_61/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_62/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_63/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_64/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_65/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_66/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_67/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_68/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_69/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_70/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_71/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_72/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_73/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_74/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_75/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_76/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_77/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_78/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_79/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_80/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_81/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_82/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_83/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_84/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_85/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_86/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_87/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_88/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_89/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_90/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_91/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_92/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_93/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_94/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_95/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_96/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_97/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_98/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_99/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_100/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_101/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_102/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_103/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_104/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_105/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_106/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_107/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_108/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_109/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_110/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_111/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_112/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_113/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_114/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_115/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_116/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_117/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_118/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_119/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for dense/kernel:0\n","701/701 [==============================] - ETA: 0s - loss: 3.8167 - accuracy: 0.1170 - top5_acc: 0.3336 - macro_f1score: 0.0050 \n","Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/001.h5\n","\n","Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/001.h5\n","701/701 [==============================] - 25180s 36s/step - loss: 3.8167 - accuracy: 0.1170 - top5_acc: 0.3336 - macro_f1score: 0.0050 - val_loss: 3.6400 - val_accuracy: 0.1521 - val_top5_acc: 0.3993 - val_macro_f1score: 0.0140\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","701/701 [==============================] - ETA: 0s - loss: 3.1111 - accuracy: 0.2317 - top5_acc: 0.5245 - macro_f1score: 0.0273\n","Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/002.h5\n","\n","Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/002.h5\n","701/701 [==============================] - 607s 867ms/step - loss: 3.1111 - accuracy: 0.2317 - top5_acc: 0.5245 - macro_f1score: 0.0273 - val_loss: 4.8507 - val_accuracy: 0.1574 - val_top5_acc: 0.4039 - val_macro_f1score: 0.0400\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","701/701 [==============================] - ETA: 0s - loss: 2.5857 - accuracy: 0.3311 - top5_acc: 0.6540 - macro_f1score: 0.0633\n","Epoch 00003: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/003.h5\n","\n","Epoch 00003: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/003.h5\n","701/701 [==============================] - 620s 884ms/step - loss: 2.5857 - accuracy: 0.3311 - top5_acc: 0.6540 - macro_f1score: 0.0633 - val_loss: 3.9751 - val_accuracy: 0.2047 - val_top5_acc: 0.4905 - val_macro_f1score: 0.0577\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","701/701 [==============================] - ETA: 0s - loss: 2.2175 - accuracy: 0.4097 - top5_acc: 0.7333 - macro_f1score: 0.1026\n","Epoch 00004: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/004.h5\n","\n","Epoch 00004: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/004.h5\n","701/701 [==============================] - 628s 896ms/step - loss: 2.2175 - accuracy: 0.4097 - top5_acc: 0.7333 - macro_f1score: 0.1026 - val_loss: 3.8838 - val_accuracy: 0.2557 - val_top5_acc: 0.5429 - val_macro_f1score: 0.0793\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","701/701 [==============================] - ETA: 0s - loss: 1.9581 - accuracy: 0.4684 - top5_acc: 0.7838 - macro_f1score: 0.1388\n","Epoch 00005: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/005.h5\n","\n","Epoch 00005: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/005.h5\n","701/701 [==============================] - 684s 975ms/step - loss: 1.9581 - accuracy: 0.4684 - top5_acc: 0.7838 - macro_f1score: 0.1388 - val_loss: 3.2200 - val_accuracy: 0.3198 - val_top5_acc: 0.6236 - val_macro_f1score: 0.1097\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","701/701 [==============================] - ETA: 0s - loss: 1.7734 - accuracy: 0.5124 - top5_acc: 0.8166 - macro_f1score: 0.1660\n","Epoch 00006: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/006.h5\n","\n","Epoch 00006: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/006.h5\n","701/701 [==============================] - 678s 967ms/step - loss: 1.7734 - accuracy: 0.5124 - top5_acc: 0.8166 - macro_f1score: 0.1660 - val_loss: 3.4810 - val_accuracy: 0.2903 - val_top5_acc: 0.6104 - val_macro_f1score: 0.0982\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","701/701 [==============================] - ETA: 0s - loss: 1.6334 - accuracy: 0.5476 - top5_acc: 0.8408 - macro_f1score: 0.1869\n","Epoch 00007: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/007.h5\n","\n","Epoch 00007: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/007.h5\n","701/701 [==============================] - 684s 976ms/step - loss: 1.6334 - accuracy: 0.5476 - top5_acc: 0.8408 - macro_f1score: 0.1869 - val_loss: 3.2826 - val_accuracy: 0.3580 - val_top5_acc: 0.6653 - val_macro_f1score: 0.1372\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","701/701 [==============================] - ETA: 0s - loss: 1.5065 - accuracy: 0.5743 - top5_acc: 0.8609 - macro_f1score: 0.2061\n","Epoch 00008: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/008.h5\n","\n","Epoch 00008: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/008.h5\n","701/701 [==============================] - 689s 983ms/step - loss: 1.5065 - accuracy: 0.5743 - top5_acc: 0.8609 - macro_f1score: 0.2061 - val_loss: 2.6006 - val_accuracy: 0.4165 - val_top5_acc: 0.7310 - val_macro_f1score: 0.1632\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","701/701 [==============================] - ETA: 0s - loss: 1.4017 - accuracy: 0.6001 - top5_acc: 0.8782 - macro_f1score: 0.2243\n","Epoch 00009: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/009.h5\n","\n","Epoch 00009: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/009.h5\n","701/701 [==============================] - 650s 927ms/step - loss: 1.4017 - accuracy: 0.6001 - top5_acc: 0.8782 - macro_f1score: 0.2243 - val_loss: 2.4504 - val_accuracy: 0.4541 - val_top5_acc: 0.7676 - val_macro_f1score: 0.1858\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","701/701 [==============================] - ETA: 0s - loss: 1.3102 - accuracy: 0.6243 - top5_acc: 0.8919 - macro_f1score: 0.2380\n","Epoch 00010: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/010.h5\n","\n","Epoch 00010: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/010.h5\n","701/701 [==============================] - 635s 906ms/step - loss: 1.3102 - accuracy: 0.6243 - top5_acc: 0.8919 - macro_f1score: 0.2380 - val_loss: 2.2700 - val_accuracy: 0.4810 - val_top5_acc: 0.7710 - val_macro_f1score: 0.1930\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","701/701 [==============================] - ETA: 0s - loss: 1.2272 - accuracy: 0.6452 - top5_acc: 0.9028 - macro_f1score: 0.2523\n","Epoch 00011: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/011.h5\n","\n","Epoch 00011: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/011.h5\n","701/701 [==============================] - 630s 899ms/step - loss: 1.2272 - accuracy: 0.6452 - top5_acc: 0.9028 - macro_f1score: 0.2523 - val_loss: 2.4634 - val_accuracy: 0.4701 - val_top5_acc: 0.7520 - val_macro_f1score: 0.1903\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","701/701 [==============================] - ETA: 0s - loss: 1.1570 - accuracy: 0.6656 - top5_acc: 0.9111 - macro_f1score: 0.2655\n","Epoch 00012: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/012.h5\n","\n","Epoch 00012: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/012.h5\n","701/701 [==============================] - 625s 892ms/step - loss: 1.1570 - accuracy: 0.6656 - top5_acc: 0.9111 - macro_f1score: 0.2655 - val_loss: 2.1112 - val_accuracy: 0.5063 - val_top5_acc: 0.8159 - val_macro_f1score: 0.2088\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","701/701 [==============================] - ETA: 0s - loss: 1.0756 - accuracy: 0.6831 - top5_acc: 0.9225 - macro_f1score: 0.2786\n","Epoch 00013: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/013.h5\n","\n","Epoch 00013: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/013.h5\n","701/701 [==============================] - 629s 897ms/step - loss: 1.0756 - accuracy: 0.6831 - top5_acc: 0.9225 - macro_f1score: 0.2786 - val_loss: 1.7179 - val_accuracy: 0.5694 - val_top5_acc: 0.8398 - val_macro_f1score: 0.2296\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","701/701 [==============================] - ETA: 0s - loss: 1.0224 - accuracy: 0.6982 - top5_acc: 0.9293 - macro_f1score: 0.2884\n","Epoch 00014: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/014.h5\n","\n","Epoch 00014: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/014.h5\n","701/701 [==============================] - 634s 904ms/step - loss: 1.0224 - accuracy: 0.6982 - top5_acc: 0.9293 - macro_f1score: 0.2884 - val_loss: 2.0264 - val_accuracy: 0.5384 - val_top5_acc: 0.8246 - val_macro_f1score: 0.2243\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","701/701 [==============================] - ETA: 0s - loss: 0.9569 - accuracy: 0.7159 - top5_acc: 0.9369 - macro_f1score: 0.2990\n","Epoch 00015: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/015.h5\n","\n","Epoch 00015: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/015.h5\n","701/701 [==============================] - 630s 899ms/step - loss: 0.9569 - accuracy: 0.7159 - top5_acc: 0.9369 - macro_f1score: 0.2990 - val_loss: 1.9643 - val_accuracy: 0.5384 - val_top5_acc: 0.8291 - val_macro_f1score: 0.2227\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","701/701 [==============================] - ETA: 0s - loss: 0.9081 - accuracy: 0.7274 - top5_acc: 0.9428 - macro_f1score: 0.3055\n","Epoch 00016: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/016.h5\n","\n","Epoch 00016: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/016.h5\n","701/701 [==============================] - 634s 904ms/step - loss: 0.9081 - accuracy: 0.7274 - top5_acc: 0.9428 - macro_f1score: 0.3055 - val_loss: 2.2605 - val_accuracy: 0.5235 - val_top5_acc: 0.8153 - val_macro_f1score: 0.2223\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","701/701 [==============================] - ETA: 0s - loss: 0.8680 - accuracy: 0.7396 - top5_acc: 0.9480 - macro_f1score: 0.3144\n","Epoch 00017: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/017.h5\n","\n","Epoch 00017: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/017.h5\n","701/701 [==============================] - 630s 899ms/step - loss: 0.8680 - accuracy: 0.7396 - top5_acc: 0.9480 - macro_f1score: 0.3144 - val_loss: 1.8967 - val_accuracy: 0.5532 - val_top5_acc: 0.8293 - val_macro_f1score: 0.2319\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","701/701 [==============================] - ETA: 0s - loss: 0.8087 - accuracy: 0.7536 - top5_acc: 0.9542 - macro_f1score: 0.3233\n","Epoch 00018: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/018.h5\n","\n","Epoch 00018: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/018.h5\n","701/701 [==============================] - 637s 908ms/step - loss: 0.8087 - accuracy: 0.7536 - top5_acc: 0.9542 - macro_f1score: 0.3233 - val_loss: 1.6768 - val_accuracy: 0.5910 - val_top5_acc: 0.8621 - val_macro_f1score: 0.2508\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","701/701 [==============================] - ETA: 0s - loss: 0.7600 - accuracy: 0.7674 - top5_acc: 0.9599 - macro_f1score: 0.3320\n","Epoch 00019: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/019.h5\n","\n","Epoch 00019: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/019.h5\n","701/701 [==============================] - 646s 922ms/step - loss: 0.7600 - accuracy: 0.7674 - top5_acc: 0.9599 - macro_f1score: 0.3320 - val_loss: 1.7606 - val_accuracy: 0.5829 - val_top5_acc: 0.8560 - val_macro_f1score: 0.2477\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","701/701 [==============================] - ETA: 0s - loss: 0.7215 - accuracy: 0.7781 - top5_acc: 0.9636 - macro_f1score: 0.3378\n","Epoch 00020: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/020.h5\n","\n","Epoch 00020: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/020.h5\n","701/701 [==============================] - 631s 900ms/step - loss: 0.7215 - accuracy: 0.7781 - top5_acc: 0.9636 - macro_f1score: 0.3378 - val_loss: 1.7890 - val_accuracy: 0.5742 - val_top5_acc: 0.8509 - val_macro_f1score: 0.2452\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","701/701 [==============================] - ETA: 0s - loss: 0.6757 - accuracy: 0.7903 - top5_acc: 0.9673 - macro_f1score: 0.3472\n","Epoch 00021: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/021.h5\n","\n","Epoch 00021: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/021.h5\n","701/701 [==============================] - 629s 898ms/step - loss: 0.6757 - accuracy: 0.7903 - top5_acc: 0.9673 - macro_f1score: 0.3472 - val_loss: 1.6128 - val_accuracy: 0.6121 - val_top5_acc: 0.8770 - val_macro_f1score: 0.2687\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","701/701 [==============================] - ETA: 0s - loss: 0.6431 - accuracy: 0.7986 - top5_acc: 0.9713 - macro_f1score: 0.3529\n","Epoch 00022: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/022.h5\n","\n","Epoch 00022: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/022.h5\n","701/701 [==============================] - 636s 907ms/step - loss: 0.6431 - accuracy: 0.7986 - top5_acc: 0.9713 - macro_f1score: 0.3529 - val_loss: 1.8131 - val_accuracy: 0.6021 - val_top5_acc: 0.8600 - val_macro_f1score: 0.2622\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","701/701 [==============================] - ETA: 0s - loss: 0.6184 - accuracy: 0.8076 - top5_acc: 0.9732 - macro_f1score: 0.3584\n","Epoch 00023: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/023.h5\n","\n","Epoch 00023: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/023.h5\n","701/701 [==============================] - 633s 903ms/step - loss: 0.6184 - accuracy: 0.8076 - top5_acc: 0.9732 - macro_f1score: 0.3584 - val_loss: 1.7727 - val_accuracy: 0.5999 - val_top5_acc: 0.8744 - val_macro_f1score: 0.2631\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","701/701 [==============================] - ETA: 0s - loss: 0.5795 - accuracy: 0.8190 - top5_acc: 0.9765 - macro_f1score: 0.3672\n","Epoch 00024: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/024.h5\n","\n","Epoch 00024: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/024.h5\n","701/701 [==============================] - 632s 902ms/step - loss: 0.5795 - accuracy: 0.8190 - top5_acc: 0.9765 - macro_f1score: 0.3672 - val_loss: 1.7983 - val_accuracy: 0.5997 - val_top5_acc: 0.8651 - val_macro_f1score: 0.2646\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","701/701 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.8253 - top5_acc: 0.9792 - macro_f1score: 0.3693\n","Epoch 00025: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/025.h5\n","\n","Epoch 00025: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/025.h5\n","701/701 [==============================] - 634s 904ms/step - loss: 0.5502 - accuracy: 0.8253 - top5_acc: 0.9792 - macro_f1score: 0.3693 - val_loss: 2.1190 - val_accuracy: 0.5556 - val_top5_acc: 0.8273 - val_macro_f1score: 0.2419\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","701/701 [==============================] - ETA: 0s - loss: 0.5210 - accuracy: 0.8361 - top5_acc: 0.9815 - macro_f1score: 0.3768\n","Epoch 00026: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/026.h5\n","\n","Epoch 00026: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/026.h5\n","701/701 [==============================] - 633s 903ms/step - loss: 0.5210 - accuracy: 0.8361 - top5_acc: 0.9815 - macro_f1score: 0.3768 - val_loss: 1.9143 - val_accuracy: 0.5951 - val_top5_acc: 0.8740 - val_macro_f1score: 0.2611\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","701/701 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.8371 - top5_acc: 0.9821 - macro_f1score: 0.3782\n","Epoch 00027: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/027.h5\n","\n","Epoch 00027: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/027.h5\n","701/701 [==============================] - 631s 900ms/step - loss: 0.5075 - accuracy: 0.8371 - top5_acc: 0.9821 - macro_f1score: 0.3782 - val_loss: 1.9222 - val_accuracy: 0.6062 - val_top5_acc: 0.8600 - val_macro_f1score: 0.2715\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","701/701 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.8496 - top5_acc: 0.9849 - macro_f1score: 0.3867\n","Epoch 00028: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/028.h5\n","\n","Epoch 00028: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/028.h5\n","701/701 [==============================] - 633s 903ms/step - loss: 0.4707 - accuracy: 0.8496 - top5_acc: 0.9849 - macro_f1score: 0.3867 - val_loss: 1.6535 - val_accuracy: 0.6404 - val_top5_acc: 0.8847 - val_macro_f1score: 0.2838\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","701/701 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.8529 - top5_acc: 0.9860 - macro_f1score: 0.3893\n","Epoch 00029: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/029.h5\n","\n","Epoch 00029: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/029.h5\n","701/701 [==============================] - 635s 905ms/step - loss: 0.4610 - accuracy: 0.8529 - top5_acc: 0.9860 - macro_f1score: 0.3893 - val_loss: 2.0095 - val_accuracy: 0.5997 - val_top5_acc: 0.8584 - val_macro_f1score: 0.2662\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","701/701 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.8616 - top5_acc: 0.9872 - macro_f1score: 0.3926\n","Epoch 00030: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/030.h5\n","\n","Epoch 00030: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/030.h5\n","701/701 [==============================] - 629s 897ms/step - loss: 0.4367 - accuracy: 0.8616 - top5_acc: 0.9872 - macro_f1score: 0.3926 - val_loss: 2.2239 - val_accuracy: 0.5617 - val_top5_acc: 0.8416 - val_macro_f1score: 0.2430\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","701/701 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.9294 - top5_acc: 0.9964 - macro_f1score: 0.4309\n","Epoch 00031: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/031.h5\n","\n","Epoch 00031: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/031.h5\n","701/701 [==============================] - 632s 902ms/step - loss: 0.2369 - accuracy: 0.9294 - top5_acc: 0.9964 - macro_f1score: 0.4309 - val_loss: 1.2027 - val_accuracy: 0.7122 - val_top5_acc: 0.9169 - val_macro_f1score: 0.3182\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","701/701 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.9557 - top5_acc: 0.9984 - macro_f1score: 0.4458\n","Epoch 00032: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/032.h5\n","\n","Epoch 00032: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/032.h5\n","701/701 [==============================] - 626s 892ms/step - loss: 0.1678 - accuracy: 0.9557 - top5_acc: 0.9984 - macro_f1score: 0.4458 - val_loss: 1.1780 - val_accuracy: 0.7201 - val_top5_acc: 0.9167 - val_macro_f1score: 0.3209\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","701/701 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.9618 - top5_acc: 0.9989 - macro_f1score: 0.4491\n","Epoch 00033: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/033.h5\n","\n","Epoch 00033: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/033.h5\n","701/701 [==============================] - 630s 899ms/step - loss: 0.1532 - accuracy: 0.9618 - top5_acc: 0.9989 - macro_f1score: 0.4491 - val_loss: 1.1589 - val_accuracy: 0.7184 - val_top5_acc: 0.9201 - val_macro_f1score: 0.3250\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","701/701 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.9675 - top5_acc: 0.9992 - macro_f1score: 0.4527\n","Epoch 00034: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/034.h5\n","\n","Epoch 00034: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/034.h5\n","701/701 [==============================] - 627s 894ms/step - loss: 0.1355 - accuracy: 0.9675 - top5_acc: 0.9992 - macro_f1score: 0.4527 - val_loss: 1.1779 - val_accuracy: 0.7130 - val_top5_acc: 0.9181 - val_macro_f1score: 0.3204\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","701/701 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9703 - top5_acc: 0.9993 - macro_f1score: 0.4543\n","Epoch 00035: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/035.h5\n","\n","Epoch 00035: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/035.h5\n","701/701 [==============================] - 625s 891ms/step - loss: 0.1274 - accuracy: 0.9703 - top5_acc: 0.9993 - macro_f1score: 0.4543 - val_loss: 1.1317 - val_accuracy: 0.7237 - val_top5_acc: 0.9241 - val_macro_f1score: 0.3252\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","701/701 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.9734 - top5_acc: 0.9994 - macro_f1score: 0.4578\n","Epoch 00036: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/036.h5\n","\n","Epoch 00036: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/036.h5\n","701/701 [==============================] - 626s 894ms/step - loss: 0.1191 - accuracy: 0.9734 - top5_acc: 0.9994 - macro_f1score: 0.4578 - val_loss: 1.1546 - val_accuracy: 0.7162 - val_top5_acc: 0.9219 - val_macro_f1score: 0.3235\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","701/701 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9758 - top5_acc: 0.9997 - macro_f1score: 0.4586\n","Epoch 00037: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/037.h5\n","\n","Epoch 00037: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/037.h5\n","701/701 [==============================] - 627s 894ms/step - loss: 0.1095 - accuracy: 0.9758 - top5_acc: 0.9997 - macro_f1score: 0.4586 - val_loss: 1.1621 - val_accuracy: 0.7184 - val_top5_acc: 0.9205 - val_macro_f1score: 0.3266\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","701/701 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9761 - top5_acc: 0.9997 - macro_f1score: 0.4604\n","Epoch 00038: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/038.h5\n","\n","Epoch 00038: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/038.h5\n","701/701 [==============================] - 625s 892ms/step - loss: 0.1090 - accuracy: 0.9761 - top5_acc: 0.9997 - macro_f1score: 0.4604 - val_loss: 1.1325 - val_accuracy: 0.7225 - val_top5_acc: 0.9225 - val_macro_f1score: 0.3259\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","701/701 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9786 - top5_acc: 0.9997 - macro_f1score: 0.4594\n","Epoch 00039: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/039.h5\n","\n","Epoch 00039: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/039.h5\n","701/701 [==============================] - 626s 894ms/step - loss: 0.1008 - accuracy: 0.9786 - top5_acc: 0.9997 - macro_f1score: 0.4594 - val_loss: 1.1628 - val_accuracy: 0.7170 - val_top5_acc: 0.9189 - val_macro_f1score: 0.3255\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9813 - top5_acc: 0.9998 - macro_f1score: 0.4630\n","Epoch 00040: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/040.h5\n","\n","Epoch 00040: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/040.h5\n","701/701 [==============================] - 637s 908ms/step - loss: 0.0959 - accuracy: 0.9813 - top5_acc: 0.9998 - macro_f1score: 0.4630 - val_loss: 1.1375 - val_accuracy: 0.7233 - val_top5_acc: 0.9201 - val_macro_f1score: 0.3267\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9833 - top5_acc: 0.9997 - macro_f1score: 0.4639\n","Epoch 00041: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/041.h5\n","\n","Epoch 00041: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/041.h5\n","701/701 [==============================] - 659s 940ms/step - loss: 0.0889 - accuracy: 0.9833 - top5_acc: 0.9997 - macro_f1score: 0.4639 - val_loss: 1.1440 - val_accuracy: 0.7201 - val_top5_acc: 0.9185 - val_macro_f1score: 0.3221\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9823 - top5_acc: 0.9999 - macro_f1score: 0.4631\n","Epoch 00042: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/042.h5\n","\n","Epoch 00042: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/042.h5\n","701/701 [==============================] - 706s 1s/step - loss: 0.0894 - accuracy: 0.9823 - top5_acc: 0.9999 - macro_f1score: 0.4631 - val_loss: 1.1413 - val_accuracy: 0.7191 - val_top5_acc: 0.9225 - val_macro_f1score: 0.3280\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9834 - top5_acc: 0.9999 - macro_f1score: 0.4640\n","Epoch 00043: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/043.h5\n","\n","Epoch 00043: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/043.h5\n","701/701 [==============================] - 718s 1s/step - loss: 0.0846 - accuracy: 0.9834 - top5_acc: 0.9999 - macro_f1score: 0.4640 - val_loss: 1.1481 - val_accuracy: 0.7205 - val_top5_acc: 0.9199 - val_macro_f1score: 0.3287\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9848 - top5_acc: 0.9998 - macro_f1score: 0.4650\n","Epoch 00044: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/044.h5\n","\n","Epoch 00044: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/044.h5\n","701/701 [==============================] - 715s 1s/step - loss: 0.0812 - accuracy: 0.9848 - top5_acc: 0.9998 - macro_f1score: 0.4650 - val_loss: 1.1286 - val_accuracy: 0.7207 - val_top5_acc: 0.9229 - val_macro_f1score: 0.3247\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9858 - top5_acc: 0.9998 - macro_f1score: 0.4646\n","Epoch 00045: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/045.h5\n","\n","Epoch 00045: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/045.h5\n","701/701 [==============================] - 713s 1s/step - loss: 0.0779 - accuracy: 0.9858 - top5_acc: 0.9998 - macro_f1score: 0.4646 - val_loss: 1.1372 - val_accuracy: 0.7193 - val_top5_acc: 0.9227 - val_macro_f1score: 0.3221\n","Learning rate:  0.0001\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 46/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9857 - top5_acc: 0.9998 - macro_f1score: 0.4661\n","Epoch 00046: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/046.h5\n","\n","Epoch 00046: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/046.h5\n","701/701 [==============================] - 717s 1s/step - loss: 0.0768 - accuracy: 0.9857 - top5_acc: 0.9998 - macro_f1score: 0.4661 - val_loss: 1.1730 - val_accuracy: 0.7146 - val_top5_acc: 0.9185 - val_macro_f1score: 0.3177\n","Learning rate:  0.0001\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 47/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9869 - top5_acc: 0.9999 - macro_f1score: 0.4668\n","Epoch 00047: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/047.h5\n","\n","Epoch 00047: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/047.h5\n","701/701 [==============================] - 731s 1s/step - loss: 0.0728 - accuracy: 0.9869 - top5_acc: 0.9999 - macro_f1score: 0.4668 - val_loss: 1.1919 - val_accuracy: 0.7172 - val_top5_acc: 0.9191 - val_macro_f1score: 0.3185\n","Learning rate:  0.0001\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 48/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9863 - top5_acc: 0.9998 - macro_f1score: 0.4675\n","Epoch 00048: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/048.h5\n","\n","Epoch 00048: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/048.h5\n","701/701 [==============================] - 723s 1s/step - loss: 0.0723 - accuracy: 0.9863 - top5_acc: 0.9998 - macro_f1score: 0.4675 - val_loss: 1.1987 - val_accuracy: 0.7122 - val_top5_acc: 0.9167 - val_macro_f1score: 0.3202\n","Learning rate:  0.0001\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 49/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9871 - top5_acc: 1.0000 - macro_f1score: 0.4669\n","Epoch 00049: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/049.h5\n","\n","Epoch 00049: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/049.h5\n","701/701 [==============================] - 718s 1s/step - loss: 0.0694 - accuracy: 0.9871 - top5_acc: 1.0000 - macro_f1score: 0.4669 - val_loss: 1.1664 - val_accuracy: 0.7195 - val_top5_acc: 0.9175 - val_macro_f1score: 0.3247\n","Learning rate:  0.0001\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 50/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9865 - top5_acc: 0.9999 - macro_f1score: 0.4666\n","Epoch 00050: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/050.h5\n","\n","Epoch 00050: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/050.h5\n","701/701 [==============================] - 717s 1s/step - loss: 0.0697 - accuracy: 0.9865 - top5_acc: 0.9999 - macro_f1score: 0.4666 - val_loss: 1.1606 - val_accuracy: 0.7237 - val_top5_acc: 0.9203 - val_macro_f1score: 0.3254\n","Learning rate:  0.0001\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 51/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9871 - top5_acc: 1.0000 - macro_f1score: 0.4671\n","Epoch 00051: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/051.h5\n","\n","Epoch 00051: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/051.h5\n","701/701 [==============================] - 724s 1s/step - loss: 0.0689 - accuracy: 0.9871 - top5_acc: 1.0000 - macro_f1score: 0.4671 - val_loss: 1.1700 - val_accuracy: 0.7189 - val_top5_acc: 0.9197 - val_macro_f1score: 0.3293\n","Learning rate:  0.0001\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 52/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9895 - top5_acc: 1.0000 - macro_f1score: 0.4675\n","Epoch 00052: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/052.h5\n","\n","Epoch 00052: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/052.h5\n","701/701 [==============================] - 731s 1s/step - loss: 0.0632 - accuracy: 0.9895 - top5_acc: 1.0000 - macro_f1score: 0.4675 - val_loss: 1.1844 - val_accuracy: 0.7221 - val_top5_acc: 0.9159 - val_macro_f1score: 0.3261\n","Learning rate:  0.0001\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 53/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9889 - top5_acc: 0.9999 - macro_f1score: 0.4686\n","Epoch 00053: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/053.h5\n","\n","Epoch 00053: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/053.h5\n","701/701 [==============================] - 724s 1s/step - loss: 0.0631 - accuracy: 0.9889 - top5_acc: 0.9999 - macro_f1score: 0.4686 - val_loss: 1.1710 - val_accuracy: 0.7217 - val_top5_acc: 0.9185 - val_macro_f1score: 0.3257\n","Learning rate:  0.0001\n","\n","Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 54/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9882 - top5_acc: 0.9999 - macro_f1score: 0.4680\n","Epoch 00054: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/054.h5\n","\n","Epoch 00054: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/054.h5\n","701/701 [==============================] - 734s 1s/step - loss: 0.0629 - accuracy: 0.9882 - top5_acc: 0.9999 - macro_f1score: 0.4680 - val_loss: 1.1941 - val_accuracy: 0.7193 - val_top5_acc: 0.9163 - val_macro_f1score: 0.3234\n","Learning rate:  0.0001\n","\n","Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 55/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9889 - top5_acc: 1.0000 - macro_f1score: 0.4682\n","Epoch 00055: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/055.h5\n","\n","Epoch 00055: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/055.h5\n","701/701 [==============================] - 734s 1s/step - loss: 0.0606 - accuracy: 0.9889 - top5_acc: 1.0000 - macro_f1score: 0.4682 - val_loss: 1.1981 - val_accuracy: 0.7178 - val_top5_acc: 0.9171 - val_macro_f1score: 0.3238\n","Learning rate:  0.0001\n","\n","Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 56/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9894 - top5_acc: 0.9999 - macro_f1score: 0.4670\n","Epoch 00056: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/056.h5\n","\n","Epoch 00056: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/056.h5\n","701/701 [==============================] - 723s 1s/step - loss: 0.0614 - accuracy: 0.9894 - top5_acc: 0.9999 - macro_f1score: 0.4670 - val_loss: 1.2037 - val_accuracy: 0.7079 - val_top5_acc: 0.9146 - val_macro_f1score: 0.3176\n","Learning rate:  0.0001\n","\n","Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 57/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9898 - top5_acc: 0.9999 - macro_f1score: 0.4698\n","Epoch 00057: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/057.h5\n","\n","Epoch 00057: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/057.h5\n","701/701 [==============================] - 734s 1s/step - loss: 0.0577 - accuracy: 0.9898 - top5_acc: 0.9999 - macro_f1score: 0.4698 - val_loss: 1.2293 - val_accuracy: 0.7150 - val_top5_acc: 0.9159 - val_macro_f1score: 0.3223\n","Learning rate:  0.0001\n","\n","Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 58/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9891 - top5_acc: 0.9999 - macro_f1score: 0.4672\n","Epoch 00058: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/058.h5\n","\n","Epoch 00058: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/058.h5\n","701/701 [==============================] - 723s 1s/step - loss: 0.0583 - accuracy: 0.9891 - top5_acc: 0.9999 - macro_f1score: 0.4672 - val_loss: 1.1827 - val_accuracy: 0.7174 - val_top5_acc: 0.9152 - val_macro_f1score: 0.3245\n","Learning rate:  0.0001\n","\n","Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 59/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9899 - top5_acc: 1.0000 - macro_f1score: 0.4683\n","Epoch 00059: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/059.h5\n","\n","Epoch 00059: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/059.h5\n","701/701 [==============================] - 717s 1s/step - loss: 0.0566 - accuracy: 0.9899 - top5_acc: 1.0000 - macro_f1score: 0.4683 - val_loss: 1.1973 - val_accuracy: 0.7201 - val_top5_acc: 0.9152 - val_macro_f1score: 0.3271\n","Learning rate:  0.0001\n","\n","Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 60/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9900 - top5_acc: 0.9999 - macro_f1score: 0.4699\n","Epoch 00060: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/060.h5\n","\n","Epoch 00060: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/060.h5\n","701/701 [==============================] - 715s 1s/step - loss: 0.0549 - accuracy: 0.9900 - top5_acc: 0.9999 - macro_f1score: 0.4699 - val_loss: 1.2747 - val_accuracy: 0.7027 - val_top5_acc: 0.9102 - val_macro_f1score: 0.3209\n","Learning rate:  1e-05\n","\n","Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 61/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9931 - top5_acc: 0.9999 - macro_f1score: 0.4698\n","Epoch 00061: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/061.h5\n","\n","Epoch 00061: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/061.h5\n","701/701 [==============================] - 721s 1s/step - loss: 0.0457 - accuracy: 0.9931 - top5_acc: 0.9999 - macro_f1score: 0.4698 - val_loss: 1.1725 - val_accuracy: 0.7203 - val_top5_acc: 0.9179 - val_macro_f1score: 0.3274\n","Learning rate:  1e-05\n","\n","Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 62/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9946 - top5_acc: 1.0000 - macro_f1score: 0.4727\n","Epoch 00062: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/062.h5\n","\n","Epoch 00062: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/062.h5\n","701/701 [==============================] - 726s 1s/step - loss: 0.0408 - accuracy: 0.9946 - top5_acc: 1.0000 - macro_f1score: 0.4727 - val_loss: 1.1441 - val_accuracy: 0.7201 - val_top5_acc: 0.9193 - val_macro_f1score: 0.3235\n","Learning rate:  1e-05\n","\n","Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 63/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9958 - top5_acc: 1.0000 - macro_f1score: 0.4717\n","Epoch 00063: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/063.h5\n","\n","Epoch 00063: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/063.h5\n","701/701 [==============================] - 721s 1s/step - loss: 0.0400 - accuracy: 0.9958 - top5_acc: 1.0000 - macro_f1score: 0.4717 - val_loss: 1.1236 - val_accuracy: 0.7247 - val_top5_acc: 0.9211 - val_macro_f1score: 0.3271\n","Learning rate:  1e-05\n","\n","Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 64/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9953 - top5_acc: 1.0000 - macro_f1score: 0.4710\n","Epoch 00064: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/064.h5\n","\n","Epoch 00064: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/064.h5\n","701/701 [==============================] - 717s 1s/step - loss: 0.0428 - accuracy: 0.9953 - top5_acc: 1.0000 - macro_f1score: 0.4710 - val_loss: 1.1184 - val_accuracy: 0.7235 - val_top5_acc: 0.9209 - val_macro_f1score: 0.3246\n","Learning rate:  1e-05\n","\n","Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 65/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9959 - top5_acc: 1.0000 - macro_f1score: 0.4713\n","Epoch 00065: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/065.h5\n","\n","Epoch 00065: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/065.h5\n","701/701 [==============================] - 719s 1s/step - loss: 0.0421 - accuracy: 0.9959 - top5_acc: 1.0000 - macro_f1score: 0.4713 - val_loss: 1.0956 - val_accuracy: 0.7261 - val_top5_acc: 0.9217 - val_macro_f1score: 0.3260\n","Learning rate:  1e-05\n","\n","Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 66/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9962 - top5_acc: 1.0000 - macro_f1score: 0.4711\n","Epoch 00066: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/066.h5\n","\n","Epoch 00066: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/066.h5\n","701/701 [==============================] - 719s 1s/step - loss: 0.0439 - accuracy: 0.9962 - top5_acc: 1.0000 - macro_f1score: 0.4711 - val_loss: 1.0901 - val_accuracy: 0.7235 - val_top5_acc: 0.9207 - val_macro_f1score: 0.3268\n","Learning rate:  1e-05\n","\n","Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 67/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9970 - top5_acc: 1.0000 - macro_f1score: 0.4721\n","Epoch 00067: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/067.h5\n","\n","Epoch 00067: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/067.h5\n","701/701 [==============================] - 732s 1s/step - loss: 0.0441 - accuracy: 0.9970 - top5_acc: 1.0000 - macro_f1score: 0.4721 - val_loss: 1.0754 - val_accuracy: 0.7288 - val_top5_acc: 0.9229 - val_macro_f1score: 0.3222\n","Learning rate:  1e-05\n","\n","Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 68/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9965 - top5_acc: 1.0000 - macro_f1score: 0.4736\n","Epoch 00068: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/068.h5\n","\n","Epoch 00068: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/068.h5\n","701/701 [==============================] - 721s 1s/step - loss: 0.0463 - accuracy: 0.9965 - top5_acc: 1.0000 - macro_f1score: 0.4736 - val_loss: 1.0704 - val_accuracy: 0.7306 - val_top5_acc: 0.9225 - val_macro_f1score: 0.3272\n","Learning rate:  1e-05\n","\n","Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 69/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9962 - top5_acc: 1.0000 - macro_f1score: 0.4716\n","Epoch 00069: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/069.h5\n","\n","Epoch 00069: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/DenseNet121/069.h5\n","701/701 [==============================] - 721s 1s/step - loss: 0.0487 - accuracy: 0.9962 - top5_acc: 1.0000 - macro_f1score: 0.4716 - val_loss: 1.0588 - val_accuracy: 0.7278 - val_top5_acc: 0.9233 - val_macro_f1score: 0.3254\n","Learning rate:  1e-05\n","\n","Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 70/70\n","649/701 [==========================>...] - ETA: 50s - loss: 0.0492 - accuracy: 0.9967 - top5_acc: 1.0000 - macro_f1score: 0.4723"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FAr6jLIR1qmu"},"source":["### 2) DenseNet121 Evaluate"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"ZvKx1in81qmu"},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fbdRXP391qmx"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRtTWKDk1qm0"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lB5x2Y_1qm3"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'DenseNet121.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQVReEQO1qm5"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEBcd6Hx1qm8"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jkbe4ajm1qnG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Pvhb84dK3dt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLDgyUtp1qnJ","executionInfo":{"status":"ok","timestamp":1606103499107,"user_tz":-540,"elapsed":1344,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / DenseNet121"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c","executionInfo":{"status":"ok","timestamp":1606103500351,"user_tz":-540,"elapsed":2578,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak","executionInfo":{"status":"ok","timestamp":1606103500357,"user_tz":-540,"elapsed":2579,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"2cgpzDgH1qnL","executionInfo":{"status":"ok","timestamp":1606103514211,"user_tz":-540,"elapsed":16431,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["model=load_model(os.path.join(dir,'model_output',number,'DenseNet121','069.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0IvhWkE1qnN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606108415506,"user_tz":-540,"elapsed":4917716,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"0bd1e3fd-9f9c-4130-bdf3-b383b6d4a074"},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["156/156 [==============================] - 4860s 31s/step - loss: 1.0967 - accuracy: 0.7278 - top5_acc: 0.9187 - macro_f1score: 0.3235\n","[Test Loss: 1.0967 /  Test Top-1 Accuracy: 0.7278 / Test Top-5 Accuracy: 0.9187 / Test Macro f1: 0.3235]\n","\n"],"name":"stdout"}]}]}
