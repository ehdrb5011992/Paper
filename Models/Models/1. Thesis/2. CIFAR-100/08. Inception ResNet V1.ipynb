{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"8.Inception ResNet V1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"E-OCKgEwJfTn","executionInfo":{"status":"ok","timestamp":1606103283640,"user_tz":-540,"elapsed":965,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["#모형 출처 : https://github.com/titu1994/keras-squeeze-excite-network 에서 각색함"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [Inception ResNet V1]"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original Inception-ResNet-V1\n","```\n","1) Support Functions\n","2) Almost Original Inception-ResNet-V1\n","3) Inception-ResNet-V1 Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages\n"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103323640,"user_tz":-540,"elapsed":40894,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"0618c758-fc39-43be-af4f-2409da41c99d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103323643,"user_tz":-540,"elapsed":40876,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"273fb616-057f-4e42-cd7f-7d12c7481a92"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1606103326197,"user_tz":-540,"elapsed":43424,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1606103326709,"user_tz":-540,"elapsed":43933,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606103326718,"user_tz":-540,"elapsed":43917,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"b0fc5f86-d17c-4e25-926f-26b3cecff385"},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103326720,"user_tz":-540,"elapsed":43902,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"2c2ee101-d115-4f07-9ac4-10c7af5bc224"},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606103330600,"user_tz":-540,"elapsed":47762,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"ae763752-e8f0-409f-ddcb-affff965fc7a"},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Kf057Rw2yigs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103330602,"user_tz":-540,"elapsed":47745,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"8dfe5b96-83c4-4803-d0dd-54aaf814d7bb"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 146385061570780978\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 1459216088794224600\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 9810316881860760224\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15473775744\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 3934092059747640650\n","physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OPD7FiWCh0Pd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103330603,"user_tz":-540,"elapsed":47722,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"6f4102c9-8717-4f8a-c21a-b313b7fa7ab7"},"source":["!cat /proc/cpuinfo"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.198\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.39\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.198\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.39\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.198\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.39\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.198\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.39\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"BeJ7UtuOEgWY","executionInfo":{"status":"ok","timestamp":1606103330604,"user_tz":-540,"elapsed":47715,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CIFAR100'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 299 # sizes after cropping\n","super_size = 330 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 64\n","weight_decay = 1e-3\n","epochs = 70"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1606103330605,"user_tz":-540,"elapsed":47697,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmbsCoo_qXED","executionInfo":{"status":"ok","timestamp":1606103330606,"user_tz":-540,"elapsed":47682,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1606103330606,"user_tz":-540,"elapsed":47673,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0VGsPxccqXEI"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"zUAUYE9eqXEJ","executionInfo":{"status":"ok","timestamp":1606103330622,"user_tz":-540,"elapsed":47675,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1606103330623,"user_tz":-540,"elapsed":47668,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"4vIFMllQqXEN","executionInfo":{"status":"ok","timestamp":1606103330624,"user_tz":-540,"elapsed":47664,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"o1nWsjrYqXEQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103384879,"user_tz":-540,"elapsed":101906,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"6f3c49fc-a072-4f65-e156-dbf9005b59c8"},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Found 44923 images belonging to 100 classes.\n","Found 5077 images belonging to 100 classes.\n","Found 10000 images belonging to 100 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original Inception-ResNet-V1"]},{"cell_type":"markdown","metadata":{"id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIV9crIRUmBc"},"source":["def conv2d_bn(x, filters, kernel_size, strides=1, padding='same', activation='relu', use_bias=False, name=None, weight_decay=weight_decay):\n","\n","    x = Conv2D(filters, kernel_size, strides=strides, padding=padding,  use_bias=use_bias, name=name, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    if not use_bias:\n","        bn_axis =  3\n","        bn_name = None if name is None else '{name}_bn'.format(name=name)\n","        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n","        \n","    if activation is not None:\n","        ac_name = None if name is None else '{name}_ac'.format(name=name)\n","        x = Activation(activation, name=ac_name)(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyMaexRzUl_x"},"source":["def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n"," \n","    if block_type == 'block35':\n","        branch_0 = conv2d_bn(x, 32, 1)\n","        branch_1 = conv2d_bn(x, 32, 1)\n","        branch_1 = conv2d_bn(branch_1, 32, 3)\n","        branch_2 = conv2d_bn(x, 32, 1)\n","        branch_2 = conv2d_bn(branch_2, 32, 3)\n","        branch_2 = conv2d_bn(branch_2, 32, 3)\n","        branches = [branch_0, branch_1, branch_2]\n","    elif block_type == 'block17':\n","        branch_0 = conv2d_bn(x, 128, 1)\n","        branch_1 = conv2d_bn(x, 128, 1)\n","        branch_1 = conv2d_bn(branch_1, 128, [1, 7])\n","        branch_1 = conv2d_bn(branch_1, 128, [7, 1])\n","        branches = [branch_0, branch_1]\n","    elif block_type == 'block8':\n","        branch_0 = conv2d_bn(x, 192, 1)\n","        branch_1 = conv2d_bn(x, 192, 1)\n","        branch_1 = conv2d_bn(branch_1, 192, [1, 3])\n","        branch_1 = conv2d_bn(branch_1, 192, [3, 1])\n","        branches = [branch_0, branch_1]\n","    else:\n","        raise ValueError('Unknown Inception-ResNet block type. '\n","                         'Expects \"block35\", \"block17\" or \"block8\", '\n","                         'but got: {block_type}'.format(block_type=block_type))\n","\n","    block_name = '{block_type}_{block_idx}'.format(block_type=block_type, block_idx=block_idx)\n","    channel_axis = 3\n","    mixed = Concatenate(axis=channel_axis, name='{block_name}_mixed'.format(block_name=block_name))(branches)\n","    up = conv2d_bn(mixed,\n","                   K.int_shape(x)[channel_axis],\n","                   1,\n","                   activation=None,\n","                   use_bias=True,\n","                   name='{block_name}_conv'.format(block_name=block_name))\n","\n","    x = Lambda(lambda inputs, scale_: inputs[0] + inputs[1] * scale_,\n","               output_shape=K.int_shape(x)[1:],\n","               arguments={'scale_': scale},\n","               name=block_name)([x, up])\n","    if activation is not None:\n","        x = Activation(activation, name='{block_name}_ac'.format(block_name=block_name))(x)\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-R2NfkqUl60"},"source":["def Inception_ResNet_v1(input_shape=None, weight_decay=weight_decay, classes=classes, name=None):\n"," \n","    img_input = Input(shape=input_shape)\n","\n","    # Stem block: 35 x 35 x 192\n","    x = conv2d_bn(img_input, 32, 3, strides=2, padding='valid')\n","    x = conv2d_bn(x, 32, 3, padding='valid')\n","    x = conv2d_bn(x, 64, 3)\n","    x = MaxPooling2D(3, strides=2)(x)\n","    x = conv2d_bn(x, 80, 1)\n","    x = conv2d_bn(x, 192, 3, padding='valid')\n","    x = conv2d_bn(x, 256, 3, strides=2, padding='valid')\n","\n","    channel_axis = 3\n","\n","    # 5x block35 (Inception-ResNet-A block): 35 x 35 x 320\n","    for block_idx in range(1, 6):\n","        x = inception_resnet_block(x,\n","                                   scale=0.17,\n","                                   block_type='block35',\n","                                   block_idx=block_idx)\n","\n","    # Mixed 6a (Reduction-A block): 17 x 17 \n","    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid')\n","    branch_1 = conv2d_bn(x, 192, 1)\n","    branch_1 = conv2d_bn(branch_1, 192, 3)\n","    branch_1 = conv2d_bn(branch_1, 256, 3, strides=2, padding='valid')\n","    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n","    branches = [branch_0, branch_1, branch_pool]\n","    x = Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n","\n","\n","    # 10x block17 (Inception-ResNet-B block): 17 x 17 x 960\n","    for block_idx in range(1, 11):\n","        x = inception_resnet_block(x,\n","                                   scale=0.1,\n","                                   block_type='block17',\n","                                   block_idx=block_idx)\n","\n","    # Mixed 7a (Reduction-B block): 8 x 8 \n","    branch_0 = conv2d_bn(x, 256, 1)\n","    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid')\n","    branch_1 = conv2d_bn(x, 256, 1)\n","    branch_1 = conv2d_bn(branch_1, 256, 3, strides=2, padding='valid')\n","    branch_2 = conv2d_bn(x, 256, 1)\n","    branch_2 = conv2d_bn(branch_2, 256, 3)\n","    branch_2 = conv2d_bn(branch_2, 256, 3, strides=2, padding='valid')\n","    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n","    branches = [branch_0, branch_1, branch_2, branch_pool]\n","    x = Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n","\n","\n","    # 5x block8 (Inception-ResNet-C block): 8 x 8 x 1856\n","    for block_idx in range(1, 5):\n","        x = inception_resnet_block(x,\n","                                   scale=0.2,\n","                                   block_type='block8',\n","                                   block_idx=block_idx)\n","    x = inception_resnet_block(x,\n","                               scale=1.,\n","                               activation=None,\n","                               block_type='block8',\n","                               block_idx=10)\n","\n","\n","    x = GlobalAveragePooling2D(name='avg_pool')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(classes, use_bias=False, kernel_regularizer=l2(weight_decay), activation='softmax', name='predictions')(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`\n","    inputs = img_input\n","\n","    # Create model\n","    model = Model(inputs, x, name=name)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wtR2M5ELuTew"},"source":["### 2) Almost Original Inception-ResNet-V1\n"]},{"cell_type":"code","metadata":{"id":"IMgWGFKFuTe3"},"source":["model = Inception_ResNet_v1(input_sizes, classes=classes, name='Inception_ResNet_v1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Plblq9iL6HdJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605698442557,"user_tz":-540,"elapsed":62164,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"8f10b6b2-c893-4a4e-d40e-383452b10e1e"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"Inception_ResNet_v1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 35, 35, 256)  442368      activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 35, 35, 256)  768         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 35, 35, 256)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 35, 35, 32)   8192        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 35, 35, 32)   96          conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 35, 35, 32)   0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 35, 35, 32)   8192        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 35, 35, 32)   9216        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 35, 35, 32)   96          conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 35, 35, 32)   96          conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 35, 35, 32)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 35, 35, 32)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 35, 35, 32)   8192        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 35, 35, 32)   9216        activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 35, 35, 32)   9216        activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 35, 35, 32)   96          conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 35, 35, 32)   96          conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 35, 35, 32)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 35, 35, 32)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","block35_1_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_6[0][0]               \n","                                                                 activation_8[0][0]               \n","                                                                 activation_11[0][0]              \n","__________________________________________________________________________________________________\n","block35_1_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_1_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_1 (Lambda)              (None, 35, 35, 256)  0           activation_5[0][0]               \n","                                                                 block35_1_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_1_ac (Activation)       (None, 35, 35, 256)  0           block35_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 35, 35, 32)   8192        block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 35, 35, 32)   8192        block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 35, 35, 32)   9216        activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 35, 35, 32)   96          conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 35, 35, 32)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 35, 35, 32)   8192        block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 35, 35, 32)   9216        activation_13[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 35, 35, 32)   9216        activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 35, 35, 32)   96          conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 35, 35, 32)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","block35_2_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_12[0][0]              \n","                                                                 activation_14[0][0]              \n","                                                                 activation_17[0][0]              \n","__________________________________________________________________________________________________\n","block35_2_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_2_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_2 (Lambda)              (None, 35, 35, 256)  0           block35_1_ac[0][0]               \n","                                                                 block35_2_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_2_ac (Activation)       (None, 35, 35, 256)  0           block35_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 35, 35, 32)   8192        block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 35, 35, 32)   8192        block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 35, 35, 32)   9216        activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 35, 35, 32)   96          conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 35, 35, 32)   0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 35, 35, 32)   8192        block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 35, 35, 32)   9216        activation_19[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 35, 35, 32)   9216        activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 35, 35, 32)   96          conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 35, 35, 32)   96          conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 35, 35, 32)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 35, 35, 32)   0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","block35_3_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_18[0][0]              \n","                                                                 activation_20[0][0]              \n","                                                                 activation_23[0][0]              \n","__________________________________________________________________________________________________\n","block35_3_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_3_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_3 (Lambda)              (None, 35, 35, 256)  0           block35_2_ac[0][0]               \n","                                                                 block35_3_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_3_ac (Activation)       (None, 35, 35, 256)  0           block35_3[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 35, 35, 32)   8192        block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 35, 35, 32)   8192        block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 35, 35, 32)   9216        activation_27[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 35, 35, 32)   96          conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 35, 35, 32)   0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 35, 35, 32)   8192        block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 35, 35, 32)   9216        activation_25[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 35, 35, 32)   9216        activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 35, 35, 32)   96          conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 35, 35, 32)   96          conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 35, 35, 32)   0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 35, 35, 32)   0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","block35_4_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_24[0][0]              \n","                                                                 activation_26[0][0]              \n","                                                                 activation_29[0][0]              \n","__________________________________________________________________________________________________\n","block35_4_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_4_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_4 (Lambda)              (None, 35, 35, 256)  0           block35_3_ac[0][0]               \n","                                                                 block35_4_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_4_ac (Activation)       (None, 35, 35, 256)  0           block35_4[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 35, 35, 32)   8192        block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 35, 35, 32)   8192        block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 35, 35, 32)   9216        activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 35, 35, 32)   96          conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 35, 35, 32)   0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 35, 35, 32)   8192        block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 35, 35, 32)   9216        activation_31[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 35, 35, 32)   9216        activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 35, 35, 32)   96          conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 35, 35, 32)   96          conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 35, 35, 32)   0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 35, 35, 32)   0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","block35_5_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_30[0][0]              \n","                                                                 activation_32[0][0]              \n","                                                                 activation_35[0][0]              \n","__________________________________________________________________________________________________\n","block35_5_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_5_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_5 (Lambda)              (None, 35, 35, 256)  0           block35_4_ac[0][0]               \n","                                                                 block35_5_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_5_ac (Activation)       (None, 35, 35, 256)  0           block35_5[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 35, 35, 192)  49152       block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 35, 35, 192)  576         conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 35, 35, 192)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 35, 35, 192)  331776      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 35, 35, 192)  576         conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 35, 35, 192)  0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 17, 17, 384)  884736      block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 17, 17, 256)  442368      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 17, 17, 384)  1152        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 17, 17, 256)  768         conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 17, 17, 384)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 17, 17, 256)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 17, 17, 256)  0           block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","mixed_6a (Concatenate)          (None, 17, 17, 896)  0           activation_36[0][0]              \n","                                                                 activation_39[0][0]              \n","                                                                 max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 17, 17, 128)  114688      mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 17, 17, 128)  384         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 17, 17, 128)  0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 17, 17, 128)  114688      activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 17, 17, 128)  384         conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 17, 17, 128)  0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 17, 17, 128)  114688      mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 17, 17, 128)  114688      activation_42[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 17, 17, 128)  384         conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 17, 17, 128)  384         conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 17, 17, 128)  0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 17, 17, 128)  0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","block17_1_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_40[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","block17_1_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_1_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_1 (Lambda)              (None, 17, 17, 896)  0           mixed_6a[0][0]                   \n","                                                                 block17_1_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_1_ac (Activation)       (None, 17, 17, 896)  0           block17_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 17, 17, 128)  114688      block17_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 17, 17, 128)  384         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 17, 17, 128)  0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 17, 17, 128)  114688      activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 17, 17, 128)  384         conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 17, 17, 128)  0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 17, 17, 128)  114688      block17_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 17, 17, 128)  114688      activation_46[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 17, 17, 128)  384         conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 17, 17, 128)  384         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 17, 17, 128)  0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 17, 17, 128)  0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","block17_2_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_44[0][0]              \n","                                                                 activation_47[0][0]              \n","__________________________________________________________________________________________________\n","block17_2_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_2_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_2 (Lambda)              (None, 17, 17, 896)  0           block17_1_ac[0][0]               \n","                                                                 block17_2_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_2_ac (Activation)       (None, 17, 17, 896)  0           block17_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 17, 17, 128)  114688      block17_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 17, 17, 128)  384         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 17, 17, 128)  0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 17, 17, 128)  114688      activation_49[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 17, 17, 128)  384         conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 17, 17, 128)  0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 17, 17, 128)  114688      block17_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 17, 17, 128)  114688      activation_50[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 17, 17, 128)  384         conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 17, 17, 128)  384         conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 17, 17, 128)  0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 17, 17, 128)  0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","block17_3_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_48[0][0]              \n","                                                                 activation_51[0][0]              \n","__________________________________________________________________________________________________\n","block17_3_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_3_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_3 (Lambda)              (None, 17, 17, 896)  0           block17_2_ac[0][0]               \n","                                                                 block17_3_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_3_ac (Activation)       (None, 17, 17, 896)  0           block17_3[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 17, 17, 128)  114688      block17_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 17, 17, 128)  384         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 17, 17, 128)  0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 17, 17, 128)  114688      activation_53[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 17, 17, 128)  384         conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","activation_54 (Activation)      (None, 17, 17, 128)  0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 17, 17, 128)  114688      block17_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 17, 17, 128)  114688      activation_54[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 17, 17, 128)  384         conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 17, 17, 128)  384         conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 17, 17, 128)  0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","activation_55 (Activation)      (None, 17, 17, 128)  0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","block17_4_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_52[0][0]              \n","                                                                 activation_55[0][0]              \n","__________________________________________________________________________________________________\n","block17_4_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_4_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_4 (Lambda)              (None, 17, 17, 896)  0           block17_3_ac[0][0]               \n","                                                                 block17_4_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_4_ac (Activation)       (None, 17, 17, 896)  0           block17_4[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 17, 17, 128)  114688      block17_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 17, 17, 128)  384         conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","activation_57 (Activation)      (None, 17, 17, 128)  0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 17, 17, 128)  114688      activation_57[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 17, 17, 128)  384         conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","activation_58 (Activation)      (None, 17, 17, 128)  0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 17, 17, 128)  114688      block17_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, 17, 17, 128)  114688      activation_58[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 17, 17, 128)  384         conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 17, 17, 128)  384         conv2d_59[0][0]                  \n","__________________________________________________________________________________________________\n","activation_56 (Activation)      (None, 17, 17, 128)  0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","activation_59 (Activation)      (None, 17, 17, 128)  0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","block17_5_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_56[0][0]              \n","                                                                 activation_59[0][0]              \n","__________________________________________________________________________________________________\n","block17_5_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_5_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_5 (Lambda)              (None, 17, 17, 896)  0           block17_4_ac[0][0]               \n","                                                                 block17_5_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_5_ac (Activation)       (None, 17, 17, 896)  0           block17_5[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 17, 17, 128)  114688      block17_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 17, 17, 128)  384         conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 17, 17, 128)  0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, 17, 17, 128)  114688      activation_61[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 17, 17, 128)  384         conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 17, 17, 128)  0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 17, 17, 128)  114688      block17_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, 17, 17, 128)  114688      activation_62[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 17, 17, 128)  384         conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 17, 17, 128)  384         conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 17, 17, 128)  0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 17, 17, 128)  0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","block17_6_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_60[0][0]              \n","                                                                 activation_63[0][0]              \n","__________________________________________________________________________________________________\n","block17_6_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_6_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_6 (Lambda)              (None, 17, 17, 896)  0           block17_5_ac[0][0]               \n","                                                                 block17_6_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_6_ac (Activation)       (None, 17, 17, 896)  0           block17_6[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_65 (Conv2D)              (None, 17, 17, 128)  114688      block17_6_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 17, 17, 128)  384         conv2d_65[0][0]                  \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 17, 17, 128)  0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_66 (Conv2D)              (None, 17, 17, 128)  114688      activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 17, 17, 128)  384         conv2d_66[0][0]                  \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 17, 17, 128)  0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_64 (Conv2D)              (None, 17, 17, 128)  114688      block17_6_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_67 (Conv2D)              (None, 17, 17, 128)  114688      activation_66[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 17, 17, 128)  384         conv2d_64[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 17, 17, 128)  384         conv2d_67[0][0]                  \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 17, 17, 128)  0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 17, 17, 128)  0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","block17_7_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_64[0][0]              \n","                                                                 activation_67[0][0]              \n","__________________________________________________________________________________________________\n","block17_7_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_7_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_7 (Lambda)              (None, 17, 17, 896)  0           block17_6_ac[0][0]               \n","                                                                 block17_7_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_7_ac (Activation)       (None, 17, 17, 896)  0           block17_7[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_69 (Conv2D)              (None, 17, 17, 128)  114688      block17_7_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 17, 17, 128)  384         conv2d_69[0][0]                  \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 17, 17, 128)  0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_70 (Conv2D)              (None, 17, 17, 128)  114688      activation_69[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 17, 17, 128)  384         conv2d_70[0][0]                  \n","__________________________________________________________________________________________________\n","activation_70 (Activation)      (None, 17, 17, 128)  0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_68 (Conv2D)              (None, 17, 17, 128)  114688      block17_7_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_71 (Conv2D)              (None, 17, 17, 128)  114688      activation_70[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 17, 17, 128)  384         conv2d_68[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 17, 17, 128)  384         conv2d_71[0][0]                  \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 17, 17, 128)  0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","activation_71 (Activation)      (None, 17, 17, 128)  0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","block17_8_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_68[0][0]              \n","                                                                 activation_71[0][0]              \n","__________________________________________________________________________________________________\n","block17_8_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_8_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_8 (Lambda)              (None, 17, 17, 896)  0           block17_7_ac[0][0]               \n","                                                                 block17_8_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_8_ac (Activation)       (None, 17, 17, 896)  0           block17_8[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_73 (Conv2D)              (None, 17, 17, 128)  114688      block17_8_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 17, 17, 128)  384         conv2d_73[0][0]                  \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 17, 17, 128)  0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_74 (Conv2D)              (None, 17, 17, 128)  114688      activation_73[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 17, 17, 128)  384         conv2d_74[0][0]                  \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 17, 17, 128)  0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_72 (Conv2D)              (None, 17, 17, 128)  114688      block17_8_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_75 (Conv2D)              (None, 17, 17, 128)  114688      activation_74[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 17, 17, 128)  384         conv2d_72[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 17, 17, 128)  384         conv2d_75[0][0]                  \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 17, 17, 128)  0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 17, 17, 128)  0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","block17_9_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_72[0][0]              \n","                                                                 activation_75[0][0]              \n","__________________________________________________________________________________________________\n","block17_9_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_9_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_9 (Lambda)              (None, 17, 17, 896)  0           block17_8_ac[0][0]               \n","                                                                 block17_9_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_9_ac (Activation)       (None, 17, 17, 896)  0           block17_9[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_77 (Conv2D)              (None, 17, 17, 128)  114688      block17_9_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 17, 17, 128)  0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_78 (Conv2D)              (None, 17, 17, 128)  114688      activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 17, 17, 128)  384         conv2d_78[0][0]                  \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 17, 17, 128)  0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_76 (Conv2D)              (None, 17, 17, 128)  114688      block17_9_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_79 (Conv2D)              (None, 17, 17, 128)  114688      activation_78[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 17, 17, 128)  384         conv2d_76[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 17, 17, 128)  384         conv2d_79[0][0]                  \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 17, 17, 128)  0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 17, 17, 128)  0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","block17_10_mixed (Concatenate)  (None, 17, 17, 256)  0           activation_76[0][0]              \n","                                                                 activation_79[0][0]              \n","__________________________________________________________________________________________________\n","block17_10_conv (Conv2D)        (None, 17, 17, 896)  230272      block17_10_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_10 (Lambda)             (None, 17, 17, 896)  0           block17_9_ac[0][0]               \n","                                                                 block17_10_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_10_ac (Activation)      (None, 17, 17, 896)  0           block17_10[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_84 (Conv2D)              (None, 17, 17, 256)  229376      block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 17, 17, 256)  768         conv2d_84[0][0]                  \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 17, 17, 256)  0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_80 (Conv2D)              (None, 17, 17, 256)  229376      block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_82 (Conv2D)              (None, 17, 17, 256)  229376      block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_85 (Conv2D)              (None, 17, 17, 256)  589824      activation_84[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 17, 17, 256)  768         conv2d_80[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 17, 17, 256)  768         conv2d_82[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 17, 17, 256)  768         conv2d_85[0][0]                  \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 17, 17, 256)  0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 17, 17, 256)  0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 17, 17, 256)  0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_81 (Conv2D)              (None, 8, 8, 384)    884736      activation_80[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_83 (Conv2D)              (None, 8, 8, 256)    589824      activation_82[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_86 (Conv2D)              (None, 8, 8, 256)    589824      activation_85[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 8, 8, 256)    768         conv2d_83[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 8, 8, 256)    768         conv2d_86[0][0]                  \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 8, 8, 256)    0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 8, 8, 256)    0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 896)    0           block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","mixed_7a (Concatenate)          (None, 8, 8, 1792)   0           activation_81[0][0]              \n","                                                                 activation_83[0][0]              \n","                                                                 activation_86[0][0]              \n","                                                                 max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 8, 8, 192)    344064      mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 8, 8, 192)    576         conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 8, 8, 192)    0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 8, 8, 192)    110592      activation_88[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 8, 8, 192)    576         conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 8, 8, 192)    0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_87 (Conv2D)              (None, 8, 8, 192)    344064      mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 8, 8, 192)    110592      activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 8, 8, 192)    576         conv2d_87[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 8, 8, 192)    576         conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 8, 8, 192)    0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 8, 8, 192)    0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","block8_1_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_87[0][0]              \n","                                                                 activation_90[0][0]              \n","__________________________________________________________________________________________________\n","block8_1_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_1_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_1 (Lambda)               (None, 8, 8, 1792)   0           mixed_7a[0][0]                   \n","                                                                 block8_1_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_1_ac (Activation)        (None, 8, 8, 1792)   0           block8_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 8, 8, 192)    344064      block8_1_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 8, 8, 192)    576         conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 8, 8, 192)    0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 8, 8, 192)    110592      activation_92[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 8, 8, 192)    344064      block8_1_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 8, 8, 192)    110592      activation_93[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 8, 8, 192)    576         conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 8, 8, 192)    0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","block8_2_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_91[0][0]              \n","                                                                 activation_94[0][0]              \n","__________________________________________________________________________________________________\n","block8_2_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_2_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_2 (Lambda)               (None, 8, 8, 1792)   0           block8_1_ac[0][0]                \n","                                                                 block8_2_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_2_ac (Activation)        (None, 8, 8, 1792)   0           block8_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 8, 8, 192)    344064      block8_2_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 8, 8, 192)    576         conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 8, 8, 192)    0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 8, 8, 192)    110592      activation_96[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 8, 8, 192)    576         conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 8, 8, 192)    0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 8, 8, 192)    344064      block8_2_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 8, 8, 192)    110592      activation_97[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 8, 8, 192)    576         conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 8, 8, 192)    576         conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 8, 8, 192)    0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 8, 8, 192)    0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","block8_3_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_95[0][0]              \n","                                                                 activation_98[0][0]              \n","__________________________________________________________________________________________________\n","block8_3_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_3_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_3 (Lambda)               (None, 8, 8, 1792)   0           block8_2_ac[0][0]                \n","                                                                 block8_3_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_3_ac (Activation)        (None, 8, 8, 1792)   0           block8_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 8, 8, 192)    344064      block8_3_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 8, 8, 192)    576         conv2d_100[0][0]                 \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 8, 8, 192)    0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 8, 8, 192)    110592      activation_100[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 8, 8, 192)    576         conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 8, 8, 192)    0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 8, 8, 192)    344064      block8_3_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 8, 8, 192)    110592      activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 8, 8, 192)    576         conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 8, 8, 192)    576         conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 8, 8, 192)    0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 8, 8, 192)    0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","block8_4_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_99[0][0]              \n","                                                                 activation_102[0][0]             \n","__________________________________________________________________________________________________\n","block8_4_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_4_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_4 (Lambda)               (None, 8, 8, 1792)   0           block8_3_ac[0][0]                \n","                                                                 block8_4_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_4_ac (Activation)        (None, 8, 8, 1792)   0           block8_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 8, 8, 192)    344064      block8_4_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 8, 8, 192)    576         conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 8, 8, 192)    0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_105 (Conv2D)             (None, 8, 8, 192)    110592      activation_104[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_105 (BatchN (None, 8, 8, 192)    576         conv2d_105[0][0]                 \n","__________________________________________________________________________________________________\n","activation_105 (Activation)     (None, 8, 8, 192)    0           batch_normalization_105[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 8, 8, 192)    344064      block8_4_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_106 (Conv2D)             (None, 8, 8, 192)    110592      activation_105[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 8, 8, 192)    576         conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_106 (BatchN (None, 8, 8, 192)    576         conv2d_106[0][0]                 \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 8, 8, 192)    0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","activation_106 (Activation)     (None, 8, 8, 192)    0           batch_normalization_106[0][0]    \n","__________________________________________________________________________________________________\n","block8_10_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_103[0][0]             \n","                                                                 activation_106[0][0]             \n","__________________________________________________________________________________________________\n","block8_10_conv (Conv2D)         (None, 8, 8, 1792)   689920      block8_10_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block8_10 (Lambda)              (None, 8, 8, 1792)   0           block8_4_ac[0][0]                \n","                                                                 block8_10_conv[0][0]             \n","__________________________________________________________________________________________________\n","avg_pool (GlobalAveragePooling2 (None, 1792)         0           block8_10[0][0]                  \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 1792)         0           avg_pool[0][0]                   \n","__________________________________________________________________________________________________\n","predictions (Dense)             (None, 100)          179200      dropout[0][0]                    \n","==================================================================================================\n","Total params: 21,156,048\n","Trainable params: 21,129,008\n","Non-trainable params: 27,040\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HflF2mp1EsHM"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AsDrV7ONZBDr"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XAwJuKTh6Kvy"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N27iJUAkuTfC"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=False, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=False, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"efoKrIVUuTfF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"57f2ab7b-888b-4be5-b41f-9ac50bcbb89a"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_5/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_9/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_7/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_10/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_6/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_8/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_11/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block35_1_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_15/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_13/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_16/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_12/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_14/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_17/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block35_2_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_21/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_19/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_22/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_18/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_20/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_23/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block35_3_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_27/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_25/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_28/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_24/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_26/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_29/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block35_4_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_33/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_31/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_34/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_30/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_32/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_35/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block35_5_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_37/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_38/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_36/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_39/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_41/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_42/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_40/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_43/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block17_1_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_45/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_46/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_44/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_47/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block17_2_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_49/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_50/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_48/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_51/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block17_3_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_53/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_54/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_52/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_55/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block17_4_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_57/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_58/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_56/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_59/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block17_5_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_61/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_62/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_60/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_63/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block17_6_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_65/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_66/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_64/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_67/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block17_7_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_69/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_70/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_68/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_71/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block17_8_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_73/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_74/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_72/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_75/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block17_9_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_77/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_78/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_76/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_79/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block17_10_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_84/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_80/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_82/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_85/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_81/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_83/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_86/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_88/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_89/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_87/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_90/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block8_1_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_92/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_93/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_91/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_94/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block8_2_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_96/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_97/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_95/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_98/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block8_3_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_100/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_101/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_99/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_102/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block8_4_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_104/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_105/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_103/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for conv2d_106/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for block8_10_conv/kernel:0\n","0.0(L1), 3.7769480523978874e-05(L2) weight decay set for predictions/kernel:0\n","701/701 [==============================] - ETA: 0s - loss: 3.8980 - accuracy: 0.1185 - top5_acc: 0.3357 - macro_f1score: 0.0057 \n","Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/001.h5\n","\n","Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/001.h5\n","701/701 [==============================] - 13298s 19s/step - loss: 3.8980 - accuracy: 0.1185 - top5_acc: 0.3357 - macro_f1score: 0.0057 - val_loss: 3.5780 - val_accuracy: 0.1483 - val_top5_acc: 0.4102 - val_macro_f1score: 0.0149\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","701/701 [==============================] - ETA: 0s - loss: 3.1186 - accuracy: 0.2305 - top5_acc: 0.5251 - macro_f1score: 0.0266\n","Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/002.h5\n","\n","Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/002.h5\n","701/701 [==============================] - 1183s 2s/step - loss: 3.1186 - accuracy: 0.2305 - top5_acc: 0.5251 - macro_f1score: 0.0266 - val_loss: 2.7997 - val_accuracy: 0.2961 - val_top5_acc: 0.6042 - val_macro_f1score: 0.0516\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","701/701 [==============================] - ETA: 0s - loss: 2.6304 - accuracy: 0.3244 - top5_acc: 0.6446 - macro_f1score: 0.0621\n","Epoch 00003: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/003.h5\n","\n","Epoch 00003: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/003.h5\n","701/701 [==============================] - 1180s 2s/step - loss: 2.6304 - accuracy: 0.3244 - top5_acc: 0.6446 - macro_f1score: 0.0621 - val_loss: 2.6743 - val_accuracy: 0.3226 - val_top5_acc: 0.6497 - val_macro_f1score: 0.0743\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","701/701 [==============================] - ETA: 0s - loss: 2.2396 - accuracy: 0.4057 - top5_acc: 0.7316 - macro_f1score: 0.1044\n","Epoch 00004: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/004.h5\n","\n","Epoch 00004: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/004.h5\n","701/701 [==============================] - 1180s 2s/step - loss: 2.2396 - accuracy: 0.4057 - top5_acc: 0.7316 - macro_f1score: 0.1044 - val_loss: 2.2509 - val_accuracy: 0.4088 - val_top5_acc: 0.7371 - val_macro_f1score: 0.1095\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","701/701 [==============================] - ETA: 0s - loss: 1.9598 - accuracy: 0.4697 - top5_acc: 0.7845 - macro_f1score: 0.1417\n","Epoch 00005: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/005.h5\n","\n","Epoch 00005: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/005.h5\n","701/701 [==============================] - 1176s 2s/step - loss: 1.9598 - accuracy: 0.4697 - top5_acc: 0.7845 - macro_f1score: 0.1417 - val_loss: 1.9097 - val_accuracy: 0.4769 - val_top5_acc: 0.7973 - val_macro_f1score: 0.1541\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","701/701 [==============================] - ETA: 0s - loss: 1.7435 - accuracy: 0.5198 - top5_acc: 0.8236 - macro_f1score: 0.1726\n","Epoch 00006: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/006.h5\n","\n","Epoch 00006: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/006.h5\n","701/701 [==============================] - 1176s 2s/step - loss: 1.7435 - accuracy: 0.5198 - top5_acc: 0.8236 - macro_f1score: 0.1726 - val_loss: 1.8137 - val_accuracy: 0.5024 - val_top5_acc: 0.8167 - val_macro_f1score: 0.1709\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","701/701 [==============================] - ETA: 0s - loss: 1.6839 - accuracy: 0.5363 - top5_acc: 0.8323 - macro_f1score: 0.1833\n","Epoch 00007: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/007.h5\n","\n","Epoch 00007: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/007.h5\n","701/701 [==============================] - 1169s 2s/step - loss: 1.6839 - accuracy: 0.5363 - top5_acc: 0.8323 - macro_f1score: 0.1833 - val_loss: 1.6477 - val_accuracy: 0.5467 - val_top5_acc: 0.8347 - val_macro_f1score: 0.1873\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","701/701 [==============================] - ETA: 0s - loss: 1.4727 - accuracy: 0.5857 - top5_acc: 0.8676 - macro_f1score: 0.2152\n","Epoch 00008: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/008.h5\n","\n","Epoch 00008: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/008.h5\n","701/701 [==============================] - 1157s 2s/step - loss: 1.4727 - accuracy: 0.5857 - top5_acc: 0.8676 - macro_f1score: 0.2152 - val_loss: 1.6146 - val_accuracy: 0.5578 - val_top5_acc: 0.8451 - val_macro_f1score: 0.2078\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","701/701 [==============================] - ETA: 0s - loss: 1.3544 - accuracy: 0.6149 - top5_acc: 0.8872 - macro_f1score: 0.2339\n","Epoch 00009: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/009.h5\n","\n","Epoch 00009: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/009.h5\n","701/701 [==============================] - 1157s 2s/step - loss: 1.3544 - accuracy: 0.6149 - top5_acc: 0.8872 - macro_f1score: 0.2339 - val_loss: 1.5917 - val_accuracy: 0.5645 - val_top5_acc: 0.8473 - val_macro_f1score: 0.2095\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","701/701 [==============================] - ETA: 0s - loss: 1.2741 - accuracy: 0.6364 - top5_acc: 0.8971 - macro_f1score: 0.2475\n","Epoch 00010: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/010.h5\n","\n","Epoch 00010: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/010.h5\n","701/701 [==============================] - 1156s 2s/step - loss: 1.2741 - accuracy: 0.6364 - top5_acc: 0.8971 - macro_f1score: 0.2475 - val_loss: 1.5095 - val_accuracy: 0.5740 - val_top5_acc: 0.8663 - val_macro_f1score: 0.2165\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","701/701 [==============================] - ETA: 0s - loss: 1.1962 - accuracy: 0.6563 - top5_acc: 0.9076 - macro_f1score: 0.2595\n","Epoch 00011: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/011.h5\n","\n","Epoch 00011: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/011.h5\n","701/701 [==============================] - 1156s 2s/step - loss: 1.1962 - accuracy: 0.6563 - top5_acc: 0.9076 - macro_f1score: 0.2595 - val_loss: 1.4954 - val_accuracy: 0.5912 - val_top5_acc: 0.8617 - val_macro_f1score: 0.2299\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","701/701 [==============================] - ETA: 0s - loss: 1.1874 - accuracy: 0.6567 - top5_acc: 0.9098 - macro_f1score: 0.2621\n","Epoch 00012: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/012.h5\n","\n","Epoch 00012: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/012.h5\n","701/701 [==============================] - 1159s 2s/step - loss: 1.1874 - accuracy: 0.6567 - top5_acc: 0.9098 - macro_f1score: 0.2621 - val_loss: 1.4730 - val_accuracy: 0.5953 - val_top5_acc: 0.8649 - val_macro_f1score: 0.2389\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","701/701 [==============================] - ETA: 0s - loss: 1.0387 - accuracy: 0.6957 - top5_acc: 0.9282 - macro_f1score: 0.2855\n","Epoch 00013: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/013.h5\n","\n","Epoch 00013: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/013.h5\n","701/701 [==============================] - 1160s 2s/step - loss: 1.0387 - accuracy: 0.6957 - top5_acc: 0.9282 - macro_f1score: 0.2855 - val_loss: 1.3796 - val_accuracy: 0.6230 - val_top5_acc: 0.8867 - val_macro_f1score: 0.2589\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","701/701 [==============================] - ETA: 0s - loss: 0.9643 - accuracy: 0.7119 - top5_acc: 0.9382 - macro_f1score: 0.2985\n","Epoch 00014: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/014.h5\n","\n","Epoch 00014: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/014.h5\n","701/701 [==============================] - 1174s 2s/step - loss: 0.9643 - accuracy: 0.7119 - top5_acc: 0.9382 - macro_f1score: 0.2985 - val_loss: 1.5337 - val_accuracy: 0.6117 - val_top5_acc: 0.8815 - val_macro_f1score: 0.2520\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","701/701 [==============================] - ETA: 0s - loss: 0.9629 - accuracy: 0.7168 - top5_acc: 0.9385 - macro_f1score: 0.2988\n","Epoch 00015: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/015.h5\n","\n","Epoch 00015: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/015.h5\n","701/701 [==============================] - 1173s 2s/step - loss: 0.9629 - accuracy: 0.7168 - top5_acc: 0.9385 - macro_f1score: 0.2988 - val_loss: 1.3951 - val_accuracy: 0.6288 - val_top5_acc: 0.8888 - val_macro_f1score: 0.2646\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","701/701 [==============================] - ETA: 0s - loss: 0.8593 - accuracy: 0.7412 - top5_acc: 0.9497 - macro_f1score: 0.3155\n","Epoch 00016: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/016.h5\n","\n","Epoch 00016: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/016.h5\n","701/701 [==============================] - 1178s 2s/step - loss: 0.8593 - accuracy: 0.7412 - top5_acc: 0.9497 - macro_f1score: 0.3155 - val_loss: 1.3986 - val_accuracy: 0.6258 - val_top5_acc: 0.8908 - val_macro_f1score: 0.2629\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","701/701 [==============================] - ETA: 0s - loss: 0.9046 - accuracy: 0.7320 - top5_acc: 0.9436 - macro_f1score: 0.3090\n","Epoch 00017: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/017.h5\n","\n","Epoch 00017: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/017.h5\n","701/701 [==============================] - 1177s 2s/step - loss: 0.9046 - accuracy: 0.7320 - top5_acc: 0.9436 - macro_f1score: 0.3090 - val_loss: 1.2266 - val_accuracy: 0.6632 - val_top5_acc: 0.9098 - val_macro_f1score: 0.2823\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","701/701 [==============================] - ETA: 0s - loss: 0.7534 - accuracy: 0.7718 - top5_acc: 0.9608 - macro_f1score: 0.3342\n","Epoch 00018: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/018.h5\n","\n","Epoch 00018: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/018.h5\n","701/701 [==============================] - 1175s 2s/step - loss: 0.7534 - accuracy: 0.7718 - top5_acc: 0.9608 - macro_f1score: 0.3342 - val_loss: 1.2940 - val_accuracy: 0.6586 - val_top5_acc: 0.9017 - val_macro_f1score: 0.2843\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","701/701 [==============================] - ETA: 0s - loss: 0.6981 - accuracy: 0.7844 - top5_acc: 0.9664 - macro_f1score: 0.3438\n","Epoch 00019: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/019.h5\n","\n","Epoch 00019: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/019.h5\n","701/701 [==============================] - 1174s 2s/step - loss: 0.6981 - accuracy: 0.7844 - top5_acc: 0.9664 - macro_f1score: 0.3438 - val_loss: 1.3135 - val_accuracy: 0.6561 - val_top5_acc: 0.9009 - val_macro_f1score: 0.2806\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","701/701 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.7907 - top5_acc: 0.9682 - macro_f1score: 0.3478\n","Epoch 00020: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/020.h5\n","\n","Epoch 00020: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/020.h5\n","701/701 [==============================] - 1176s 2s/step - loss: 0.6776 - accuracy: 0.7907 - top5_acc: 0.9682 - macro_f1score: 0.3478 - val_loss: 1.2404 - val_accuracy: 0.6632 - val_top5_acc: 0.9064 - val_macro_f1score: 0.2847\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","701/701 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.8068 - top5_acc: 0.9740 - macro_f1score: 0.3585\n","Epoch 00021: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/021.h5\n","\n","Epoch 00021: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/021.h5\n","701/701 [==============================] - 1176s 2s/step - loss: 0.6215 - accuracy: 0.8068 - top5_acc: 0.9740 - macro_f1score: 0.3585 - val_loss: 1.4293 - val_accuracy: 0.6363 - val_top5_acc: 0.8954 - val_macro_f1score: 0.2746\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","701/701 [==============================] - ETA: 0s - loss: 0.5915 - accuracy: 0.8150 - top5_acc: 0.9770 - macro_f1score: 0.3610\n","Epoch 00022: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/022.h5\n","\n","Epoch 00022: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/022.h5\n","701/701 [==============================] - 1171s 2s/step - loss: 0.5915 - accuracy: 0.8150 - top5_acc: 0.9770 - macro_f1score: 0.3610 - val_loss: 1.2982 - val_accuracy: 0.6535 - val_top5_acc: 0.9025 - val_macro_f1score: 0.2842\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","701/701 [==============================] - ETA: 0s - loss: 0.5580 - accuracy: 0.8224 - top5_acc: 0.9791 - macro_f1score: 0.3681\n","Epoch 00023: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/023.h5\n","\n","Epoch 00023: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/023.h5\n","701/701 [==============================] - 1172s 2s/step - loss: 0.5580 - accuracy: 0.8224 - top5_acc: 0.9791 - macro_f1score: 0.3681 - val_loss: 1.4632 - val_accuracy: 0.6367 - val_top5_acc: 0.8972 - val_macro_f1score: 0.2767\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","701/701 [==============================] - ETA: 0s - loss: 0.5353 - accuracy: 0.8300 - top5_acc: 0.9803 - macro_f1score: 0.3725\n","Epoch 00024: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/024.h5\n","\n","Epoch 00024: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/024.h5\n","701/701 [==============================] - 1172s 2s/step - loss: 0.5353 - accuracy: 0.8300 - top5_acc: 0.9803 - macro_f1score: 0.3725 - val_loss: 1.3459 - val_accuracy: 0.6598 - val_top5_acc: 0.9059 - val_macro_f1score: 0.2874\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","701/701 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.8447 - top5_acc: 0.9847 - macro_f1score: 0.3824\n","Epoch 00025: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/025.h5\n","\n","Epoch 00025: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/025.h5\n","701/701 [==============================] - 1172s 2s/step - loss: 0.4911 - accuracy: 0.8447 - top5_acc: 0.9847 - macro_f1score: 0.3824 - val_loss: 1.3948 - val_accuracy: 0.6527 - val_top5_acc: 0.8918 - val_macro_f1score: 0.2882\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","701/701 [==============================] - ETA: 0s - loss: 0.4633 - accuracy: 0.8525 - top5_acc: 0.9858 - macro_f1score: 0.3856\n","Epoch 00026: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/026.h5\n","\n","Epoch 00026: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/026.h5\n","701/701 [==============================] - 1176s 2s/step - loss: 0.4633 - accuracy: 0.8525 - top5_acc: 0.9858 - macro_f1score: 0.3856 - val_loss: 1.6094 - val_accuracy: 0.6325 - val_top5_acc: 0.8805 - val_macro_f1score: 0.2767\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","701/701 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.8603 - top5_acc: 0.9866 - macro_f1score: 0.3921\n","Epoch 00027: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/027.h5\n","\n","Epoch 00027: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/027.h5\n","701/701 [==============================] - 1171s 2s/step - loss: 0.4409 - accuracy: 0.8603 - top5_acc: 0.9866 - macro_f1score: 0.3921 - val_loss: 1.4080 - val_accuracy: 0.6547 - val_top5_acc: 0.9045 - val_macro_f1score: 0.2906\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","701/701 [==============================] - ETA: 0s - loss: 0.4198 - accuracy: 0.8649 - top5_acc: 0.9890 - macro_f1score: 0.3957\n","Epoch 00028: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/028.h5\n","\n","Epoch 00028: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/028.h5\n","701/701 [==============================] - 1169s 2s/step - loss: 0.4198 - accuracy: 0.8649 - top5_acc: 0.9890 - macro_f1score: 0.3957 - val_loss: 1.5899 - val_accuracy: 0.6477 - val_top5_acc: 0.8873 - val_macro_f1score: 0.2898\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","701/701 [==============================] - ETA: 0s - loss: 0.3990 - accuracy: 0.8704 - top5_acc: 0.9897 - macro_f1score: 0.3996\n","Epoch 00029: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/029.h5\n","\n","Epoch 00029: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/029.h5\n","701/701 [==============================] - 1168s 2s/step - loss: 0.3990 - accuracy: 0.8704 - top5_acc: 0.9897 - macro_f1score: 0.3996 - val_loss: 1.4599 - val_accuracy: 0.6598 - val_top5_acc: 0.8922 - val_macro_f1score: 0.2909\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","701/701 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.8798 - top5_acc: 0.9910 - macro_f1score: 0.4040\n","Epoch 00030: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/030.h5\n","\n","Epoch 00030: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/030.h5\n","701/701 [==============================] - 1168s 2s/step - loss: 0.3745 - accuracy: 0.8798 - top5_acc: 0.9910 - macro_f1score: 0.4040 - val_loss: 1.5038 - val_accuracy: 0.6527 - val_top5_acc: 0.8906 - val_macro_f1score: 0.2882\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","701/701 [==============================] - ETA: 0s - loss: 0.1595 - accuracy: 0.9512 - top5_acc: 0.9981 - macro_f1score: 0.4457\n","Epoch 00031: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/031.h5\n","\n","Epoch 00031: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/031.h5\n","701/701 [==============================] - 1169s 2s/step - loss: 0.1595 - accuracy: 0.9512 - top5_acc: 0.9981 - macro_f1score: 0.4457 - val_loss: 1.1777 - val_accuracy: 0.7280 - val_top5_acc: 0.9316 - val_macro_f1score: 0.3310\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","701/701 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9690 - top5_acc: 0.9990 - macro_f1score: 0.4553\n","Epoch 00032: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/032.h5\n","\n","Epoch 00032: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/032.h5\n","701/701 [==============================] - 1173s 2s/step - loss: 0.1039 - accuracy: 0.9690 - top5_acc: 0.9990 - macro_f1score: 0.4553 - val_loss: 1.1927 - val_accuracy: 0.7364 - val_top5_acc: 0.9333 - val_macro_f1score: 0.3397\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9743 - top5_acc: 0.9995 - macro_f1score: 0.4608\n","Epoch 00033: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/033.h5\n","\n","Epoch 00033: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/033.h5\n","701/701 [==============================] - 1174s 2s/step - loss: 0.0848 - accuracy: 0.9743 - top5_acc: 0.9995 - macro_f1score: 0.4608 - val_loss: 1.1979 - val_accuracy: 0.7360 - val_top5_acc: 0.9351 - val_macro_f1score: 0.3341\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9768 - top5_acc: 0.9994 - macro_f1score: 0.4620\n","Epoch 00034: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/034.h5\n","\n","Epoch 00034: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/034.h5\n","701/701 [==============================] - 1173s 2s/step - loss: 0.0768 - accuracy: 0.9768 - top5_acc: 0.9994 - macro_f1score: 0.4620 - val_loss: 1.2630 - val_accuracy: 0.7308 - val_top5_acc: 0.9335 - val_macro_f1score: 0.3373\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 0.9788 - top5_acc: 0.9995 - macro_f1score: 0.4619\n","Epoch 00035: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/035.h5\n","\n","Epoch 00035: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/035.h5\n","701/701 [==============================] - 1169s 2s/step - loss: 0.0721 - accuracy: 0.9788 - top5_acc: 0.9995 - macro_f1score: 0.4619 - val_loss: 1.2679 - val_accuracy: 0.7322 - val_top5_acc: 0.9322 - val_macro_f1score: 0.3336\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9792 - top5_acc: 0.9998 - macro_f1score: 0.4633\n","Epoch 00036: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/036.h5\n","\n","Epoch 00036: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/036.h5\n","701/701 [==============================] - 1169s 2s/step - loss: 0.0682 - accuracy: 0.9792 - top5_acc: 0.9998 - macro_f1score: 0.4633 - val_loss: 1.2575 - val_accuracy: 0.7354 - val_top5_acc: 0.9349 - val_macro_f1score: 0.3329\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9834 - top5_acc: 0.9997 - macro_f1score: 0.4674\n","Epoch 00037: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/037.h5\n","\n","Epoch 00037: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/037.h5\n","701/701 [==============================] - 1143s 2s/step - loss: 0.0581 - accuracy: 0.9834 - top5_acc: 0.9997 - macro_f1score: 0.4674 - val_loss: 1.3382 - val_accuracy: 0.7271 - val_top5_acc: 0.9314 - val_macro_f1score: 0.3307\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9831 - top5_acc: 0.9998 - macro_f1score: 0.4649\n","Epoch 00038: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/038.h5\n","\n","Epoch 00038: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/038.h5\n","701/701 [==============================] - 1166s 2s/step - loss: 0.0584 - accuracy: 0.9831 - top5_acc: 0.9998 - macro_f1score: 0.4649 - val_loss: 1.3410 - val_accuracy: 0.7292 - val_top5_acc: 0.9298 - val_macro_f1score: 0.3359\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9845 - top5_acc: 0.9998 - macro_f1score: 0.4664\n","Epoch 00039: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/039.h5\n","\n","Epoch 00039: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/039.h5\n","701/701 [==============================] - 1193s 2s/step - loss: 0.0553 - accuracy: 0.9845 - top5_acc: 0.9998 - macro_f1score: 0.4664 - val_loss: 1.3331 - val_accuracy: 0.7282 - val_top5_acc: 0.9290 - val_macro_f1score: 0.3358\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9841 - top5_acc: 0.9999 - macro_f1score: 0.4661\n","Epoch 00040: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/040.h5\n","\n","Epoch 00040: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/040.h5\n","701/701 [==============================] - 1220s 2s/step - loss: 0.0560 - accuracy: 0.9841 - top5_acc: 0.9999 - macro_f1score: 0.4661 - val_loss: 1.3102 - val_accuracy: 0.7298 - val_top5_acc: 0.9316 - val_macro_f1score: 0.3344\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9861 - top5_acc: 0.9998 - macro_f1score: 0.4658\n","Epoch 00041: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/041.h5\n","\n","Epoch 00041: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/041.h5\n","701/701 [==============================] - 1230s 2s/step - loss: 0.0500 - accuracy: 0.9861 - top5_acc: 0.9998 - macro_f1score: 0.4658 - val_loss: 1.3315 - val_accuracy: 0.7312 - val_top5_acc: 0.9292 - val_macro_f1score: 0.3342\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9868 - top5_acc: 0.9998 - macro_f1score: 0.4671\n","Epoch 00042: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/042.h5\n","\n","Epoch 00042: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/042.h5\n","701/701 [==============================] - 1225s 2s/step - loss: 0.0493 - accuracy: 0.9868 - top5_acc: 0.9998 - macro_f1score: 0.4671 - val_loss: 1.2887 - val_accuracy: 0.7324 - val_top5_acc: 0.9324 - val_macro_f1score: 0.3347\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9868 - top5_acc: 0.9999 - macro_f1score: 0.4666\n","Epoch 00043: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/043.h5\n","\n","Epoch 00043: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/043.h5\n","701/701 [==============================] - 1225s 2s/step - loss: 0.0495 - accuracy: 0.9868 - top5_acc: 0.9999 - macro_f1score: 0.4666 - val_loss: 1.3115 - val_accuracy: 0.7255 - val_top5_acc: 0.9316 - val_macro_f1score: 0.3330\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9883 - top5_acc: 1.0000 - macro_f1score: 0.4685\n","Epoch 00044: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/044.h5\n","\n","Epoch 00044: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/044.h5\n","701/701 [==============================] - 1163s 2s/step - loss: 0.0453 - accuracy: 0.9883 - top5_acc: 1.0000 - macro_f1score: 0.4685 - val_loss: 1.2539 - val_accuracy: 0.7336 - val_top5_acc: 0.9318 - val_macro_f1score: 0.3367\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9886 - top5_acc: 0.9999 - macro_f1score: 0.4683\n","Epoch 00045: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/045.h5\n","\n","Epoch 00045: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/045.h5\n","701/701 [==============================] - 1144s 2s/step - loss: 0.0451 - accuracy: 0.9886 - top5_acc: 0.9999 - macro_f1score: 0.4683 - val_loss: 1.2830 - val_accuracy: 0.7296 - val_top5_acc: 0.9300 - val_macro_f1score: 0.3377\n","Learning rate:  0.0001\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 46/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9887 - top5_acc: 0.9999 - macro_f1score: 0.4695\n","Epoch 00046: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/046.h5\n","\n","Epoch 00046: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/046.h5\n","701/701 [==============================] - 1152s 2s/step - loss: 0.0460 - accuracy: 0.9887 - top5_acc: 0.9999 - macro_f1score: 0.4695 - val_loss: 1.2654 - val_accuracy: 0.7298 - val_top5_acc: 0.9300 - val_macro_f1score: 0.3343\n","Learning rate:  0.0001\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 47/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9889 - top5_acc: 0.9999 - macro_f1score: 0.4680\n","Epoch 00047: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/047.h5\n","\n","Epoch 00047: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/047.h5\n","701/701 [==============================] - 1166s 2s/step - loss: 0.0455 - accuracy: 0.9889 - top5_acc: 0.9999 - macro_f1score: 0.4680 - val_loss: 1.2867 - val_accuracy: 0.7267 - val_top5_acc: 0.9274 - val_macro_f1score: 0.3307\n","Learning rate:  0.0001\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 48/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9893 - top5_acc: 0.9999 - macro_f1score: 0.4682\n","Epoch 00048: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/048.h5\n","\n","Epoch 00048: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/048.h5\n","701/701 [==============================] - 1168s 2s/step - loss: 0.0450 - accuracy: 0.9893 - top5_acc: 0.9999 - macro_f1score: 0.4682 - val_loss: 1.2488 - val_accuracy: 0.7316 - val_top5_acc: 0.9290 - val_macro_f1score: 0.3326\n","Learning rate:  0.0001\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 49/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9902 - top5_acc: 0.9999 - macro_f1score: 0.4697\n","Epoch 00049: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/049.h5\n","\n","Epoch 00049: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/049.h5\n","701/701 [==============================] - 1171s 2s/step - loss: 0.0438 - accuracy: 0.9902 - top5_acc: 0.9999 - macro_f1score: 0.4697 - val_loss: 1.2472 - val_accuracy: 0.7255 - val_top5_acc: 0.9282 - val_macro_f1score: 0.3318\n","Learning rate:  0.0001\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 50/70\n","701/701 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9894 - top5_acc: 0.9999 - macro_f1score: 0.4697\n","Epoch 00050: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/050.h5\n","\n","Epoch 00050: saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v1/050.h5\n","701/701 [==============================] - 1171s 2s/step - loss: 0.0453 - accuracy: 0.9894 - top5_acc: 0.9999 - macro_f1score: 0.4697 - val_loss: 1.2408 - val_accuracy: 0.7245 - val_top5_acc: 0.9282 - val_macro_f1score: 0.3315\n","Learning rate:  0.0001\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 51/70\n","575/701 [=======================>......] - ETA: 3:26 - loss: 0.0440 - accuracy: 0.9903 - top5_acc: 1.0000 - macro_f1score: 0.4685"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QNsVmE-_7Lyy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMKlqQh24hcq"},"source":["# colab pro가 최대 24시간 돌아가므로, 그 한계로 인해 두번 나눠서 학습을봄."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5JqngK2zwLmH"},"source":["model=load_model(os.path.join(dir,'model_output',number,'Inception_ResNet_v1','050.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgavL2IxsJ9m"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-4\n","    if epoch < 10:\n","        lr = lr\n","    else  :\n","        lr = lr * 0.1\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WmA0zyNQvEGl"},"source":["os.makedirs(os.path.join(dir,'model_output',number,'SUB',model.name), exist_ok=True) # 모델을 위에서 정의해야함"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTbhbLyX8L6F"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,'SUB',model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d_8Yy1A48KLO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605866969968,"user_tz":-540,"elapsed":30366315,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"83503dd3-fc5c-412d-d62e-20e2c4351a0f"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=20 , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.0001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 1/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9894 - top5_acc: 0.9999 - macro_f1score: 0.4685 \n","Epoch 00001: val_loss improved from inf to 1.31802, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v1/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.72330, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v1/001.h5\n","701/701 [==============================] - 11982s 17s/step - loss: 0.0424 - accuracy: 0.9894 - top5_acc: 0.9999 - macro_f1score: 0.4685 - val_loss: 1.3180 - val_accuracy: 0.7233 - val_top5_acc: 0.9205 - val_macro_f1score: 0.3326\n","Learning rate:  0.0001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 2/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9908 - top5_acc: 1.0000 - macro_f1score: 0.4684\n","Epoch 00002: val_loss improved from 1.31802 to 1.31321, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v1/002.h5\n","\n","Epoch 00002: val_accuracy improved from 0.72330 to 0.72983, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v1/002.h5\n","701/701 [==============================] - 1007s 1s/step - loss: 0.0382 - accuracy: 0.9908 - top5_acc: 1.0000 - macro_f1score: 0.4684 - val_loss: 1.3132 - val_accuracy: 0.7298 - val_top5_acc: 0.9244 - val_macro_f1score: 0.3361\n","Learning rate:  0.0001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 3/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9881 - top5_acc: 1.0000 - macro_f1score: 0.4687\n","Epoch 00003: val_loss improved from 1.31321 to 1.30035, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v1/003.h5\n","\n","Epoch 00003: val_accuracy did not improve from 0.72983\n","701/701 [==============================] - 987s 1s/step - loss: 0.0445 - accuracy: 0.9881 - top5_acc: 1.0000 - macro_f1score: 0.4687 - val_loss: 1.3004 - val_accuracy: 0.7292 - val_top5_acc: 0.9294 - val_macro_f1score: 0.3382\n","Learning rate:  0.0001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 4/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9927 - top5_acc: 0.9999 - macro_f1score: 0.4702\n","Epoch 00004: val_loss did not improve from 1.30035\n","\n","Epoch 00004: val_accuracy did not improve from 0.72983\n","701/701 [==============================] - 959s 1s/step - loss: 0.0313 - accuracy: 0.9927 - top5_acc: 0.9999 - macro_f1score: 0.4702 - val_loss: 1.3118 - val_accuracy: 0.7296 - val_top5_acc: 0.9326 - val_macro_f1score: 0.3355\n","Learning rate:  0.0001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 5/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9935 - top5_acc: 1.0000 - macro_f1score: 0.4688\n","Epoch 00005: val_loss did not improve from 1.30035\n","\n","Epoch 00005: val_accuracy did not improve from 0.72983\n","701/701 [==============================] - 962s 1s/step - loss: 0.0279 - accuracy: 0.9935 - top5_acc: 1.0000 - macro_f1score: 0.4688 - val_loss: 1.3586 - val_accuracy: 0.7286 - val_top5_acc: 0.9284 - val_macro_f1score: 0.3348\n","Learning rate:  0.0001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 6/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9941 - top5_acc: 0.9999 - macro_f1score: 0.4717\n","Epoch 00006: val_loss did not improve from 1.30035\n","\n","Epoch 00006: val_accuracy did not improve from 0.72983\n","701/701 [==============================] - 962s 1s/step - loss: 0.0250 - accuracy: 0.9941 - top5_acc: 0.9999 - macro_f1score: 0.4717 - val_loss: 1.4016 - val_accuracy: 0.7245 - val_top5_acc: 0.9221 - val_macro_f1score: 0.3345\n","Learning rate:  0.0001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 7/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9924 - top5_acc: 0.9999 - macro_f1score: 0.4704\n","Epoch 00007: val_loss did not improve from 1.30035\n","\n","Epoch 00007: val_accuracy did not improve from 0.72983\n","701/701 [==============================] - 967s 1s/step - loss: 0.0306 - accuracy: 0.9924 - top5_acc: 0.9999 - macro_f1score: 0.4704 - val_loss: 1.4326 - val_accuracy: 0.7211 - val_top5_acc: 0.9231 - val_macro_f1score: 0.3284\n","Learning rate:  0.0001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 8/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9930 - top5_acc: 1.0000 - macro_f1score: 0.4712\n","Epoch 00008: val_loss did not improve from 1.30035\n","\n","Epoch 00008: val_accuracy improved from 0.72983 to 0.73141, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v1/008.h5\n","701/701 [==============================] - 961s 1s/step - loss: 0.0282 - accuracy: 0.9930 - top5_acc: 1.0000 - macro_f1score: 0.4712 - val_loss: 1.3862 - val_accuracy: 0.7314 - val_top5_acc: 0.9268 - val_macro_f1score: 0.3341\n","Learning rate:  0.0001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 9/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9938 - top5_acc: 1.0000 - macro_f1score: 0.4712\n","Epoch 00009: val_loss did not improve from 1.30035\n","\n","Epoch 00009: val_accuracy did not improve from 0.73141\n","701/701 [==============================] - 957s 1s/step - loss: 0.0257 - accuracy: 0.9938 - top5_acc: 1.0000 - macro_f1score: 0.4712 - val_loss: 1.4125 - val_accuracy: 0.7263 - val_top5_acc: 0.9227 - val_macro_f1score: 0.3322\n","Learning rate:  0.0001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 10/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9932 - top5_acc: 0.9999 - macro_f1score: 0.4712\n","Epoch 00010: val_loss did not improve from 1.30035\n","\n","Epoch 00010: val_accuracy did not improve from 0.73141\n","701/701 [==============================] - 955s 1s/step - loss: 0.0269 - accuracy: 0.9932 - top5_acc: 0.9999 - macro_f1score: 0.4712 - val_loss: 1.4565 - val_accuracy: 0.7265 - val_top5_acc: 0.9211 - val_macro_f1score: 0.3301\n","Learning rate:  1e-05\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 11/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9958 - top5_acc: 1.0000 - macro_f1score: 0.4720\n","Epoch 00011: val_loss did not improve from 1.30035\n","\n","Epoch 00011: val_accuracy improved from 0.73141 to 0.73675, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v1/011.h5\n","701/701 [==============================] - 961s 1s/step - loss: 0.0180 - accuracy: 0.9958 - top5_acc: 1.0000 - macro_f1score: 0.4720 - val_loss: 1.3697 - val_accuracy: 0.7367 - val_top5_acc: 0.9258 - val_macro_f1score: 0.3380\n","Learning rate:  1e-05\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 12/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9967 - top5_acc: 1.0000 - macro_f1score: 0.4724\n","Epoch 00012: val_loss did not improve from 1.30035\n","\n","Epoch 00012: val_accuracy improved from 0.73675 to 0.73794, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v1/012.h5\n","701/701 [==============================] - 959s 1s/step - loss: 0.0148 - accuracy: 0.9967 - top5_acc: 1.0000 - macro_f1score: 0.4724 - val_loss: 1.3728 - val_accuracy: 0.7379 - val_top5_acc: 0.9254 - val_macro_f1score: 0.3407\n","Learning rate:  1e-05\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 13/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9972 - top5_acc: 1.0000 - macro_f1score: 0.4726\n","Epoch 00013: val_loss did not improve from 1.30035\n","\n","Epoch 00013: val_accuracy improved from 0.73794 to 0.73932, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v1/013.h5\n","701/701 [==============================] - 961s 1s/step - loss: 0.0129 - accuracy: 0.9972 - top5_acc: 1.0000 - macro_f1score: 0.4726 - val_loss: 1.3786 - val_accuracy: 0.7393 - val_top5_acc: 0.9250 - val_macro_f1score: 0.3397\n","Learning rate:  1e-05\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 14/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.4744\n","Epoch 00014: val_loss did not improve from 1.30035\n","\n","Epoch 00014: val_accuracy did not improve from 0.73932\n","701/701 [==============================] - 961s 1s/step - loss: 0.0107 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.4744 - val_loss: 1.3703 - val_accuracy: 0.7379 - val_top5_acc: 0.9256 - val_macro_f1score: 0.3406\n","Learning rate:  1e-05\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 15/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9978 - top5_acc: 1.0000 - macro_f1score: 0.4738\n","Epoch 00015: val_loss did not improve from 1.30035\n","\n","Epoch 00015: val_accuracy improved from 0.73932 to 0.74150, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v1/015.h5\n","701/701 [==============================] - 960s 1s/step - loss: 0.0110 - accuracy: 0.9978 - top5_acc: 1.0000 - macro_f1score: 0.4738 - val_loss: 1.3781 - val_accuracy: 0.7415 - val_top5_acc: 0.9270 - val_macro_f1score: 0.3377\n","Learning rate:  1e-05\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 16/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.4728\n","Epoch 00016: val_loss did not improve from 1.30035\n","\n","Epoch 00016: val_accuracy improved from 0.74150 to 0.74288, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v1/016.h5\n","701/701 [==============================] - 960s 1s/step - loss: 0.0101 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.4728 - val_loss: 1.3744 - val_accuracy: 0.7429 - val_top5_acc: 0.9290 - val_macro_f1score: 0.3393\n","Learning rate:  1e-05\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 17/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9983 - top5_acc: 1.0000 - macro_f1score: 0.4724\n","Epoch 00017: val_loss did not improve from 1.30035\n","\n","Epoch 00017: val_accuracy did not improve from 0.74288\n","701/701 [==============================] - 961s 1s/step - loss: 0.0093 - accuracy: 0.9983 - top5_acc: 1.0000 - macro_f1score: 0.4724 - val_loss: 1.3771 - val_accuracy: 0.7399 - val_top5_acc: 0.9302 - val_macro_f1score: 0.3380\n","Learning rate:  1e-05\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 18/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9984 - top5_acc: 1.0000 - macro_f1score: 0.4729\n","Epoch 00018: val_loss did not improve from 1.30035\n","\n","Epoch 00018: val_accuracy did not improve from 0.74288\n","701/701 [==============================] - 957s 1s/step - loss: 0.0086 - accuracy: 0.9984 - top5_acc: 1.0000 - macro_f1score: 0.4729 - val_loss: 1.3926 - val_accuracy: 0.7417 - val_top5_acc: 0.9306 - val_macro_f1score: 0.3409\n","Learning rate:  1e-05\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 19/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9985 - top5_acc: 1.0000 - macro_f1score: 0.4738\n","Epoch 00019: val_loss did not improve from 1.30035\n","\n","Epoch 00019: val_accuracy did not improve from 0.74288\n","701/701 [==============================] - 959s 1s/step - loss: 0.0082 - accuracy: 0.9985 - top5_acc: 1.0000 - macro_f1score: 0.4738 - val_loss: 1.3897 - val_accuracy: 0.7427 - val_top5_acc: 0.9302 - val_macro_f1score: 0.3424\n","Learning rate:  1e-05\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 20/20\n","701/701 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9988 - top5_acc: 1.0000 - macro_f1score: 0.4741\n","Epoch 00020: val_loss did not improve from 1.30035\n","\n","Epoch 00020: val_accuracy did not improve from 0.74288\n","701/701 [==============================] - 955s 1s/step - loss: 0.0074 - accuracy: 0.9988 - top5_acc: 1.0000 - macro_f1score: 0.4741 - val_loss: 1.3905 - val_accuracy: 0.7409 - val_top5_acc: 0.9294 - val_macro_f1score: 0.3406\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cEoIHxnL8KJQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVMmeSLI7MRR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S8EgwffcuTfI"},"source":["### 3) Inception-ResNet-V1 Evaluate\n"]},{"cell_type":"code","metadata":{"id":"D7tz2zjeuTfL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605869799346,"user_tz":-540,"elapsed":33195682,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"7522e4ef-1300-406c-cd17-cb57ab2eb5ba"},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["156/156 [==============================] - 2804s 18s/step - loss: 1.4373 - accuracy: 0.7404 - top5_acc: 0.9273 - macro_f1score: 0.3438\n","[Test Loss: 1.4373 /  Test Top-1 Accuracy: 0.7404 / Test Top-5 Accuracy: 0.9273 / Test Macro f1: 0.3438]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PBq7ajsyuTfN"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFQNe0dfuTfP"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zsHYi8xGuTfT"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'Inception_ResNet_v1.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXjdmTfLuTfW"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEgWb_-DuTfY","colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"status":"ok","timestamp":1605869799986,"user_tz":-540,"elapsed":33196303,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"3503b30f-6567-4293-9bdd-c972f1ee8e7b"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwU1bn/8c/XAUEFRBYNiwgaREFggBHiCmpUXAIBN8ANuQlqXKK56NVolGC4GCX+XKImxhA1ekGiETHqdUEJqNfIIKCigIAjDCgihE1Etuf3x6kZmqZnpmemZ3qm5nm/Xv2a6qpTVU9X1zx96lTVKZkZzjnn4muvbAfgnHOuanmid865mPNE75xzMeeJ3jnnYs4TvXPOxZwneuecizlP9LWIpJclXZrpstkkqUDSD6tgudMl/SQavlDSq+mUrcB62knaJCmnorE6V9U80VexKAkUvXZK+jbh/YXlWZaZnWFmj2e6bE0k6SZJM1KMbyFpq6Sj0l2WmT1lZqdlKK7dfpjMbJmZNTKzHZlYfrSOdkn7jUn6JuH9CRlaT79on0xcV6mVAwVLJX2ciRhc9aiX7QDizswaFQ1LKgB+YmavJ5eTVM/MtldnbDXck8BvJHUws88Sxg8BPjSzj7IUV5Uzs2VA4n5jQHczW1wFq1tpZm3LUf5E4ECgnqSjzWxWFcSUkv+PVJzX6LMkqk0VSvovSV8Cf5F0gKR/SFot6d/RcNuEeRKbI4ZLekvS+KjsZ5LOqGDZDpJmSNoo6XVJD0p6soS404nxDklvR8t7VVKLhOkXS/pc0hpJt5S0fcysEHgDuDhp0iXAE2XFkRTzcElvJbw/VdICSesl/R5QwrTDJL0Rxfe1pKckNY2m/RVoB7wQ1X5vlNQ+qnHXi8q0ljRV0lpJiyX9NGHZoyVNlvREtG3mS8oraRuU8Fn2j+ZfHW3HWyXtlfA535b0++izLZB0SnmWn4ZLgeeBl6LhxNi6SHot+uyrJP0yGp8j6ZeSlkSfe7akg5O3XVQ2eb99W9L/k7QGGF3a9xPNc7Ckv0fbZ020LfaOYuqaUO5ASZsltczw9qmRPNFn1/eAZsAhwEjC9/GX6H074Fvg96XM3wdYCLQA7gL+LEkVKPs/wHtAc2A0eybXROnEOAy4jFDz2xsYBSCpM/BwtPzW0fpKq00+nhiLpE5AbhRvebdV0TJaAH8HbiVsiyXAcYlFgHFRfEcCBxO2CWZ2MbAM+FHUXHNXilVMAgqj+c8F/lvSyQnTB0RlmgJT04k5yQPA/sChQF/CD99lCdP7RJ+pBXA78HdJzUpZ3oFRUv4sSqj7lVRQ0r7RZ3oqeg2RtHc0rTHwOvC/hM/+fWBaNOsvgKHAmUATYASwOc3P2wdYChwEjKWU70fhPMk/gM+B9kAbYJKZbSVs84sSljsUmGZmq9OMo3YzM39V0wsoAH4YDfcDtgINSymfC/w74f10QtMPwHBgccK0fQEDvleesoQkuR3YN2H6k8CTaX6mVDHemvD+Z8D/RsO3Ef7xiqbtF22DH5aw7H2BDcCx0fuxwPMV3FZvRcOXAO8mlBMhMf+khOX+GJiT6juM3rePtmU9QtLZATROmD4OeCwaHg28njCtM/BtGtvYCIkzJ9penROmXQ5MT/icKwElTH8PuLiE5X4vimEvoAMwA/hjKXFcBKyOPmtDYD0wKJo2NHE7Jc23EBiYYnzxtivle1tWxrYp/n6AY4riS1GuD+FHWtH7fOD8ivwf18aX1+iza7WZbSl6I2lfSX+MDsk3EP7xmqrkKzq+LBows6IaUqNylm0NrE0YB7C8pIDTjPHLhOHNCTG1Tly2mX0DrClpXVFMfwMuiY4+LgSeKEccqSTHYInvJR0kaZKkFdFynyTUjtNRtC03Joz7nFCzLJK8bRomNl2UoQVQP1pmSctfEX2mxOmtJZ2gXSdc5wOY2Zdm9rGZ7bRwHuRG4JxS1n8pMNnMtkf77bPsar45mHAkkUpp08qy275YxvdzMPC5pWjHN7N/EbZ3P0lHEH44p1YwplrHE312JXcd+p9AJ6CPmTUhnPiChDbkKvAF0Cw6LC9ycCnlKxPjF4nLjtbZvIx5HgfOB04FGgMvVDKO5BjE7p/3vwnfS9douRclLbO07l5XErZl44Rx7YAVZcSUrq+BbYTmqpKW3yap+a4d4YTrTAvNTY3MrEsJyzdKyAkK5z9OBi6S9KXCeaVzgTOj5rDlhOakVJYDh6UY/030N3Hf+16KmBKV9v0sB9qV8sP5eFT+YuCZxEpW3Hmir1kaE9qa10XtqrdX9QrN7HPCYezo6KTVMcCPqijGZ4CzJR0fte2Ooex9cCawDniEXe2tlYnjRaCLpMFRQriW3ZNLY2ATsF5SG+CGpPlXUUJCM7PlwDvAOEkNJXUD/oNQ66w0C5dwTgbGSmos6RBC+3fi8g8ErpVUX9J5hHbsl1ItT9JJkg5RcDBwJ+FEayoXA4sIP6650etwQrPXUELbeCtJ10lqEMXXJ5r3UeAOSR2jdXWT1NxC+/gKwo9HjqQRpP5BSFTa9/Me4Yf8Tkn7Rd9B4vmXJ4FBhGT/RBnriRVP9DXLvcA+hJrbu4QTW9XhQkL75hrgN8DTwHcllK1wjGY2H7iKcDL1C+DfhERR2jxG+Kc8hN3/OSsUh5l9DZxHSGprgI7A2wlFfg30JLQ/v0g4cZtoHHCrpHWSRqVYxVBC2/NK4DngdktxOW0lXEOoCS8F3iJsywkJ0/9F+ExfE85pnGtmJTWP9SD8MH0T/f2Q8MOXyqXAQ1FzT/EL+ANwadRcdSqhkvAl8ClwUjTvPYQfqFcJ51z+TPjuAH5KSNZrgC5RHKUp8fuJfgh/RGiWWUbYty5ImL4ceJ9wRDCzjPXEStGJCeeKSXoaWGBmVX5E4TJH0nDCiczjsx1LTSVpAqEp69Zsx1Kd/IYph6SjgbXAZ8BpwEBCjde52JDUHhhMOJKpU7zpxkFoo55OaPu8H7jSzOZkNSLnMkjSHcBHwN22+53WdYI33TjnXMx5jd4552KuxrXRt2jRwtq3b5/tMJxzrlaZPXv212aWsu+eGpfo27dvT35+frbDcM65WkXS5yVN86Yb55yLOU/0zjkXc57onXMu5jzRO+dczHmid865mCsz0UuaIOkrSSmf0Rn1Rne/wmPTPpDUM2HapZI+jV6lPnTYOedc1UinRv8Y0L+U6WcQesvrSHgc3sMACV3H9gF6A7dLOqAywTrnnCu/Mq+jN7MZUWdAJRkIPBF1J/uupKaSWhEelfeama0FkPQa4QdjYmWDTmXzZnjooTAspX6VNC15/F57hVficPL7sqaZwc6du16J79OZVtQzRXljTzW+MhLjKeuzlDScKTk5Yfvm5Ow+XNbfouHEz5Pu95D8vrLMyt6m6UzLlHT2pXTLlDStrPGV3RZx6sWlbVsYOTLzy83EDVNt2P1xX4XRuJLG70HSSMLRAO3atatQEJs2wQ3Jj4hwLqYq+wMO8UmQmdgWNUWfPjU30VeamT1CeIIQeXl5Fdr9WrSAjRt3/cInv8J60h9fmVrfzp0VPxJIPiqoSOyJ4zMh3XhLGs5UUtqxI2zb8vxNHE78LBU5WsvUZ6noPlH0PtNK25fS2d8qu4+W9NnT2RZxSvJVKROJfgW7P3OzbTRuBaH5JnH89AysL6W99oJGJT0W2zlXosRmFBdPmbi8cipwSXT1zQ+A9Wb2BfAKcJqkA6KTsKdF45xzzlWjMmv0kiYSauYtJBUSrqSpD2BmfyA8ePhMYDGwGbgsmrY26ux/VrSoMUUnZp1zzlWfdK66GVrGdCM88DnVtAns/uBi55xz1czvjHXOuZjzRO+cczHnid4552LOE71zzsWcJ3rnnIs5T/TOORdznuidcy7mPNE751zMeaJ3zrmY80TvnHMx54neOedizhO9c87FnCd655yLOU/0zjkXc57onXMu5jzRO+dczKWV6CX1l7RQ0mJJN6WYfoikaZI+kDRdUtuEab+V9FH0uiCTwTvnnCtbmYleUg7wIHAG0BkYKqlzUrHxwBNm1g0YA4yL5j0L6AnkAn2AUZKaZC5855xzZUmnRt8bWGxmS81sKzAJGJhUpjPwRjT8ZsL0zsAMM9tuZt8AHwD9Kx+2c865dKWT6NsAyxPeF0bjEs0DBkfDg4DGkppH4/tL2ldSC+Ak4ODkFUgaKSlfUv7q1avL+xmcc86VIlMnY0cBfSXNAfoCK4AdZvYq8BLwDjAR+D9gR/LMZvaImeWZWV7Lli0zFJJzzjlIL9GvYPdaeNtoXDEzW2lmg82sB3BLNG5d9HesmeWa2amAgEUZidw551xa0kn0s4COkjpI2hsYAkxNLCCphaSiZd0MTIjG50RNOEjqBnQDXs1U8M4558pWr6wCZrZd0tXAK0AOMMHM5ksaA+Sb2VSgHzBOkgEzgKui2esDMyUBbAAuMrPtmf8YzjnnSiIzy3YMu8nLy7P8/Pxsh+Gcc7WKpNlmlpdqmt8Z65xzMeeJ3jnnYs4TvXPOxZwneuecizlP9M45F3Oe6J1zLuY80TvnXMx5onfOuZjzRO+cczHnid4552LOE71zzsWcJ3rnnIs5T/TOORdznuidcy7mPNE751zMeaJ3zrmYSyvRS+ovaaGkxZJuSjH9EEnTJH0gabqktgnT7pI0X9Inku5X9Lgp55xz1aPMRC8pB3gQOAPoDAyV1Dmp2HjgCTPrBowBxkXzHgscR3hW7FHA0UDfjEXvnHOuTOnU6HsDi81sqZltBSYBA5PKdAbeiIbfTJhuQENgb6AB4RmyqyobtHPOufSlk+jbAMsT3hdG4xLNAwZHw4OAxpKam9n/ERL/F9HrFTP7JHkFkkZKypeUv3r16vJ+Buecc6XI1MnYUUBfSXMITTMrgB2Svg8cCbQl/DicLOmE5JnN7BEzyzOzvJYtW2YoJOeccwD10iizAjg44X3baFwxM1tJVKOX1Ag4x8zWSfop8K6ZbYqmvQwcA8zMQOzOOefSkE6NfhbQUVIHSXsDQ4CpiQUktZBUtKybgQnR8DJCTb+epPqE2v4eTTfOOeeqTpmJ3sy2A1cDrxCS9GQzmy9pjKQBUbF+wEJJi4CDgLHR+GeAJcCHhHb8eWb2QmY/gnPOudLIzLIdw27y8vIsPz8/22E451ytImm2meWlmuZ3xjrnXMx5onfOuZjzRO+cczHnid4552LOE71zzsWcJ3rnnIs5T/TOORdznuidcy7mPNE751zMeaJ3zrmY80TvnHMx54neOedizhO9c87FnCd655yLOU/0zjkXc57onXMu5tJK9JL6S1ooabGkm1JMP0TSNEkfSJouqW00/iRJcxNeWyT9ONMfwjnnXMnKTPSScoAHgTOAzsBQSZ2Tio0HnjCzbsAYYByAmb1pZrlmlgucDGwGXs1g/M4558qQTo2+N7DYzJaa2VZgEjAwqUxn4I1o+M0U0wHOBV42s80VDdY551z5pZPo2wDLE94XRuMSzQMGR8ODgMaSmieVGQJMTLUCSSMl5UvKX716dRohOeecS1emTsaOAvpKmgP0BVYAO4omSmoFdAVeSTWzmT1iZnlmlteyZcsMheSccw6gXhplVgAHJ7xvG40rZmYriWr0khoB55jZuoQi5wPPmdm2yoXrnHOuvNKp0c8COkrqIGlvQhPM1MQCklpIKlrWzcCEpGUMpYRmG+ecc1WrzERvZtuBqwnNLp8Ak81svqQxkgZExfoBCyUtAg4CxhbNL6k94YjgnxmN3DnnXFpkZtmOYTd5eXmWn5+f7TCcc65WkTTbzPJSTfM7Y51zLuY80TvnXMylc9WNc66W27ZtG4WFhWzZsiXbobhKatiwIW3btqV+/fppz+OJ3rk6oLCwkMaNG9O+fXskZTscV0Fmxpo1aygsLKRDhw5pz+dNN87VAVu2bKF58+ae5Gs5STRv3rzcR2ae6J2rIzzJx0NFvkdP9M65KrdmzRpyc3PJzc3le9/7Hm3atCl+v3Xr1lLnzc/P59prry1zHccee2xGYi0oKGCfffYpju+KK64otXxubi5DhgzJyLqrirfRO+eqXPPmzZk7dy4Ao0ePplGjRowaNap4+vbt26lXL3U6ysvLIy8v5eXhu3nnnXcyEyxw2GGHFcdbmk8++YQdO3Ywc+ZMvvnmG/bbb7+MxZBJXqN3zmXF8OHDueKKK+jTpw833ngj7733Hscccww9evTg2GOPZeHChQBMnz6ds88+Gwg/EiNGjKBfv34ceuih3H///cXLa9SoUXH5fv36ce6553LEEUdw4YUXUnRj6EsvvcQRRxxBr169uPbaa4uXW1ETJ07k4osv5rTTTuP5558vHj9r1iyOPfZYunfvTu/evdm4cSM7duxg1KhRHHXUUXTr1o0HHnigUusuD6/RO1fHXHcdpFFZLZfcXLj33vLPV1hYyDvvvENOTg4bNmxg5syZ1KtXj9dff51f/vKXPPvss3vMs2DBAt588002btxIp06duPLKK/e41HDOnDnMnz+f1q1bc9xxx/H222+Tl5fH5ZdfzowZM+jQoQNDhw4tMa7PPvuMHj160KRJE37zm99wwgknpCz39NNP89prr7FgwQIeeOABhg0bxtatW7ngggt4+umnOfroo9mwYQP77LMPjzzyCAUFBcydO5d69eqxdu3a8m+wCvJE75zLmvPOO4+cnBwA1q9fz6WXXsqnn36KJLZtS93Z7VlnnUWDBg1o0KABBx54IKtWraJt27a7lendu3fxuNzcXAoKCmjUqBGHHnpo8WWJQ4cO5ZFHHtlj+a1atWLZsmU0b96c2bNn8+Mf/5j58+fTpEmT3crl5+fTokUL2rVrR5s2bRgxYgRr165lxYoVtGrViqOPPhqgeL7XX3+dK664oriJqlmzZhXdbOXmid65OqYiNe+qktim/atf/YqTTjqJ5557joKCAvr165dyngYNGhQP5+TksH379gqVKUnRjwhAr169OOyww1i0aBHLly/n17/+NQCPPvooEydOZMGCBbRv3x6ADRs28Oyzz/KDH/wg7XVVF2+jd87VCOvXr6dNm/Dwusceeyzjy+/UqRNLly6loKAACM0uqaxevZodO8Jzk5YuXcqnn37KoYceyqBBg5g7dy5z586lZ8+eTJ48mQ8//JCCggIKCgp4/vnnmThxIp06deKLL75g1qxZAGzcuJHt27dz6qmn8sc//rH4R6c6m2480TvnaoQbb7yRm2++mR49epSrBp6uffbZh4ceeoj+/fvTq1cvGjduzP77779HuRkzZtCtWzdyc3M599xz+cMf/rBHM8vMmTNp06YNrVu3Lh534okn8vHHH7NmzRqefvpprrnmGrp3786pp57Kli1b+MlPfkK7du3o1q0b3bt353/+538y/hlL4t0UO1cHfPLJJxx55JHZDiPrNm3aRKNGjTAzrrrqKjp27Mj111+f7bDKLdX36d0UO+cc8Kc//Ync3Fy6dOnC+vXrufzyy7MdUrVI62SspP7AfUAO8KiZ3Zk0/RDC4wNbAmuBi8ysMJrWDniU8JQpA840s4JMfQDnnEvX9ddfXytr8JVVZo1eUg7wIHAG0BkYKqlzUrHxwBNm1g0YA4xLmPYEcLeZHQn0Br7KRODOOefSk07TTW9gsZktNbOtwCRgYFKZzsAb0fCbRdOjH4R6ZvYagJltMrPNGYncOedcWtJJ9G2A5QnvC6NxieYBg6PhQUBjSc2Bw4F1kv4uaY6ku6MjhN1IGikpX1L+6tWry/8pnHPOlShTJ2NHAX0lzQH6AiuAHYRzACdE048GDgWGJ89sZo+YWZ6Z5bVs2TJDITnnnIP0Ev0KwonUIm2jccXMbKWZDTazHsAt0bh1hNr/3KjZZzswBeiZkcidc7XGSSedxCuvvLLbuHvvvZcrr7yyxHn69etH0aXWZ555JuvWrdujzOjRoxk/fnyp654yZQoff/xx8fvbbruN119/vTzhp1SbujNO56qbWUBHSR0ICX4IMCyxgKQWwFoz2wncTLgCp2jeppJamtlq4GTAL5J3ro4ZOnQokyZN4vTTTy8eN2nSJO6666605n/ppZcqvO4pU6Zw9tln07lzuIZkzJgxFV5WstrSnXGZNfqoJn418ArwCTDZzOZLGiNpQFSsH7BQ0iLgIGBsNO8OQrPNNEkfAgL+lPFP4Zyr0c4991xefPHF4oeMFBQUsHLlSk444QSuvPJK8vLy6NKlC7fffnvK+du3b8/XX38NwNixYzn88MM5/vjji7syhnCN/NFHH0337t0555xz2Lx5M++88w5Tp07lhhtuIDc3lyVLljB8+HCeeeYZAKZNm0aPHj3o2rUrI0aM4Lvvvite3+23307Pnj3p2rUrCxYsqNTnz3Z3xmldR29mLwEvJY27LWH4GeCZEuZ9DehWiRidc5mUhX6KmzVrRu/evXn55ZcZOHAgkyZN4vzzz0cSY8eOpVmzZuzYsYNTTjmFDz74gG7dUqeM2bNnM2nSJObOncv27dvp2bMnvXr1AmDw4MH89Kc/BeDWW2/lz3/+M9dccw0DBgzg7LPP5txzz91tWVu2bGH48OFMmzaNww8/nEsuuYSHH36Y6667DoAWLVrw/vvv89BDDzF+/HgeffTRPeKpLd0Z+52xzrlqUdR8A6HZpqg/+MmTJ9OzZ0969OjB/Pnzd2tPTzZz5kwGDRrEvvvuS5MmTRgwYEDxtI8++ogTTjiBrl278tRTTzF//vxS41m4cCEdOnTg8MMPB+DSSy9lxowZxdMHDw4XEvbq1au4I7RERd0Zz5kzh3vuuYdhw4axYcOGPcoldmd8yimnMGfOHNauXcvChQv36M64qC/+yy+/PKPdGXs3xc7VNVnqp3jgwIFcf/31vP/++2zevJlevXrx2WefMX78eGbNmsUBBxzA8OHD2bJlS4WWP3z4cKZMmUL37t157LHHmD59eqXiLeqquLSukGtLd8Zeo3fOVYtGjRpx0kknMWLEiOLa/IYNG9hvv/3Yf//9WbVqFS+//HKpyzjxxBOZMmUK3377LRs3buSFF14onrZx40ZatWrFtm3beOqpp4rHN27cmI0bN+6xrE6dOlFQUMDixYsB+Otf/0rfvn3T/jy1qTtjT/TOuWozdOhQ5s2bV5zou3fvTo8ePTjiiCMYNmwYxx13XKnz9+zZkwsuuIDu3btzxhlnFDd7ANxxxx306dOH4447jiOOOKJ4/JAhQ7j77rvp0aMHS5YsKR7fsGFD/vKXv3DeeefRtWtX9tprrzIvkUxUm7oz9m6KnasDvJviePFuip1zzu3GE71zzsWcJ3rnnIs5T/TO1RE17Xycq5iKfI+e6J2rAxo2bMiaNWs82ddyZsaaNWto2LBhuebzG6acqwPatm1LYWEh/ryH2q9hw4a0bdu2XPN4oneuDqhfvz4dOnTIdhguS7zpxjnnYs4TvXPOxZwneuecizlP9M45F3NpJXpJ/SUtlLRY0k0pph8iaZqkDyRNl9Q2YdoOSXOj19RMBu+cc65sZV51IykHeBA4lfCw71mSpppZ4tMBxgNPmNnjkk4GxgEXR9O+NbPcDMftnHMuTenU6HsDi81sqZltBSYBA5PKdAbeiIbfTDHdOedclqST6NsAyxPeF0bjEs0DBkfDg4DGkppH7xtKypf0rqQfp1qBpJFRmXy/ocM55zIrUydjRwF9Jc0B+gIrgB3RtEOiPpKHAfdKOix5ZjN7xMzyzCyvZcuWGQrJOeccpHdn7Arg4IT3baNxxcxsJVGNXlIj4BwzWxdNWxH9XSppOtADWIJzzrlqkU6NfhbQUVIHSXsDQ4Ddrp6R1EJS0bJuBiZE4w+Q1KCoDHAcUPIj3p1zzmVcmYnezLYDVwOvAJ8Ak81svqQxkgZExfoBCyUtAg4CxkbjjwTyJc0jnKS9M+lqHeecc1XMnxnrnHMx4M+Mdc65OswTvXPOxZwneuecizlP9M45F3Oe6J1zLuY80TvnXMx5onfOuZjzRO+cczHnid4552LOE71zzsWcJ3rnnIs5T/TOORdznuidcy7mPNE751zMeaJ3zrmY80TvnHMxl1ail9Rf0kJJiyXdlGL6IZKmSfpA0nRJbZOmN5FUKOn3mQrcOedcespM9JJygAeBM4DOwFBJnZOKjQeeMLNuwBhgXNL0O4AZlQ/XOedceaVTo+8NLDazpWa2FZgEDEwq0xl4Ixp+M3G6pF6E58i+WvlwnXPOlVc6ib4NsDzhfWE0LtE8YHA0PAhoLKm5pL2A3wGjKhuoc865isnUydhRQF9Jc4C+wApgB/Az4CUzKyxtZkkjJeVLyl+9enWGQnLOOQdQL40yK4CDE963jcYVM7OVRDV6SY2Ac8xsnaRjgBMk/QxoBOwtaZOZ3ZQ0/yPAIwB5eXlW0Q/jnHNuT+kk+llAR0kdCAl+CDAssYCkFsBaM9sJ3AxMADCzCxPKDAfykpO8c865qlVm042ZbQeuBl4BPgEmm9l8SWMkDYiK9QMWSlpEOPE6toridc45V04yq1ktJXl5eZafn5/tMJxzrlaRNNvM8lJN8ztjnXMu5jzRO+dczHmid865mPNE75xzMeeJ3jnnYs4TvXPOxZwneuecizlP9M45F3Oe6J1zLuY80TvnXMx5onfOuZjzRO+cczHniT7T5s6FO++Ezz/PdiTOOQd4os8MM5g+Hfr3hx494OaboXNnuOsu2LYt29E55+o4T/SVsXMnTJkCxxwDJ50Ec+bAuHHwwQdw2mnwX/8VEv/MmdmO1DlXh3mir4itW+Gxx6BLFxg0CFavhocfhoICuOkm6NoVnnsOpk6FTZvgxBNhxAj4+utsR+6cq4PSSvSS+ktaKGmxpD0eBSjpEEnTJH0gabqktgnj35c0V9J8SVdk+gNUq02b4N574bDD4LLLoEEDmDgRFi6EK66AffbZvfyPfgTz54ea/V//Cp06wZ//HI4EnHOumpT5hClJOcAi4FSgkPAM2aFm9nFCmb8B/zCzxyWdDFxmZhdL2jtax3fRQ8M/Ao6NHiaeUo18wtSaNfDAA+G1di307Rtq7qefDlJ6y5g/H668MjTjHHdcOALo2rVq43auLjMLlbP168t+bdsGTZrA/vuX/VDs69cAABAhSURBVKqXzqO2q19pT5hKJ+LewGIzWxotbBIwEPg4oUxn4BfR8JvAFAAz25pQpgG1ralo2TK45x74059g82YYODDUzo85pvzL6tIF/vlPePxxGDUqtN3/4hdw223QqFHmY3curnbsgCVL4MMPw2vJEli3bs/kvWFD2UfPe+0Vkvfee4fy335b9vr33Tf1D0CLFtCu3e6v1q1rxA9DOhG0AZYnvC8E+iSVmQcMBu4DBgGNJTU3szWSDgZeBL4P3FBabb7G+PjjcMXMU0+F9xdeCDfeGK6kqQwJhg8PTTo33QR33w2TJoUjhYEDKx22c7FiBqtW7UroRa+PP96VkCU4+GBo1iwk2/bt06uVF73222/3o/KtW0PCL632n/yjsm5duJz6q6/g3//e/TPstRe0abPnD0Dia//9028ZqKB0mm7OBfqb2U+i9xcDfczs6oQyrYHfAx2AGcA5wFFmti6pzBTgR2a2KmkdI4GRAO3atev1ebauQV++HK69NlxJs+++8NOfhlp3u3ZVs7633w5t+x99FJL/Aw/AIYdUzbqcq8k2bQrNm8lJPfEChgMPDM2dia/OnUOyrik2bQp5ZNmy1K/ly/e85Lpx411J/+ij4de/rtCqS2u6SSfRHwOMNrPTo/c3A5jZuBLKNwIWmFnbFNMmAC+Z2TMlrS9rbfRTp4YTrN99B//5n3DNNeFQrKpt2wb33Qe33x7e33Zb+HGpX7/q1+1ctixdCi++CG+8ES5H/uyzUIOHUMnq0mXPpH7ggdmNORN27gxHKSX9EHToAM+UmB5LVdlEX49wMvYUYAXhZOwwM5ufUKYFsNbMdkoaC+wws9uiq2/WmNm3kg4A/gWcY2YflrS+ak/0W7aEZpkHHoCePUNTSseO1bf+IsuWwc9/Ho4mOneGP/wBTjih+uNwrips2wZvvRWS+4svwoIFYfyhh4b/u8SEfuihocnDlUulTsaa2XZJVwOvADnABDObL2kMkG9mU4F+wDhJRmi6uSqa/Ujgd9F4AeNLS/LVbuFCuOACmDcPrrsudF3QoEF2YmnXLlx7/8IL4Wiib1/4/e/hZz/LTjzOVdaqVfDyyyGxv/pqaPuuXz/s25dfDmedlZ1KVR1UZo2+ulVLjd4sXP1y9dXQsGG4+enss6t2neXxzTcwdGhI+v/936FLBedqup074f33d9XaZ80K41u1gjPPDIn9hz8MbdIu4yp7eWW8bNwYrmd/6ino1w+efDKcFa9J9tsPnn02XKHzy1+GM/vjxlX5mXnnym3DBnjttZDYX34Zvvwy7Kd9+sCYMSG59+jh+26W1a1En58PQ4aEEz9jxoQkmpOT7ahSq18/3E3bpAn89rfhEq4HH6y58ZZk8+bQPrv//tmOxGXCihXh/2jWLHjnndDuvm0bNG0abiA866zQuV/LltmO1CWoG4l+587QdcFNN8FBB4WeJmvDic699oKHHgr/RHfeGWpPjz9eO67I2b493Gh2++3hKOqWW+CGG7J3DsSV39dfh4RelNjz8+GLL8K0nBw46qhwbuvss+HYY2vEjUEutfh/M6tXhyaQl14KNyVNmBBurqgtpNBss//+oa1+wwb429/27FenpjALh/E33BCurDjxxHBZ3K9+FZrJHnoITj4521G6ZOvXw+zZu5L6rFm7nqkghX6aTjklXOedlwe5ueEySFcrxDvRv/EGXHRR6J+m6AqW2tpWeNNNoWb/s5/BGWeE6/6bNMl2VLubMyd07/DGG3D44eFS0QEDwjZ/5RW46qqQLC68EH73u3B0VVusWxd+rJYtq9ydl9lU1PfLqlWhCWbOnF2JfdGiXeU6dAht7FddFRJ7z541b19z5RLPq262b4fRo8MVK4cfDk8/Dd27ZyS+rJs4ES65JNSoXn65em7qKkthIdx6KzzxRDhaGj06XD6X3MT07bfh6OS3vw1HJOPGwciRNf+8w/TpYZt/8UW4x6E8fank5JTdWVbTphX/sdixI1RkVq0Kr6++Kv3vli27z9+mTaihF9XU8/KgefOMbDZXvSp1w1R1q3SiX7YMhg0L3Qtcdlm4Eaom3SKdCf/4B5x3Xrix5NVXs3fV0MaNIWnfc09IONddF5qXmjYtfb6FC8ORyRtvQO/e4eawHj2qJ+by+O67UIsfPz5c7/3kkyEhFilP74ilvcr7Y9G4cZjvq69C02Sq+evVC01mBx4YjpyS/x50ULg5qXXrzG4zlzV1J9E/91x4wMeOHSF5DBuW2eBqkunTQ/84LVvC66+HpF9dtm8P/erfdltINkOHhqOn9u3TX4ZZODq5/vpw0u+aa8KVUDWliWD+/NDENG9e6I9o/PiqqTCYhfsmyvPDsHFj2E6pEnjR36ZN/e7SOqa0RI+Z1ahXr169rEIWLDCTzPLyzBYvrtgyapv33jNr1sysVSuzDz+s+vXt3Gn24otmnTubgdnxx5u9+27llvnvf5v97Gfhu2vd2mzy5LCebNmxw+y++8waNDBr2dJs6tTsxeJcORB6KkiZV+Pzk9+pU2jSePvt8ASouuDoo2HGjDDcty+8917VrWvevPAc3LPOCl25PvtsWHef5B6ry6lp03B/wLvvhpro+eeHuyiXLMlM3OWxcmVY989/Hu7g/PDDcNTkXC0Xn0QP4Z90772zHUX16tIl3LTStGm4ouXNNzO7/BUrQnNYjx7h9vb77gvNGoMHZ/Zqkt69ww/VffeFH+ujjoLf/Ca0k1eHv/8dunULP14PPxy6n6hNVwU5V4p4tdHXZStXhhr34sXhOvvy1kR37gzLWLQIPv10199p00Kb/LXXhjuJDzigauJPtHJlaLufPDkcqVXltfcbN4aTyBMmQK9eoWuMTp2qZl3OVaG6czK2rluzJlxj//774Q7aCy/cfbpZOPGZmMyLhj/9dPfHqDVsCN//fmgeuvXW6j3ZW6To2vslS0JTykknwfHHh5gyccPY//1fuM+ioCBcLXT77bXjrmPnUvBOzeqK5s1DDXzAALj4Yvjkk5C4EhP7+vW7yterFxJ4x46h2adjx3DfQceO0LZt9q/aOP300E5+993hXohbbgnj69cP13sff3x4HXdc+a793rYN7rgDxo4N3UP/859hOc7FlNfo4+jbb0M/+y+8ENrR27XblcAT/7ZvX7v6J1mzZldHWm+9Fe7oLHos25FH7kr8xx8f7u5MdQ5h0aJQi581Cy69FO6/v+Zc0ulcJXjTTV20c2foq6RVq9AME0fffhtu4S9K/G+/veuIpVWr3RN/t26hHf7660PHan/8Y7jpzLmYqHSil9QfuI/whKlHzezOpOmHABOAlsBa4CIzK5SUCzwMNAF2AGPN7OnS1uWJ3lXYzp3hiqCixP/WW+FOaQjJ/bvvQlv/Y4/VvGcQOFdJlX1mbA7hmbGnAoWEZ8YONbOPE8r8DfiHmT0u6WTgMjO7WNLhgJnZp5JaA7OBI81sXUnr80TvMmrZslDTf+edcCnqyJHZP/fgXBWo7MnY3sBiM1saLWwSMBD4OKFMZ+AX0fCbwBQAMyvuEs/MVkr6ilDrLzHRO5dR7dqF19Ch2Y7EuaxJp2rTBlie8L4wGpdoHjA4Gh4ENJa022UQknoDewNZuOXROefqrkwdw44C+kqaA/QFVhDa5AGQ1Ar4K6FJZ4+u9iSNlJQvKX/16tUZCsk55xykl+hXAAcnvG8bjStmZivNbLCZ9QBuicatA5DUBHgRuMXM3k21AjN7xMzyzCyvpT9r0jnnMiqdRD8L6Cipg6S9gSHA1MQCklpIKlrWzYQrcIjKPwc8YWbPZC5s55xz6Soz0ZvZduBq4BXgE2Cymc2XNEbSgKhYP2ChpEXAQcDYaPz5wInAcElzo1dupj+Ec865kvkNU845FwOlXV7pFxQ751zMeaJ3zrmYq3FNN5JWA59X4SpaAF9X4fIzpbbECbUnVo8zs2pLnFB7Yq1MnIeYWcrLFmtcoq9qkvJLaseqSWpLnFB7YvU4M6u2xAm1J9aqitObbpxzLuY80TvnXMzVxUT/SLYDSFNtiRNqT6weZ2bVljih9sRaJXHWuTZ655yra+pijd455+oUT/TOORdzsUz0kg6W9KakjyXNl/TzFGX6SVqf0AfPbVmKtUDSh1EMe/T9oOB+SYslfSCpZxZi7JSwneZK2iDpuqQyWduekiZI+krSRwnjmkl6TdKn0d8DSpj30qjMp5IuzUKcd0taEH23z0lqWsK8pe4n1RDnaEkrEr7fM0uYt7+khdH+elNVxllKrE8nxFkgaW4J81bnNk2Zk6ptPzWz2L2AVkDPaLgx4VGInZPK9CM8/jDbsRYALUqZfibwMiDgB8C/shxvDvAl4eaMGrE9CR3n9QQ+Shh3F3BTNHwT8NsU8zUDlkZ/D4iGD6jmOE8D6kXDv00VZzr7STXEORoYlca+sQQ4lPCQoXnJ/3fVEWvS9N8Bt9WAbZoyJ1XXfhrLGr2ZfWFm70fDGwm9btbWp0EPJHTzbBb6828aPcglW04BlphZVd69XC5mNoPwUPpEA4HHo+HHgR+nmPV04DUzW2tm/wZeA/pXZ5xm9qqFHmIB3iU87yGrStie6Sh+7KiZbQWKHjtaZUqLVZIIPehOrMoY0lFKTqqW/TSWiT6RpPZAD+BfKSYfI2mepJcldanWwHYx4FVJsyWNTDE9nUc5VqchlPyPUxO2Z5GDzOyLaPhLQvfZyWrath1BOHpLpaz9pDpcHTUxTSihiaGmbc8TgFVm9mkJ07OyTZNyUrXsp7FO9JIaAc8C15nZhqTJ7xOaH7oDDxA90DwLjjeznsAZwFWSTsxSHGVSeJDMAOBvKSbXlO25BwvHvzX6OmJJtwDbgadKKJLt/eRh4DAgF/iC0CRS0w2l9Np8tW/T0nJSVe6nsU30kuoTNuhTZvb35OlmtsHMNkXDLwH1JbWo5jAxsxXR368IT+PqnVSkzEc5VqMzgPfNbFXyhJqyPROsKmriiv5+laJMjdi2koYDZwMXRv/se0hjP6lSZrbKzHZYeObzn0pYf43YngCS6gGDgadLKlPd27SEnFQt+2ksE33UNvdn4BMzu6eEMt+LyiGpN2FbrKm+KEHSfpIaFw0TTsx9lFRsKnBJdPXND4D1CYd61a3EGlJN2J5JpgJFVydcCjyfoswrwGmSDoiaIk6LxlUbSf2BG4EBZra5hDLp7CdVKum80KAS1l/mY0er0Q+BBWZWmGpidW/TUnJS9eyn1XHGubpfwPGEQ6APgLnR60zgCuCKqMzVwHzClQHvAsdmIc5Do/XPi2K5JRqfGKeABwlXM3wI5GVpm+5HSNz7J4yrEduT8OPzBbCN0H75H0BzYBrwKfA60Cwqmwc8mjDvCGBx9LosC3EuJrS/Fu2nf4jKtgZeKm0/qeY4/xrtfx8QklOr5Dij92cSrihZUtVxlhRrNP6xon0zoWw2t2lJOala9lPvAsE552Iulk03zjnndvFE75xzMeeJ3jnnYs4TvXPOxZwneuecizlP9M45F3Oe6J1zLub+P92iGUqgDGlFAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"0RgXbQzqwGoP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBSIISJWFFs4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0z6BwcAulnw","executionInfo":{"status":"ok","timestamp":1606103464556,"user_tz":-540,"elapsed":1233,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / Inception_Resnet_V1"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c","executionInfo":{"status":"ok","timestamp":1606103465446,"user_tz":-540,"elapsed":2116,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak","executionInfo":{"status":"ok","timestamp":1606103465447,"user_tz":-540,"elapsed":2106,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pFcw51AuDG4","executionInfo":{"status":"ok","timestamp":1606103488643,"user_tz":-540,"elapsed":25299,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["model=load_model(os.path.join(dir,'model_output',number,'SUB','Inception_ResNet_v1','016.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWlrnY9EuDG-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606108415761,"user_tz":-540,"elapsed":4952405,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"e345d394-bf0a-4435-8679-502f20e66c4e"},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["156/156 [==============================] - 4890s 31s/step - loss: 1.4198 - accuracy: 0.7396 - top5_acc: 0.9262 - macro_f1score: 0.3384\n","[Test Loss: 1.4198 /  Test Top-1 Accuracy: 0.7396 / Test Top-5 Accuracy: 0.9262 / Test Macro f1: 0.3384]\n","\n"],"name":"stdout"}]}]}
