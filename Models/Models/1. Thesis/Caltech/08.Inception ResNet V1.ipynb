{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"08.Inception ResNet V1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"E-OCKgEwJfTn","executionInfo":{"status":"ok","timestamp":1606099352166,"user_tz":-540,"elapsed":1091,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["#모형 출처 : https://github.com/titu1994/keras-squeeze-excite-network 에서 각색함"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [Inception ResNet V1]"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original Inception-ResNet-V1\n","```\n","1) Support Functions\n","2) Almost Original Inception-ResNet-V1\n","3) Inception-ResNet-V1 Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages\n"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099404230,"user_tz":-540,"elapsed":53132,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"a6817ef9-1dea-4af0-ab59-771ed4ed7a49"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099404233,"user_tz":-540,"elapsed":53116,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"370a8562-ac29-4900-8093-adbc1a6e2a22"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1606099407056,"user_tz":-540,"elapsed":55933,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1606099407079,"user_tz":-540,"elapsed":55948,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606099407083,"user_tz":-540,"elapsed":55904,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"7b65dd95-7c5f-4aea-cccf-d71efedb9164"},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099407084,"user_tz":-540,"elapsed":55876,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"7792d977-e570-4139-cbbb-6b52aa307cf3"},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606099410646,"user_tz":-540,"elapsed":59404,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"bf0c5c61-990e-4739-b995-ca716e1a57b1"},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Kf057Rw2yigs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099410653,"user_tz":-540,"elapsed":59392,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"3bff1046-789f-4362-a312-dbd49fa0f897"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 5798040938348216144\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 9789951736001215843\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 17597368981865006030\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15695549568\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 9985045836754038987\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OPD7FiWCh0Pd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099410656,"user_tz":-540,"elapsed":59371,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"43892ed7-b3e9-4c66-8bec-1376bdf390eb"},"source":["!cat /proc/cpuinfo"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.182\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.36\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.182\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.36\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.182\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.36\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 85\n","model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n","stepping\t: 3\n","microcode\t: 0x1\n","cpu MHz\t\t: 2000.182\n","cache size\t: 39424 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4000.36\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"BeJ7UtuOEgWY","executionInfo":{"status":"ok","timestamp":1606099410658,"user_tz":-540,"elapsed":59366,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CALTECH'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 299 # sizes after cropping\n","super_size = 330 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 64\n","weight_decay = 1e-3\n","epochs = 70"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1606099410664,"user_tz":-540,"elapsed":59367,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmbsCoo_qXED","executionInfo":{"status":"ok","timestamp":1606099410665,"user_tz":-540,"elapsed":59365,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1606099410666,"user_tz":-540,"elapsed":59362,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0VGsPxccqXEI"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"zUAUYE9eqXEJ","executionInfo":{"status":"ok","timestamp":1606099410667,"user_tz":-540,"elapsed":59358,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1606099410668,"user_tz":-540,"elapsed":59355,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"4vIFMllQqXEN","executionInfo":{"status":"ok","timestamp":1606099410673,"user_tz":-540,"elapsed":59357,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"o1nWsjrYqXEQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606099463668,"user_tz":-540,"elapsed":112342,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"6690a7f7-723f-4b98-b690-20a28fc25365"},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Found 24509 images belonging to 257 classes.\n","Found 2980 images belonging to 257 classes.\n","Found 3118 images belonging to 257 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original Inception-ResNet-V1"]},{"cell_type":"markdown","metadata":{"id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIV9crIRUmBc"},"source":["def conv2d_bn(x, filters, kernel_size, strides=1, padding='same', activation='relu', use_bias=False, name=None, weight_decay=weight_decay):\n","\n","    x = Conv2D(filters, kernel_size, strides=strides, padding=padding,  use_bias=use_bias, name=name, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    if not use_bias:\n","        bn_axis =  3\n","        bn_name = None if name is None else '{name}_bn'.format(name=name)\n","        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n","        \n","    if activation is not None:\n","        ac_name = None if name is None else '{name}_ac'.format(name=name)\n","        x = Activation(activation, name=ac_name)(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyMaexRzUl_x"},"source":["def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n"," \n","    if block_type == 'block35':\n","        branch_0 = conv2d_bn(x, 32, 1)\n","        branch_1 = conv2d_bn(x, 32, 1)\n","        branch_1 = conv2d_bn(branch_1, 32, 3)\n","        branch_2 = conv2d_bn(x, 32, 1)\n","        branch_2 = conv2d_bn(branch_2, 32, 3)\n","        branch_2 = conv2d_bn(branch_2, 32, 3)\n","        branches = [branch_0, branch_1, branch_2]\n","    elif block_type == 'block17':\n","        branch_0 = conv2d_bn(x, 128, 1)\n","        branch_1 = conv2d_bn(x, 128, 1)\n","        branch_1 = conv2d_bn(branch_1, 128, [1, 7])\n","        branch_1 = conv2d_bn(branch_1, 128, [7, 1])\n","        branches = [branch_0, branch_1]\n","    elif block_type == 'block8':\n","        branch_0 = conv2d_bn(x, 192, 1)\n","        branch_1 = conv2d_bn(x, 192, 1)\n","        branch_1 = conv2d_bn(branch_1, 192, [1, 3])\n","        branch_1 = conv2d_bn(branch_1, 192, [3, 1])\n","        branches = [branch_0, branch_1]\n","    else:\n","        raise ValueError('Unknown Inception-ResNet block type. '\n","                         'Expects \"block35\", \"block17\" or \"block8\", '\n","                         'but got: {block_type}'.format(block_type=block_type))\n","\n","    block_name = '{block_type}_{block_idx}'.format(block_type=block_type, block_idx=block_idx)\n","    channel_axis = 3\n","    mixed = Concatenate(axis=channel_axis, name='{block_name}_mixed'.format(block_name=block_name))(branches)\n","    up = conv2d_bn(mixed,\n","                   K.int_shape(x)[channel_axis],\n","                   1,\n","                   activation=None,\n","                   use_bias=True,\n","                   name='{block_name}_conv'.format(block_name=block_name))\n","\n","    x = Lambda(lambda inputs, scale_: inputs[0] + inputs[1] * scale_,\n","               output_shape=K.int_shape(x)[1:],\n","               arguments={'scale_': scale},\n","               name=block_name)([x, up])\n","    if activation is not None:\n","        x = Activation(activation, name='{block_name}_ac'.format(block_name=block_name))(x)\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-R2NfkqUl60"},"source":["def Inception_ResNet_v1(input_shape=None, weight_decay=weight_decay, classes=classes, name=None):\n"," \n","    img_input = Input(shape=input_shape)\n","\n","    # Stem block: 35 x 35 x 192\n","    x = conv2d_bn(img_input, 32, 3, strides=2, padding='valid')\n","    x = conv2d_bn(x, 32, 3, padding='valid')\n","    x = conv2d_bn(x, 64, 3)\n","    x = MaxPooling2D(3, strides=2)(x)\n","    x = conv2d_bn(x, 80, 1)\n","    x = conv2d_bn(x, 192, 3, padding='valid')\n","    x = conv2d_bn(x, 256, 3, strides=2, padding='valid')\n","\n","    channel_axis = 3\n","\n","    # 5x block35 (Inception-ResNet-A block): 35 x 35 x 320\n","    for block_idx in range(1, 6):\n","        x = inception_resnet_block(x,\n","                                   scale=0.17,\n","                                   block_type='block35',\n","                                   block_idx=block_idx)\n","\n","    # Mixed 6a (Reduction-A block): 17 x 17 \n","    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid')\n","    branch_1 = conv2d_bn(x, 192, 1)\n","    branch_1 = conv2d_bn(branch_1, 192, 3)\n","    branch_1 = conv2d_bn(branch_1, 256, 3, strides=2, padding='valid')\n","    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n","    branches = [branch_0, branch_1, branch_pool]\n","    x = Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n","\n","\n","    # 10x block17 (Inception-ResNet-B block): 17 x 17 x 960\n","    for block_idx in range(1, 11):\n","        x = inception_resnet_block(x,\n","                                   scale=0.1,\n","                                   block_type='block17',\n","                                   block_idx=block_idx)\n","\n","    # Mixed 7a (Reduction-B block): 8 x 8 \n","    branch_0 = conv2d_bn(x, 256, 1)\n","    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid')\n","    branch_1 = conv2d_bn(x, 256, 1)\n","    branch_1 = conv2d_bn(branch_1, 256, 3, strides=2, padding='valid')\n","    branch_2 = conv2d_bn(x, 256, 1)\n","    branch_2 = conv2d_bn(branch_2, 256, 3)\n","    branch_2 = conv2d_bn(branch_2, 256, 3, strides=2, padding='valid')\n","    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n","    branches = [branch_0, branch_1, branch_2, branch_pool]\n","    x = Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n","\n","\n","    # 5x block8 (Inception-ResNet-C block): 8 x 8 x 1856\n","    for block_idx in range(1, 5):\n","        x = inception_resnet_block(x,\n","                                   scale=0.2,\n","                                   block_type='block8',\n","                                   block_idx=block_idx)\n","    x = inception_resnet_block(x,\n","                               scale=1.,\n","                               activation=None,\n","                               block_type='block8',\n","                               block_idx=10)\n","\n","\n","    x = GlobalAveragePooling2D(name='avg_pool')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(classes, use_bias=False, kernel_regularizer=l2(weight_decay), activation='softmax', name='predictions')(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`\n","    inputs = img_input\n","\n","    # Create model\n","    model = Model(inputs, x, name=name)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wtR2M5ELuTew"},"source":["### 2) Almost Original Inception-ResNet-V1\n"]},{"cell_type":"code","metadata":{"id":"IMgWGFKFuTe3"},"source":["model = Inception_ResNet_v1(input_sizes, classes=classes, name='Inception_ResNet_v1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Plblq9iL6HdJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605323487192,"user_tz":-540,"elapsed":98413,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"707af8dd-f2f3-47ea-f265-a98c28574258"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"Inception_ResNet_v1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 35, 35, 256)  442368      activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 35, 35, 256)  768         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 35, 35, 256)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 35, 35, 32)   8192        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 35, 35, 32)   96          conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 35, 35, 32)   0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 35, 35, 32)   8192        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 35, 35, 32)   9216        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 35, 35, 32)   96          conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 35, 35, 32)   96          conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 35, 35, 32)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 35, 35, 32)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 35, 35, 32)   8192        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 35, 35, 32)   9216        activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 35, 35, 32)   9216        activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 35, 35, 32)   96          conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 35, 35, 32)   96          conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 35, 35, 32)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 35, 35, 32)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","block35_1_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_6[0][0]               \n","                                                                 activation_8[0][0]               \n","                                                                 activation_11[0][0]              \n","__________________________________________________________________________________________________\n","block35_1_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_1_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_1 (Lambda)              (None, 35, 35, 256)  0           activation_5[0][0]               \n","                                                                 block35_1_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_1_ac (Activation)       (None, 35, 35, 256)  0           block35_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 35, 35, 32)   8192        block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 35, 35, 32)   8192        block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 35, 35, 32)   9216        activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 35, 35, 32)   96          conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 35, 35, 32)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 35, 35, 32)   8192        block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 35, 35, 32)   9216        activation_13[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 35, 35, 32)   9216        activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 35, 35, 32)   96          conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 35, 35, 32)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","block35_2_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_12[0][0]              \n","                                                                 activation_14[0][0]              \n","                                                                 activation_17[0][0]              \n","__________________________________________________________________________________________________\n","block35_2_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_2_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_2 (Lambda)              (None, 35, 35, 256)  0           block35_1_ac[0][0]               \n","                                                                 block35_2_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_2_ac (Activation)       (None, 35, 35, 256)  0           block35_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 35, 35, 32)   8192        block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 35, 35, 32)   8192        block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 35, 35, 32)   9216        activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 35, 35, 32)   96          conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 35, 35, 32)   0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 35, 35, 32)   8192        block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 35, 35, 32)   9216        activation_19[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 35, 35, 32)   9216        activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 35, 35, 32)   96          conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 35, 35, 32)   96          conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 35, 35, 32)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 35, 35, 32)   0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","block35_3_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_18[0][0]              \n","                                                                 activation_20[0][0]              \n","                                                                 activation_23[0][0]              \n","__________________________________________________________________________________________________\n","block35_3_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_3_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_3 (Lambda)              (None, 35, 35, 256)  0           block35_2_ac[0][0]               \n","                                                                 block35_3_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_3_ac (Activation)       (None, 35, 35, 256)  0           block35_3[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 35, 35, 32)   8192        block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 35, 35, 32)   8192        block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 35, 35, 32)   9216        activation_27[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 35, 35, 32)   96          conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 35, 35, 32)   0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 35, 35, 32)   8192        block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 35, 35, 32)   9216        activation_25[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 35, 35, 32)   9216        activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 35, 35, 32)   96          conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 35, 35, 32)   96          conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 35, 35, 32)   0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 35, 35, 32)   0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","block35_4_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_24[0][0]              \n","                                                                 activation_26[0][0]              \n","                                                                 activation_29[0][0]              \n","__________________________________________________________________________________________________\n","block35_4_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_4_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_4 (Lambda)              (None, 35, 35, 256)  0           block35_3_ac[0][0]               \n","                                                                 block35_4_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_4_ac (Activation)       (None, 35, 35, 256)  0           block35_4[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 35, 35, 32)   8192        block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 35, 35, 32)   8192        block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 35, 35, 32)   9216        activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 35, 35, 32)   96          conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 35, 35, 32)   0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 35, 35, 32)   8192        block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 35, 35, 32)   9216        activation_31[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 35, 35, 32)   9216        activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 35, 35, 32)   96          conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 35, 35, 32)   96          conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 35, 35, 32)   0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 35, 35, 32)   0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","block35_5_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_30[0][0]              \n","                                                                 activation_32[0][0]              \n","                                                                 activation_35[0][0]              \n","__________________________________________________________________________________________________\n","block35_5_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_5_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_5 (Lambda)              (None, 35, 35, 256)  0           block35_4_ac[0][0]               \n","                                                                 block35_5_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_5_ac (Activation)       (None, 35, 35, 256)  0           block35_5[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 35, 35, 192)  49152       block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 35, 35, 192)  576         conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 35, 35, 192)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 35, 35, 192)  331776      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 35, 35, 192)  576         conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 35, 35, 192)  0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 17, 17, 384)  884736      block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 17, 17, 256)  442368      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 17, 17, 384)  1152        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 17, 17, 256)  768         conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 17, 17, 384)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 17, 17, 256)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 17, 17, 256)  0           block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","mixed_6a (Concatenate)          (None, 17, 17, 896)  0           activation_36[0][0]              \n","                                                                 activation_39[0][0]              \n","                                                                 max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 17, 17, 128)  114688      mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 17, 17, 128)  384         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 17, 17, 128)  0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 17, 17, 128)  114688      activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 17, 17, 128)  384         conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 17, 17, 128)  0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 17, 17, 128)  114688      mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 17, 17, 128)  114688      activation_42[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 17, 17, 128)  384         conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 17, 17, 128)  384         conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 17, 17, 128)  0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 17, 17, 128)  0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","block17_1_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_40[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","block17_1_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_1_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_1 (Lambda)              (None, 17, 17, 896)  0           mixed_6a[0][0]                   \n","                                                                 block17_1_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_1_ac (Activation)       (None, 17, 17, 896)  0           block17_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 17, 17, 128)  114688      block17_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 17, 17, 128)  384         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 17, 17, 128)  0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 17, 17, 128)  114688      activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 17, 17, 128)  384         conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 17, 17, 128)  0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 17, 17, 128)  114688      block17_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 17, 17, 128)  114688      activation_46[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 17, 17, 128)  384         conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 17, 17, 128)  384         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 17, 17, 128)  0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 17, 17, 128)  0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","block17_2_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_44[0][0]              \n","                                                                 activation_47[0][0]              \n","__________________________________________________________________________________________________\n","block17_2_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_2_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_2 (Lambda)              (None, 17, 17, 896)  0           block17_1_ac[0][0]               \n","                                                                 block17_2_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_2_ac (Activation)       (None, 17, 17, 896)  0           block17_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 17, 17, 128)  114688      block17_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 17, 17, 128)  384         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 17, 17, 128)  0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 17, 17, 128)  114688      activation_49[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 17, 17, 128)  384         conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 17, 17, 128)  0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 17, 17, 128)  114688      block17_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 17, 17, 128)  114688      activation_50[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 17, 17, 128)  384         conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 17, 17, 128)  384         conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 17, 17, 128)  0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 17, 17, 128)  0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","block17_3_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_48[0][0]              \n","                                                                 activation_51[0][0]              \n","__________________________________________________________________________________________________\n","block17_3_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_3_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_3 (Lambda)              (None, 17, 17, 896)  0           block17_2_ac[0][0]               \n","                                                                 block17_3_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_3_ac (Activation)       (None, 17, 17, 896)  0           block17_3[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 17, 17, 128)  114688      block17_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 17, 17, 128)  384         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 17, 17, 128)  0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 17, 17, 128)  114688      activation_53[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 17, 17, 128)  384         conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","activation_54 (Activation)      (None, 17, 17, 128)  0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 17, 17, 128)  114688      block17_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 17, 17, 128)  114688      activation_54[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 17, 17, 128)  384         conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 17, 17, 128)  384         conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 17, 17, 128)  0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","activation_55 (Activation)      (None, 17, 17, 128)  0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","block17_4_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_52[0][0]              \n","                                                                 activation_55[0][0]              \n","__________________________________________________________________________________________________\n","block17_4_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_4_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_4 (Lambda)              (None, 17, 17, 896)  0           block17_3_ac[0][0]               \n","                                                                 block17_4_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_4_ac (Activation)       (None, 17, 17, 896)  0           block17_4[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 17, 17, 128)  114688      block17_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 17, 17, 128)  384         conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","activation_57 (Activation)      (None, 17, 17, 128)  0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 17, 17, 128)  114688      activation_57[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 17, 17, 128)  384         conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","activation_58 (Activation)      (None, 17, 17, 128)  0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 17, 17, 128)  114688      block17_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, 17, 17, 128)  114688      activation_58[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 17, 17, 128)  384         conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 17, 17, 128)  384         conv2d_59[0][0]                  \n","__________________________________________________________________________________________________\n","activation_56 (Activation)      (None, 17, 17, 128)  0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","activation_59 (Activation)      (None, 17, 17, 128)  0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","block17_5_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_56[0][0]              \n","                                                                 activation_59[0][0]              \n","__________________________________________________________________________________________________\n","block17_5_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_5_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_5 (Lambda)              (None, 17, 17, 896)  0           block17_4_ac[0][0]               \n","                                                                 block17_5_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_5_ac (Activation)       (None, 17, 17, 896)  0           block17_5[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 17, 17, 128)  114688      block17_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 17, 17, 128)  384         conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 17, 17, 128)  0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, 17, 17, 128)  114688      activation_61[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 17, 17, 128)  384         conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 17, 17, 128)  0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 17, 17, 128)  114688      block17_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, 17, 17, 128)  114688      activation_62[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 17, 17, 128)  384         conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 17, 17, 128)  384         conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 17, 17, 128)  0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 17, 17, 128)  0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","block17_6_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_60[0][0]              \n","                                                                 activation_63[0][0]              \n","__________________________________________________________________________________________________\n","block17_6_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_6_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_6 (Lambda)              (None, 17, 17, 896)  0           block17_5_ac[0][0]               \n","                                                                 block17_6_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_6_ac (Activation)       (None, 17, 17, 896)  0           block17_6[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_65 (Conv2D)              (None, 17, 17, 128)  114688      block17_6_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 17, 17, 128)  384         conv2d_65[0][0]                  \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 17, 17, 128)  0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_66 (Conv2D)              (None, 17, 17, 128)  114688      activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 17, 17, 128)  384         conv2d_66[0][0]                  \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 17, 17, 128)  0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_64 (Conv2D)              (None, 17, 17, 128)  114688      block17_6_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_67 (Conv2D)              (None, 17, 17, 128)  114688      activation_66[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 17, 17, 128)  384         conv2d_64[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 17, 17, 128)  384         conv2d_67[0][0]                  \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 17, 17, 128)  0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 17, 17, 128)  0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","block17_7_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_64[0][0]              \n","                                                                 activation_67[0][0]              \n","__________________________________________________________________________________________________\n","block17_7_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_7_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_7 (Lambda)              (None, 17, 17, 896)  0           block17_6_ac[0][0]               \n","                                                                 block17_7_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_7_ac (Activation)       (None, 17, 17, 896)  0           block17_7[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_69 (Conv2D)              (None, 17, 17, 128)  114688      block17_7_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 17, 17, 128)  384         conv2d_69[0][0]                  \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 17, 17, 128)  0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_70 (Conv2D)              (None, 17, 17, 128)  114688      activation_69[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 17, 17, 128)  384         conv2d_70[0][0]                  \n","__________________________________________________________________________________________________\n","activation_70 (Activation)      (None, 17, 17, 128)  0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_68 (Conv2D)              (None, 17, 17, 128)  114688      block17_7_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_71 (Conv2D)              (None, 17, 17, 128)  114688      activation_70[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 17, 17, 128)  384         conv2d_68[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 17, 17, 128)  384         conv2d_71[0][0]                  \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 17, 17, 128)  0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","activation_71 (Activation)      (None, 17, 17, 128)  0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","block17_8_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_68[0][0]              \n","                                                                 activation_71[0][0]              \n","__________________________________________________________________________________________________\n","block17_8_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_8_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_8 (Lambda)              (None, 17, 17, 896)  0           block17_7_ac[0][0]               \n","                                                                 block17_8_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_8_ac (Activation)       (None, 17, 17, 896)  0           block17_8[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_73 (Conv2D)              (None, 17, 17, 128)  114688      block17_8_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 17, 17, 128)  384         conv2d_73[0][0]                  \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 17, 17, 128)  0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_74 (Conv2D)              (None, 17, 17, 128)  114688      activation_73[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 17, 17, 128)  384         conv2d_74[0][0]                  \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 17, 17, 128)  0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_72 (Conv2D)              (None, 17, 17, 128)  114688      block17_8_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_75 (Conv2D)              (None, 17, 17, 128)  114688      activation_74[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 17, 17, 128)  384         conv2d_72[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 17, 17, 128)  384         conv2d_75[0][0]                  \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 17, 17, 128)  0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 17, 17, 128)  0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","block17_9_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_72[0][0]              \n","                                                                 activation_75[0][0]              \n","__________________________________________________________________________________________________\n","block17_9_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_9_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_9 (Lambda)              (None, 17, 17, 896)  0           block17_8_ac[0][0]               \n","                                                                 block17_9_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_9_ac (Activation)       (None, 17, 17, 896)  0           block17_9[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_77 (Conv2D)              (None, 17, 17, 128)  114688      block17_9_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 17, 17, 128)  0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_78 (Conv2D)              (None, 17, 17, 128)  114688      activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 17, 17, 128)  384         conv2d_78[0][0]                  \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 17, 17, 128)  0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_76 (Conv2D)              (None, 17, 17, 128)  114688      block17_9_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_79 (Conv2D)              (None, 17, 17, 128)  114688      activation_78[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 17, 17, 128)  384         conv2d_76[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 17, 17, 128)  384         conv2d_79[0][0]                  \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 17, 17, 128)  0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 17, 17, 128)  0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","block17_10_mixed (Concatenate)  (None, 17, 17, 256)  0           activation_76[0][0]              \n","                                                                 activation_79[0][0]              \n","__________________________________________________________________________________________________\n","block17_10_conv (Conv2D)        (None, 17, 17, 896)  230272      block17_10_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_10 (Lambda)             (None, 17, 17, 896)  0           block17_9_ac[0][0]               \n","                                                                 block17_10_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_10_ac (Activation)      (None, 17, 17, 896)  0           block17_10[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_84 (Conv2D)              (None, 17, 17, 256)  229376      block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 17, 17, 256)  768         conv2d_84[0][0]                  \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 17, 17, 256)  0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_80 (Conv2D)              (None, 17, 17, 256)  229376      block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_82 (Conv2D)              (None, 17, 17, 256)  229376      block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_85 (Conv2D)              (None, 17, 17, 256)  589824      activation_84[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 17, 17, 256)  768         conv2d_80[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 17, 17, 256)  768         conv2d_82[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 17, 17, 256)  768         conv2d_85[0][0]                  \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 17, 17, 256)  0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 17, 17, 256)  0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 17, 17, 256)  0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_81 (Conv2D)              (None, 8, 8, 384)    884736      activation_80[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_83 (Conv2D)              (None, 8, 8, 256)    589824      activation_82[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_86 (Conv2D)              (None, 8, 8, 256)    589824      activation_85[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 8, 8, 256)    768         conv2d_83[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 8, 8, 256)    768         conv2d_86[0][0]                  \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 8, 8, 256)    0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 8, 8, 256)    0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 896)    0           block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","mixed_7a (Concatenate)          (None, 8, 8, 1792)   0           activation_81[0][0]              \n","                                                                 activation_83[0][0]              \n","                                                                 activation_86[0][0]              \n","                                                                 max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 8, 8, 192)    344064      mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 8, 8, 192)    576         conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 8, 8, 192)    0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 8, 8, 192)    110592      activation_88[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 8, 8, 192)    576         conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 8, 8, 192)    0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_87 (Conv2D)              (None, 8, 8, 192)    344064      mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 8, 8, 192)    110592      activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 8, 8, 192)    576         conv2d_87[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 8, 8, 192)    576         conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 8, 8, 192)    0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 8, 8, 192)    0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","block8_1_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_87[0][0]              \n","                                                                 activation_90[0][0]              \n","__________________________________________________________________________________________________\n","block8_1_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_1_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_1 (Lambda)               (None, 8, 8, 1792)   0           mixed_7a[0][0]                   \n","                                                                 block8_1_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_1_ac (Activation)        (None, 8, 8, 1792)   0           block8_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 8, 8, 192)    344064      block8_1_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 8, 8, 192)    576         conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 8, 8, 192)    0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 8, 8, 192)    110592      activation_92[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 8, 8, 192)    344064      block8_1_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 8, 8, 192)    110592      activation_93[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 8, 8, 192)    576         conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 8, 8, 192)    0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","block8_2_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_91[0][0]              \n","                                                                 activation_94[0][0]              \n","__________________________________________________________________________________________________\n","block8_2_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_2_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_2 (Lambda)               (None, 8, 8, 1792)   0           block8_1_ac[0][0]                \n","                                                                 block8_2_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_2_ac (Activation)        (None, 8, 8, 1792)   0           block8_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 8, 8, 192)    344064      block8_2_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 8, 8, 192)    576         conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 8, 8, 192)    0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 8, 8, 192)    110592      activation_96[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 8, 8, 192)    576         conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 8, 8, 192)    0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 8, 8, 192)    344064      block8_2_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 8, 8, 192)    110592      activation_97[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 8, 8, 192)    576         conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 8, 8, 192)    576         conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 8, 8, 192)    0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 8, 8, 192)    0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","block8_3_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_95[0][0]              \n","                                                                 activation_98[0][0]              \n","__________________________________________________________________________________________________\n","block8_3_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_3_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_3 (Lambda)               (None, 8, 8, 1792)   0           block8_2_ac[0][0]                \n","                                                                 block8_3_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_3_ac (Activation)        (None, 8, 8, 1792)   0           block8_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 8, 8, 192)    344064      block8_3_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 8, 8, 192)    576         conv2d_100[0][0]                 \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 8, 8, 192)    0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 8, 8, 192)    110592      activation_100[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 8, 8, 192)    576         conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 8, 8, 192)    0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 8, 8, 192)    344064      block8_3_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 8, 8, 192)    110592      activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 8, 8, 192)    576         conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 8, 8, 192)    576         conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 8, 8, 192)    0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 8, 8, 192)    0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","block8_4_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_99[0][0]              \n","                                                                 activation_102[0][0]             \n","__________________________________________________________________________________________________\n","block8_4_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_4_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_4 (Lambda)               (None, 8, 8, 1792)   0           block8_3_ac[0][0]                \n","                                                                 block8_4_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_4_ac (Activation)        (None, 8, 8, 1792)   0           block8_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 8, 8, 192)    344064      block8_4_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 8, 8, 192)    576         conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 8, 8, 192)    0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_105 (Conv2D)             (None, 8, 8, 192)    110592      activation_104[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_105 (BatchN (None, 8, 8, 192)    576         conv2d_105[0][0]                 \n","__________________________________________________________________________________________________\n","activation_105 (Activation)     (None, 8, 8, 192)    0           batch_normalization_105[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 8, 8, 192)    344064      block8_4_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_106 (Conv2D)             (None, 8, 8, 192)    110592      activation_105[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 8, 8, 192)    576         conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_106 (BatchN (None, 8, 8, 192)    576         conv2d_106[0][0]                 \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 8, 8, 192)    0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","activation_106 (Activation)     (None, 8, 8, 192)    0           batch_normalization_106[0][0]    \n","__________________________________________________________________________________________________\n","block8_10_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_103[0][0]             \n","                                                                 activation_106[0][0]             \n","__________________________________________________________________________________________________\n","block8_10_conv (Conv2D)         (None, 8, 8, 1792)   689920      block8_10_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block8_10 (Lambda)              (None, 8, 8, 1792)   0           block8_4_ac[0][0]                \n","                                                                 block8_10_conv[0][0]             \n","__________________________________________________________________________________________________\n","avg_pool (GlobalAveragePooling2 (None, 1792)         0           block8_10[0][0]                  \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 1792)         0           avg_pool[0][0]                   \n","__________________________________________________________________________________________________\n","predictions (Dense)             (None, 257)          460544      dropout[0][0]                    \n","==================================================================================================\n","Total params: 21,437,392\n","Trainable params: 21,410,352\n","Non-trainable params: 27,040\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HflF2mp1EsHM"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AsDrV7ONZBDr"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XAwJuKTh6Kvy"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N27iJUAkuTfC"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"efoKrIVUuTfF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605384338697,"user_tz":-540,"elapsed":60949885,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"d67852a9-4d05-43e3-aa76-6b47ffa59575"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_5/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_9/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_7/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_10/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_6/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_8/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_11/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block35_1_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_15/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_13/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_16/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_12/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_14/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_17/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block35_2_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_21/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_19/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_22/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_18/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_20/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_23/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block35_3_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_27/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_25/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_28/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_24/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_26/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_29/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block35_4_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_33/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_31/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_34/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_30/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_32/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_35/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block35_5_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_37/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_38/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_36/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_39/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_41/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_42/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_40/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_43/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block17_1_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_45/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_46/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_44/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_47/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block17_2_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_49/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_50/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_48/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_51/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block17_3_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_53/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_54/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_52/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_55/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block17_4_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_57/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_58/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_56/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_59/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block17_5_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_61/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_62/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_60/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_63/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block17_6_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_65/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_66/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_64/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_67/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block17_7_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_69/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_70/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_68/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_71/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block17_8_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_73/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_74/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_72/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_75/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block17_9_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_77/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_78/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_76/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_79/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block17_10_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_84/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_80/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_82/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_85/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_81/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_83/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_86/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_88/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_89/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_87/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_90/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block8_1_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_92/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_93/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_91/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_94/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block8_2_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_96/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_97/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_95/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_98/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block8_3_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_100/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_101/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_99/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_102/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block8_4_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_104/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_105/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_103/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for conv2d_106/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for block8_10_conv/kernel:0\n","0.0(L1), 5.116445343984611e-05(L2) weight decay set for predictions/kernel:0\n","382/382 [==============================] - ETA: 0s - loss: 4.9988 - accuracy: 0.1018 - top5_acc: 0.2102 - macro_f1score: 0.0026 \n","Epoch 00001: val_loss improved from inf to 4.79676, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.10394, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/001.h5\n","382/382 [==============================] - 14345s 38s/step - loss: 4.9988 - accuracy: 0.1018 - top5_acc: 0.2102 - macro_f1score: 0.0026 - val_loss: 4.7968 - val_accuracy: 0.1039 - val_top5_acc: 0.2354 - val_macro_f1score: 0.0042\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","382/382 [==============================] - ETA: 0s - loss: 4.1466 - accuracy: 0.1766 - top5_acc: 0.3341 - macro_f1score: 0.0096\n","Epoch 00002: val_loss improved from 4.79676 to 4.08920, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/002.h5\n","\n","Epoch 00002: val_accuracy improved from 0.10394 to 0.17901, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/002.h5\n","382/382 [==============================] - 690s 2s/step - loss: 4.1466 - accuracy: 0.1766 - top5_acc: 0.3341 - macro_f1score: 0.0096 - val_loss: 4.0892 - val_accuracy: 0.1790 - val_top5_acc: 0.3546 - val_macro_f1score: 0.0104\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","382/382 [==============================] - ETA: 0s - loss: 3.6364 - accuracy: 0.2370 - top5_acc: 0.4418 - macro_f1score: 0.0163\n","Epoch 00003: val_loss improved from 4.08920 to 3.63968, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/003.h5\n","\n","Epoch 00003: val_accuracy improved from 0.17901 to 0.25272, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/003.h5\n","382/382 [==============================] - 695s 2s/step - loss: 3.6364 - accuracy: 0.2370 - top5_acc: 0.4418 - macro_f1score: 0.0163 - val_loss: 3.6397 - val_accuracy: 0.2527 - val_top5_acc: 0.4501 - val_macro_f1score: 0.0177\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","382/382 [==============================] - ETA: 0s - loss: 3.1689 - accuracy: 0.3088 - top5_acc: 0.5365 - macro_f1score: 0.0259\n","Epoch 00004: val_loss improved from 3.63968 to 3.40479, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/004.h5\n","\n","Epoch 00004: val_accuracy improved from 0.25272 to 0.28159, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/004.h5\n","382/382 [==============================] - 673s 2s/step - loss: 3.1689 - accuracy: 0.3088 - top5_acc: 0.5365 - macro_f1score: 0.0259 - val_loss: 3.4048 - val_accuracy: 0.2816 - val_top5_acc: 0.4993 - val_macro_f1score: 0.0240\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","382/382 [==============================] - ETA: 0s - loss: 2.7966 - accuracy: 0.3736 - top5_acc: 0.6140 - macro_f1score: 0.0371\n","Epoch 00005: val_loss improved from 3.40479 to 3.13631, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/005.h5\n","\n","Epoch 00005: val_accuracy improved from 0.28159 to 0.34035, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/005.h5\n","382/382 [==============================] - 671s 2s/step - loss: 2.7966 - accuracy: 0.3736 - top5_acc: 0.6140 - macro_f1score: 0.0371 - val_loss: 3.1363 - val_accuracy: 0.3404 - val_top5_acc: 0.5662 - val_macro_f1score: 0.0389\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","382/382 [==============================] - ETA: 0s - loss: 2.5435 - accuracy: 0.4209 - top5_acc: 0.6603 - macro_f1score: 0.0469\n","Epoch 00006: val_loss improved from 3.13631 to 2.74630, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/006.h5\n","\n","Epoch 00006: val_accuracy improved from 0.34035 to 0.38723, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/006.h5\n","382/382 [==============================] - 676s 2s/step - loss: 2.5435 - accuracy: 0.4209 - top5_acc: 0.6603 - macro_f1score: 0.0469 - val_loss: 2.7463 - val_accuracy: 0.3872 - val_top5_acc: 0.6226 - val_macro_f1score: 0.0458\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","382/382 [==============================] - ETA: 0s - loss: 2.2784 - accuracy: 0.4667 - top5_acc: 0.7119 - macro_f1score: 0.0579\n","Epoch 00007: val_loss did not improve from 2.74630\n","\n","Epoch 00007: val_accuracy improved from 0.38723 to 0.39640, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/007.h5\n","382/382 [==============================] - 672s 2s/step - loss: 2.2784 - accuracy: 0.4667 - top5_acc: 0.7119 - macro_f1score: 0.0579 - val_loss: 2.7749 - val_accuracy: 0.3964 - val_top5_acc: 0.6338 - val_macro_f1score: 0.0560\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","382/382 [==============================] - ETA: 0s - loss: 2.0538 - accuracy: 0.5120 - top5_acc: 0.7514 - macro_f1score: 0.0690\n","Epoch 00008: val_loss improved from 2.74630 to 2.49482, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/008.h5\n","\n","Epoch 00008: val_accuracy improved from 0.39640 to 0.45075, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/008.h5\n","382/382 [==============================] - 674s 2s/step - loss: 2.0538 - accuracy: 0.5120 - top5_acc: 0.7514 - macro_f1score: 0.0690 - val_loss: 2.4948 - val_accuracy: 0.4507 - val_top5_acc: 0.6865 - val_macro_f1score: 0.0614\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","382/382 [==============================] - ETA: 0s - loss: 1.8566 - accuracy: 0.5536 - top5_acc: 0.7855 - macro_f1score: 0.0794\n","Epoch 00009: val_loss improved from 2.49482 to 2.48350, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/009.h5\n","\n","Epoch 00009: val_accuracy did not improve from 0.45075\n","382/382 [==============================] - 708s 2s/step - loss: 1.8566 - accuracy: 0.5536 - top5_acc: 0.7855 - macro_f1score: 0.0794 - val_loss: 2.4835 - val_accuracy: 0.4446 - val_top5_acc: 0.6787 - val_macro_f1score: 0.0627\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","382/382 [==============================] - ETA: 0s - loss: 1.6880 - accuracy: 0.5833 - top5_acc: 0.8129 - macro_f1score: 0.0887\n","Epoch 00010: val_loss did not improve from 2.48350\n","\n","Epoch 00010: val_accuracy did not improve from 0.45075\n","382/382 [==============================] - 706s 2s/step - loss: 1.6880 - accuracy: 0.5833 - top5_acc: 0.8129 - macro_f1score: 0.0887 - val_loss: 2.7996 - val_accuracy: 0.4497 - val_top5_acc: 0.6783 - val_macro_f1score: 0.0697\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","382/382 [==============================] - ETA: 0s - loss: 1.5514 - accuracy: 0.6120 - top5_acc: 0.8353 - macro_f1score: 0.0957\n","Epoch 00011: val_loss improved from 2.48350 to 2.16162, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/011.h5\n","\n","Epoch 00011: val_accuracy improved from 0.45075 to 0.51087, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/011.h5\n","382/382 [==============================] - 717s 2s/step - loss: 1.5514 - accuracy: 0.6120 - top5_acc: 0.8353 - macro_f1score: 0.0957 - val_loss: 2.1616 - val_accuracy: 0.5109 - val_top5_acc: 0.7381 - val_macro_f1score: 0.0812\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","382/382 [==============================] - ETA: 0s - loss: 1.4037 - accuracy: 0.6475 - top5_acc: 0.8575 - macro_f1score: 0.1059\n","Epoch 00012: val_loss improved from 2.16162 to 2.12603, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/012.h5\n","\n","Epoch 00012: val_accuracy improved from 0.51087 to 0.54178, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/012.h5\n","382/382 [==============================] - 712s 2s/step - loss: 1.4037 - accuracy: 0.6475 - top5_acc: 0.8575 - macro_f1score: 0.1059 - val_loss: 2.1260 - val_accuracy: 0.5418 - val_top5_acc: 0.7456 - val_macro_f1score: 0.0888\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","382/382 [==============================] - ETA: 0s - loss: 1.2748 - accuracy: 0.6725 - top5_acc: 0.8751 - macro_f1score: 0.1142\n","Epoch 00013: val_loss did not improve from 2.12603\n","\n","Epoch 00013: val_accuracy did not improve from 0.54178\n","382/382 [==============================] - 690s 2s/step - loss: 1.2748 - accuracy: 0.6725 - top5_acc: 0.8751 - macro_f1score: 0.1142 - val_loss: 2.4516 - val_accuracy: 0.4908 - val_top5_acc: 0.7065 - val_macro_f1score: 0.0822\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","382/382 [==============================] - ETA: 0s - loss: 1.1645 - accuracy: 0.6965 - top5_acc: 0.8919 - macro_f1score: 0.1200\n","Epoch 00014: val_loss did not improve from 2.12603\n","\n","Epoch 00014: val_accuracy did not improve from 0.54178\n","382/382 [==============================] - 700s 2s/step - loss: 1.1645 - accuracy: 0.6965 - top5_acc: 0.8919 - macro_f1score: 0.1200 - val_loss: 2.2746 - val_accuracy: 0.5241 - val_top5_acc: 0.7357 - val_macro_f1score: 0.0911\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","382/382 [==============================] - ETA: 0s - loss: 1.0449 - accuracy: 0.7227 - top5_acc: 0.9125 - macro_f1score: 0.1277\n","Epoch 00015: val_loss improved from 2.12603 to 2.11165, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/015.h5\n","\n","Epoch 00015: val_accuracy did not improve from 0.54178\n","382/382 [==============================] - 705s 2s/step - loss: 1.0449 - accuracy: 0.7227 - top5_acc: 0.9125 - macro_f1score: 0.1277 - val_loss: 2.1116 - val_accuracy: 0.5380 - val_top5_acc: 0.7575 - val_macro_f1score: 0.0911\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","382/382 [==============================] - ETA: 0s - loss: 0.9441 - accuracy: 0.7450 - top5_acc: 0.9256 - macro_f1score: 0.1343\n","Epoch 00016: val_loss did not improve from 2.11165\n","\n","Epoch 00016: val_accuracy did not improve from 0.54178\n","382/382 [==============================] - 696s 2s/step - loss: 0.9441 - accuracy: 0.7450 - top5_acc: 0.9256 - macro_f1score: 0.1343 - val_loss: 2.1692 - val_accuracy: 0.5367 - val_top5_acc: 0.7541 - val_macro_f1score: 0.0931\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","382/382 [==============================] - ETA: 0s - loss: 0.8699 - accuracy: 0.7616 - top5_acc: 0.9354 - macro_f1score: 0.1392\n","Epoch 00017: val_loss improved from 2.11165 to 2.09886, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/017.h5\n","\n","Epoch 00017: val_accuracy improved from 0.54178 to 0.54823, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/017.h5\n","382/382 [==============================] - 683s 2s/step - loss: 0.8699 - accuracy: 0.7616 - top5_acc: 0.9354 - macro_f1score: 0.1392 - val_loss: 2.0989 - val_accuracy: 0.5482 - val_top5_acc: 0.7565 - val_macro_f1score: 0.0955\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","382/382 [==============================] - ETA: 0s - loss: 0.7704 - accuracy: 0.7858 - top5_acc: 0.9493 - macro_f1score: 0.1472\n","Epoch 00018: val_loss did not improve from 2.09886\n","\n","Epoch 00018: val_accuracy improved from 0.54823 to 0.54925, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/018.h5\n","382/382 [==============================] - 681s 2s/step - loss: 0.7704 - accuracy: 0.7858 - top5_acc: 0.9493 - macro_f1score: 0.1472 - val_loss: 2.2036 - val_accuracy: 0.5493 - val_top5_acc: 0.7724 - val_macro_f1score: 0.1004\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","382/382 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.8046 - top5_acc: 0.9574 - macro_f1score: 0.1522\n","Epoch 00019: val_loss did not improve from 2.09886\n","\n","Epoch 00019: val_accuracy did not improve from 0.54925\n","382/382 [==============================] - 684s 2s/step - loss: 0.6951 - accuracy: 0.8046 - top5_acc: 0.9574 - macro_f1score: 0.1522 - val_loss: 2.2198 - val_accuracy: 0.5374 - val_top5_acc: 0.7575 - val_macro_f1score: 0.0975\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","382/382 [==============================] - ETA: 0s - loss: 0.6321 - accuracy: 0.8206 - top5_acc: 0.9626 - macro_f1score: 0.1580\n","Epoch 00020: val_loss did not improve from 2.09886\n","\n","Epoch 00020: val_accuracy did not improve from 0.54925\n","382/382 [==============================] - 675s 2s/step - loss: 0.6321 - accuracy: 0.8206 - top5_acc: 0.9626 - macro_f1score: 0.1580 - val_loss: 2.2737 - val_accuracy: 0.5452 - val_top5_acc: 0.7544 - val_macro_f1score: 0.0971\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","382/382 [==============================] - ETA: 0s - loss: 0.6019 - accuracy: 0.8273 - top5_acc: 0.9665 - macro_f1score: 0.1608\n","Epoch 00021: val_loss did not improve from 2.09886\n","\n","Epoch 00021: val_accuracy did not improve from 0.54925\n","382/382 [==============================] - 666s 2s/step - loss: 0.6019 - accuracy: 0.8273 - top5_acc: 0.9665 - macro_f1score: 0.1608 - val_loss: 2.3523 - val_accuracy: 0.5469 - val_top5_acc: 0.7629 - val_macro_f1score: 0.1011\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","382/382 [==============================] - ETA: 0s - loss: 0.5394 - accuracy: 0.8449 - top5_acc: 0.9721 - macro_f1score: 0.1656\n","Epoch 00022: val_loss did not improve from 2.09886\n","\n","Epoch 00022: val_accuracy did not improve from 0.54925\n","382/382 [==============================] - 671s 2s/step - loss: 0.5394 - accuracy: 0.8449 - top5_acc: 0.9721 - macro_f1score: 0.1656 - val_loss: 2.4196 - val_accuracy: 0.5367 - val_top5_acc: 0.7459 - val_macro_f1score: 0.1007\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","382/382 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.8598 - top5_acc: 0.9794 - macro_f1score: 0.1695\n","Epoch 00023: val_loss did not improve from 2.09886\n","\n","Epoch 00023: val_accuracy did not improve from 0.54925\n","382/382 [==============================] - 673s 2s/step - loss: 0.4800 - accuracy: 0.8598 - top5_acc: 0.9794 - macro_f1score: 0.1695 - val_loss: 2.5976 - val_accuracy: 0.5166 - val_top5_acc: 0.7412 - val_macro_f1score: 0.0972\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","382/382 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.8691 - top5_acc: 0.9817 - macro_f1score: 0.1727\n","Epoch 00024: val_loss did not improve from 2.09886\n","\n","Epoch 00024: val_accuracy did not improve from 0.54925\n","382/382 [==============================] - 688s 2s/step - loss: 0.4456 - accuracy: 0.8691 - top5_acc: 0.9817 - macro_f1score: 0.1727 - val_loss: 2.5310 - val_accuracy: 0.5455 - val_top5_acc: 0.7578 - val_macro_f1score: 0.1031\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","382/382 [==============================] - ETA: 0s - loss: 0.4133 - accuracy: 0.8776 - top5_acc: 0.9852 - macro_f1score: 0.1751\n","Epoch 00025: val_loss did not improve from 2.09886\n","\n","Epoch 00025: val_accuracy improved from 0.54925 to 0.55367, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/025.h5\n","382/382 [==============================] - 684s 2s/step - loss: 0.4133 - accuracy: 0.8776 - top5_acc: 0.9852 - macro_f1score: 0.1751 - val_loss: 2.4578 - val_accuracy: 0.5537 - val_top5_acc: 0.7575 - val_macro_f1score: 0.1061\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","382/382 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8884 - top5_acc: 0.9867 - macro_f1score: 0.1792\n","Epoch 00026: val_loss did not improve from 2.09886\n","\n","Epoch 00026: val_accuracy did not improve from 0.55367\n","382/382 [==============================] - 677s 2s/step - loss: 0.3798 - accuracy: 0.8884 - top5_acc: 0.9867 - macro_f1score: 0.1792 - val_loss: 2.5900 - val_accuracy: 0.5187 - val_top5_acc: 0.7371 - val_macro_f1score: 0.0968\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","382/382 [==============================] - ETA: 0s - loss: 0.3449 - accuracy: 0.8977 - top5_acc: 0.9901 - macro_f1score: 0.1815\n","Epoch 00027: val_loss did not improve from 2.09886\n","\n","Epoch 00027: val_accuracy did not improve from 0.55367\n","382/382 [==============================] - 674s 2s/step - loss: 0.3449 - accuracy: 0.8977 - top5_acc: 0.9901 - macro_f1score: 0.1815 - val_loss: 2.5652 - val_accuracy: 0.5211 - val_top5_acc: 0.7456 - val_macro_f1score: 0.0959\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","382/382 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.9000 - top5_acc: 0.9895 - macro_f1score: 0.1827\n","Epoch 00028: val_loss did not improve from 2.09886\n","\n","Epoch 00028: val_accuracy improved from 0.55367 to 0.56793, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/028.h5\n","382/382 [==============================] - 674s 2s/step - loss: 0.3369 - accuracy: 0.9000 - top5_acc: 0.9895 - macro_f1score: 0.1827 - val_loss: 2.3643 - val_accuracy: 0.5679 - val_top5_acc: 0.7724 - val_macro_f1score: 0.1068\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","382/382 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.9049 - top5_acc: 0.9909 - macro_f1score: 0.1848\n","Epoch 00029: val_loss did not improve from 2.09886\n","\n","Epoch 00029: val_accuracy improved from 0.56793 to 0.57099, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/029.h5\n","382/382 [==============================] - 665s 2s/step - loss: 0.3224 - accuracy: 0.9049 - top5_acc: 0.9909 - macro_f1score: 0.1848 - val_loss: 2.3177 - val_accuracy: 0.5710 - val_top5_acc: 0.7711 - val_macro_f1score: 0.1072\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","382/382 [==============================] - ETA: 0s - loss: 0.2984 - accuracy: 0.9110 - top5_acc: 0.9924 - macro_f1score: 0.1863\n","Epoch 00030: val_loss did not improve from 2.09886\n","\n","Epoch 00030: val_accuracy did not improve from 0.57099\n","382/382 [==============================] - 642s 2s/step - loss: 0.2984 - accuracy: 0.9110 - top5_acc: 0.9924 - macro_f1score: 0.1863 - val_loss: 2.5260 - val_accuracy: 0.5591 - val_top5_acc: 0.7615 - val_macro_f1score: 0.1066\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","382/382 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9730 - top5_acc: 0.9989 - macro_f1score: 0.2031\n","Epoch 00031: val_loss improved from 2.09886 to 1.98605, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/031.h5\n","\n","Epoch 00031: val_accuracy improved from 0.57099 to 0.64096, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/031.h5\n","382/382 [==============================] - 668s 2s/step - loss: 0.1050 - accuracy: 0.9730 - top5_acc: 0.9989 - macro_f1score: 0.2031 - val_loss: 1.9861 - val_accuracy: 0.6410 - val_top5_acc: 0.8224 - val_macro_f1score: 0.1250\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9868 - top5_acc: 0.9998 - macro_f1score: 0.2077\n","Epoch 00032: val_loss did not improve from 1.98605\n","\n","Epoch 00032: val_accuracy improved from 0.64096 to 0.64232, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/032.h5\n","382/382 [==============================] - 684s 2s/step - loss: 0.0576 - accuracy: 0.9868 - top5_acc: 0.9998 - macro_f1score: 0.2077 - val_loss: 2.0246 - val_accuracy: 0.6423 - val_top5_acc: 0.8247 - val_macro_f1score: 0.1304\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9903 - top5_acc: 0.9997 - macro_f1score: 0.2095\n","Epoch 00033: val_loss did not improve from 1.98605\n","\n","Epoch 00033: val_accuracy improved from 0.64232 to 0.64436, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/033.h5\n","382/382 [==============================] - 684s 2s/step - loss: 0.0450 - accuracy: 0.9903 - top5_acc: 0.9997 - macro_f1score: 0.2095 - val_loss: 2.0257 - val_accuracy: 0.6444 - val_top5_acc: 0.8264 - val_macro_f1score: 0.1279\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9922 - top5_acc: 0.9996 - macro_f1score: 0.2098\n","Epoch 00034: val_loss did not improve from 1.98605\n","\n","Epoch 00034: val_accuracy improved from 0.64436 to 0.64878, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/034.h5\n","382/382 [==============================] - 676s 2s/step - loss: 0.0373 - accuracy: 0.9922 - top5_acc: 0.9996 - macro_f1score: 0.2098 - val_loss: 2.0256 - val_accuracy: 0.6488 - val_top5_acc: 0.8278 - val_macro_f1score: 0.1284\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9925 - top5_acc: 0.9999 - macro_f1score: 0.2101\n","Epoch 00035: val_loss did not improve from 1.98605\n","\n","Epoch 00035: val_accuracy improved from 0.64878 to 0.65014, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/035.h5\n","382/382 [==============================] - 682s 2s/step - loss: 0.0353 - accuracy: 0.9925 - top5_acc: 0.9999 - macro_f1score: 0.2101 - val_loss: 2.0774 - val_accuracy: 0.6501 - val_top5_acc: 0.8193 - val_macro_f1score: 0.1292\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9942 - top5_acc: 0.9998 - macro_f1score: 0.2114\n","Epoch 00036: val_loss did not improve from 1.98605\n","\n","Epoch 00036: val_accuracy did not improve from 0.65014\n","382/382 [==============================] - 671s 2s/step - loss: 0.0309 - accuracy: 0.9942 - top5_acc: 0.9998 - macro_f1score: 0.2114 - val_loss: 2.1155 - val_accuracy: 0.6461 - val_top5_acc: 0.8200 - val_macro_f1score: 0.1306\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9940 - top5_acc: 0.9999 - macro_f1score: 0.2105\n","Epoch 00037: val_loss did not improve from 1.98605\n","\n","Epoch 00037: val_accuracy improved from 0.65014 to 0.65217, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/037.h5\n","382/382 [==============================] - 659s 2s/step - loss: 0.0294 - accuracy: 0.9940 - top5_acc: 0.9999 - macro_f1score: 0.2105 - val_loss: 2.0714 - val_accuracy: 0.6522 - val_top5_acc: 0.8237 - val_macro_f1score: 0.1291\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9942 - top5_acc: 0.9999 - macro_f1score: 0.2105\n","Epoch 00038: val_loss did not improve from 1.98605\n","\n","Epoch 00038: val_accuracy did not improve from 0.65217\n","382/382 [==============================] - 663s 2s/step - loss: 0.0297 - accuracy: 0.9942 - top5_acc: 0.9999 - macro_f1score: 0.2105 - val_loss: 2.1392 - val_accuracy: 0.6396 - val_top5_acc: 0.8179 - val_macro_f1score: 0.1284\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9947 - top5_acc: 0.9999 - macro_f1score: 0.2111\n","Epoch 00039: val_loss did not improve from 1.98605\n","\n","Epoch 00039: val_accuracy did not improve from 0.65217\n","382/382 [==============================] - 643s 2s/step - loss: 0.0279 - accuracy: 0.9947 - top5_acc: 0.9999 - macro_f1score: 0.2111 - val_loss: 2.0716 - val_accuracy: 0.6464 - val_top5_acc: 0.8251 - val_macro_f1score: 0.1287\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9959 - top5_acc: 0.9999 - macro_f1score: 0.2107\n","Epoch 00040: val_loss did not improve from 1.98605\n","\n","Epoch 00040: val_accuracy did not improve from 0.65217\n","382/382 [==============================] - 665s 2s/step - loss: 0.0246 - accuracy: 0.9959 - top5_acc: 0.9999 - macro_f1score: 0.2107 - val_loss: 2.0702 - val_accuracy: 0.6478 - val_top5_acc: 0.8217 - val_macro_f1score: 0.1297\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9953 - top5_acc: 1.0000 - macro_f1score: 0.2105\n","Epoch 00041: val_loss did not improve from 1.98605\n","\n","Epoch 00041: val_accuracy did not improve from 0.65217\n","382/382 [==============================] - 669s 2s/step - loss: 0.0264 - accuracy: 0.9953 - top5_acc: 1.0000 - macro_f1score: 0.2105 - val_loss: 2.0612 - val_accuracy: 0.6389 - val_top5_acc: 0.8173 - val_macro_f1score: 0.1271\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9953 - top5_acc: 0.9999 - macro_f1score: 0.2099\n","Epoch 00042: val_loss did not improve from 1.98605\n","\n","Epoch 00042: val_accuracy improved from 0.65217 to 0.65319, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/042.h5\n","382/382 [==============================] - 649s 2s/step - loss: 0.0276 - accuracy: 0.9953 - top5_acc: 0.9999 - macro_f1score: 0.2099 - val_loss: 2.0149 - val_accuracy: 0.6532 - val_top5_acc: 0.8227 - val_macro_f1score: 0.1320\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9954 - top5_acc: 1.0000 - macro_f1score: 0.2112\n","Epoch 00043: val_loss did not improve from 1.98605\n","\n","Epoch 00043: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 651s 2s/step - loss: 0.0258 - accuracy: 0.9954 - top5_acc: 1.0000 - macro_f1score: 0.2112 - val_loss: 2.0522 - val_accuracy: 0.6437 - val_top5_acc: 0.8217 - val_macro_f1score: 0.1274\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9951 - top5_acc: 1.0000 - macro_f1score: 0.2102\n","Epoch 00044: val_loss did not improve from 1.98605\n","\n","Epoch 00044: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 662s 2s/step - loss: 0.0260 - accuracy: 0.9951 - top5_acc: 1.0000 - macro_f1score: 0.2102 - val_loss: 1.9972 - val_accuracy: 0.6440 - val_top5_acc: 0.8217 - val_macro_f1score: 0.1257\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9963 - top5_acc: 0.9999 - macro_f1score: 0.2108\n","Epoch 00045: val_loss did not improve from 1.98605\n","\n","Epoch 00045: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 657s 2s/step - loss: 0.0254 - accuracy: 0.9963 - top5_acc: 0.9999 - macro_f1score: 0.2108 - val_loss: 2.0023 - val_accuracy: 0.6372 - val_top5_acc: 0.8190 - val_macro_f1score: 0.1258\n","Learning rate:  0.0001\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 46/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9967 - top5_acc: 1.0000 - macro_f1score: 0.2118\n","Epoch 00046: val_loss did not improve from 1.98605\n","\n","Epoch 00046: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 655s 2s/step - loss: 0.0254 - accuracy: 0.9967 - top5_acc: 1.0000 - macro_f1score: 0.2118 - val_loss: 2.0459 - val_accuracy: 0.6396 - val_top5_acc: 0.8152 - val_macro_f1score: 0.1279\n","Learning rate:  0.0001\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 47/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9965 - top5_acc: 1.0000 - macro_f1score: 0.2113\n","Epoch 00047: val_loss improved from 1.98605 to 1.96039, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/047.h5\n","\n","Epoch 00047: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 641s 2s/step - loss: 0.0243 - accuracy: 0.9965 - top5_acc: 1.0000 - macro_f1score: 0.2113 - val_loss: 1.9604 - val_accuracy: 0.6433 - val_top5_acc: 0.8224 - val_macro_f1score: 0.1270\n","Learning rate:  0.0001\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 48/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9971 - top5_acc: 0.9999 - macro_f1score: 0.2109\n","Epoch 00048: val_loss did not improve from 1.96039\n","\n","Epoch 00048: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 665s 2s/step - loss: 0.0251 - accuracy: 0.9971 - top5_acc: 0.9999 - macro_f1score: 0.2109 - val_loss: 1.9734 - val_accuracy: 0.6427 - val_top5_acc: 0.8207 - val_macro_f1score: 0.1267\n","Learning rate:  0.0001\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 49/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9953 - top5_acc: 1.0000 - macro_f1score: 0.2112\n","Epoch 00049: val_loss did not improve from 1.96039\n","\n","Epoch 00049: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 666s 2s/step - loss: 0.0287 - accuracy: 0.9953 - top5_acc: 1.0000 - macro_f1score: 0.2112 - val_loss: 1.9631 - val_accuracy: 0.6423 - val_top5_acc: 0.8193 - val_macro_f1score: 0.1260\n","Learning rate:  0.0001\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 50/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9970 - top5_acc: 1.0000 - macro_f1score: 0.2115\n","Epoch 00050: val_loss improved from 1.96039 to 1.90830, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/050.h5\n","\n","Epoch 00050: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 664s 2s/step - loss: 0.0251 - accuracy: 0.9970 - top5_acc: 1.0000 - macro_f1score: 0.2115 - val_loss: 1.9083 - val_accuracy: 0.6447 - val_top5_acc: 0.8271 - val_macro_f1score: 0.1257\n","Learning rate:  0.0001\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 51/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9971 - top5_acc: 1.0000 - macro_f1score: 0.2105\n","Epoch 00051: val_loss did not improve from 1.90830\n","\n","Epoch 00051: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 665s 2s/step - loss: 0.0258 - accuracy: 0.9971 - top5_acc: 1.0000 - macro_f1score: 0.2105 - val_loss: 1.9585 - val_accuracy: 0.6474 - val_top5_acc: 0.8234 - val_macro_f1score: 0.1267\n","Learning rate:  0.0001\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 52/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9972 - top5_acc: 0.9999 - macro_f1score: 0.2105\n","Epoch 00052: val_loss did not improve from 1.90830\n","\n","Epoch 00052: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 673s 2s/step - loss: 0.0246 - accuracy: 0.9972 - top5_acc: 0.9999 - macro_f1score: 0.2105 - val_loss: 1.9358 - val_accuracy: 0.6440 - val_top5_acc: 0.8152 - val_macro_f1score: 0.1233\n","Learning rate:  0.0001\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 53/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9971 - top5_acc: 1.0000 - macro_f1score: 0.2108\n","Epoch 00053: val_loss did not improve from 1.90830\n","\n","Epoch 00053: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 701s 2s/step - loss: 0.0253 - accuracy: 0.9971 - top5_acc: 1.0000 - macro_f1score: 0.2108 - val_loss: 1.9447 - val_accuracy: 0.6495 - val_top5_acc: 0.8220 - val_macro_f1score: 0.1266\n","Learning rate:  0.0001\n","\n","Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 54/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9966 - top5_acc: 1.0000 - macro_f1score: 0.2103\n","Epoch 00054: val_loss did not improve from 1.90830\n","\n","Epoch 00054: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 712s 2s/step - loss: 0.0276 - accuracy: 0.9966 - top5_acc: 1.0000 - macro_f1score: 0.2103 - val_loss: 1.9347 - val_accuracy: 0.6403 - val_top5_acc: 0.8173 - val_macro_f1score: 0.1255\n","Learning rate:  0.0001\n","\n","Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 55/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9973 - top5_acc: 1.0000 - macro_f1score: 0.2112\n","Epoch 00055: val_loss improved from 1.90830 to 1.86367, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/055.h5\n","\n","Epoch 00055: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 713s 2s/step - loss: 0.0255 - accuracy: 0.9973 - top5_acc: 1.0000 - macro_f1score: 0.2112 - val_loss: 1.8637 - val_accuracy: 0.6457 - val_top5_acc: 0.8244 - val_macro_f1score: 0.1280\n","Learning rate:  0.0001\n","\n","Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 56/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9973 - top5_acc: 1.0000 - macro_f1score: 0.2111\n","Epoch 00056: val_loss did not improve from 1.86367\n","\n","Epoch 00056: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 696s 2s/step - loss: 0.0264 - accuracy: 0.9973 - top5_acc: 1.0000 - macro_f1score: 0.2111 - val_loss: 1.9877 - val_accuracy: 0.6294 - val_top5_acc: 0.8162 - val_macro_f1score: 0.1225\n","Learning rate:  0.0001\n","\n","Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 57/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9963 - top5_acc: 1.0000 - macro_f1score: 0.2110\n","Epoch 00057: val_loss did not improve from 1.86367\n","\n","Epoch 00057: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 672s 2s/step - loss: 0.0289 - accuracy: 0.9963 - top5_acc: 1.0000 - macro_f1score: 0.2110 - val_loss: 1.9336 - val_accuracy: 0.6498 - val_top5_acc: 0.8159 - val_macro_f1score: 0.1273\n","Learning rate:  0.0001\n","\n","Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 58/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9961 - top5_acc: 1.0000 - macro_f1score: 0.2102\n","Epoch 00058: val_loss did not improve from 1.86367\n","\n","Epoch 00058: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 672s 2s/step - loss: 0.0294 - accuracy: 0.9961 - top5_acc: 1.0000 - macro_f1score: 0.2102 - val_loss: 1.8946 - val_accuracy: 0.6355 - val_top5_acc: 0.8183 - val_macro_f1score: 0.1252\n","Learning rate:  0.0001\n","\n","Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 59/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9965 - top5_acc: 1.0000 - macro_f1score: 0.2115\n","Epoch 00059: val_loss did not improve from 1.86367\n","\n","Epoch 00059: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 674s 2s/step - loss: 0.0285 - accuracy: 0.9965 - top5_acc: 1.0000 - macro_f1score: 0.2115 - val_loss: 1.8985 - val_accuracy: 0.6437 - val_top5_acc: 0.8213 - val_macro_f1score: 0.1245\n","Learning rate:  0.0001\n","\n","Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 60/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9961 - top5_acc: 0.9999 - macro_f1score: 0.2108\n","Epoch 00060: val_loss did not improve from 1.86367\n","\n","Epoch 00060: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 673s 2s/step - loss: 0.0310 - accuracy: 0.9961 - top5_acc: 0.9999 - macro_f1score: 0.2108 - val_loss: 1.9170 - val_accuracy: 0.6294 - val_top5_acc: 0.8149 - val_macro_f1score: 0.1241\n","Learning rate:  1e-05\n","\n","Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 61/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.2119\n","Epoch 00061: val_loss improved from 1.86367 to 1.80637, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/061.h5\n","\n","Epoch 00061: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 676s 2s/step - loss: 0.0234 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.2119 - val_loss: 1.8064 - val_accuracy: 0.6505 - val_top5_acc: 0.8240 - val_macro_f1score: 0.1268\n","Learning rate:  1e-05\n","\n","Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 62/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9988 - top5_acc: 1.0000 - macro_f1score: 0.2119\n","Epoch 00062: val_loss improved from 1.80637 to 1.80229, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/062.h5\n","\n","Epoch 00062: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 652s 2s/step - loss: 0.0200 - accuracy: 0.9988 - top5_acc: 1.0000 - macro_f1score: 0.2119 - val_loss: 1.8023 - val_accuracy: 0.6484 - val_top5_acc: 0.8244 - val_macro_f1score: 0.1264\n","Learning rate:  1e-05\n","\n","Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 63/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9988 - top5_acc: 1.0000 - macro_f1score: 0.2120\n","Epoch 00063: val_loss improved from 1.80229 to 1.77021, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/063.h5\n","\n","Epoch 00063: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 636s 2s/step - loss: 0.0208 - accuracy: 0.9988 - top5_acc: 1.0000 - macro_f1score: 0.2120 - val_loss: 1.7702 - val_accuracy: 0.6498 - val_top5_acc: 0.8237 - val_macro_f1score: 0.1267\n","Learning rate:  1e-05\n","\n","Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 64/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9988 - top5_acc: 1.0000 - macro_f1score: 0.2119\n","Epoch 00064: val_loss improved from 1.77021 to 1.76447, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/064.h5\n","\n","Epoch 00064: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 629s 2s/step - loss: 0.0228 - accuracy: 0.9988 - top5_acc: 1.0000 - macro_f1score: 0.2119 - val_loss: 1.7645 - val_accuracy: 0.6488 - val_top5_acc: 0.8254 - val_macro_f1score: 0.1247\n","Learning rate:  1e-05\n","\n","Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 65/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9991 - top5_acc: 1.0000 - macro_f1score: 0.2115\n","Epoch 00065: val_loss improved from 1.76447 to 1.74532, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/065.h5\n","\n","Epoch 00065: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 632s 2s/step - loss: 0.0244 - accuracy: 0.9991 - top5_acc: 1.0000 - macro_f1score: 0.2115 - val_loss: 1.7453 - val_accuracy: 0.6488 - val_top5_acc: 0.8213 - val_macro_f1score: 0.1232\n","Learning rate:  1e-05\n","\n","Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 66/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9989 - top5_acc: 1.0000 - macro_f1score: 0.2121\n","Epoch 00066: val_loss improved from 1.74532 to 1.73773, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/066.h5\n","\n","Epoch 00066: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 629s 2s/step - loss: 0.0267 - accuracy: 0.9989 - top5_acc: 1.0000 - macro_f1score: 0.2121 - val_loss: 1.7377 - val_accuracy: 0.6491 - val_top5_acc: 0.8247 - val_macro_f1score: 0.1237\n","Learning rate:  1e-05\n","\n","Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 67/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9989 - top5_acc: 1.0000 - macro_f1score: 0.2122\n","Epoch 00067: val_loss improved from 1.73773 to 1.73082, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/067.h5\n","\n","Epoch 00067: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 638s 2s/step - loss: 0.0286 - accuracy: 0.9989 - top5_acc: 1.0000 - macro_f1score: 0.2122 - val_loss: 1.7308 - val_accuracy: 0.6437 - val_top5_acc: 0.8257 - val_macro_f1score: 0.1244\n","Learning rate:  1e-05\n","\n","Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 68/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9988 - top5_acc: 1.0000 - macro_f1score: 0.2119\n","Epoch 00068: val_loss improved from 1.73082 to 1.70703, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v1/068.h5\n","\n","Epoch 00068: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 648s 2s/step - loss: 0.0312 - accuracy: 0.9988 - top5_acc: 1.0000 - macro_f1score: 0.2119 - val_loss: 1.7070 - val_accuracy: 0.6444 - val_top5_acc: 0.8268 - val_macro_f1score: 0.1238\n","Learning rate:  1e-05\n","\n","Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 69/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9989 - top5_acc: 1.0000 - macro_f1score: 0.2127\n","Epoch 00069: val_loss did not improve from 1.70703\n","\n","Epoch 00069: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 659s 2s/step - loss: 0.0337 - accuracy: 0.9989 - top5_acc: 1.0000 - macro_f1score: 0.2127 - val_loss: 1.7088 - val_accuracy: 0.6440 - val_top5_acc: 0.8251 - val_macro_f1score: 0.1213\n","Learning rate:  1e-05\n","\n","Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 70/70\n","382/382 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9990 - top5_acc: 1.0000 - macro_f1score: 0.2115\n","Epoch 00070: val_loss did not improve from 1.70703\n","\n","Epoch 00070: val_accuracy did not improve from 0.65319\n","382/382 [==============================] - 663s 2s/step - loss: 0.0366 - accuracy: 0.9990 - top5_acc: 1.0000 - macro_f1score: 0.2115 - val_loss: 1.7212 - val_accuracy: 0.6423 - val_top5_acc: 0.8213 - val_macro_f1score: 0.1228\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S8EgwffcuTfI"},"source":["### 3) Inception-ResNet-V1 Evaluate\n"]},{"cell_type":"code","metadata":{"id":"D7tz2zjeuTfL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605385617436,"user_tz":-540,"elapsed":62228616,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"300080cb-c94f-44ea-d0bc-c0b2a98c5371"},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["48/48 [==============================] - 1233s 26s/step - loss: 1.7703 - accuracy: 0.6367 - top5_acc: 0.8190 - macro_f1score: 0.1179\n","[Test Loss: 1.7703 /  Test Top-1 Accuracy: 0.6367 / Test Top-5 Accuracy: 0.8190 / Test Macro f1: 0.1179]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PBq7ajsyuTfN"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFQNe0dfuTfP"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zsHYi8xGuTfT"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'Inception_ResNet_v1.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXjdmTfLuTfW"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEgWb_-DuTfY","colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"status":"ok","timestamp":1605385618829,"user_tz":-540,"elapsed":62229970,"user":{"displayName":"이동규","photoUrl":"","userId":"04369103463727261091"}},"outputId":"04ae64d9-afdd-4211-da08-c0957df1a7c0"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"0RgXbQzqwGoP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ZRdW6Xk60Jm"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0z6BwcAulnw","executionInfo":{"status":"ok","timestamp":1606099484720,"user_tz":-540,"elapsed":1098,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / Inception_Resnet_V1"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c","executionInfo":{"status":"ok","timestamp":1606099485862,"user_tz":-540,"elapsed":2229,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak","executionInfo":{"status":"ok","timestamp":1606099485865,"user_tz":-540,"elapsed":2218,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pFcw51AuDG4","executionInfo":{"status":"ok","timestamp":1606099499013,"user_tz":-540,"elapsed":15341,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["model=load_model(os.path.join(dir,'model_output',number,'Inception_ResNet_v1','068.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWlrnY9EuDG-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606101112728,"user_tz":-540,"elapsed":1629050,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"0f8a287d-5a8a-4f96-ba59-35b4331cf515"},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["48/48 [==============================] - 1549s 32s/step - loss: 1.7722 - accuracy: 0.6361 - top5_acc: 0.8200 - macro_f1score: 0.1207\n","[Test Loss: 1.7722 /  Test Top-1 Accuracy: 0.6361 / Test Top-5 Accuracy: 0.8200 / Test Macro f1: 0.1207]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LBSIISJWFFs4","executionInfo":{"status":"ok","timestamp":1606101112733,"user_tz":-540,"elapsed":1629050,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":[""],"execution_count":23,"outputs":[]}]}