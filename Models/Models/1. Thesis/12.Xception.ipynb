{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"12.Xception.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"E-OCKgEwJfTn","executionInfo":{"status":"ok","timestamp":1605236969241,"user_tz":-540,"elapsed":709,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["### 참고 : https://github.com/fchollet/deep-learning-models/blob/master/xception.py"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [Xception]"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original Xception\n","```\n","1) Support Functions\n","2) Almost Original Xception\n","```\n","3. Xception\n","```\n","1) Xception\n","2) Xception Evaluate\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages\n"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","executionInfo":{"status":"ok","timestamp":1605237046012,"user_tz":-540,"elapsed":77464,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"9d9fbf29-cfeb-4800-a69a-f3367431f04d","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","executionInfo":{"status":"ok","timestamp":1605237046655,"user_tz":-540,"elapsed":78096,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"19787a99-b4ea-45d5-df2f-64f1badbc6cf","colab":{"base_uri":"https://localhost:8080/"}},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1605237050818,"user_tz":-540,"elapsed":82210,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1605237050821,"user_tz":-540,"elapsed":82210,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","executionInfo":{"status":"ok","timestamp":1605237050822,"user_tz":-540,"elapsed":82192,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"8a10123d-c710-436f-9133-c2643ec90269","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","executionInfo":{"status":"ok","timestamp":1605237050824,"user_tz":-540,"elapsed":82182,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"74ff2a60-da23-4daf-d5fe-4cac20e6a108","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","executionInfo":{"status":"ok","timestamp":1605237056734,"user_tz":-540,"elapsed":88014,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"4289cef3-96b7-4972-bb9e-84dd5e6b2dd3","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Kf057Rw2yigs","executionInfo":{"status":"ok","timestamp":1605237056738,"user_tz":-540,"elapsed":88005,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"f9fa6800-a4d9-49e3-8fea-262a8b60696d","colab":{"base_uri":"https://localhost:8080/"}},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 1329536936715964392\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 13162594008826260133\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 9717835033010762049\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15695549568\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 9423526127792629098\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k5ubMy33cQZV","executionInfo":{"status":"ok","timestamp":1605237056740,"user_tz":-540,"elapsed":87993,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"953d2243-5b8b-433b-df9a-179d29556729","colab":{"base_uri":"https://localhost:8080/"}},"source":["!cat /proc/cpuinfo"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"BeJ7UtuOEgWY","executionInfo":{"status":"ok","timestamp":1605237056741,"user_tz":-540,"elapsed":87991,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CALTECH'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 299 # sizes after cropping\n","super_size = 330 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 32\n","weight_decay = 1e-6\n","epochs = 70"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1605237056742,"user_tz":-540,"elapsed":87989,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4wDCqXKpNBz","executionInfo":{"status":"ok","timestamp":1605237056743,"user_tz":-540,"elapsed":87987,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1605237056744,"user_tz":-540,"elapsed":87980,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ayj6GUEvpNB4"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"UVHXXOYqpNB4","executionInfo":{"status":"ok","timestamp":1605237056745,"user_tz":-540,"elapsed":87977,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1605237056746,"user_tz":-540,"elapsed":87958,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_6Z9x0vpNB8","executionInfo":{"status":"ok","timestamp":1605237056747,"user_tz":-540,"elapsed":87950,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qeao4HympNB9","executionInfo":{"status":"ok","timestamp":1605237144456,"user_tz":-540,"elapsed":175648,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"06fc4544-5caa-4e6c-a5c8-345d5276026c","colab":{"base_uri":"https://localhost:8080/"}},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Found 24509 images belonging to 257 classes.\n","Found 2980 images belonging to 257 classes.\n","Found 3118 images belonging to 257 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original Xception\n","---"]},{"cell_type":"markdown","metadata":{"id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS","executionInfo":{"status":"ok","timestamp":1605237144457,"user_tz":-540,"elapsed":175646,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vJixgnY7Z6j7"},"source":["### 2) Almost Original Xception\n"]},{"cell_type":"code","metadata":{"id":"xpAHo3rnaJKw","executionInfo":{"status":"ok","timestamp":1605237144457,"user_tz":-540,"elapsed":175641,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["def Xception(input_shape=None, classes=1000, name = \"Xception\", weight_decay = weight_decay):\n","\n","\n","    img_input = Input(shape=input_shape)\n","\n","\n","    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay), name='block1_conv1')(img_input)\n","    x = BatchNormalization(name='block1_conv1_bn')(x)\n","    x = Activation('relu', name='block1_conv1_act')(x)\n","    x = Conv2D(64, (3, 3), use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay), name='block1_conv2')(x)\n","    x = BatchNormalization(name='block1_conv2_bn')(x)\n","    x = Activation('relu', name='block1_conv2_act')(x)\n","\n","    residual = Conv2D(128, (1, 1), strides=(2, 2),\n","                      padding='same', use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    residual = BatchNormalization()(residual)\n","\n","    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block2_sepconv1')(x)\n","    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n","    x = Activation('relu', name='block2_sepconv2_act')(x)\n","    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block2_sepconv2')(x)\n","    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n","\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block2_pool')(x)\n","    x = add([x, residual])\n","\n","    residual = Conv2D(256, (1, 1), strides=(2, 2),\n","                      padding='same', use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    residual = BatchNormalization()(residual)\n","\n","    x = Activation('relu', name='block3_sepconv1_act')(x)\n","    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block3_sepconv1')(x)\n","    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n","    x = Activation('relu', name='block3_sepconv2_act')(x)\n","    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block3_sepconv2')(x)\n","    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n","\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block3_pool')(x)\n","    x = add([x, residual])\n","\n","    residual = Conv2D(728, (1, 1), strides=(2, 2),\n","                      padding='same', use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    residual = BatchNormalization()(residual)\n","\n","    x = Activation('relu', name='block4_sepconv1_act')(x)\n","    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block4_sepconv1')(x)\n","    x = BatchNormalization(name='block4_sepconv1_bn')(x)\n","    x = Activation('relu', name='block4_sepconv2_act')(x)\n","    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block4_sepconv2')(x)\n","    x = BatchNormalization(name='block4_sepconv2_bn')(x)\n","\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block4_pool')(x)\n","    x = add([x, residual])\n","\n","    for i in range(8):\n","        residual = x\n","        prefix = 'block' + str(i + 5)\n","\n","        x = Activation('relu', name=prefix + '_sepconv1_act')(x)\n","        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name=prefix + '_sepconv1')(x)\n","        x = BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n","        x = Activation('relu', name=prefix + '_sepconv2_act')(x)\n","        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name=prefix + '_sepconv2')(x)\n","        x = BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n","        x = Activation('relu', name=prefix + '_sepconv3_act')(x)\n","        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name=prefix + '_sepconv3')(x)\n","        x = BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n","\n","        x = add([x, residual])\n","\n","    residual = Conv2D(1024, (1, 1), strides=(2, 2),\n","                      padding='same', use_bias=False, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    residual = BatchNormalization()(residual)\n","\n","    x = Activation('relu', name='block13_sepconv1_act')(x)\n","    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block13_sepconv1')(x)\n","    x = BatchNormalization(name='block13_sepconv1_bn')(x)\n","    x = Activation('relu', name='block13_sepconv2_act')(x)\n","    x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block13_sepconv2')(x)\n","    x = BatchNormalization(name='block13_sepconv2_bn')(x)\n","\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block13_pool')(x)\n","    x = add([x, residual])\n","\n","    x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block14_sepconv1')(x)\n","    x = BatchNormalization(name='block14_sepconv1_bn')(x)\n","    x = Activation('relu', name='block14_sepconv1_act')(x)\n","\n","    x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay), name='block14_sepconv2')(x)\n","    x = BatchNormalization(name='block14_sepconv2_bn')(x)\n","    x = Activation('relu', name='block14_sepconv2_act')(x)\n","\n","\n","    x = GlobalAveragePooling2D(name='avg_pool')(x)\n","    x = Dropout(0.5)(x)\n","    x = Dense(classes, activation='softmax', kernel_regularizer=l2(weight_decay), name='predictions')(x)\n","\n","\n","    inputs = img_input\n","\n","    # Create model.\n","    model = Model(inputs, x, name=name)\n","\n","    return model\n"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOAp8LsWRMR6"},"source":["## 3. Xception\n","---"]},{"cell_type":"markdown","metadata":{"id":"18V3G5o-RMR7"},"source":["### 1) Xception"]},{"cell_type":"code","metadata":{"id":"5YOrZ2rhneyq","executionInfo":{"status":"ok","timestamp":1605237145927,"user_tz":-540,"elapsed":177107,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["model = Xception(input_sizes, classes=classes, name='Xception')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HuelUizNJWz","executionInfo":{"status":"ok","timestamp":1605237145928,"user_tz":-540,"elapsed":177059,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"e3295062-ee6c-4a1d-93b6-bb960836dfd3","colab":{"base_uri":"https://localhost:8080/"}},"source":["model.summary()"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Model: \"Xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n","                                                                 add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n","                                                                 add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n","                                                                 add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n","                                                                 add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n","                                                                 add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n","                                                                 add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n","                                                                 batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 2048)         0           avg_pool[0][0]                   \n","__________________________________________________________________________________________________\n","predictions (Dense)             (None, 257)          526593      dropout[0][0]                    \n","==================================================================================================\n","Total params: 21,388,073\n","Trainable params: 21,333,545\n","Non-trainable params: 54,528\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yNCT3g8eE6vT","executionInfo":{"status":"ok","timestamp":1605237145931,"user_tz":-540,"elapsed":177057,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0hcwfHt4efG","executionInfo":{"status":"ok","timestamp":1605237146603,"user_tz":-540,"elapsed":177722,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# AdamW 시작 / AdamWR은 epoch을 500번은 돌려야 될 것 같아 힘듦.\n","# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWz2b3riipUA","executionInfo":{"status":"ok","timestamp":1605237146605,"user_tz":-540,"elapsed":177718,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoWLeggG6dBf","executionInfo":{"status":"ok","timestamp":1605237146607,"user_tz":-540,"elapsed":177718,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9pnv0cw6dBm","executionInfo":{"status":"ok","timestamp":1605296013457,"user_tz":-540,"elapsed":59044535,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"3eb8125d-c63e-497b-dc49-5f2d7663c03c","colab":{"base_uri":"https://localhost:8080/"}},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs, verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for block1_conv1/kernel:0\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for block1_conv2/kernel:0\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for predictions/kernel:0\n","765/765 [==============================] - ETA: 0s - loss: 5.1879 - accuracy: 0.0715 - top5_acc: 0.1615 - macro_f1score: 4.4709e-04 \n","Epoch 00001: val_loss improved from inf to 4.88790, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.08569, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/001.h5\n","765/765 [==============================] - 17349s 23s/step - loss: 5.1879 - accuracy: 0.0715 - top5_acc: 0.1615 - macro_f1score: 4.4709e-04 - val_loss: 4.8879 - val_accuracy: 0.0857 - val_top5_acc: 0.1935 - val_macro_f1score: 0.0031\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","765/765 [==============================] - ETA: 0s - loss: 4.5502 - accuracy: 0.1270 - top5_acc: 0.2533 - macro_f1score: 0.0037\n","Epoch 00002: val_loss did not improve from 4.88790\n","\n","Epoch 00002: val_accuracy improved from 0.08569 to 0.09308, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/002.h5\n","765/765 [==============================] - 608s 794ms/step - loss: 4.5502 - accuracy: 0.1270 - top5_acc: 0.2533 - macro_f1score: 0.0037 - val_loss: 5.6358 - val_accuracy: 0.0931 - val_top5_acc: 0.1986 - val_macro_f1score: 0.0031\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","765/765 [==============================] - ETA: 0s - loss: 4.0517 - accuracy: 0.1855 - top5_acc: 0.3559 - macro_f1score: 0.0067\n","Epoch 00003: val_loss improved from 4.88790 to 4.05155, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/003.h5\n","\n","Epoch 00003: val_accuracy improved from 0.09308 to 0.19019, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/003.h5\n","765/765 [==============================] - 603s 788ms/step - loss: 4.0517 - accuracy: 0.1855 - top5_acc: 0.3559 - macro_f1score: 0.0067 - val_loss: 4.0516 - val_accuracy: 0.1902 - val_top5_acc: 0.3626 - val_macro_f1score: 0.0082\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","765/765 [==============================] - ETA: 0s - loss: 3.5681 - accuracy: 0.2535 - top5_acc: 0.4631 - macro_f1score: 0.0109\n","Epoch 00004: val_loss improved from 4.05155 to 3.70676, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/004.h5\n","\n","Epoch 00004: val_accuracy improved from 0.19019 to 0.25000, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/004.h5\n","765/765 [==============================] - 605s 790ms/step - loss: 3.5681 - accuracy: 0.2535 - top5_acc: 0.4631 - macro_f1score: 0.0109 - val_loss: 3.7068 - val_accuracy: 0.2500 - val_top5_acc: 0.4567 - val_macro_f1score: 0.0135\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","765/765 [==============================] - ETA: 0s - loss: 3.1225 - accuracy: 0.3247 - top5_acc: 0.5548 - macro_f1score: 0.0169\n","Epoch 00005: val_loss improved from 3.70676 to 3.61392, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/005.h5\n","\n","Epoch 00005: val_accuracy improved from 0.25000 to 0.29469, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/005.h5\n","765/765 [==============================] - 606s 792ms/step - loss: 3.1225 - accuracy: 0.3247 - top5_acc: 0.5548 - macro_f1score: 0.0169 - val_loss: 3.6139 - val_accuracy: 0.2947 - val_top5_acc: 0.5020 - val_macro_f1score: 0.0192\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","765/765 [==============================] - ETA: 0s - loss: 2.7744 - accuracy: 0.3859 - top5_acc: 0.6245 - macro_f1score: 0.0234\n","Epoch 00006: val_loss improved from 3.61392 to 3.36920, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/006.h5\n","\n","Epoch 00006: val_accuracy improved from 0.29469 to 0.33905, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/006.h5\n","765/765 [==============================] - 603s 788ms/step - loss: 2.7744 - accuracy: 0.3859 - top5_acc: 0.6245 - macro_f1score: 0.0234 - val_loss: 3.3692 - val_accuracy: 0.3390 - val_top5_acc: 0.5659 - val_macro_f1score: 0.0261\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","765/765 [==============================] - ETA: 0s - loss: 2.4928 - accuracy: 0.4414 - top5_acc: 0.6834 - macro_f1score: 0.0299\n","Epoch 00007: val_loss improved from 3.36920 to 2.88431, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/007.h5\n","\n","Epoch 00007: val_accuracy improved from 0.33905 to 0.40255, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/007.h5\n","765/765 [==============================] - 603s 789ms/step - loss: 2.4928 - accuracy: 0.4414 - top5_acc: 0.6834 - macro_f1score: 0.0299 - val_loss: 2.8843 - val_accuracy: 0.4026 - val_top5_acc: 0.6438 - val_macro_f1score: 0.0325\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","765/765 [==============================] - ETA: 0s - loss: 2.2485 - accuracy: 0.4924 - top5_acc: 0.7282 - macro_f1score: 0.0360\n","Epoch 00008: val_loss improved from 2.88431 to 2.66583, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/008.h5\n","\n","Epoch 00008: val_accuracy improved from 0.40255 to 0.43548, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/008.h5\n","765/765 [==============================] - 604s 789ms/step - loss: 2.2485 - accuracy: 0.4924 - top5_acc: 0.7282 - macro_f1score: 0.0360 - val_loss: 2.6658 - val_accuracy: 0.4355 - val_top5_acc: 0.6747 - val_macro_f1score: 0.0362\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","765/765 [==============================] - ETA: 0s - loss: 2.0524 - accuracy: 0.5294 - top5_acc: 0.7604 - macro_f1score: 0.0420\n","Epoch 00009: val_loss did not improve from 2.66583\n","\n","Epoch 00009: val_accuracy did not improve from 0.43548\n","765/765 [==============================] - 602s 787ms/step - loss: 2.0524 - accuracy: 0.5294 - top5_acc: 0.7604 - macro_f1score: 0.0420 - val_loss: 2.7987 - val_accuracy: 0.4315 - val_top5_acc: 0.6707 - val_macro_f1score: 0.0357\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","765/765 [==============================] - ETA: 0s - loss: 1.8847 - accuracy: 0.5621 - top5_acc: 0.7898 - macro_f1score: 0.0469\n","Epoch 00010: val_loss did not improve from 2.66583\n","\n","Epoch 00010: val_accuracy did not improve from 0.43548\n","765/765 [==============================] - 602s 786ms/step - loss: 1.8847 - accuracy: 0.5621 - top5_acc: 0.7898 - macro_f1score: 0.0469 - val_loss: 2.7991 - val_accuracy: 0.4247 - val_top5_acc: 0.6475 - val_macro_f1score: 0.0345\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","765/765 [==============================] - ETA: 0s - loss: 1.7296 - accuracy: 0.5924 - top5_acc: 0.8157 - macro_f1score: 0.0513\n","Epoch 00011: val_loss improved from 2.66583 to 2.33563, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/011.h5\n","\n","Epoch 00011: val_accuracy improved from 0.43548 to 0.51915, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/011.h5\n","765/765 [==============================] - 604s 790ms/step - loss: 1.7296 - accuracy: 0.5924 - top5_acc: 0.8157 - macro_f1score: 0.0513 - val_loss: 2.3356 - val_accuracy: 0.5192 - val_top5_acc: 0.7211 - val_macro_f1score: 0.0445\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","765/765 [==============================] - ETA: 0s - loss: 1.5799 - accuracy: 0.6237 - top5_acc: 0.8418 - macro_f1score: 0.0566\n","Epoch 00012: val_loss did not improve from 2.33563\n","\n","Epoch 00012: val_accuracy did not improve from 0.51915\n","765/765 [==============================] - 599s 783ms/step - loss: 1.5799 - accuracy: 0.6237 - top5_acc: 0.8418 - macro_f1score: 0.0566 - val_loss: 2.4731 - val_accuracy: 0.5057 - val_top5_acc: 0.7224 - val_macro_f1score: 0.0472\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","765/765 [==============================] - ETA: 0s - loss: 1.4550 - accuracy: 0.6505 - top5_acc: 0.8606 - macro_f1score: 0.0603\n","Epoch 00013: val_loss did not improve from 2.33563\n","\n","Epoch 00013: val_accuracy did not improve from 0.51915\n","765/765 [==============================] - 598s 782ms/step - loss: 1.4550 - accuracy: 0.6505 - top5_acc: 0.8606 - macro_f1score: 0.0603 - val_loss: 2.5220 - val_accuracy: 0.5101 - val_top5_acc: 0.7214 - val_macro_f1score: 0.0484\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","765/765 [==============================] - ETA: 0s - loss: 1.3373 - accuracy: 0.6788 - top5_acc: 0.8793 - macro_f1score: 0.0647\n","Epoch 00014: val_loss improved from 2.33563 to 2.31442, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/014.h5\n","\n","Epoch 00014: val_accuracy improved from 0.51915 to 0.54671, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/014.h5\n","765/765 [==============================] - 601s 786ms/step - loss: 1.3373 - accuracy: 0.6788 - top5_acc: 0.8793 - macro_f1score: 0.0647 - val_loss: 2.3144 - val_accuracy: 0.5467 - val_top5_acc: 0.7500 - val_macro_f1score: 0.0525\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","765/765 [==============================] - ETA: 0s - loss: 1.2320 - accuracy: 0.7015 - top5_acc: 0.8937 - macro_f1score: 0.0680\n","Epoch 00015: val_loss improved from 2.31442 to 2.16160, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/015.h5\n","\n","Epoch 00015: val_accuracy improved from 0.54671 to 0.55242, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/015.h5\n","765/765 [==============================] - 603s 789ms/step - loss: 1.2320 - accuracy: 0.7015 - top5_acc: 0.8937 - macro_f1score: 0.0680 - val_loss: 2.1616 - val_accuracy: 0.5524 - val_top5_acc: 0.7574 - val_macro_f1score: 0.0523\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","765/765 [==============================] - ETA: 0s - loss: 1.1198 - accuracy: 0.7254 - top5_acc: 0.9113 - macro_f1score: 0.0715\n","Epoch 00016: val_loss did not improve from 2.16160\n","\n","Epoch 00016: val_accuracy did not improve from 0.55242\n","765/765 [==============================] - 601s 785ms/step - loss: 1.1198 - accuracy: 0.7254 - top5_acc: 0.9113 - macro_f1score: 0.0715 - val_loss: 2.5765 - val_accuracy: 0.5319 - val_top5_acc: 0.7419 - val_macro_f1score: 0.0534\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","765/765 [==============================] - ETA: 0s - loss: 1.0226 - accuracy: 0.7496 - top5_acc: 0.9247 - macro_f1score: 0.0753\n","Epoch 00017: val_loss did not improve from 2.16160\n","\n","Epoch 00017: val_accuracy did not improve from 0.55242\n","765/765 [==============================] - 599s 783ms/step - loss: 1.0226 - accuracy: 0.7496 - top5_acc: 0.9247 - macro_f1score: 0.0753 - val_loss: 2.7012 - val_accuracy: 0.5215 - val_top5_acc: 0.7204 - val_macro_f1score: 0.0521\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","765/765 [==============================] - ETA: 0s - loss: 0.9447 - accuracy: 0.7704 - top5_acc: 0.9352 - macro_f1score: 0.0781\n","Epoch 00018: val_loss did not improve from 2.16160\n","\n","Epoch 00018: val_accuracy improved from 0.55242 to 0.55847, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/018.h5\n","765/765 [==============================] - 599s 783ms/step - loss: 0.9447 - accuracy: 0.7704 - top5_acc: 0.9352 - macro_f1score: 0.0781 - val_loss: 2.3333 - val_accuracy: 0.5585 - val_top5_acc: 0.7594 - val_macro_f1score: 0.0571\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","765/765 [==============================] - ETA: 0s - loss: 0.8678 - accuracy: 0.7866 - top5_acc: 0.9469 - macro_f1score: 0.0810\n","Epoch 00019: val_loss did not improve from 2.16160\n","\n","Epoch 00019: val_accuracy did not improve from 0.55847\n","765/765 [==============================] - 599s 783ms/step - loss: 0.8678 - accuracy: 0.7866 - top5_acc: 0.9469 - macro_f1score: 0.0810 - val_loss: 2.2863 - val_accuracy: 0.5450 - val_top5_acc: 0.7601 - val_macro_f1score: 0.0525\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","765/765 [==============================] - ETA: 0s - loss: 0.7993 - accuracy: 0.8031 - top5_acc: 0.9544 - macro_f1score: 0.0844\n","Epoch 00020: val_loss did not improve from 2.16160\n","\n","Epoch 00020: val_accuracy did not improve from 0.55847\n","765/765 [==============================] - 600s 785ms/step - loss: 0.7993 - accuracy: 0.8031 - top5_acc: 0.9544 - macro_f1score: 0.0844 - val_loss: 2.3181 - val_accuracy: 0.5585 - val_top5_acc: 0.7557 - val_macro_f1score: 0.0564\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","765/765 [==============================] - ETA: 0s - loss: 0.7480 - accuracy: 0.8240 - top5_acc: 0.9620 - macro_f1score: 0.0864\n","Epoch 00021: val_loss did not improve from 2.16160\n","\n","Epoch 00021: val_accuracy improved from 0.55847 to 0.56384, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/021.h5\n","765/765 [==============================] - 602s 787ms/step - loss: 0.7480 - accuracy: 0.8240 - top5_acc: 0.9620 - macro_f1score: 0.0864 - val_loss: 2.2968 - val_accuracy: 0.5638 - val_top5_acc: 0.7631 - val_macro_f1score: 0.0572\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","765/765 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.8364 - top5_acc: 0.9675 - macro_f1score: 0.0889\n","Epoch 00022: val_loss did not improve from 2.16160\n","\n","Epoch 00022: val_accuracy did not improve from 0.56384\n","765/765 [==============================] - 602s 787ms/step - loss: 0.6841 - accuracy: 0.8364 - top5_acc: 0.9675 - macro_f1score: 0.0889 - val_loss: 2.4659 - val_accuracy: 0.5595 - val_top5_acc: 0.7554 - val_macro_f1score: 0.0556\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","765/765 [==============================] - ETA: 0s - loss: 0.6297 - accuracy: 0.8535 - top5_acc: 0.9747 - macro_f1score: 0.0913\n","Epoch 00023: val_loss did not improve from 2.16160\n","\n","Epoch 00023: val_accuracy improved from 0.56384 to 0.58972, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/023.h5\n","765/765 [==============================] - 601s 785ms/step - loss: 0.6297 - accuracy: 0.8535 - top5_acc: 0.9747 - macro_f1score: 0.0913 - val_loss: 2.1881 - val_accuracy: 0.5897 - val_top5_acc: 0.7836 - val_macro_f1score: 0.0611\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","765/765 [==============================] - ETA: 0s - loss: 0.5934 - accuracy: 0.8639 - top5_acc: 0.9785 - macro_f1score: 0.0931\n","Epoch 00024: val_loss did not improve from 2.16160\n","\n","Epoch 00024: val_accuracy did not improve from 0.58972\n","765/765 [==============================] - 600s 784ms/step - loss: 0.5934 - accuracy: 0.8639 - top5_acc: 0.9785 - macro_f1score: 0.0931 - val_loss: 2.4624 - val_accuracy: 0.5830 - val_top5_acc: 0.7735 - val_macro_f1score: 0.0605\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","765/765 [==============================] - ETA: 0s - loss: 0.5416 - accuracy: 0.8786 - top5_acc: 0.9824 - macro_f1score: 0.0952\n","Epoch 00025: val_loss did not improve from 2.16160\n","\n","Epoch 00025: val_accuracy did not improve from 0.58972\n","765/765 [==============================] - 599s 783ms/step - loss: 0.5416 - accuracy: 0.8786 - top5_acc: 0.9824 - macro_f1score: 0.0952 - val_loss: 2.5890 - val_accuracy: 0.5652 - val_top5_acc: 0.7634 - val_macro_f1score: 0.0596\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","765/765 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.8794 - top5_acc: 0.9826 - macro_f1score: 0.0958\n","Epoch 00026: val_loss did not improve from 2.16160\n","\n","Epoch 00026: val_accuracy did not improve from 0.58972\n","765/765 [==============================] - 598s 782ms/step - loss: 0.5378 - accuracy: 0.8794 - top5_acc: 0.9826 - macro_f1score: 0.0958 - val_loss: 2.6782 - val_accuracy: 0.5706 - val_top5_acc: 0.7611 - val_macro_f1score: 0.0599\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","765/765 [==============================] - ETA: 0s - loss: 0.5181 - accuracy: 0.8850 - top5_acc: 0.9851 - macro_f1score: 0.0967\n","Epoch 00027: val_loss did not improve from 2.16160\n","\n","Epoch 00027: val_accuracy did not improve from 0.58972\n","765/765 [==============================] - 600s 785ms/step - loss: 0.5181 - accuracy: 0.8850 - top5_acc: 0.9851 - macro_f1score: 0.0967 - val_loss: 2.6780 - val_accuracy: 0.5709 - val_top5_acc: 0.7702 - val_macro_f1score: 0.0606\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","765/765 [==============================] - ETA: 0s - loss: 0.4829 - accuracy: 0.8977 - top5_acc: 0.9882 - macro_f1score: 0.0984\n","Epoch 00028: val_loss did not improve from 2.16160\n","\n","Epoch 00028: val_accuracy did not improve from 0.58972\n","765/765 [==============================] - 600s 785ms/step - loss: 0.4829 - accuracy: 0.8977 - top5_acc: 0.9882 - macro_f1score: 0.0984 - val_loss: 2.5224 - val_accuracy: 0.5894 - val_top5_acc: 0.7816 - val_macro_f1score: 0.0625\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","765/765 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.9060 - top5_acc: 0.9906 - macro_f1score: 0.1004\n","Epoch 00029: val_loss did not improve from 2.16160\n","\n","Epoch 00029: val_accuracy did not improve from 0.58972\n","765/765 [==============================] - 601s 785ms/step - loss: 0.4527 - accuracy: 0.9060 - top5_acc: 0.9906 - macro_f1score: 0.1004 - val_loss: 2.7106 - val_accuracy: 0.5890 - val_top5_acc: 0.7762 - val_macro_f1score: 0.0629\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","765/765 [==============================] - ETA: 0s - loss: 0.4380 - accuracy: 0.9121 - top5_acc: 0.9908 - macro_f1score: 0.1010\n","Epoch 00030: val_loss did not improve from 2.16160\n","\n","Epoch 00030: val_accuracy did not improve from 0.58972\n","765/765 [==============================] - 600s 784ms/step - loss: 0.4380 - accuracy: 0.9121 - top5_acc: 0.9908 - macro_f1score: 0.1010 - val_loss: 2.5966 - val_accuracy: 0.5840 - val_top5_acc: 0.7789 - val_macro_f1score: 0.0617\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","765/765 [==============================] - ETA: 0s - loss: 0.3129 - accuracy: 0.9512 - top5_acc: 0.9962 - macro_f1score: 0.1065\n","Epoch 00031: val_loss improved from 2.16160 to 2.05840, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/031.h5\n","\n","Epoch 00031: val_accuracy improved from 0.58972 to 0.64281, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/031.h5\n","765/765 [==============================] - 603s 789ms/step - loss: 0.3129 - accuracy: 0.9512 - top5_acc: 0.9962 - macro_f1score: 0.1065 - val_loss: 2.0584 - val_accuracy: 0.6428 - val_top5_acc: 0.8266 - val_macro_f1score: 0.0696\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","765/765 [==============================] - ETA: 0s - loss: 0.2491 - accuracy: 0.9717 - top5_acc: 0.9984 - macro_f1score: 0.1099\n","Epoch 00032: val_loss improved from 2.05840 to 2.05281, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/032.h5\n","\n","Epoch 00032: val_accuracy improved from 0.64281 to 0.65289, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/032.h5\n","765/765 [==============================] - 607s 793ms/step - loss: 0.2491 - accuracy: 0.9717 - top5_acc: 0.9984 - macro_f1score: 0.1099 - val_loss: 2.0528 - val_accuracy: 0.6529 - val_top5_acc: 0.8296 - val_macro_f1score: 0.0701\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","765/765 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.9752 - top5_acc: 0.9991 - macro_f1score: 0.1103\n","Epoch 00033: val_loss did not improve from 2.05281\n","\n","Epoch 00033: val_accuracy did not improve from 0.65289\n","765/765 [==============================] - 601s 785ms/step - loss: 0.2321 - accuracy: 0.9752 - top5_acc: 0.9991 - macro_f1score: 0.1103 - val_loss: 2.0609 - val_accuracy: 0.6522 - val_top5_acc: 0.8286 - val_macro_f1score: 0.0705\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","765/765 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.9783 - top5_acc: 0.9990 - macro_f1score: 0.1109\n","Epoch 00034: val_loss did not improve from 2.05281\n","\n","Epoch 00034: val_accuracy did not improve from 0.65289\n","765/765 [==============================] - 600s 785ms/step - loss: 0.2217 - accuracy: 0.9783 - top5_acc: 0.9990 - macro_f1score: 0.1109 - val_loss: 2.0580 - val_accuracy: 0.6512 - val_top5_acc: 0.8276 - val_macro_f1score: 0.0706\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","765/765 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.9799 - top5_acc: 0.9994 - macro_f1score: 0.1113\n","Epoch 00035: val_loss did not improve from 2.05281\n","\n","Epoch 00035: val_accuracy improved from 0.65289 to 0.65524, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/035.h5\n","765/765 [==============================] - 601s 786ms/step - loss: 0.2120 - accuracy: 0.9799 - top5_acc: 0.9994 - macro_f1score: 0.1113 - val_loss: 2.0883 - val_accuracy: 0.6552 - val_top5_acc: 0.8313 - val_macro_f1score: 0.0708\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","765/765 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 0.9826 - top5_acc: 0.9993 - macro_f1score: 0.1122\n","Epoch 00036: val_loss did not improve from 2.05281\n","\n","Epoch 00036: val_accuracy did not improve from 0.65524\n","765/765 [==============================] - 600s 784ms/step - loss: 0.2068 - accuracy: 0.9826 - top5_acc: 0.9993 - macro_f1score: 0.1122 - val_loss: 2.0775 - val_accuracy: 0.6542 - val_top5_acc: 0.8290 - val_macro_f1score: 0.0698\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","765/765 [==============================] - ETA: 0s - loss: 0.2004 - accuracy: 0.9839 - top5_acc: 0.9997 - macro_f1score: 0.1119\n","Epoch 00037: val_loss did not improve from 2.05281\n","\n","Epoch 00037: val_accuracy did not improve from 0.65524\n","765/765 [==============================] - 598s 782ms/step - loss: 0.2004 - accuracy: 0.9839 - top5_acc: 0.9997 - macro_f1score: 0.1119 - val_loss: 2.0994 - val_accuracy: 0.6549 - val_top5_acc: 0.8306 - val_macro_f1score: 0.0713\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.9862 - top5_acc: 0.9997 - macro_f1score: 0.1124\n","Epoch 00038: val_loss did not improve from 2.05281\n","\n","Epoch 00038: val_accuracy did not improve from 0.65524\n","765/765 [==============================] - 597s 781ms/step - loss: 0.1920 - accuracy: 0.9862 - top5_acc: 0.9997 - macro_f1score: 0.1124 - val_loss: 2.0843 - val_accuracy: 0.6542 - val_top5_acc: 0.8306 - val_macro_f1score: 0.0709\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1897 - accuracy: 0.9866 - top5_acc: 0.9996 - macro_f1score: 0.1123\n","Epoch 00039: val_loss did not improve from 2.05281\n","\n","Epoch 00039: val_accuracy improved from 0.65524 to 0.65860, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/039.h5\n","765/765 [==============================] - 600s 784ms/step - loss: 0.1897 - accuracy: 0.9866 - top5_acc: 0.9996 - macro_f1score: 0.1123 - val_loss: 2.1068 - val_accuracy: 0.6586 - val_top5_acc: 0.8353 - val_macro_f1score: 0.0708\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.9873 - top5_acc: 0.9998 - macro_f1score: 0.1127\n","Epoch 00040: val_loss did not improve from 2.05281\n","\n","Epoch 00040: val_accuracy did not improve from 0.65860\n","765/765 [==============================] - 599s 783ms/step - loss: 0.1862 - accuracy: 0.9873 - top5_acc: 0.9998 - macro_f1score: 0.1127 - val_loss: 2.1358 - val_accuracy: 0.6549 - val_top5_acc: 0.8280 - val_macro_f1score: 0.0712\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.9895 - top5_acc: 0.9997 - macro_f1score: 0.1125\n","Epoch 00041: val_loss did not improve from 2.05281\n","\n","Epoch 00041: val_accuracy did not improve from 0.65860\n","765/765 [==============================] - 598s 781ms/step - loss: 0.1784 - accuracy: 0.9895 - top5_acc: 0.9997 - macro_f1score: 0.1125 - val_loss: 2.0822 - val_accuracy: 0.6536 - val_top5_acc: 0.8303 - val_macro_f1score: 0.0709\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.9888 - top5_acc: 0.9998 - macro_f1score: 0.1123\n","Epoch 00042: val_loss did not improve from 2.05281\n","\n","Epoch 00042: val_accuracy did not improve from 0.65860\n","765/765 [==============================] - 598s 782ms/step - loss: 0.1809 - accuracy: 0.9888 - top5_acc: 0.9998 - macro_f1score: 0.1123 - val_loss: 2.1260 - val_accuracy: 0.6573 - val_top5_acc: 0.8343 - val_macro_f1score: 0.0710\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.9891 - top5_acc: 0.9996 - macro_f1score: 0.1128\n","Epoch 00043: val_loss did not improve from 2.05281\n","\n","Epoch 00043: val_accuracy improved from 0.65860 to 0.65995, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/043.h5\n","765/765 [==============================] - 599s 783ms/step - loss: 0.1766 - accuracy: 0.9891 - top5_acc: 0.9996 - macro_f1score: 0.1128 - val_loss: 2.0783 - val_accuracy: 0.6599 - val_top5_acc: 0.8290 - val_macro_f1score: 0.0724\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1736 - accuracy: 0.9900 - top5_acc: 0.9999 - macro_f1score: 0.1126\n","Epoch 00044: val_loss did not improve from 2.05281\n","\n","Epoch 00044: val_accuracy did not improve from 0.65995\n","765/765 [==============================] - 600s 785ms/step - loss: 0.1736 - accuracy: 0.9900 - top5_acc: 0.9999 - macro_f1score: 0.1126 - val_loss: 2.1018 - val_accuracy: 0.6589 - val_top5_acc: 0.8347 - val_macro_f1score: 0.0710\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9902 - top5_acc: 0.9998 - macro_f1score: 0.1132\n","Epoch 00045: val_loss did not improve from 2.05281\n","\n","Epoch 00045: val_accuracy did not improve from 0.65995\n","765/765 [==============================] - 602s 787ms/step - loss: 0.1711 - accuracy: 0.9902 - top5_acc: 0.9998 - macro_f1score: 0.1132 - val_loss: 2.1083 - val_accuracy: 0.6526 - val_top5_acc: 0.8317 - val_macro_f1score: 0.0712\n","Learning rate:  0.0001\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 46/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9907 - top5_acc: 0.9999 - macro_f1score: 0.1133\n","Epoch 00046: val_loss did not improve from 2.05281\n","\n","Epoch 00046: val_accuracy did not improve from 0.65995\n","765/765 [==============================] - 601s 786ms/step - loss: 0.1697 - accuracy: 0.9907 - top5_acc: 0.9999 - macro_f1score: 0.1133 - val_loss: 2.1127 - val_accuracy: 0.6573 - val_top5_acc: 0.8370 - val_macro_f1score: 0.0720\n","Learning rate:  0.0001\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 47/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9918 - top5_acc: 0.9998 - macro_f1score: 0.1131\n","Epoch 00047: val_loss did not improve from 2.05281\n","\n","Epoch 00047: val_accuracy did not improve from 0.65995\n","765/765 [==============================] - 600s 784ms/step - loss: 0.1663 - accuracy: 0.9918 - top5_acc: 0.9998 - macro_f1score: 0.1131 - val_loss: 2.1579 - val_accuracy: 0.6512 - val_top5_acc: 0.8320 - val_macro_f1score: 0.0714\n","Learning rate:  0.0001\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 48/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.9913 - top5_acc: 0.9998 - macro_f1score: 0.1130\n","Epoch 00048: val_loss did not improve from 2.05281\n","\n","Epoch 00048: val_accuracy did not improve from 0.65995\n","765/765 [==============================] - 600s 784ms/step - loss: 0.1658 - accuracy: 0.9913 - top5_acc: 0.9998 - macro_f1score: 0.1130 - val_loss: 2.1688 - val_accuracy: 0.6519 - val_top5_acc: 0.8317 - val_macro_f1score: 0.0706\n","Learning rate:  0.0001\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 49/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1637 - accuracy: 0.9921 - top5_acc: 0.9999 - macro_f1score: 0.1134\n","Epoch 00049: val_loss did not improve from 2.05281\n","\n","Epoch 00049: val_accuracy did not improve from 0.65995\n","765/765 [==============================] - 600s 784ms/step - loss: 0.1637 - accuracy: 0.9921 - top5_acc: 0.9999 - macro_f1score: 0.1134 - val_loss: 2.1408 - val_accuracy: 0.6556 - val_top5_acc: 0.8350 - val_macro_f1score: 0.0713\n","Learning rate:  0.0001\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 50/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9927 - top5_acc: 0.9999 - macro_f1score: 0.1133\n","Epoch 00050: val_loss did not improve from 2.05281\n","\n","Epoch 00050: val_accuracy improved from 0.65995 to 0.66095, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/050.h5\n","765/765 [==============================] - 599s 783ms/step - loss: 0.1612 - accuracy: 0.9927 - top5_acc: 0.9999 - macro_f1score: 0.1133 - val_loss: 2.1431 - val_accuracy: 0.6610 - val_top5_acc: 0.8357 - val_macro_f1score: 0.0715\n","Learning rate:  0.0001\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 51/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9936 - top5_acc: 0.9998 - macro_f1score: 0.1133\n","Epoch 00051: val_loss did not improve from 2.05281\n","\n","Epoch 00051: val_accuracy did not improve from 0.66095\n","765/765 [==============================] - 601s 786ms/step - loss: 0.1589 - accuracy: 0.9936 - top5_acc: 0.9998 - macro_f1score: 0.1133 - val_loss: 2.1797 - val_accuracy: 0.6559 - val_top5_acc: 0.8317 - val_macro_f1score: 0.0731\n","Learning rate:  0.0001\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 52/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9927 - top5_acc: 0.9999 - macro_f1score: 0.1130\n","Epoch 00052: val_loss did not improve from 2.05281\n","\n","Epoch 00052: val_accuracy improved from 0.66095 to 0.66465, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/052.h5\n","765/765 [==============================] - 600s 785ms/step - loss: 0.1592 - accuracy: 0.9927 - top5_acc: 0.9999 - macro_f1score: 0.1130 - val_loss: 2.1719 - val_accuracy: 0.6647 - val_top5_acc: 0.8337 - val_macro_f1score: 0.0724\n","Learning rate:  0.0001\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 53/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9924 - top5_acc: 0.9999 - macro_f1score: 0.1131\n","Epoch 00053: val_loss did not improve from 2.05281\n","\n","Epoch 00053: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 600s 784ms/step - loss: 0.1580 - accuracy: 0.9924 - top5_acc: 0.9999 - macro_f1score: 0.1131 - val_loss: 2.1642 - val_accuracy: 0.6559 - val_top5_acc: 0.8330 - val_macro_f1score: 0.0716\n","Learning rate:  0.0001\n","\n","Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 54/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9940 - top5_acc: 1.0000 - macro_f1score: 0.1137\n","Epoch 00054: val_loss did not improve from 2.05281\n","\n","Epoch 00054: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 597s 781ms/step - loss: 0.1540 - accuracy: 0.9940 - top5_acc: 1.0000 - macro_f1score: 0.1137 - val_loss: 2.1575 - val_accuracy: 0.6529 - val_top5_acc: 0.8333 - val_macro_f1score: 0.0708\n","Learning rate:  0.0001\n","\n","Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 55/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9935 - top5_acc: 1.0000 - macro_f1score: 0.1132\n","Epoch 00055: val_loss did not improve from 2.05281\n","\n","Epoch 00055: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 598s 782ms/step - loss: 0.1540 - accuracy: 0.9935 - top5_acc: 1.0000 - macro_f1score: 0.1132 - val_loss: 2.1927 - val_accuracy: 0.6546 - val_top5_acc: 0.8280 - val_macro_f1score: 0.0719\n","Learning rate:  0.0001\n","\n","Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 56/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9941 - top5_acc: 0.9998 - macro_f1score: 0.1138\n","Epoch 00056: val_loss did not improve from 2.05281\n","\n","Epoch 00056: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 599s 784ms/step - loss: 0.1525 - accuracy: 0.9941 - top5_acc: 0.9998 - macro_f1score: 0.1138 - val_loss: 2.2235 - val_accuracy: 0.6586 - val_top5_acc: 0.8273 - val_macro_f1score: 0.0711\n","Learning rate:  0.0001\n","\n","Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 57/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9944 - top5_acc: 1.0000 - macro_f1score: 0.1137\n","Epoch 00057: val_loss did not improve from 2.05281\n","\n","Epoch 00057: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 600s 784ms/step - loss: 0.1509 - accuracy: 0.9944 - top5_acc: 1.0000 - macro_f1score: 0.1137 - val_loss: 2.2230 - val_accuracy: 0.6559 - val_top5_acc: 0.8337 - val_macro_f1score: 0.0721\n","Learning rate:  0.0001\n","\n","Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 58/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9937 - top5_acc: 1.0000 - macro_f1score: 0.1132\n","Epoch 00058: val_loss did not improve from 2.05281\n","\n","Epoch 00058: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 600s 784ms/step - loss: 0.1517 - accuracy: 0.9937 - top5_acc: 1.0000 - macro_f1score: 0.1132 - val_loss: 2.1998 - val_accuracy: 0.6542 - val_top5_acc: 0.8333 - val_macro_f1score: 0.0710\n","Learning rate:  0.0001\n","\n","Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 59/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1481 - accuracy: 0.9954 - top5_acc: 0.9999 - macro_f1score: 0.1139\n","Epoch 00059: val_loss did not improve from 2.05281\n","\n","Epoch 00059: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 599s 783ms/step - loss: 0.1481 - accuracy: 0.9954 - top5_acc: 0.9999 - macro_f1score: 0.1139 - val_loss: 2.2172 - val_accuracy: 0.6579 - val_top5_acc: 0.8310 - val_macro_f1score: 0.0717\n","Learning rate:  0.0001\n","\n","Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 60/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.9949 - top5_acc: 1.0000 - macro_f1score: 0.1136\n","Epoch 00060: val_loss did not improve from 2.05281\n","\n","Epoch 00060: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 599s 783ms/step - loss: 0.1484 - accuracy: 0.9949 - top5_acc: 1.0000 - macro_f1score: 0.1136 - val_loss: 2.1988 - val_accuracy: 0.6546 - val_top5_acc: 0.8347 - val_macro_f1score: 0.0709\n","Learning rate:  1e-05\n","\n","Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 61/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9946 - top5_acc: 0.9999 - macro_f1score: 0.1137\n","Epoch 00061: val_loss did not improve from 2.05281\n","\n","Epoch 00061: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 598s 781ms/step - loss: 0.1479 - accuracy: 0.9946 - top5_acc: 0.9999 - macro_f1score: 0.1137 - val_loss: 2.1924 - val_accuracy: 0.6559 - val_top5_acc: 0.8364 - val_macro_f1score: 0.0718\n","Learning rate:  1e-05\n","\n","Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 62/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.9956 - top5_acc: 1.0000 - macro_f1score: 0.1139\n","Epoch 00062: val_loss did not improve from 2.05281\n","\n","Epoch 00062: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 596s 779ms/step - loss: 0.1452 - accuracy: 0.9956 - top5_acc: 1.0000 - macro_f1score: 0.1139 - val_loss: 2.1831 - val_accuracy: 0.6566 - val_top5_acc: 0.8343 - val_macro_f1score: 0.0713\n","Learning rate:  1e-05\n","\n","Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 63/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9963 - top5_acc: 0.9999 - macro_f1score: 0.1140\n","Epoch 00063: val_loss did not improve from 2.05281\n","\n","Epoch 00063: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 597s 780ms/step - loss: 0.1439 - accuracy: 0.9963 - top5_acc: 0.9999 - macro_f1score: 0.1140 - val_loss: 2.1857 - val_accuracy: 0.6569 - val_top5_acc: 0.8333 - val_macro_f1score: 0.0717\n","Learning rate:  1e-05\n","\n","Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 64/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.9958 - top5_acc: 0.9999 - macro_f1score: 0.1138\n","Epoch 00064: val_loss did not improve from 2.05281\n","\n","Epoch 00064: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 598s 782ms/step - loss: 0.1443 - accuracy: 0.9958 - top5_acc: 0.9999 - macro_f1score: 0.1138 - val_loss: 2.1805 - val_accuracy: 0.6593 - val_top5_acc: 0.8330 - val_macro_f1score: 0.0723\n","Learning rate:  1e-05\n","\n","Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 65/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9955 - top5_acc: 1.0000 - macro_f1score: 0.1140\n","Epoch 00065: val_loss did not improve from 2.05281\n","\n","Epoch 00065: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 599s 783ms/step - loss: 0.1445 - accuracy: 0.9955 - top5_acc: 1.0000 - macro_f1score: 0.1140 - val_loss: 2.1864 - val_accuracy: 0.6573 - val_top5_acc: 0.8327 - val_macro_f1score: 0.0720\n","Learning rate:  1e-05\n","\n","Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 66/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9955 - top5_acc: 1.0000 - macro_f1score: 0.1140\n","Epoch 00066: val_loss did not improve from 2.05281\n","\n","Epoch 00066: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 599s 782ms/step - loss: 0.1439 - accuracy: 0.9955 - top5_acc: 1.0000 - macro_f1score: 0.1140 - val_loss: 2.1727 - val_accuracy: 0.6576 - val_top5_acc: 0.8340 - val_macro_f1score: 0.0716\n","Learning rate:  1e-05\n","\n","Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 67/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9964 - top5_acc: 0.9999 - macro_f1score: 0.1141\n","Epoch 00067: val_loss did not improve from 2.05281\n","\n","Epoch 00067: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 598s 782ms/step - loss: 0.1432 - accuracy: 0.9964 - top5_acc: 0.9999 - macro_f1score: 0.1141 - val_loss: 2.1634 - val_accuracy: 0.6589 - val_top5_acc: 0.8320 - val_macro_f1score: 0.0724\n","Learning rate:  1e-05\n","\n","Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 68/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9960 - top5_acc: 0.9999 - macro_f1score: 0.1139\n","Epoch 00068: val_loss did not improve from 2.05281\n","\n","Epoch 00068: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 600s 784ms/step - loss: 0.1433 - accuracy: 0.9960 - top5_acc: 0.9999 - macro_f1score: 0.1139 - val_loss: 2.1838 - val_accuracy: 0.6566 - val_top5_acc: 0.8347 - val_macro_f1score: 0.0726\n","Learning rate:  1e-05\n","\n","Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 69/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9964 - top5_acc: 1.0000 - macro_f1score: 0.1141\n","Epoch 00069: val_loss did not improve from 2.05281\n","\n","Epoch 00069: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 599s 782ms/step - loss: 0.1419 - accuracy: 0.9964 - top5_acc: 1.0000 - macro_f1score: 0.1141 - val_loss: 2.1720 - val_accuracy: 0.6593 - val_top5_acc: 0.8353 - val_macro_f1score: 0.0715\n","Learning rate:  1e-05\n","\n","Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 70/70\n","765/765 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9958 - top5_acc: 1.0000 - macro_f1score: 0.1141\n","Epoch 00070: val_loss did not improve from 2.05281\n","\n","Epoch 00070: val_accuracy did not improve from 0.66465\n","765/765 [==============================] - 598s 781ms/step - loss: 0.1434 - accuracy: 0.9958 - top5_acc: 1.0000 - macro_f1score: 0.1141 - val_loss: 2.1797 - val_accuracy: 0.6599 - val_top5_acc: 0.8337 - val_macro_f1score: 0.0717\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bRiw3ebD-FhC","executionInfo":{"status":"ok","timestamp":1605297939360,"user_tz":-540,"elapsed":60970433,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"d67524f5-5f65-44b4-e43e-6f4792b1edbe","colab":{"base_uri":"https://localhost:8080/"}},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["97/97 [==============================] - 1896s 20s/step - loss: 2.1826 - accuracy: 0.6601 - top5_acc: 0.8302 - macro_f1score: 0.0731\n","[Test Loss: 2.1826 /  Test Top-1 Accuracy: 0.6601 / Test Top-5 Accuracy: 0.8302 / Test Macro f1: 0.0731]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zWPdDUWI-FhG","executionInfo":{"status":"ok","timestamp":1605297939373,"user_tz":-540,"elapsed":60970443,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jhTx3Gm8-FhB"},"source":["### 2) Xception Evaluate\n"]},{"cell_type":"code","metadata":{"id":"yp2_HCXHyihu","executionInfo":{"status":"ok","timestamp":1605297940250,"user_tz":-540,"elapsed":60971261,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"PpEXLWpmyihx","executionInfo":{"status":"ok","timestamp":1605297940253,"user_tz":-540,"elapsed":60971205,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'Xception.txt'))"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1UoLe1oyihz","executionInfo":{"status":"ok","timestamp":1605297940257,"user_tz":-540,"elapsed":60971195,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ITeu5vTyih3","executionInfo":{"status":"ok","timestamp":1605297940258,"user_tz":-540,"elapsed":60971188,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"553020f3-8c7d-4bef-f2a9-9aaf38098442","colab":{"base_uri":"https://localhost:8080/","height":808}},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":33,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"_RmXQw95FFrY","executionInfo":{"status":"ok","timestamp":1605297940260,"user_tz":-540,"elapsed":60971141,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":[""],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"-opNS8oXFHdB","executionInfo":{"status":"ok","timestamp":1605297940261,"user_tz":-540,"elapsed":60971138,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / Xception"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-38Ov61FHdE","executionInfo":{"status":"error","timestamp":1605297943884,"user_tz":-540,"elapsed":60974748,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"a9d745e5-23ef-4ee0-f30c-2a47cffe880f","colab":{"base_uri":"https://localhost:8080/","height":315}},"source":["model=load_model(os.path.join(dir,'model_output',number,'Xception','022.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc})"],"execution_count":35,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-23b907eef81c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model_output'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Xception'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'022.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"macro_f1score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmacro_f1score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"top5_acc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtop5_acc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/022.h5/{saved_model.pbtxt|saved_model.pb}"]}]},{"cell_type":"code","metadata":{"id":"hxpCFriTFHdG","executionInfo":{"status":"aborted","timestamp":1605297942730,"user_tz":-540,"elapsed":60973591,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[]}]}