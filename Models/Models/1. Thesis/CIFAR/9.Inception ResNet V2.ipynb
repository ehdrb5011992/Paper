{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"9.Inception ResNet V2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"E-OCKgEwJfTn","executionInfo":{"status":"ok","timestamp":1606102931164,"user_tz":-540,"elapsed":934,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["#모형 출처 : https://github.com/titu1994/keras-squeeze-excite-network\n","# https://ai.googleblog.com/2016/08/improving-inception-and-image.html "],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [Inception ResNet V2]"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original Inception-ResNet-V2\n","```\n","1) Support Functions\n","2) Almost Original Inception-ResNet-V2\n","3) Inception-ResNet-V2 Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages\n"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606102961511,"user_tz":-540,"elapsed":31250,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"c629cfc1-c2de-4cba-9a94-313aaed32e9b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606102961513,"user_tz":-540,"elapsed":31228,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"0fac2afb-5ea4-41ab-94b1-ee009b8e8003"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1606102963861,"user_tz":-540,"elapsed":33573,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1606102964475,"user_tz":-540,"elapsed":34183,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606102964480,"user_tz":-540,"elapsed":34167,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"60b293f0-9818-410b-8973-b4a6c77d80bf"},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606102964482,"user_tz":-540,"elapsed":34154,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"8ba3e70d-cf37-4861-d891-cde38bc0145a"},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606102967894,"user_tz":-540,"elapsed":37545,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"ace361ee-c68a-48f1-9f08-096e02247a59"},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Kf057Rw2yigs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606102967897,"user_tz":-540,"elapsed":37529,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"50c70e03-735b-483c-8269-c7c3420ade57"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 14601833509456002437\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 8159690391294324978\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 8114179696277814263\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15695549568\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 11300142130914116813\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IiIzUpEZhyS4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606102967899,"user_tz":-540,"elapsed":37520,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"07d71de1-22ea-4879-971e-6188e9f2fc14"},"source":["!cat /proc/cpuinfo"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"BeJ7UtuOEgWY","executionInfo":{"status":"ok","timestamp":1606102967900,"user_tz":-540,"elapsed":37518,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CIFAR100'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 299 # sizes after cropping\n","super_size = 330 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 32\n","weight_decay = 1e-3\n","epochs = 70"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1606102967901,"user_tz":-540,"elapsed":37517,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"wmFJMXETpKFW","executionInfo":{"status":"ok","timestamp":1606102967903,"user_tz":-540,"elapsed":37517,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1606102967904,"user_tz":-540,"elapsed":37516,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s8v29_oXpKFa"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"-eSf1NktpKFb","executionInfo":{"status":"ok","timestamp":1606102967905,"user_tz":-540,"elapsed":37515,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1606102967906,"user_tz":-540,"elapsed":37514,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0KLhu5WpKFe","executionInfo":{"status":"ok","timestamp":1606102967907,"user_tz":-540,"elapsed":37513,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"u3v_aI9cpKFg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606103027157,"user_tz":-540,"elapsed":96753,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"7be97870-2c0f-4be9-e275-7b3683875a58"},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Found 44923 images belonging to 100 classes.\n","Found 5077 images belonging to 100 classes.\n","Found 10000 images belonging to 100 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original Inception-ResNet-V2\n","---"]},{"cell_type":"markdown","metadata":{"id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F6RRSCgoAsl9"},"source":["def conv2d_bn(x, filters, kernel_size, strides=1, padding='same', activation='relu', use_bias=False, name=None, weight_decay=weight_decay):\n","\n","    x = Conv2D(filters, kernel_size, strides=strides, padding=padding,  use_bias=use_bias, name=name, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    if not use_bias:\n","        bn_axis =  3\n","        bn_name = None if name is None else '{name}_bn'.format(name=name)\n","        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n","        \n","    if activation is not None:\n","        ac_name = None if name is None else '{name}_ac'.format(name=name)\n","        x = Activation(activation, name=ac_name)(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kr4VbL3uAtui"},"source":["def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n"," \n","    if block_type == 'block35':\n","        branch_0 = conv2d_bn(x, 32, 1)\n","        branch_1 = conv2d_bn(x, 32, 1)\n","        branch_1 = conv2d_bn(branch_1, 32, 3)\n","        branch_2 = conv2d_bn(x, 32, 1)\n","        branch_2 = conv2d_bn(branch_2, 48, 3)\n","        branch_2 = conv2d_bn(branch_2, 64, 3)\n","        branches = [branch_0, branch_1, branch_2]\n","    elif block_type == 'block17':\n","        branch_0 = conv2d_bn(x, 192, 1)\n","        branch_1 = conv2d_bn(x, 128, 1)\n","        branch_1 = conv2d_bn(branch_1, 160, [1, 7])\n","        branch_1 = conv2d_bn(branch_1, 192, [7, 1])\n","        branches = [branch_0, branch_1]\n","    elif block_type == 'block8':\n","        branch_0 = conv2d_bn(x, 192, 1)\n","        branch_1 = conv2d_bn(x, 192, 1)\n","        branch_1 = conv2d_bn(branch_1, 224, [1, 3])\n","        branch_1 = conv2d_bn(branch_1, 256, [3, 1])\n","        branches = [branch_0, branch_1]\n","    else:\n","        raise ValueError('Unknown Inception-ResNet block type. '\n","                         'Expects \"block35\", \"block17\" or \"block8\", '\n","                         'but got: {block_type}'.format(block_type=block_type))\n","\n","    block_name = '{block_type}_{block_idx}'.format(block_type=block_type, block_idx=block_idx)\n","    channel_axis = 3\n","    mixed = Concatenate(axis=channel_axis, name='{block_name}_mixed'.format(block_name=block_name))(branches)\n","    up = conv2d_bn(mixed,\n","                   K.int_shape(x)[channel_axis],\n","                   1,\n","                   activation=None,\n","                   use_bias=True,\n","                   name='{block_name}_conv'.format(block_name=block_name))\n","\n","    x = Lambda(lambda inputs, scale_: inputs[0] + inputs[1] * scale_,\n","               output_shape=K.int_shape(x)[1:],\n","               arguments={'scale_': scale},\n","               name=block_name)([x, up])\n","    if activation is not None:\n","        x = Activation(activation, name='{block_name}_ac'.format(block_name=block_name))(x)\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-R2NfkqUl60"},"source":["def Inception_ResNet_v2(input_shape=None, weight_decay=weight_decay, classes=classes, name=None):\n"," \n","    img_input = Input(shape=input_shape)\n","\n","\n","    # Stem block: 35 x 35 x 192\n","    x = conv2d_bn(img_input, 32, 3, strides=2, padding='valid')\n","    x = conv2d_bn(x, 32, 3, padding='valid')\n","    x = conv2d_bn(x, 64, 3)\n","    x = MaxPooling2D(3, strides=2)(x)\n","    x = conv2d_bn(x, 80, 1, padding='valid')\n","    x = conv2d_bn(x, 192, 3, padding='valid')\n","    x = MaxPooling2D(3, strides=2)(x)\n","\n","    # Mixed 5b (Inception-A block): 35 x 35 x 320\n","    branch_0 = conv2d_bn(x, 96, 1)\n","    branch_1 = conv2d_bn(x, 48, 1)\n","    branch_1 = conv2d_bn(branch_1, 64, 5)\n","    branch_2 = conv2d_bn(x, 64, 1)\n","    branch_2 = conv2d_bn(branch_2, 96, 3)\n","    branch_2 = conv2d_bn(branch_2, 96, 3)\n","    branch_pool = AveragePooling2D(3, strides=1, padding='same')(x)\n","    branch_pool = conv2d_bn(branch_pool, 64, 1)\n","    branches = [branch_0, branch_1, branch_2, branch_pool]\n","    channel_axis = 3\n","    x = Concatenate(axis=channel_axis, name='mixed_5b')(branches)\n","\n","\n","    # 10x block35 (Inception-ResNet-A block): 35 x 35 x 320\n","    for block_idx in range(1, 11):\n","        x = inception_resnet_block(x,\n","                                   scale=0.17,\n","                                   block_type='block35',\n","                                   block_idx=block_idx)\n","\n","    # Mixed 6a (Reduction-A block): 17 x 17 x 1088\n","    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid')\n","    branch_1 = conv2d_bn(x, 256, 1)\n","    branch_1 = conv2d_bn(branch_1, 256, 3)\n","    branch_1 = conv2d_bn(branch_1, 384, 3, strides=2, padding='valid')\n","    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n","    branches = [branch_0, branch_1, branch_pool]\n","    x = Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n","\n","\n","    # 20x block17 (Inception-ResNet-B block): 17 x 17 x 1088\n","    for block_idx in range(1, 21):\n","        x = inception_resnet_block(x,\n","                                   scale=0.1,\n","                                   block_type='block17',\n","                                   block_idx=block_idx)\n","\n","    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n","    branch_0 = conv2d_bn(x, 256, 1)\n","    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid')\n","    branch_1 = conv2d_bn(x, 256, 1)\n","    branch_1 = conv2d_bn(branch_1, 288, 3, strides=2, padding='valid')\n","    branch_2 = conv2d_bn(x, 256, 1)\n","    branch_2 = conv2d_bn(branch_2, 288, 3)\n","    branch_2 = conv2d_bn(branch_2, 320, 3, strides=2, padding='valid')\n","    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n","    branches = [branch_0, branch_1, branch_2, branch_pool]\n","    x = Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n","\n","\n","    # 10x block8 (Inception-ResNet-C block): 8 x 8 x 2080\n","    for block_idx in range(1, 10):\n","        x = inception_resnet_block(x,\n","                                   scale=0.2,\n","                                   block_type='block8',\n","                                   block_idx=block_idx)\n","    x = inception_resnet_block(x,\n","                               scale=1.,\n","                               activation=None,\n","                               block_type='block8',\n","                               block_idx=10)\n","\n","    # Final convolution block: 8 x 8 x 1536\n","    x = conv2d_bn(x, 1536, 1, name='conv_7b')\n","\n","    x = GlobalAveragePooling2D(name='avg_pool')(x)\n","    x = Dense(classes, use_bias=False, kernel_regularizer=l2(weight_decay), activation='softmax', name='predictions')(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`\n","    inputs = img_input\n","\n","    # Create model\n","    model = Model(inputs, x, name=name)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vJixgnY7Z6j7"},"source":["### 2) Almost Original Inception-ResNet-V2\n"]},{"cell_type":"code","metadata":{"id":"5YOrZ2rhneyq"},"source":["model = Inception_ResNet_v2(input_shape=input_sizes, weight_decay=weight_decay, classes=classes, name='Inception_ResNet_v2')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HuelUizNJWz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605572058381,"user_tz":-540,"elapsed":131653,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"d934be10-58a5-4b2c-a766-5207f9ef3dec"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"Inception_ResNet_v2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 35, 35, 96)   18432       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 35, 35, 64)   12288       average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 35, 35, 96)   288         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 35, 35, 64)   192         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 35, 35, 96)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 35, 35, 64)   0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_5[0][0]               \n","                                                                 activation_7[0][0]               \n","                                                                 activation_10[0][0]              \n","                                                                 activation_11[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 35, 35, 48)   13824       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 35, 35, 48)   144         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 35, 35, 48)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 35, 35, 32)   9216        activation_13[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 35, 35, 64)   27648       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 35, 35, 64)   192         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 35, 35, 64)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_12[0][0]              \n","                                                                 activation_14[0][0]              \n","                                                                 activation_17[0][0]              \n","__________________________________________________________________________________________________\n","block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n","                                                                 block35_1_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 35, 35, 48)   13824       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 35, 35, 48)   144         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 35, 35, 48)   0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 35, 35, 32)   9216        activation_19[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 35, 35, 64)   27648       activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 35, 35, 32)   96          conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 35, 35, 32)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_18[0][0]              \n","                                                                 activation_20[0][0]              \n","                                                                 activation_23[0][0]              \n","__________________________________________________________________________________________________\n","block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n","                                                                 block35_2_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 35, 35, 48)   13824       activation_27[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 35, 35, 48)   144         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 35, 35, 48)   0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 35, 35, 32)   9216        activation_25[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 35, 35, 64)   27648       activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 35, 35, 32)   96          conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 35, 35, 64)   192         conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 35, 35, 32)   0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 35, 35, 64)   0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_24[0][0]              \n","                                                                 activation_26[0][0]              \n","                                                                 activation_29[0][0]              \n","__________________________________________________________________________________________________\n","block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n","                                                                 block35_3_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 35, 35, 48)   13824       activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 35, 35, 48)   144         conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 35, 35, 48)   0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 35, 35, 32)   9216        activation_31[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 35, 35, 64)   27648       activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 35, 35, 32)   96          conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 35, 35, 64)   192         conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 35, 35, 32)   0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 35, 35, 64)   0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_30[0][0]              \n","                                                                 activation_32[0][0]              \n","                                                                 activation_35[0][0]              \n","__________________________________________________________________________________________________\n","block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n","                                                                 block35_4_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 35, 35, 32)   96          conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 35, 35, 32)   0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 35, 35, 48)   13824       activation_39[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 35, 35, 32)   96          conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 35, 35, 48)   144         conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 35, 35, 32)   0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 35, 35, 48)   0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 35, 35, 32)   9216        activation_37[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 35, 35, 64)   27648       activation_40[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 35, 35, 32)   96          conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 35, 35, 32)   96          conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 35, 35, 64)   192         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 35, 35, 32)   0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 35, 35, 32)   0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 35, 35, 64)   0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_36[0][0]              \n","                                                                 activation_38[0][0]              \n","                                                                 activation_41[0][0]              \n","__________________________________________________________________________________________________\n","block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n","                                                                 block35_5_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 35, 35, 32)   96          conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 35, 35, 32)   0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 35, 35, 48)   13824       activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 35, 35, 32)   96          conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 35, 35, 48)   144         conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 35, 35, 32)   0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 35, 35, 48)   0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 35, 35, 32)   9216        activation_43[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 35, 35, 64)   27648       activation_46[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 35, 35, 32)   96          conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 35, 35, 32)   96          conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 35, 35, 64)   192         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 35, 35, 32)   0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 35, 35, 32)   0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 35, 35, 64)   0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_42[0][0]              \n","                                                                 activation_44[0][0]              \n","                                                                 activation_47[0][0]              \n","__________________________________________________________________________________________________\n","block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n","                                                                 block35_6_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 35, 35, 32)   96          conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 35, 35, 32)   0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 35, 35, 48)   13824       activation_51[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 35, 35, 32)   96          conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 35, 35, 48)   144         conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 35, 35, 32)   0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 35, 35, 48)   0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 35, 35, 32)   9216        activation_49[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 35, 35, 64)   27648       activation_52[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 35, 35, 32)   96          conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 35, 35, 32)   96          conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 35, 35, 64)   192         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 35, 35, 32)   0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 35, 35, 32)   0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 35, 35, 64)   0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_48[0][0]              \n","                                                                 activation_50[0][0]              \n","                                                                 activation_53[0][0]              \n","__________________________________________________________________________________________________\n","block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n","                                                                 block35_7_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 35, 35, 32)   96          conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","activation_57 (Activation)      (None, 35, 35, 32)   0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 35, 35, 48)   13824       activation_57[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 35, 35, 32)   96          conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 35, 35, 48)   144         conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","activation_55 (Activation)      (None, 35, 35, 32)   0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","activation_58 (Activation)      (None, 35, 35, 48)   0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 35, 35, 32)   9216        activation_55[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, 35, 35, 64)   27648       activation_58[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 35, 35, 32)   96          conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 35, 35, 32)   96          conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 35, 35, 64)   192         conv2d_59[0][0]                  \n","__________________________________________________________________________________________________\n","activation_54 (Activation)      (None, 35, 35, 32)   0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","activation_56 (Activation)      (None, 35, 35, 32)   0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","activation_59 (Activation)      (None, 35, 35, 64)   0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_54[0][0]              \n","                                                                 activation_56[0][0]              \n","                                                                 activation_59[0][0]              \n","__________________________________________________________________________________________________\n","block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n","                                                                 block35_8_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 35, 35, 32)   96          conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 35, 35, 32)   0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_64 (Conv2D)              (None, 35, 35, 48)   13824       activation_63[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 35, 35, 32)   96          conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 35, 35, 48)   144         conv2d_64[0][0]                  \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 35, 35, 32)   0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 35, 35, 48)   0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, 35, 35, 32)   9216        activation_61[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_65 (Conv2D)              (None, 35, 35, 64)   27648       activation_64[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 35, 35, 32)   96          conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 35, 35, 32)   96          conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 35, 35, 64)   192         conv2d_65[0][0]                  \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 35, 35, 32)   0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 35, 35, 32)   0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 35, 35, 64)   0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_60[0][0]              \n","                                                                 activation_62[0][0]              \n","                                                                 activation_65[0][0]              \n","__________________________________________________________________________________________________\n","block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n","                                                                 block35_9_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_69 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 35, 35, 32)   96          conv2d_69[0][0]                  \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 35, 35, 32)   0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_67 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_70 (Conv2D)              (None, 35, 35, 48)   13824       activation_69[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 35, 35, 32)   96          conv2d_67[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 35, 35, 48)   144         conv2d_70[0][0]                  \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 35, 35, 32)   0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","activation_70 (Activation)      (None, 35, 35, 48)   0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_66 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_68 (Conv2D)              (None, 35, 35, 32)   9216        activation_67[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_71 (Conv2D)              (None, 35, 35, 64)   27648       activation_70[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 35, 35, 32)   96          conv2d_66[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 35, 35, 32)   96          conv2d_68[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 35, 35, 64)   192         conv2d_71[0][0]                  \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 35, 35, 32)   0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 35, 35, 32)   0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","activation_71 (Activation)      (None, 35, 35, 64)   0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_66[0][0]              \n","                                                                 activation_68[0][0]              \n","                                                                 activation_71[0][0]              \n","__________________________________________________________________________________________________\n","block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n","                                                                 block35_10_conv[0][0]            \n","__________________________________________________________________________________________________\n","block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_73 (Conv2D)              (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 35, 35, 256)  768         conv2d_73[0][0]                  \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 35, 35, 256)  0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_74 (Conv2D)              (None, 35, 35, 256)  589824      activation_73[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 35, 35, 256)  768         conv2d_74[0][0]                  \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 35, 35, 256)  0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_72 (Conv2D)              (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_75 (Conv2D)              (None, 17, 17, 384)  884736      activation_74[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 17, 17, 384)  1152        conv2d_72[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 17, 17, 384)  1152        conv2d_75[0][0]                  \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 17, 17, 384)  0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 17, 17, 384)  0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_72[0][0]              \n","                                                                 activation_75[0][0]              \n","                                                                 max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_77 (Conv2D)              (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 17, 17, 128)  0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_78 (Conv2D)              (None, 17, 17, 160)  143360      activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 17, 17, 160)  480         conv2d_78[0][0]                  \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 17, 17, 160)  0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_76 (Conv2D)              (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_79 (Conv2D)              (None, 17, 17, 192)  215040      activation_78[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 17, 17, 192)  576         conv2d_76[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 17, 17, 192)  576         conv2d_79[0][0]                  \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 17, 17, 192)  0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 17, 17, 192)  0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_76[0][0]              \n","                                                                 activation_79[0][0]              \n","__________________________________________________________________________________________________\n","block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n","                                                                 block17_1_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_81 (Conv2D)              (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 17, 17, 128)  384         conv2d_81[0][0]                  \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 17, 17, 128)  0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_82 (Conv2D)              (None, 17, 17, 160)  143360      activation_81[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 17, 17, 160)  480         conv2d_82[0][0]                  \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 17, 17, 160)  0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_80 (Conv2D)              (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_83 (Conv2D)              (None, 17, 17, 192)  215040      activation_82[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 17, 17, 192)  576         conv2d_80[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 17, 17, 192)  576         conv2d_83[0][0]                  \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 17, 17, 192)  0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_80[0][0]              \n","                                                                 activation_83[0][0]              \n","__________________________________________________________________________________________________\n","block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n","                                                                 block17_2_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_85 (Conv2D)              (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 17, 17, 128)  384         conv2d_85[0][0]                  \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 17, 17, 128)  0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_86 (Conv2D)              (None, 17, 17, 160)  143360      activation_85[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 17, 17, 160)  480         conv2d_86[0][0]                  \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 17, 17, 160)  0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_84 (Conv2D)              (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_87 (Conv2D)              (None, 17, 17, 192)  215040      activation_86[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 17, 17, 192)  576         conv2d_87[0][0]                  \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 17, 17, 192)  0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 17, 17, 192)  0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_84[0][0]              \n","                                                                 activation_87[0][0]              \n","__________________________________________________________________________________________________\n","block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n","                                                                 block17_3_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 17, 17, 128)  384         conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 17, 17, 128)  0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 17, 17, 160)  143360      activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 17, 17, 160)  480         conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 17, 17, 160)  0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 17, 17, 192)  215040      activation_90[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 17, 17, 192)  576         conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 17, 17, 192)  0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_88[0][0]              \n","                                                                 activation_91[0][0]              \n","__________________________________________________________________________________________________\n","block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n","                                                                 block17_4_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 17, 17, 128)  384         conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 17, 17, 128)  0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 17, 17, 160)  143360      activation_93[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 17, 17, 160)  480         conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 17, 17, 160)  0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 17, 17, 192)  215040      activation_94[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 17, 17, 192)  576         conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 17, 17, 192)  576         conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 17, 17, 192)  0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 17, 17, 192)  0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_92[0][0]              \n","                                                                 activation_95[0][0]              \n","__________________________________________________________________________________________________\n","block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n","                                                                 block17_5_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 17, 17, 128)  384         conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 17, 17, 128)  0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 17, 17, 160)  143360      activation_97[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 17, 17, 160)  480         conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 17, 17, 160)  0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 17, 17, 192)  215040      activation_98[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 17, 17, 192)  576         conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 17, 17, 192)  0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 17, 17, 192)  0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_96[0][0]              \n","                                                                 activation_99[0][0]              \n","__________________________________________________________________________________________________\n","block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n","                                                                 block17_6_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 17, 17, 128)  384         conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 17, 17, 128)  0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 17, 17, 160)  143360      activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 17, 17, 160)  480         conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 17, 17, 160)  0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 17, 17, 192)  215040      activation_102[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 17, 17, 192)  576         conv2d_100[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 17, 17, 192)  576         conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 17, 17, 192)  0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 17, 17, 192)  0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_100[0][0]             \n","                                                                 activation_103[0][0]             \n","__________________________________________________________________________________________________\n","block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n","                                                                 block17_7_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_105 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_105 (BatchN (None, 17, 17, 128)  384         conv2d_105[0][0]                 \n","__________________________________________________________________________________________________\n","activation_105 (Activation)     (None, 17, 17, 128)  0           batch_normalization_105[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_106 (Conv2D)             (None, 17, 17, 160)  143360      activation_105[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_106 (BatchN (None, 17, 17, 160)  480         conv2d_106[0][0]                 \n","__________________________________________________________________________________________________\n","activation_106 (Activation)     (None, 17, 17, 160)  0           batch_normalization_106[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_107 (Conv2D)             (None, 17, 17, 192)  215040      activation_106[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 17, 17, 192)  576         conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_107 (BatchN (None, 17, 17, 192)  576         conv2d_107[0][0]                 \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 17, 17, 192)  0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","activation_107 (Activation)     (None, 17, 17, 192)  0           batch_normalization_107[0][0]    \n","__________________________________________________________________________________________________\n","block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_104[0][0]             \n","                                                                 activation_107[0][0]             \n","__________________________________________________________________________________________________\n","block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n","                                                                 block17_8_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_109 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_109 (BatchN (None, 17, 17, 128)  384         conv2d_109[0][0]                 \n","__________________________________________________________________________________________________\n","activation_109 (Activation)     (None, 17, 17, 128)  0           batch_normalization_109[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_110 (Conv2D)             (None, 17, 17, 160)  143360      activation_109[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_110 (BatchN (None, 17, 17, 160)  480         conv2d_110[0][0]                 \n","__________________________________________________________________________________________________\n","activation_110 (Activation)     (None, 17, 17, 160)  0           batch_normalization_110[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_108 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_111 (Conv2D)             (None, 17, 17, 192)  215040      activation_110[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_108 (BatchN (None, 17, 17, 192)  576         conv2d_108[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_111 (BatchN (None, 17, 17, 192)  576         conv2d_111[0][0]                 \n","__________________________________________________________________________________________________\n","activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_108[0][0]    \n","__________________________________________________________________________________________________\n","activation_111 (Activation)     (None, 17, 17, 192)  0           batch_normalization_111[0][0]    \n","__________________________________________________________________________________________________\n","block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_108[0][0]             \n","                                                                 activation_111[0][0]             \n","__________________________________________________________________________________________________\n","block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n","                                                                 block17_9_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_113 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_113 (BatchN (None, 17, 17, 128)  384         conv2d_113[0][0]                 \n","__________________________________________________________________________________________________\n","activation_113 (Activation)     (None, 17, 17, 128)  0           batch_normalization_113[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_114 (Conv2D)             (None, 17, 17, 160)  143360      activation_113[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_114 (BatchN (None, 17, 17, 160)  480         conv2d_114[0][0]                 \n","__________________________________________________________________________________________________\n","activation_114 (Activation)     (None, 17, 17, 160)  0           batch_normalization_114[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_112 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_115 (Conv2D)             (None, 17, 17, 192)  215040      activation_114[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_112 (BatchN (None, 17, 17, 192)  576         conv2d_112[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_115 (BatchN (None, 17, 17, 192)  576         conv2d_115[0][0]                 \n","__________________________________________________________________________________________________\n","activation_112 (Activation)     (None, 17, 17, 192)  0           batch_normalization_112[0][0]    \n","__________________________________________________________________________________________________\n","activation_115 (Activation)     (None, 17, 17, 192)  0           batch_normalization_115[0][0]    \n","__________________________________________________________________________________________________\n","block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_112[0][0]             \n","                                                                 activation_115[0][0]             \n","__________________________________________________________________________________________________\n","block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n","                                                                 block17_10_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_117 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_117 (BatchN (None, 17, 17, 128)  384         conv2d_117[0][0]                 \n","__________________________________________________________________________________________________\n","activation_117 (Activation)     (None, 17, 17, 128)  0           batch_normalization_117[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_118 (Conv2D)             (None, 17, 17, 160)  143360      activation_117[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_118 (BatchN (None, 17, 17, 160)  480         conv2d_118[0][0]                 \n","__________________________________________________________________________________________________\n","activation_118 (Activation)     (None, 17, 17, 160)  0           batch_normalization_118[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_116 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_119 (Conv2D)             (None, 17, 17, 192)  215040      activation_118[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_116 (BatchN (None, 17, 17, 192)  576         conv2d_116[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_119 (BatchN (None, 17, 17, 192)  576         conv2d_119[0][0]                 \n","__________________________________________________________________________________________________\n","activation_116 (Activation)     (None, 17, 17, 192)  0           batch_normalization_116[0][0]    \n","__________________________________________________________________________________________________\n","activation_119 (Activation)     (None, 17, 17, 192)  0           batch_normalization_119[0][0]    \n","__________________________________________________________________________________________________\n","block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_116[0][0]             \n","                                                                 activation_119[0][0]             \n","__________________________________________________________________________________________________\n","block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n","                                                                 block17_11_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_121 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_121 (BatchN (None, 17, 17, 128)  384         conv2d_121[0][0]                 \n","__________________________________________________________________________________________________\n","activation_121 (Activation)     (None, 17, 17, 128)  0           batch_normalization_121[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_122 (Conv2D)             (None, 17, 17, 160)  143360      activation_121[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_122 (BatchN (None, 17, 17, 160)  480         conv2d_122[0][0]                 \n","__________________________________________________________________________________________________\n","activation_122 (Activation)     (None, 17, 17, 160)  0           batch_normalization_122[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_120 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_123 (Conv2D)             (None, 17, 17, 192)  215040      activation_122[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_120 (BatchN (None, 17, 17, 192)  576         conv2d_120[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_123 (BatchN (None, 17, 17, 192)  576         conv2d_123[0][0]                 \n","__________________________________________________________________________________________________\n","activation_120 (Activation)     (None, 17, 17, 192)  0           batch_normalization_120[0][0]    \n","__________________________________________________________________________________________________\n","activation_123 (Activation)     (None, 17, 17, 192)  0           batch_normalization_123[0][0]    \n","__________________________________________________________________________________________________\n","block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_120[0][0]             \n","                                                                 activation_123[0][0]             \n","__________________________________________________________________________________________________\n","block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n","                                                                 block17_12_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_125 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_125 (BatchN (None, 17, 17, 128)  384         conv2d_125[0][0]                 \n","__________________________________________________________________________________________________\n","activation_125 (Activation)     (None, 17, 17, 128)  0           batch_normalization_125[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_126 (Conv2D)             (None, 17, 17, 160)  143360      activation_125[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_126 (BatchN (None, 17, 17, 160)  480         conv2d_126[0][0]                 \n","__________________________________________________________________________________________________\n","activation_126 (Activation)     (None, 17, 17, 160)  0           batch_normalization_126[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_124 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_127 (Conv2D)             (None, 17, 17, 192)  215040      activation_126[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_127 (BatchN (None, 17, 17, 192)  576         conv2d_127[0][0]                 \n","__________________________________________________________________________________________________\n","activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    \n","__________________________________________________________________________________________________\n","activation_127 (Activation)     (None, 17, 17, 192)  0           batch_normalization_127[0][0]    \n","__________________________________________________________________________________________________\n","block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_124[0][0]             \n","                                                                 activation_127[0][0]             \n","__________________________________________________________________________________________________\n","block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n","                                                                 block17_13_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_129 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_129 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n","__________________________________________________________________________________________________\n","activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_129[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_130 (Conv2D)             (None, 17, 17, 160)  143360      activation_129[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_130 (BatchN (None, 17, 17, 160)  480         conv2d_130[0][0]                 \n","__________________________________________________________________________________________________\n","activation_130 (Activation)     (None, 17, 17, 160)  0           batch_normalization_130[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_128 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_131 (Conv2D)             (None, 17, 17, 192)  215040      activation_130[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_128 (BatchN (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_131 (BatchN (None, 17, 17, 192)  576         conv2d_131[0][0]                 \n","__________________________________________________________________________________________________\n","activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_128[0][0]    \n","__________________________________________________________________________________________________\n","activation_131 (Activation)     (None, 17, 17, 192)  0           batch_normalization_131[0][0]    \n","__________________________________________________________________________________________________\n","block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_128[0][0]             \n","                                                                 activation_131[0][0]             \n","__________________________________________________________________________________________________\n","block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n","                                                                 block17_14_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_133 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_133 (BatchN (None, 17, 17, 128)  384         conv2d_133[0][0]                 \n","__________________________________________________________________________________________________\n","activation_133 (Activation)     (None, 17, 17, 128)  0           batch_normalization_133[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_134 (Conv2D)             (None, 17, 17, 160)  143360      activation_133[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_134 (BatchN (None, 17, 17, 160)  480         conv2d_134[0][0]                 \n","__________________________________________________________________________________________________\n","activation_134 (Activation)     (None, 17, 17, 160)  0           batch_normalization_134[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_132 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_135 (Conv2D)             (None, 17, 17, 192)  215040      activation_134[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_135 (BatchN (None, 17, 17, 192)  576         conv2d_135[0][0]                 \n","__________________________________________________________________________________________________\n","activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    \n","__________________________________________________________________________________________________\n","activation_135 (Activation)     (None, 17, 17, 192)  0           batch_normalization_135[0][0]    \n","__________________________________________________________________________________________________\n","block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_132[0][0]             \n","                                                                 activation_135[0][0]             \n","__________________________________________________________________________________________________\n","block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n","                                                                 block17_15_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_137 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_137 (BatchN (None, 17, 17, 128)  384         conv2d_137[0][0]                 \n","__________________________________________________________________________________________________\n","activation_137 (Activation)     (None, 17, 17, 128)  0           batch_normalization_137[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_138 (Conv2D)             (None, 17, 17, 160)  143360      activation_137[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_138 (BatchN (None, 17, 17, 160)  480         conv2d_138[0][0]                 \n","__________________________________________________________________________________________________\n","activation_138 (Activation)     (None, 17, 17, 160)  0           batch_normalization_138[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_136 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_139 (Conv2D)             (None, 17, 17, 192)  215040      activation_138[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_136 (BatchN (None, 17, 17, 192)  576         conv2d_136[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_139 (BatchN (None, 17, 17, 192)  576         conv2d_139[0][0]                 \n","__________________________________________________________________________________________________\n","activation_136 (Activation)     (None, 17, 17, 192)  0           batch_normalization_136[0][0]    \n","__________________________________________________________________________________________________\n","activation_139 (Activation)     (None, 17, 17, 192)  0           batch_normalization_139[0][0]    \n","__________________________________________________________________________________________________\n","block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_136[0][0]             \n","                                                                 activation_139[0][0]             \n","__________________________________________________________________________________________________\n","block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n","                                                                 block17_16_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_141 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_141 (BatchN (None, 17, 17, 128)  384         conv2d_141[0][0]                 \n","__________________________________________________________________________________________________\n","activation_141 (Activation)     (None, 17, 17, 128)  0           batch_normalization_141[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_142 (Conv2D)             (None, 17, 17, 160)  143360      activation_141[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_142 (BatchN (None, 17, 17, 160)  480         conv2d_142[0][0]                 \n","__________________________________________________________________________________________________\n","activation_142 (Activation)     (None, 17, 17, 160)  0           batch_normalization_142[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_140 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_143 (Conv2D)             (None, 17, 17, 192)  215040      activation_142[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_140 (BatchN (None, 17, 17, 192)  576         conv2d_140[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_143 (BatchN (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n","__________________________________________________________________________________________________\n","activation_140 (Activation)     (None, 17, 17, 192)  0           batch_normalization_140[0][0]    \n","__________________________________________________________________________________________________\n","activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_143[0][0]    \n","__________________________________________________________________________________________________\n","block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_140[0][0]             \n","                                                                 activation_143[0][0]             \n","__________________________________________________________________________________________________\n","block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n","                                                                 block17_17_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_145 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_145 (BatchN (None, 17, 17, 128)  384         conv2d_145[0][0]                 \n","__________________________________________________________________________________________________\n","activation_145 (Activation)     (None, 17, 17, 128)  0           batch_normalization_145[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_146 (Conv2D)             (None, 17, 17, 160)  143360      activation_145[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_146 (BatchN (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n","__________________________________________________________________________________________________\n","activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_146[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_144 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_147 (Conv2D)             (None, 17, 17, 192)  215040      activation_146[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_147 (BatchN (None, 17, 17, 192)  576         conv2d_147[0][0]                 \n","__________________________________________________________________________________________________\n","activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n","__________________________________________________________________________________________________\n","activation_147 (Activation)     (None, 17, 17, 192)  0           batch_normalization_147[0][0]    \n","__________________________________________________________________________________________________\n","block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_144[0][0]             \n","                                                                 activation_147[0][0]             \n","__________________________________________________________________________________________________\n","block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n","                                                                 block17_18_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_149 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_149 (BatchN (None, 17, 17, 128)  384         conv2d_149[0][0]                 \n","__________________________________________________________________________________________________\n","activation_149 (Activation)     (None, 17, 17, 128)  0           batch_normalization_149[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_150 (Conv2D)             (None, 17, 17, 160)  143360      activation_149[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_150 (BatchN (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n","__________________________________________________________________________________________________\n","activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_150[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_148 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_151 (Conv2D)             (None, 17, 17, 192)  215040      activation_150[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_148 (BatchN (None, 17, 17, 192)  576         conv2d_148[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_151 (BatchN (None, 17, 17, 192)  576         conv2d_151[0][0]                 \n","__________________________________________________________________________________________________\n","activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_148[0][0]    \n","__________________________________________________________________________________________________\n","activation_151 (Activation)     (None, 17, 17, 192)  0           batch_normalization_151[0][0]    \n","__________________________________________________________________________________________________\n","block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_148[0][0]             \n","                                                                 activation_151[0][0]             \n","__________________________________________________________________________________________________\n","block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n","                                                                 block17_19_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_153 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_153 (BatchN (None, 17, 17, 128)  384         conv2d_153[0][0]                 \n","__________________________________________________________________________________________________\n","activation_153 (Activation)     (None, 17, 17, 128)  0           batch_normalization_153[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_154 (Conv2D)             (None, 17, 17, 160)  143360      activation_153[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_154 (BatchN (None, 17, 17, 160)  480         conv2d_154[0][0]                 \n","__________________________________________________________________________________________________\n","activation_154 (Activation)     (None, 17, 17, 160)  0           batch_normalization_154[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_152 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_155 (Conv2D)             (None, 17, 17, 192)  215040      activation_154[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_155 (BatchN (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n","__________________________________________________________________________________________________\n","activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    \n","__________________________________________________________________________________________________\n","activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_155[0][0]    \n","__________________________________________________________________________________________________\n","block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_152[0][0]             \n","                                                                 activation_155[0][0]             \n","__________________________________________________________________________________________________\n","block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n","                                                                 block17_20_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_160 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_160 (BatchN (None, 17, 17, 256)  768         conv2d_160[0][0]                 \n","__________________________________________________________________________________________________\n","activation_160 (Activation)     (None, 17, 17, 256)  0           batch_normalization_160[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_156 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_158 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_161 (Conv2D)             (None, 17, 17, 288)  663552      activation_160[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_156 (BatchN (None, 17, 17, 256)  768         conv2d_156[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_158 (BatchN (None, 17, 17, 256)  768         conv2d_158[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_161 (BatchN (None, 17, 17, 288)  864         conv2d_161[0][0]                 \n","__________________________________________________________________________________________________\n","activation_156 (Activation)     (None, 17, 17, 256)  0           batch_normalization_156[0][0]    \n","__________________________________________________________________________________________________\n","activation_158 (Activation)     (None, 17, 17, 256)  0           batch_normalization_158[0][0]    \n","__________________________________________________________________________________________________\n","activation_161 (Activation)     (None, 17, 17, 288)  0           batch_normalization_161[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_157 (Conv2D)             (None, 8, 8, 384)    884736      activation_156[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_159 (Conv2D)             (None, 8, 8, 288)    663552      activation_158[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_162 (Conv2D)             (None, 8, 8, 320)    829440      activation_161[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_157 (BatchN (None, 8, 8, 384)    1152        conv2d_157[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_159 (BatchN (None, 8, 8, 288)    864         conv2d_159[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_162 (BatchN (None, 8, 8, 320)    960         conv2d_162[0][0]                 \n","__________________________________________________________________________________________________\n","activation_157 (Activation)     (None, 8, 8, 384)    0           batch_normalization_157[0][0]    \n","__________________________________________________________________________________________________\n","activation_159 (Activation)     (None, 8, 8, 288)    0           batch_normalization_159[0][0]    \n","__________________________________________________________________________________________________\n","activation_162 (Activation)     (None, 8, 8, 320)    0           batch_normalization_162[0][0]    \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n","__________________________________________________________________________________________________\n","mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_157[0][0]             \n","                                                                 activation_159[0][0]             \n","                                                                 activation_162[0][0]             \n","                                                                 max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_164 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_164 (BatchN (None, 8, 8, 192)    576         conv2d_164[0][0]                 \n","__________________________________________________________________________________________________\n","activation_164 (Activation)     (None, 8, 8, 192)    0           batch_normalization_164[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_165 (Conv2D)             (None, 8, 8, 224)    129024      activation_164[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_165 (BatchN (None, 8, 8, 224)    672         conv2d_165[0][0]                 \n","__________________________________________________________________________________________________\n","activation_165 (Activation)     (None, 8, 8, 224)    0           batch_normalization_165[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_163 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_166 (Conv2D)             (None, 8, 8, 256)    172032      activation_165[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_163 (BatchN (None, 8, 8, 192)    576         conv2d_163[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_166 (BatchN (None, 8, 8, 256)    768         conv2d_166[0][0]                 \n","__________________________________________________________________________________________________\n","activation_163 (Activation)     (None, 8, 8, 192)    0           batch_normalization_163[0][0]    \n","__________________________________________________________________________________________________\n","activation_166 (Activation)     (None, 8, 8, 256)    0           batch_normalization_166[0][0]    \n","__________________________________________________________________________________________________\n","block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_163[0][0]             \n","                                                                 activation_166[0][0]             \n","__________________________________________________________________________________________________\n","block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n","                                                                 block8_1_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_168 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_168 (BatchN (None, 8, 8, 192)    576         conv2d_168[0][0]                 \n","__________________________________________________________________________________________________\n","activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_168[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_169 (Conv2D)             (None, 8, 8, 224)    129024      activation_168[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_169 (BatchN (None, 8, 8, 224)    672         conv2d_169[0][0]                 \n","__________________________________________________________________________________________________\n","activation_169 (Activation)     (None, 8, 8, 224)    0           batch_normalization_169[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_167 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_170 (Conv2D)             (None, 8, 8, 256)    172032      activation_169[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_167 (BatchN (None, 8, 8, 192)    576         conv2d_167[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_170 (BatchN (None, 8, 8, 256)    768         conv2d_170[0][0]                 \n","__________________________________________________________________________________________________\n","activation_167 (Activation)     (None, 8, 8, 192)    0           batch_normalization_167[0][0]    \n","__________________________________________________________________________________________________\n","activation_170 (Activation)     (None, 8, 8, 256)    0           batch_normalization_170[0][0]    \n","__________________________________________________________________________________________________\n","block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_167[0][0]             \n","                                                                 activation_170[0][0]             \n","__________________________________________________________________________________________________\n","block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n","                                                                 block8_2_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_172 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_172 (BatchN (None, 8, 8, 192)    576         conv2d_172[0][0]                 \n","__________________________________________________________________________________________________\n","activation_172 (Activation)     (None, 8, 8, 192)    0           batch_normalization_172[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_173 (Conv2D)             (None, 8, 8, 224)    129024      activation_172[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_173 (BatchN (None, 8, 8, 224)    672         conv2d_173[0][0]                 \n","__________________________________________________________________________________________________\n","activation_173 (Activation)     (None, 8, 8, 224)    0           batch_normalization_173[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_171 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_174 (Conv2D)             (None, 8, 8, 256)    172032      activation_173[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_171 (BatchN (None, 8, 8, 192)    576         conv2d_171[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_174 (BatchN (None, 8, 8, 256)    768         conv2d_174[0][0]                 \n","__________________________________________________________________________________________________\n","activation_171 (Activation)     (None, 8, 8, 192)    0           batch_normalization_171[0][0]    \n","__________________________________________________________________________________________________\n","activation_174 (Activation)     (None, 8, 8, 256)    0           batch_normalization_174[0][0]    \n","__________________________________________________________________________________________________\n","block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_171[0][0]             \n","                                                                 activation_174[0][0]             \n","__________________________________________________________________________________________________\n","block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n","                                                                 block8_3_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_176 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_176 (BatchN (None, 8, 8, 192)    576         conv2d_176[0][0]                 \n","__________________________________________________________________________________________________\n","activation_176 (Activation)     (None, 8, 8, 192)    0           batch_normalization_176[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_177 (Conv2D)             (None, 8, 8, 224)    129024      activation_176[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_177 (BatchN (None, 8, 8, 224)    672         conv2d_177[0][0]                 \n","__________________________________________________________________________________________________\n","activation_177 (Activation)     (None, 8, 8, 224)    0           batch_normalization_177[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_175 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_178 (Conv2D)             (None, 8, 8, 256)    172032      activation_177[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_175 (BatchN (None, 8, 8, 192)    576         conv2d_175[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_178 (BatchN (None, 8, 8, 256)    768         conv2d_178[0][0]                 \n","__________________________________________________________________________________________________\n","activation_175 (Activation)     (None, 8, 8, 192)    0           batch_normalization_175[0][0]    \n","__________________________________________________________________________________________________\n","activation_178 (Activation)     (None, 8, 8, 256)    0           batch_normalization_178[0][0]    \n","__________________________________________________________________________________________________\n","block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_175[0][0]             \n","                                                                 activation_178[0][0]             \n","__________________________________________________________________________________________________\n","block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n","                                                                 block8_4_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_180 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_180 (BatchN (None, 8, 8, 192)    576         conv2d_180[0][0]                 \n","__________________________________________________________________________________________________\n","activation_180 (Activation)     (None, 8, 8, 192)    0           batch_normalization_180[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_181 (Conv2D)             (None, 8, 8, 224)    129024      activation_180[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_181 (BatchN (None, 8, 8, 224)    672         conv2d_181[0][0]                 \n","__________________________________________________________________________________________________\n","activation_181 (Activation)     (None, 8, 8, 224)    0           batch_normalization_181[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_179 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_182 (Conv2D)             (None, 8, 8, 256)    172032      activation_181[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_179 (BatchN (None, 8, 8, 192)    576         conv2d_179[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_182 (BatchN (None, 8, 8, 256)    768         conv2d_182[0][0]                 \n","__________________________________________________________________________________________________\n","activation_179 (Activation)     (None, 8, 8, 192)    0           batch_normalization_179[0][0]    \n","__________________________________________________________________________________________________\n","activation_182 (Activation)     (None, 8, 8, 256)    0           batch_normalization_182[0][0]    \n","__________________________________________________________________________________________________\n","block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_179[0][0]             \n","                                                                 activation_182[0][0]             \n","__________________________________________________________________________________________________\n","block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n","                                                                 block8_5_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_184 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_184 (BatchN (None, 8, 8, 192)    576         conv2d_184[0][0]                 \n","__________________________________________________________________________________________________\n","activation_184 (Activation)     (None, 8, 8, 192)    0           batch_normalization_184[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_185 (Conv2D)             (None, 8, 8, 224)    129024      activation_184[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_185 (BatchN (None, 8, 8, 224)    672         conv2d_185[0][0]                 \n","__________________________________________________________________________________________________\n","activation_185 (Activation)     (None, 8, 8, 224)    0           batch_normalization_185[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_183 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_186 (Conv2D)             (None, 8, 8, 256)    172032      activation_185[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_183 (BatchN (None, 8, 8, 192)    576         conv2d_183[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_186 (BatchN (None, 8, 8, 256)    768         conv2d_186[0][0]                 \n","__________________________________________________________________________________________________\n","activation_183 (Activation)     (None, 8, 8, 192)    0           batch_normalization_183[0][0]    \n","__________________________________________________________________________________________________\n","activation_186 (Activation)     (None, 8, 8, 256)    0           batch_normalization_186[0][0]    \n","__________________________________________________________________________________________________\n","block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_183[0][0]             \n","                                                                 activation_186[0][0]             \n","__________________________________________________________________________________________________\n","block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n","                                                                 block8_6_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_188 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_188 (BatchN (None, 8, 8, 192)    576         conv2d_188[0][0]                 \n","__________________________________________________________________________________________________\n","activation_188 (Activation)     (None, 8, 8, 192)    0           batch_normalization_188[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_189 (Conv2D)             (None, 8, 8, 224)    129024      activation_188[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_189 (BatchN (None, 8, 8, 224)    672         conv2d_189[0][0]                 \n","__________________________________________________________________________________________________\n","activation_189 (Activation)     (None, 8, 8, 224)    0           batch_normalization_189[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_187 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_190 (Conv2D)             (None, 8, 8, 256)    172032      activation_189[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_187 (BatchN (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_190 (BatchN (None, 8, 8, 256)    768         conv2d_190[0][0]                 \n","__________________________________________________________________________________________________\n","activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_187[0][0]    \n","__________________________________________________________________________________________________\n","activation_190 (Activation)     (None, 8, 8, 256)    0           batch_normalization_190[0][0]    \n","__________________________________________________________________________________________________\n","block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_187[0][0]             \n","                                                                 activation_190[0][0]             \n","__________________________________________________________________________________________________\n","block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n","                                                                 block8_7_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_192 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_192 (BatchN (None, 8, 8, 192)    576         conv2d_192[0][0]                 \n","__________________________________________________________________________________________________\n","activation_192 (Activation)     (None, 8, 8, 192)    0           batch_normalization_192[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_193 (Conv2D)             (None, 8, 8, 224)    129024      activation_192[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_193 (BatchN (None, 8, 8, 224)    672         conv2d_193[0][0]                 \n","__________________________________________________________________________________________________\n","activation_193 (Activation)     (None, 8, 8, 224)    0           batch_normalization_193[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_191 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_194 (Conv2D)             (None, 8, 8, 256)    172032      activation_193[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_191 (BatchN (None, 8, 8, 192)    576         conv2d_191[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_194 (BatchN (None, 8, 8, 256)    768         conv2d_194[0][0]                 \n","__________________________________________________________________________________________________\n","activation_191 (Activation)     (None, 8, 8, 192)    0           batch_normalization_191[0][0]    \n","__________________________________________________________________________________________________\n","activation_194 (Activation)     (None, 8, 8, 256)    0           batch_normalization_194[0][0]    \n","__________________________________________________________________________________________________\n","block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_191[0][0]             \n","                                                                 activation_194[0][0]             \n","__________________________________________________________________________________________________\n","block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n","                                                                 block8_8_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_196 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_196 (BatchN (None, 8, 8, 192)    576         conv2d_196[0][0]                 \n","__________________________________________________________________________________________________\n","activation_196 (Activation)     (None, 8, 8, 192)    0           batch_normalization_196[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_197 (Conv2D)             (None, 8, 8, 224)    129024      activation_196[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_197 (BatchN (None, 8, 8, 224)    672         conv2d_197[0][0]                 \n","__________________________________________________________________________________________________\n","activation_197 (Activation)     (None, 8, 8, 224)    0           batch_normalization_197[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_195 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_198 (Conv2D)             (None, 8, 8, 256)    172032      activation_197[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_195 (BatchN (None, 8, 8, 192)    576         conv2d_195[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_198 (BatchN (None, 8, 8, 256)    768         conv2d_198[0][0]                 \n","__________________________________________________________________________________________________\n","activation_195 (Activation)     (None, 8, 8, 192)    0           batch_normalization_195[0][0]    \n","__________________________________________________________________________________________________\n","activation_198 (Activation)     (None, 8, 8, 256)    0           batch_normalization_198[0][0]    \n","__________________________________________________________________________________________________\n","block8_9_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_195[0][0]             \n","                                                                 activation_198[0][0]             \n","__________________________________________________________________________________________________\n","block8_9_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_9_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_9 (Lambda)               (None, 8, 8, 2080)   0           block8_8_ac[0][0]                \n","                                                                 block8_9_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_9_ac (Activation)        (None, 8, 8, 2080)   0           block8_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_200 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_200 (BatchN (None, 8, 8, 192)    576         conv2d_200[0][0]                 \n","__________________________________________________________________________________________________\n","activation_200 (Activation)     (None, 8, 8, 192)    0           batch_normalization_200[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_201 (Conv2D)             (None, 8, 8, 224)    129024      activation_200[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_201 (BatchN (None, 8, 8, 224)    672         conv2d_201[0][0]                 \n","__________________________________________________________________________________________________\n","activation_201 (Activation)     (None, 8, 8, 224)    0           batch_normalization_201[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_199 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_202 (Conv2D)             (None, 8, 8, 256)    172032      activation_201[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_199 (BatchN (None, 8, 8, 192)    576         conv2d_199[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_202 (BatchN (None, 8, 8, 256)    768         conv2d_202[0][0]                 \n","__________________________________________________________________________________________________\n","activation_199 (Activation)     (None, 8, 8, 192)    0           batch_normalization_199[0][0]    \n","__________________________________________________________________________________________________\n","activation_202 (Activation)     (None, 8, 8, 256)    0           batch_normalization_202[0][0]    \n","__________________________________________________________________________________________________\n","block8_10_mixed (Concatenate)   (None, 8, 8, 448)    0           activation_199[0][0]             \n","                                                                 activation_202[0][0]             \n","__________________________________________________________________________________________________\n","block8_10_conv (Conv2D)         (None, 8, 8, 2080)   933920      block8_10_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block8_10 (Lambda)              (None, 8, 8, 2080)   0           block8_9_ac[0][0]                \n","                                                                 block8_10_conv[0][0]             \n","__________________________________________________________________________________________________\n","conv_7b (Conv2D)                (None, 8, 8, 1536)   3194880     block8_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv_7b_bn (BatchNormalization) (None, 8, 8, 1536)   4608        conv_7b[0][0]                    \n","__________________________________________________________________________________________________\n","conv_7b_ac (Activation)         (None, 8, 8, 1536)   0           conv_7b_bn[0][0]                 \n","__________________________________________________________________________________________________\n","avg_pool (GlobalAveragePooling2 (None, 1536)         0           conv_7b_ac[0][0]                 \n","__________________________________________________________________________________________________\n","predictions (Dense)             (None, 100)          153600      avg_pool[0][0]                   \n","==================================================================================================\n","Total params: 54,490,336\n","Trainable params: 54,429,792\n","Non-trainable params: 60,544\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yNCT3g8eE6vT"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3uJNxsK7bp1E"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ub52D1YRsh0n"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoWLeggG6dBf"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9pnv0cw6dBm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"889da6fc-354c-43b5-f809-312c10bca833"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_8/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_6/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_9/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_5/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_7/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_10/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_11/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_15/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_13/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_16/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_12/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_14/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_17/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_1_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_21/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_19/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_22/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_18/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_20/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_23/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_2_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_27/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_25/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_28/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_24/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_26/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_29/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_3_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_33/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_31/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_34/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_30/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_32/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_35/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_4_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_39/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_37/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_40/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_36/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_38/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_41/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_5_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_45/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_43/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_46/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_42/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_44/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_47/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_6_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_51/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_49/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_52/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_48/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_50/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_53/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_7_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_57/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_55/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_58/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_54/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_56/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_59/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_8_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_63/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_61/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_64/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_60/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_62/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_65/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_9_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_69/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_67/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_70/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_66/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_68/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_71/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_10_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_73/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_74/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_72/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_75/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_77/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_78/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_76/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_79/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_1_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_81/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_82/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_80/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_83/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_2_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_85/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_86/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_84/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_87/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_3_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_89/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_90/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_88/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_91/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_4_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_93/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_94/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_92/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_95/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_5_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_97/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_98/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_96/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_99/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_6_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_101/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_102/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_100/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_103/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_7_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_105/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_106/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_104/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_107/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_8_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_109/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_110/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_108/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_111/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_9_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_113/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_114/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_112/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_115/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_10_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_117/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_118/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_116/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_119/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_11_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_121/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_122/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_120/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_123/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_12_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_125/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_126/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_124/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_127/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_13_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_129/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_130/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_128/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_131/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_14_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_133/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_134/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_132/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_135/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_15_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_137/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_138/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_136/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_139/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_16_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_141/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_142/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_140/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_143/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_17_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_145/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_146/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_144/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_147/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_18_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_149/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_150/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_148/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_151/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_19_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_153/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_154/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_152/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_155/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_20_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_160/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_156/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_158/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_161/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_157/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_159/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_162/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_164/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_165/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_163/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_166/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_1_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_168/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_169/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_167/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_170/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_2_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_172/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_173/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_171/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_174/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_3_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_176/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_177/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_175/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_178/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_4_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_180/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_181/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_179/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_182/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_5_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_184/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_185/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_183/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_186/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_6_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_188/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_189/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_187/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_190/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_7_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_192/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_193/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_191/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_194/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_8_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_196/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_197/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_195/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_198/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_9_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_200/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_201/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_199/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_202/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_10_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv_7b/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for predictions/kernel:0\n","1403/1403 [==============================] - ETA: 0s - loss: 3.8019 - accuracy: 0.1148 - top5_acc: 0.3346 - macro_f1score: 0.0019 \n","Epoch 00001: val_loss improved from inf to 3.51205, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.16733, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/001.h5\n","1403/1403 [==============================] - 25285s 18s/step - loss: 3.8019 - accuracy: 0.1148 - top5_acc: 0.3346 - macro_f1score: 0.0019 - val_loss: 3.5120 - val_accuracy: 0.1673 - val_top5_acc: 0.4242 - val_macro_f1score: 0.0084\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","1403/1403 [==============================] - ETA: 0s - loss: 2.9886 - accuracy: 0.2468 - top5_acc: 0.5585 - macro_f1score: 0.0178\n","Epoch 00002: val_loss improved from 3.51205 to 2.87846, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/002.h5\n","\n","Epoch 00002: val_accuracy improved from 0.16733 to 0.29826, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/002.h5\n","1403/1403 [==============================] - 1157s 825ms/step - loss: 2.9886 - accuracy: 0.2468 - top5_acc: 0.5585 - macro_f1score: 0.0178 - val_loss: 2.8785 - val_accuracy: 0.2983 - val_top5_acc: 0.6090 - val_macro_f1score: 0.0349\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","1403/1403 [==============================] - ETA: 0s - loss: 2.4320 - accuracy: 0.3593 - top5_acc: 0.6890 - macro_f1score: 0.0459\n","Epoch 00003: val_loss improved from 2.87846 to 2.64102, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/003.h5\n","\n","Epoch 00003: val_accuracy improved from 0.29826 to 0.33979, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/003.h5\n","1403/1403 [==============================] - 1161s 828ms/step - loss: 2.4320 - accuracy: 0.3593 - top5_acc: 0.6890 - macro_f1score: 0.0459 - val_loss: 2.6410 - val_accuracy: 0.3398 - val_top5_acc: 0.6671 - val_macro_f1score: 0.0537\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","1403/1403 [==============================] - ETA: 0s - loss: 2.0767 - accuracy: 0.4402 - top5_acc: 0.7633 - macro_f1score: 0.0720\n","Epoch 00004: val_loss improved from 2.64102 to 2.08052, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/004.h5\n","\n","Epoch 00004: val_accuracy improved from 0.33979 to 0.45194, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/004.h5\n","1403/1403 [==============================] - 1178s 840ms/step - loss: 2.0767 - accuracy: 0.4402 - top5_acc: 0.7633 - macro_f1score: 0.0720 - val_loss: 2.0805 - val_accuracy: 0.4519 - val_top5_acc: 0.7668 - val_macro_f1score: 0.0804\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.8046 - accuracy: 0.5011 - top5_acc: 0.8126 - macro_f1score: 0.0937\n","Epoch 00005: val_loss improved from 2.08052 to 1.97723, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/005.h5\n","\n","Epoch 00005: val_accuracy improved from 0.45194 to 0.47646, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/005.h5\n","1403/1403 [==============================] - 1171s 834ms/step - loss: 1.8046 - accuracy: 0.5011 - top5_acc: 0.8126 - macro_f1score: 0.0937 - val_loss: 1.9772 - val_accuracy: 0.4765 - val_top5_acc: 0.7801 - val_macro_f1score: 0.0909\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.6216 - accuracy: 0.5493 - top5_acc: 0.8444 - macro_f1score: 0.1103\n","Epoch 00006: val_loss improved from 1.97723 to 1.78331, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/006.h5\n","\n","Epoch 00006: val_accuracy improved from 0.47646 to 0.51147, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/006.h5\n","1403/1403 [==============================] - 1168s 833ms/step - loss: 1.6216 - accuracy: 0.5493 - top5_acc: 0.8444 - macro_f1score: 0.1103 - val_loss: 1.7833 - val_accuracy: 0.5115 - val_top5_acc: 0.8190 - val_macro_f1score: 0.1120\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.4501 - accuracy: 0.5896 - top5_acc: 0.8701 - macro_f1score: 0.1261\n","Epoch 00007: val_loss improved from 1.78331 to 1.67284, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/007.h5\n","\n","Epoch 00007: val_accuracy improved from 0.51147 to 0.53916, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/007.h5\n","1403/1403 [==============================] - 1161s 828ms/step - loss: 1.4501 - accuracy: 0.5896 - top5_acc: 0.8701 - macro_f1score: 0.1261 - val_loss: 1.6728 - val_accuracy: 0.5392 - val_top5_acc: 0.8416 - val_macro_f1score: 0.1146\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.2955 - accuracy: 0.6305 - top5_acc: 0.8912 - macro_f1score: 0.1412\n","Epoch 00008: val_loss improved from 1.67284 to 1.52378, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/008.h5\n","\n","Epoch 00008: val_accuracy improved from 0.53916 to 0.58841, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/008.h5\n","1403/1403 [==============================] - 1174s 837ms/step - loss: 1.2955 - accuracy: 0.6305 - top5_acc: 0.8912 - macro_f1score: 0.1412 - val_loss: 1.5238 - val_accuracy: 0.5884 - val_top5_acc: 0.8580 - val_macro_f1score: 0.1321\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.1765 - accuracy: 0.6579 - top5_acc: 0.9090 - macro_f1score: 0.1522\n","Epoch 00009: val_loss did not improve from 1.52378\n","\n","Epoch 00009: val_accuracy did not improve from 0.58841\n","1403/1403 [==============================] - 1133s 807ms/step - loss: 1.1765 - accuracy: 0.6579 - top5_acc: 0.9090 - macro_f1score: 0.1522 - val_loss: 1.6290 - val_accuracy: 0.5627 - val_top5_acc: 0.8443 - val_macro_f1score: 0.1281\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","1403/1403 [==============================] - ETA: 0s - loss: 1.0667 - accuracy: 0.6869 - top5_acc: 0.9226 - macro_f1score: 0.1630\n","Epoch 00010: val_loss did not improve from 1.52378\n","\n","Epoch 00010: val_accuracy did not improve from 0.58841\n","1403/1403 [==============================] - 1117s 796ms/step - loss: 1.0667 - accuracy: 0.6869 - top5_acc: 0.9226 - macro_f1score: 0.1630 - val_loss: 2.0259 - val_accuracy: 0.5398 - val_top5_acc: 0.8364 - val_macro_f1score: 0.1247\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.9600 - accuracy: 0.7143 - top5_acc: 0.9377 - macro_f1score: 0.1732\n","Epoch 00011: val_loss did not improve from 1.52378\n","\n","Epoch 00011: val_accuracy improved from 0.58841 to 0.59494, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/011.h5\n","1403/1403 [==============================] - 1150s 820ms/step - loss: 0.9600 - accuracy: 0.7143 - top5_acc: 0.9377 - macro_f1score: 0.1732 - val_loss: 1.5386 - val_accuracy: 0.5949 - val_top5_acc: 0.8586 - val_macro_f1score: 0.1424\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.8709 - accuracy: 0.7381 - top5_acc: 0.9469 - macro_f1score: 0.1814\n","Epoch 00012: val_loss improved from 1.52378 to 1.33175, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/012.h5\n","\n","Epoch 00012: val_accuracy improved from 0.59494 to 0.62718, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/012.h5\n","1403/1403 [==============================] - 1164s 830ms/step - loss: 0.8709 - accuracy: 0.7381 - top5_acc: 0.9469 - macro_f1score: 0.1814 - val_loss: 1.3317 - val_accuracy: 0.6272 - val_top5_acc: 0.8902 - val_macro_f1score: 0.1531\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.7919 - accuracy: 0.7611 - top5_acc: 0.9560 - macro_f1score: 0.1895\n","Epoch 00013: val_loss did not improve from 1.33175\n","\n","Epoch 00013: val_accuracy did not improve from 0.62718\n","1403/1403 [==============================] - 1157s 825ms/step - loss: 0.7919 - accuracy: 0.7611 - top5_acc: 0.9560 - macro_f1score: 0.1895 - val_loss: 1.3778 - val_accuracy: 0.6254 - val_top5_acc: 0.8894 - val_macro_f1score: 0.1539\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.7042 - accuracy: 0.7845 - top5_acc: 0.9644 - macro_f1score: 0.1984\n","Epoch 00014: val_loss improved from 1.33175 to 1.29108, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/014.h5\n","\n","Epoch 00014: val_accuracy improved from 0.62718 to 0.65724, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/014.h5\n","1403/1403 [==============================] - 1129s 805ms/step - loss: 0.7042 - accuracy: 0.7845 - top5_acc: 0.9644 - macro_f1score: 0.1984 - val_loss: 1.2911 - val_accuracy: 0.6572 - val_top5_acc: 0.8960 - val_macro_f1score: 0.1640\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.8047 - top5_acc: 0.9712 - macro_f1score: 0.2054\n","Epoch 00015: val_loss did not improve from 1.29108\n","\n","Epoch 00015: val_accuracy did not improve from 0.65724\n","1403/1403 [==============================] - 1148s 819ms/step - loss: 0.6357 - accuracy: 0.8047 - top5_acc: 0.9712 - macro_f1score: 0.2054 - val_loss: 1.4324 - val_accuracy: 0.6458 - val_top5_acc: 0.8843 - val_macro_f1score: 0.1613\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.5721 - accuracy: 0.8222 - top5_acc: 0.9770 - macro_f1score: 0.2115\n","Epoch 00016: val_loss did not improve from 1.29108\n","\n","Epoch 00016: val_accuracy improved from 0.65724 to 0.66080, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/016.h5\n","1403/1403 [==============================] - 1169s 833ms/step - loss: 0.5721 - accuracy: 0.8222 - top5_acc: 0.9770 - macro_f1score: 0.2115 - val_loss: 1.3608 - val_accuracy: 0.6608 - val_top5_acc: 0.8995 - val_macro_f1score: 0.1664\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.8407 - top5_acc: 0.9815 - macro_f1score: 0.2184\n","Epoch 00017: val_loss improved from 1.29108 to 1.27948, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/017.h5\n","\n","Epoch 00017: val_accuracy improved from 0.66080 to 0.66199, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/017.h5\n","1403/1403 [==============================] - 1158s 826ms/step - loss: 0.5104 - accuracy: 0.8407 - top5_acc: 0.9815 - macro_f1score: 0.2184 - val_loss: 1.2795 - val_accuracy: 0.6620 - val_top5_acc: 0.9031 - val_macro_f1score: 0.1685\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.4757 - accuracy: 0.8504 - top5_acc: 0.9847 - macro_f1score: 0.2226\n","Epoch 00018: val_loss did not improve from 1.27948\n","\n","Epoch 00018: val_accuracy improved from 0.66199 to 0.66396, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/018.h5\n","1403/1403 [==============================] - 1092s 778ms/step - loss: 0.4757 - accuracy: 0.8504 - top5_acc: 0.9847 - macro_f1score: 0.2226 - val_loss: 1.3043 - val_accuracy: 0.6640 - val_top5_acc: 0.8995 - val_macro_f1score: 0.1683\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.8633 - top5_acc: 0.9881 - macro_f1score: 0.2269\n","Epoch 00019: val_loss did not improve from 1.27948\n","\n","Epoch 00019: val_accuracy did not improve from 0.66396\n","1403/1403 [==============================] - 1093s 779ms/step - loss: 0.4281 - accuracy: 0.8633 - top5_acc: 0.9881 - macro_f1score: 0.2269 - val_loss: 1.4597 - val_accuracy: 0.6511 - val_top5_acc: 0.8922 - val_macro_f1score: 0.1669\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8755 - top5_acc: 0.9902 - macro_f1score: 0.2311\n","Epoch 00020: val_loss improved from 1.27948 to 1.19561, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/020.h5\n","\n","Epoch 00020: val_accuracy improved from 0.66396 to 0.69482, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/020.h5\n","1403/1403 [==============================] - 1090s 777ms/step - loss: 0.3894 - accuracy: 0.8755 - top5_acc: 0.9902 - macro_f1score: 0.2311 - val_loss: 1.1956 - val_accuracy: 0.6948 - val_top5_acc: 0.9116 - val_macro_f1score: 0.1795\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.3627 - accuracy: 0.8856 - top5_acc: 0.9918 - macro_f1score: 0.2354\n","Epoch 00021: val_loss did not improve from 1.19561\n","\n","Epoch 00021: val_accuracy did not improve from 0.69482\n","1403/1403 [==============================] - 1096s 781ms/step - loss: 0.3627 - accuracy: 0.8856 - top5_acc: 0.9918 - macro_f1score: 0.2354 - val_loss: 1.3373 - val_accuracy: 0.6681 - val_top5_acc: 0.9037 - val_macro_f1score: 0.1718\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.8941 - top5_acc: 0.9925 - macro_f1score: 0.2385\n","Epoch 00022: val_loss did not improve from 1.19561\n","\n","Epoch 00022: val_accuracy did not improve from 0.69482\n","1403/1403 [==============================] - 1059s 755ms/step - loss: 0.3364 - accuracy: 0.8941 - top5_acc: 0.9925 - macro_f1score: 0.2385 - val_loss: 1.4085 - val_accuracy: 0.6671 - val_top5_acc: 0.8970 - val_macro_f1score: 0.1706\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.9009 - top5_acc: 0.9937 - macro_f1score: 0.2408\n","Epoch 00023: val_loss did not improve from 1.19561\n","\n","Epoch 00023: val_accuracy did not improve from 0.69482\n","1403/1403 [==============================] - 1058s 754ms/step - loss: 0.3117 - accuracy: 0.9009 - top5_acc: 0.9937 - macro_f1score: 0.2408 - val_loss: 1.3181 - val_accuracy: 0.6816 - val_top5_acc: 0.9142 - val_macro_f1score: 0.1766\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2866 - accuracy: 0.9088 - top5_acc: 0.9946 - macro_f1score: 0.2443\n","Epoch 00024: val_loss did not improve from 1.19561\n","\n","Epoch 00024: val_accuracy did not improve from 0.69482\n","1403/1403 [==============================] - 1089s 776ms/step - loss: 0.2866 - accuracy: 0.9088 - top5_acc: 0.9946 - macro_f1score: 0.2443 - val_loss: 1.3759 - val_accuracy: 0.6756 - val_top5_acc: 0.9001 - val_macro_f1score: 0.1741\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2734 - accuracy: 0.9128 - top5_acc: 0.9953 - macro_f1score: 0.2456\n","Epoch 00025: val_loss did not improve from 1.19561\n","\n","Epoch 00025: val_accuracy did not improve from 0.69482\n","1403/1403 [==============================] - 1113s 794ms/step - loss: 0.2734 - accuracy: 0.9128 - top5_acc: 0.9953 - macro_f1score: 0.2456 - val_loss: 1.3608 - val_accuracy: 0.6723 - val_top5_acc: 0.9033 - val_macro_f1score: 0.1733\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.9152 - top5_acc: 0.9952 - macro_f1score: 0.2471\n","Epoch 00026: val_loss did not improve from 1.19561\n","\n","Epoch 00026: val_accuracy did not improve from 0.69482\n","1403/1403 [==============================] - 1064s 758ms/step - loss: 0.2664 - accuracy: 0.9152 - top5_acc: 0.9952 - macro_f1score: 0.2471 - val_loss: 1.4801 - val_accuracy: 0.6547 - val_top5_acc: 0.8973 - val_macro_f1score: 0.1699\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2426 - accuracy: 0.9233 - top5_acc: 0.9961 - macro_f1score: 0.2489\n","Epoch 00027: val_loss did not improve from 1.19561\n","\n","Epoch 00027: val_accuracy did not improve from 0.69482\n","1403/1403 [==============================] - 1038s 740ms/step - loss: 0.2426 - accuracy: 0.9233 - top5_acc: 0.9961 - macro_f1score: 0.2489 - val_loss: 1.4920 - val_accuracy: 0.6683 - val_top5_acc: 0.8952 - val_macro_f1score: 0.1742\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.9240 - top5_acc: 0.9968 - macro_f1score: 0.2497\n","Epoch 00028: val_loss did not improve from 1.19561\n","\n","Epoch 00028: val_accuracy did not improve from 0.69482\n","1403/1403 [==============================] - 1052s 750ms/step - loss: 0.2423 - accuracy: 0.9240 - top5_acc: 0.9968 - macro_f1score: 0.2497 - val_loss: 1.4321 - val_accuracy: 0.6822 - val_top5_acc: 0.9037 - val_macro_f1score: 0.1767\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.9263 - top5_acc: 0.9966 - macro_f1score: 0.2508\n","Epoch 00029: val_loss did not improve from 1.19561\n","\n","Epoch 00029: val_accuracy did not improve from 0.69482\n","1403/1403 [==============================] - 1049s 748ms/step - loss: 0.2344 - accuracy: 0.9263 - top5_acc: 0.9966 - macro_f1score: 0.2508 - val_loss: 1.4695 - val_accuracy: 0.6636 - val_top5_acc: 0.8926 - val_macro_f1score: 0.1749\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.9292 - top5_acc: 0.9972 - macro_f1score: 0.2512\n","Epoch 00030: val_loss did not improve from 1.19561\n","\n","Epoch 00030: val_accuracy did not improve from 0.69482\n","1403/1403 [==============================] - 1031s 735ms/step - loss: 0.2222 - accuracy: 0.9292 - top5_acc: 0.9972 - macro_f1score: 0.2512 - val_loss: 1.4717 - val_accuracy: 0.6648 - val_top5_acc: 0.9015 - val_macro_f1score: 0.1747\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9785 - top5_acc: 0.9996 - macro_f1score: 0.2676\n","Epoch 00031: val_loss improved from 1.19561 to 0.98420, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/031.h5\n","\n","Epoch 00031: val_accuracy improved from 0.69482 to 0.75514, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/031.h5\n","1403/1403 [==============================] - 1033s 736ms/step - loss: 0.0836 - accuracy: 0.9785 - top5_acc: 0.9996 - macro_f1score: 0.2676 - val_loss: 0.9842 - val_accuracy: 0.7551 - val_top5_acc: 0.9389 - val_macro_f1score: 0.1981\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9916 - top5_acc: 0.9999 - macro_f1score: 0.2721\n","Epoch 00032: val_loss improved from 0.98420 to 0.95851, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/032.h5\n","\n","Epoch 00032: val_accuracy improved from 0.75514 to 0.75811, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/032.h5\n","1403/1403 [==============================] - 1061s 756ms/step - loss: 0.0456 - accuracy: 0.9916 - top5_acc: 0.9999 - macro_f1score: 0.2721 - val_loss: 0.9585 - val_accuracy: 0.7581 - val_top5_acc: 0.9424 - val_macro_f1score: 0.2027\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9937 - top5_acc: 0.9999 - macro_f1score: 0.2730\n","Epoch 00033: val_loss did not improve from 0.95851\n","\n","Epoch 00033: val_accuracy improved from 0.75811 to 0.76108, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/033.h5\n","1403/1403 [==============================] - 1030s 734ms/step - loss: 0.0371 - accuracy: 0.9937 - top5_acc: 0.9999 - macro_f1score: 0.2730 - val_loss: 0.9623 - val_accuracy: 0.7611 - val_top5_acc: 0.9401 - val_macro_f1score: 0.1989\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9951 - top5_acc: 0.9999 - macro_f1score: 0.2739\n","Epoch 00034: val_loss did not improve from 0.95851\n","\n","Epoch 00034: val_accuracy did not improve from 0.76108\n","1403/1403 [==============================] - 1036s 739ms/step - loss: 0.0313 - accuracy: 0.9951 - top5_acc: 0.9999 - macro_f1score: 0.2739 - val_loss: 0.9590 - val_accuracy: 0.7587 - val_top5_acc: 0.9395 - val_macro_f1score: 0.2009\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9962 - top5_acc: 1.0000 - macro_f1score: 0.2736\n","Epoch 00035: val_loss improved from 0.95851 to 0.95037, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/035.h5\n","\n","Epoch 00035: val_accuracy did not improve from 0.76108\n","1403/1403 [==============================] - 1035s 738ms/step - loss: 0.0284 - accuracy: 0.9962 - top5_acc: 1.0000 - macro_f1score: 0.2736 - val_loss: 0.9504 - val_accuracy: 0.7595 - val_top5_acc: 0.9411 - val_macro_f1score: 0.2004\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9962 - top5_acc: 1.0000 - macro_f1score: 0.2744\n","Epoch 00036: val_loss improved from 0.95037 to 0.93137, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/036.h5\n","\n","Epoch 00036: val_accuracy improved from 0.76108 to 0.76978, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/Inception_ResNet_v2/036.h5\n","1403/1403 [==============================] - 1040s 741ms/step - loss: 0.0265 - accuracy: 0.9962 - top5_acc: 1.0000 - macro_f1score: 0.2744 - val_loss: 0.9314 - val_accuracy: 0.7698 - val_top5_acc: 0.9430 - val_macro_f1score: 0.2011\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9969 - top5_acc: 1.0000 - macro_f1score: 0.2742\n","Epoch 00037: val_loss did not improve from 0.93137\n","\n","Epoch 00037: val_accuracy did not improve from 0.76978\n","1403/1403 [==============================] - 1070s 762ms/step - loss: 0.0243 - accuracy: 0.9969 - top5_acc: 1.0000 - macro_f1score: 0.2742 - val_loss: 0.9549 - val_accuracy: 0.7609 - val_top5_acc: 0.9411 - val_macro_f1score: 0.2022\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9968 - top5_acc: 1.0000 - macro_f1score: 0.2744\n","Epoch 00038: val_loss did not improve from 0.93137\n","\n","Epoch 00038: val_accuracy did not improve from 0.76978\n","1403/1403 [==============================] - 1074s 766ms/step - loss: 0.0234 - accuracy: 0.9968 - top5_acc: 1.0000 - macro_f1score: 0.2744 - val_loss: 0.9616 - val_accuracy: 0.7605 - val_top5_acc: 0.9395 - val_macro_f1score: 0.2014\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9976 - top5_acc: 1.0000 - macro_f1score: 0.2734\n","Epoch 00039: val_loss did not improve from 0.93137\n","\n","Epoch 00039: val_accuracy did not improve from 0.76978\n","1403/1403 [==============================] - 1057s 753ms/step - loss: 0.0221 - accuracy: 0.9976 - top5_acc: 1.0000 - macro_f1score: 0.2734 - val_loss: 0.9397 - val_accuracy: 0.7644 - val_top5_acc: 0.9415 - val_macro_f1score: 0.2009\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2749\n","Epoch 00040: val_loss did not improve from 0.93137\n","\n","Epoch 00040: val_accuracy did not improve from 0.76978\n","1403/1403 [==============================] - 1056s 753ms/step - loss: 0.0194 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2749 - val_loss: 0.9558 - val_accuracy: 0.7623 - val_top5_acc: 0.9409 - val_macro_f1score: 0.2019\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.2750\n","Epoch 00041: val_loss did not improve from 0.93137\n","\n","Epoch 00041: val_accuracy did not improve from 0.76978\n","1403/1403 [==============================] - 1083s 772ms/step - loss: 0.0195 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.2750 - val_loss: 0.9549 - val_accuracy: 0.7636 - val_top5_acc: 0.9401 - val_macro_f1score: 0.2027\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9978 - top5_acc: 1.0000 - macro_f1score: 0.2737\n","Epoch 00042: val_loss did not improve from 0.93137\n","\n","Epoch 00042: val_accuracy did not improve from 0.76978\n","1403/1403 [==============================] - 1080s 770ms/step - loss: 0.0196 - accuracy: 0.9978 - top5_acc: 1.0000 - macro_f1score: 0.2737 - val_loss: 0.9507 - val_accuracy: 0.7670 - val_top5_acc: 0.9405 - val_macro_f1score: 0.2004\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2743\n","Epoch 00043: val_loss did not improve from 0.93137\n","\n","Epoch 00043: val_accuracy did not improve from 0.76978\n","1403/1403 [==============================] - 1095s 781ms/step - loss: 0.0187 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2743 - val_loss: 0.9443 - val_accuracy: 0.7668 - val_top5_acc: 0.9415 - val_macro_f1score: 0.2042\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n"," 389/1403 [=======>......................] - ETA: 12:55 - loss: 0.0171 - accuracy: 0.9984 - top5_acc: 1.0000 - macro_f1score: 0.2746"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O3zuWgPK_AKV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvfpoPPX_Agv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkXMQdc2Fmpo"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JP6LglI13-_c"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMKlqQh24hcq"},"source":["# colab pro가 최대 24시간 돌아가므로, 그 한계로 인해 두번 나눠서 학습을봄."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgavL2IxsJ9m"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-4\n","    if epoch < 25:\n","        lr = lr\n","    else :\n","        lr = lr * 0.1\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WmA0zyNQvEGl"},"source":["os.makedirs(os.path.join(dir,'model_output',number,'SUB',model.name), exist_ok=True) # 모델을 위에서 정의해야함"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FTbhbLyX8L6F"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,'SUB',model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5JqngK2zwLmH"},"source":["model=load_model(os.path.join(dir,'model_output',number,'Inception_ResNet_v2','036.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d_8Yy1A48KLO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605760153020,"user_tz":-540,"elapsed":47892603,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"d1c350aa-4f39-49a3-d5e9-405ab7893866"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=35 , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.0001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 1/35\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_8/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_6/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_9/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_5/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_7/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_10/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_11/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_15/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_13/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_16/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_12/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_14/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_17/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_1_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_21/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_19/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_22/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_18/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_20/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_23/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_2_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_27/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_25/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_28/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_24/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_26/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_29/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_3_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_33/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_31/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_34/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_30/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_32/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_35/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_4_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_39/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_37/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_40/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_36/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_38/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_41/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_5_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_45/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_43/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_46/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_42/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_44/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_47/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_6_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_51/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_49/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_52/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_48/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_50/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_53/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_7_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_57/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_55/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_58/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_54/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_56/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_59/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_8_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_63/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_61/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_64/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_60/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_62/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_65/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_9_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_69/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_67/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_70/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_66/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_68/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_71/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block35_10_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_73/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_74/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_72/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_75/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_77/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_78/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_76/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_79/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_1_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_81/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_82/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_80/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_83/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_2_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_85/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_86/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_84/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_87/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_3_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_89/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_90/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_88/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_91/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_4_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_93/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_94/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_92/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_95/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_5_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_97/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_98/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_96/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_99/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_6_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_101/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_102/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_100/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_103/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_7_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_105/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_106/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_104/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_107/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_8_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_109/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_110/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_108/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_111/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_9_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_113/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_114/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_112/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_115/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_10_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_117/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_118/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_116/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_119/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_11_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_121/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_122/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_120/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_123/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_12_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_125/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_126/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_124/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_127/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_13_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_129/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_130/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_128/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_131/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_14_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_133/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_134/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_132/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_135/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_15_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_137/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_138/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_136/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_139/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_16_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_141/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_142/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_140/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_143/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_17_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_145/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_146/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_144/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_147/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_18_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_149/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_150/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_148/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_151/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_19_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_153/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_154/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_152/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_155/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block17_20_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_160/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_156/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_158/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_161/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_157/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_159/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_162/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_164/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_165/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_163/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_166/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_1_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_168/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_169/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_167/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_170/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_2_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_172/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_173/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_171/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_174/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_3_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_176/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_177/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_175/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_178/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_4_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_180/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_181/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_179/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_182/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_5_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_184/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_185/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_183/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_186/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_6_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_188/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_189/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_187/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_190/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_7_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_192/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_193/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_191/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_194/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_8_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_196/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_197/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_195/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_198/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_9_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_200/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_201/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_199/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv2d_202/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for block8_10_conv/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for conv_7b/kernel:0\n","0.0(L1), 2.669753626496871e-05(L2) weight decay set for predictions/kernel:0\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9970 - top5_acc: 1.0000 - macro_f1score: 0.2739 \n","Epoch 00001: val_loss improved from inf to 0.94356, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.76602, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/001.h5\n","1403/1403 [==============================] - 24670s 18s/step - loss: 0.0237 - accuracy: 0.9970 - top5_acc: 1.0000 - macro_f1score: 0.2739 - val_loss: 0.9436 - val_accuracy: 0.7660 - val_top5_acc: 0.9415 - val_macro_f1score: 0.2020\n","Learning rate:  0.0001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 2/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9972 - top5_acc: 1.0000 - macro_f1score: 0.2742\n","Epoch 00002: val_loss improved from 0.94356 to 0.94095, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/002.h5\n","\n","Epoch 00002: val_accuracy improved from 0.76602 to 0.76721, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/002.h5\n","1403/1403 [==============================] - 1101s 785ms/step - loss: 0.0227 - accuracy: 0.9972 - top5_acc: 1.0000 - macro_f1score: 0.2742 - val_loss: 0.9410 - val_accuracy: 0.7672 - val_top5_acc: 0.9413 - val_macro_f1score: 0.2025\n","Learning rate:  0.0001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 3/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9976 - top5_acc: 1.0000 - macro_f1score: 0.2741\n","Epoch 00003: val_loss did not improve from 0.94095\n","\n","Epoch 00003: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1092s 778ms/step - loss: 0.0208 - accuracy: 0.9976 - top5_acc: 1.0000 - macro_f1score: 0.2741 - val_loss: 0.9530 - val_accuracy: 0.7634 - val_top5_acc: 0.9417 - val_macro_f1score: 0.2027\n","Learning rate:  0.0001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 4/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9976 - top5_acc: 1.0000 - macro_f1score: 0.2742\n","Epoch 00004: val_loss did not improve from 0.94095\n","\n","Epoch 00004: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1082s 771ms/step - loss: 0.0213 - accuracy: 0.9976 - top5_acc: 1.0000 - macro_f1score: 0.2742 - val_loss: 0.9464 - val_accuracy: 0.7629 - val_top5_acc: 0.9405 - val_macro_f1score: 0.2011\n","Learning rate:  0.0001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 5/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9977 - top5_acc: 1.0000 - macro_f1score: 0.2739\n","Epoch 00005: val_loss did not improve from 0.94095\n","\n","Epoch 00005: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1060s 755ms/step - loss: 0.0197 - accuracy: 0.9977 - top5_acc: 1.0000 - macro_f1score: 0.2739 - val_loss: 0.9694 - val_accuracy: 0.7613 - val_top5_acc: 0.9395 - val_macro_f1score: 0.2008\n","Learning rate:  0.0001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 6/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9978 - top5_acc: 1.0000 - macro_f1score: 0.2739\n","Epoch 00006: val_loss did not improve from 0.94095\n","\n","Epoch 00006: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1035s 738ms/step - loss: 0.0200 - accuracy: 0.9978 - top5_acc: 1.0000 - macro_f1score: 0.2739 - val_loss: 0.9539 - val_accuracy: 0.7650 - val_top5_acc: 0.9395 - val_macro_f1score: 0.2017\n","Learning rate:  0.0001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 7/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2748\n","Epoch 00007: val_loss did not improve from 0.94095\n","\n","Epoch 00007: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1019s 726ms/step - loss: 0.0186 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2748 - val_loss: 0.9447 - val_accuracy: 0.7654 - val_top5_acc: 0.9395 - val_macro_f1score: 0.2015\n","Learning rate:  0.0001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 8/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.2741\n","Epoch 00008: val_loss did not improve from 0.94095\n","\n","Epoch 00008: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1011s 721ms/step - loss: 0.0175 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.2741 - val_loss: 0.9480 - val_accuracy: 0.7650 - val_top5_acc: 0.9411 - val_macro_f1score: 0.2036\n","Learning rate:  0.0001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 9/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2746\n","Epoch 00009: val_loss did not improve from 0.94095\n","\n","Epoch 00009: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1030s 734ms/step - loss: 0.0174 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2746 - val_loss: 0.9802 - val_accuracy: 0.7565 - val_top5_acc: 0.9395 - val_macro_f1score: 0.2014\n","Learning rate:  0.0001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 10/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.2748\n","Epoch 00010: val_loss did not improve from 0.94095\n","\n","Epoch 00010: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1023s 729ms/step - loss: 0.0162 - accuracy: 0.9986 - top5_acc: 1.0000 - macro_f1score: 0.2748 - val_loss: 0.9576 - val_accuracy: 0.7633 - val_top5_acc: 0.9379 - val_macro_f1score: 0.2004\n","Learning rate:  0.0001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 11/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.2745\n","Epoch 00011: val_loss did not improve from 0.94095\n","\n","Epoch 00011: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1008s 719ms/step - loss: 0.0183 - accuracy: 0.9979 - top5_acc: 1.0000 - macro_f1score: 0.2745 - val_loss: 0.9592 - val_accuracy: 0.7636 - val_top5_acc: 0.9379 - val_macro_f1score: 0.2001\n","Learning rate:  0.0001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 12/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9984 - top5_acc: 1.0000 - macro_f1score: 0.2744\n","Epoch 00012: val_loss did not improve from 0.94095\n","\n","Epoch 00012: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1022s 729ms/step - loss: 0.0169 - accuracy: 0.9984 - top5_acc: 1.0000 - macro_f1score: 0.2744 - val_loss: 1.0052 - val_accuracy: 0.7532 - val_top5_acc: 0.9381 - val_macro_f1score: 0.1981\n","Learning rate:  0.0001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 13/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2738\n","Epoch 00013: val_loss did not improve from 0.94095\n","\n","Epoch 00013: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1042s 743ms/step - loss: 0.0174 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2738 - val_loss: 0.9690 - val_accuracy: 0.7595 - val_top5_acc: 0.9361 - val_macro_f1score: 0.2004\n","Learning rate:  0.0001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 14/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9983 - top5_acc: 1.0000 - macro_f1score: 0.2748\n","Epoch 00014: val_loss did not improve from 0.94095\n","\n","Epoch 00014: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1040s 742ms/step - loss: 0.0169 - accuracy: 0.9983 - top5_acc: 1.0000 - macro_f1score: 0.2748 - val_loss: 0.9572 - val_accuracy: 0.7613 - val_top5_acc: 0.9371 - val_macro_f1score: 0.2014\n","Learning rate:  0.0001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 15/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2750\n","Epoch 00015: val_loss did not improve from 0.94095\n","\n","Epoch 00015: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1027s 732ms/step - loss: 0.0173 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2750 - val_loss: 0.9894 - val_accuracy: 0.7532 - val_top5_acc: 0.9373 - val_macro_f1score: 0.1988\n","Learning rate:  0.0001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 16/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2745\n","Epoch 00016: val_loss did not improve from 0.94095\n","\n","Epoch 00016: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1058s 754ms/step - loss: 0.0170 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2745 - val_loss: 1.0034 - val_accuracy: 0.7634 - val_top5_acc: 0.9359 - val_macro_f1score: 0.2010\n","Learning rate:  0.0001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 17/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9983 - top5_acc: 1.0000 - macro_f1score: 0.2746\n","Epoch 00017: val_loss did not improve from 0.94095\n","\n","Epoch 00017: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1088s 776ms/step - loss: 0.0166 - accuracy: 0.9983 - top5_acc: 1.0000 - macro_f1score: 0.2746 - val_loss: 0.9889 - val_accuracy: 0.7609 - val_top5_acc: 0.9359 - val_macro_f1score: 0.2017\n","Learning rate:  0.0001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 18/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2754\n","Epoch 00018: val_loss did not improve from 0.94095\n","\n","Epoch 00018: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1055s 752ms/step - loss: 0.0165 - accuracy: 0.9980 - top5_acc: 1.0000 - macro_f1score: 0.2754 - val_loss: 0.9801 - val_accuracy: 0.7607 - val_top5_acc: 0.9363 - val_macro_f1score: 0.1986\n","Learning rate:  0.0001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 19/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9984 - top5_acc: 1.0000 - macro_f1score: 0.2744\n","Epoch 00019: val_loss did not improve from 0.94095\n","\n","Epoch 00019: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1092s 778ms/step - loss: 0.0159 - accuracy: 0.9984 - top5_acc: 1.0000 - macro_f1score: 0.2744 - val_loss: 0.9852 - val_accuracy: 0.7597 - val_top5_acc: 0.9349 - val_macro_f1score: 0.2002\n","Learning rate:  0.0001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 20/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9974 - top5_acc: 1.0000 - macro_f1score: 0.2740\n","Epoch 00020: val_loss did not improve from 0.94095\n","\n","Epoch 00020: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1086s 774ms/step - loss: 0.0184 - accuracy: 0.9974 - top5_acc: 1.0000 - macro_f1score: 0.2740 - val_loss: 0.9856 - val_accuracy: 0.7567 - val_top5_acc: 0.9355 - val_macro_f1score: 0.2012\n","Learning rate:  0.0001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 21/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9978 - top5_acc: 1.0000 - macro_f1score: 0.2744\n","Epoch 00021: val_loss did not improve from 0.94095\n","\n","Epoch 00021: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1080s 770ms/step - loss: 0.0179 - accuracy: 0.9978 - top5_acc: 1.0000 - macro_f1score: 0.2744 - val_loss: 0.9952 - val_accuracy: 0.7538 - val_top5_acc: 0.9331 - val_macro_f1score: 0.1988\n","Learning rate:  0.0001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 22/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9983 - top5_acc: 1.0000 - macro_f1score: 0.2745\n","Epoch 00022: val_loss did not improve from 0.94095\n","\n","Epoch 00022: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1093s 779ms/step - loss: 0.0159 - accuracy: 0.9983 - top5_acc: 1.0000 - macro_f1score: 0.2745 - val_loss: 1.0520 - val_accuracy: 0.7466 - val_top5_acc: 0.9286 - val_macro_f1score: 0.1956\n","Learning rate:  0.0001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 23/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9974 - top5_acc: 1.0000 - macro_f1score: 0.2744\n","Epoch 00023: val_loss did not improve from 0.94095\n","\n","Epoch 00023: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1034s 737ms/step - loss: 0.0195 - accuracy: 0.9974 - top5_acc: 1.0000 - macro_f1score: 0.2744 - val_loss: 1.0054 - val_accuracy: 0.7553 - val_top5_acc: 0.9335 - val_macro_f1score: 0.1982\n","Learning rate:  0.0001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 24/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9976 - top5_acc: 1.0000 - macro_f1score: 0.2750\n","Epoch 00024: val_loss did not improve from 0.94095\n","\n","Epoch 00024: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1044s 744ms/step - loss: 0.0182 - accuracy: 0.9976 - top5_acc: 1.0000 - macro_f1score: 0.2750 - val_loss: 1.0674 - val_accuracy: 0.7466 - val_top5_acc: 0.9308 - val_macro_f1score: 0.1985\n","Learning rate:  0.0001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 25/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2745\n","Epoch 00025: val_loss did not improve from 0.94095\n","\n","Epoch 00025: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1047s 746ms/step - loss: 0.0169 - accuracy: 0.9981 - top5_acc: 1.0000 - macro_f1score: 0.2745 - val_loss: 1.0212 - val_accuracy: 0.7569 - val_top5_acc: 0.9320 - val_macro_f1score: 0.1994\n","Learning rate:  1e-05\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 26/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9990 - top5_acc: 1.0000 - macro_f1score: 0.2753\n","Epoch 00026: val_loss improved from 0.94095 to 0.93856, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/026.h5\n","\n","Epoch 00026: val_accuracy did not improve from 0.76721\n","1403/1403 [==============================] - 1062s 757ms/step - loss: 0.0115 - accuracy: 0.9990 - top5_acc: 1.0000 - macro_f1score: 0.2753 - val_loss: 0.9386 - val_accuracy: 0.7668 - val_top5_acc: 0.9363 - val_macro_f1score: 0.2032\n","Learning rate:  1e-05\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 27/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9996 - top5_acc: 1.0000 - macro_f1score: 0.2746\n","Epoch 00027: val_loss improved from 0.93856 to 0.91871, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/027.h5\n","\n","Epoch 00027: val_accuracy improved from 0.76721 to 0.76760, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/027.h5\n","1403/1403 [==============================] - 1047s 746ms/step - loss: 0.0094 - accuracy: 0.9996 - top5_acc: 1.0000 - macro_f1score: 0.2746 - val_loss: 0.9187 - val_accuracy: 0.7676 - val_top5_acc: 0.9361 - val_macro_f1score: 0.2010\n","Learning rate:  1e-05\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 28/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9997 - top5_acc: 1.0000 - macro_f1score: 0.2755\n","Epoch 00028: val_loss improved from 0.91871 to 0.90815, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/028.h5\n","\n","Epoch 00028: val_accuracy improved from 0.76760 to 0.76899, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/028.h5\n","1403/1403 [==============================] - 1039s 740ms/step - loss: 0.0094 - accuracy: 0.9997 - top5_acc: 1.0000 - macro_f1score: 0.2755 - val_loss: 0.9082 - val_accuracy: 0.7690 - val_top5_acc: 0.9375 - val_macro_f1score: 0.1994\n","Learning rate:  1e-05\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 29/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9997 - top5_acc: 1.0000 - macro_f1score: 0.2754\n","Epoch 00029: val_loss improved from 0.90815 to 0.89549, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/029.h5\n","\n","Epoch 00029: val_accuracy improved from 0.76899 to 0.77314, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/029.h5\n","1403/1403 [==============================] - 1109s 791ms/step - loss: 0.0097 - accuracy: 0.9997 - top5_acc: 1.0000 - macro_f1score: 0.2754 - val_loss: 0.8955 - val_accuracy: 0.7731 - val_top5_acc: 0.9385 - val_macro_f1score: 0.2025\n","Learning rate:  1e-05\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 30/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9997 - top5_acc: 1.0000 - macro_f1score: 0.2745\n","Epoch 00030: val_loss improved from 0.89549 to 0.89414, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/030.h5\n","\n","Epoch 00030: val_accuracy did not improve from 0.77314\n","1403/1403 [==============================] - 1142s 814ms/step - loss: 0.0106 - accuracy: 0.9997 - top5_acc: 1.0000 - macro_f1score: 0.2745 - val_loss: 0.8941 - val_accuracy: 0.7729 - val_top5_acc: 0.9411 - val_macro_f1score: 0.2039\n","Learning rate:  1e-05\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 31/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9995 - top5_acc: 1.0000 - macro_f1score: 0.2748\n","Epoch 00031: val_loss improved from 0.89414 to 0.88551, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/031.h5\n","\n","Epoch 00031: val_accuracy improved from 0.77314 to 0.77354, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/031.h5\n","1403/1403 [==============================] - 1149s 819ms/step - loss: 0.0148 - accuracy: 0.9995 - top5_acc: 1.0000 - macro_f1score: 0.2748 - val_loss: 0.8855 - val_accuracy: 0.7735 - val_top5_acc: 0.9389 - val_macro_f1score: 0.2016\n","Learning rate:  1e-05\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 32/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9996 - top5_acc: 1.0000 - macro_f1score: 0.2749\n","Epoch 00032: val_loss improved from 0.88551 to 0.88467, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/032.h5\n","\n","Epoch 00032: val_accuracy did not improve from 0.77354\n","1403/1403 [==============================] - 1151s 821ms/step - loss: 0.0155 - accuracy: 0.9996 - top5_acc: 1.0000 - macro_f1score: 0.2749 - val_loss: 0.8847 - val_accuracy: 0.7680 - val_top5_acc: 0.9393 - val_macro_f1score: 0.2023\n","Learning rate:  1e-05\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 33/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9996 - top5_acc: 1.0000 - macro_f1score: 0.2749\n","Epoch 00033: val_loss improved from 0.88467 to 0.88402, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/033.h5\n","\n","Epoch 00033: val_accuracy did not improve from 0.77354\n","1403/1403 [==============================] - 1162s 828ms/step - loss: 0.0166 - accuracy: 0.9996 - top5_acc: 1.0000 - macro_f1score: 0.2749 - val_loss: 0.8840 - val_accuracy: 0.7727 - val_top5_acc: 0.9387 - val_macro_f1score: 0.1993\n","Learning rate:  1e-05\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 34/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9996 - top5_acc: 1.0000 - macro_f1score: 0.2753\n","Epoch 00034: val_loss improved from 0.88402 to 0.87681, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/034.h5\n","\n","Epoch 00034: val_accuracy did not improve from 0.77354\n","1403/1403 [==============================] - 1139s 812ms/step - loss: 0.0180 - accuracy: 0.9996 - top5_acc: 1.0000 - macro_f1score: 0.2753 - val_loss: 0.8768 - val_accuracy: 0.7712 - val_top5_acc: 0.9383 - val_macro_f1score: 0.2002\n","Learning rate:  1e-05\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 35/35\n","1403/1403 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9996 - top5_acc: 1.0000 - macro_f1score: 0.2747\n","Epoch 00035: val_loss improved from 0.87681 to 0.87376, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CIFAR100/No_GAN/model_output/1/SUB/Inception_ResNet_v2/035.h5\n","\n","Epoch 00035: val_accuracy did not improve from 0.77354\n","1403/1403 [==============================] - 1151s 820ms/step - loss: 0.0198 - accuracy: 0.9996 - top5_acc: 1.0000 - macro_f1score: 0.2747 - val_loss: 0.8738 - val_accuracy: 0.7700 - val_top5_acc: 0.9397 - val_macro_f1score: 0.1987\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N4tkS_eR_AIL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3AXXKnah_AGH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jhTx3Gm8-FhB"},"source":["### 3) Inception-ResNet-V2 Evaluate\n"]},{"cell_type":"code","metadata":{"id":"bRiw3ebD-FhC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605763679764,"user_tz":-540,"elapsed":3526756,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"5d93b8db-0709-467e-d6f6-d57b4332c189"},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["312/312 [==============================] - 3508s 11s/step - loss: 0.9126 - accuracy: 0.7641 - top5_acc: 0.9375 - macro_f1score: 0.1965\n","[Test Loss: 0.9126 /  Test Top-1 Accuracy: 0.7641 / Test Top-5 Accuracy: 0.9375 / Test Macro f1: 0.1965]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zWPdDUWI-FhG"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yp2_HCXHyihu"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PpEXLWpmyihx"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'Inception_ResNet_v2.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1UoLe1oyihz"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ITeu5vTyih3","colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"status":"ok","timestamp":1605763681566,"user_tz":-540,"elapsed":1811,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"82c94a3f-bc9a-491d-fc4c-2d184f844dce"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"_RmXQw95FFrY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YRihn9-yKv6g"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-opNS8oXFHdB","executionInfo":{"status":"ok","timestamp":1606103138389,"user_tz":-540,"elapsed":813,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / Inception_Resnet_V2"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c","executionInfo":{"status":"ok","timestamp":1606103139107,"user_tz":-540,"elapsed":1519,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak","executionInfo":{"status":"ok","timestamp":1606103139108,"user_tz":-540,"elapsed":1510,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-38Ov61FHdE","executionInfo":{"status":"ok","timestamp":1606103167120,"user_tz":-540,"elapsed":29502,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}}},"source":["model=load_model(os.path.join(dir,'model_output',number,'SUB','Inception_ResNet_v2','035.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"hxpCFriTFHdG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606105918005,"user_tz":-540,"elapsed":2780372,"user":{"displayName":"이동규","photoUrl":"","userId":"03303793760957673272"}},"outputId":"c67abcd2-0d27-4061-812a-41d18c372480"},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["312/312 [==============================] - 2729s 9s/step - loss: 0.9127 - accuracy: 0.7642 - top5_acc: 0.9375 - macro_f1score: 0.1963\n","[Test Loss: 0.9127 /  Test Top-1 Accuracy: 0.7642 / Test Top-5 Accuracy: 0.9375 / Test Macro f1: 0.1963]\n","\n"],"name":"stdout"}]}]}