{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"08.Inception ResNet V1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"E-OCKgEwJfTn","executionInfo":{"status":"ok","timestamp":1606109814870,"user_tz":-540,"elapsed":552,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["#모형 출처 : https://github.com/titu1994/keras-squeeze-excite-network 에서 각색함"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwVmRuFcUBkT"},"source":["# [Inception ResNet V1]"]},{"cell_type":"markdown","metadata":{"id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original Inception-ResNet-V1\n","```\n","1) Support Functions\n","2) Almost Original Inception-ResNet-V1\n","3) Inception-ResNet-V1 Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U01q4o40UBkY"},"source":["### Install Packages\n"]},{"cell_type":"markdown","metadata":{"id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606109852269,"user_tz":-540,"elapsed":37930,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"7f55fa21-5506-41a5-d64f-49cc1ceacaee"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606109852274,"user_tz":-540,"elapsed":37910,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"2486fa18-ec62-43d3-9c27-7b9e2f92d373"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I98omoQ8FF90","executionInfo":{"status":"ok","timestamp":1606109854481,"user_tz":-540,"elapsed":40115,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKLMWqbuUBkf","executionInfo":{"status":"ok","timestamp":1606109855119,"user_tz":-540,"elapsed":40748,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D , LeakyReLU\n","from tensorflow.keras.layers import add, concatenate, multiply\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606109855120,"user_tz":-540,"elapsed":40733,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"1266a4fa-4285-4f7c-9999-09989e727570"},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"AcT0A_iwEzaZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606109855122,"user_tz":-540,"elapsed":40717,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"f4a04455-20d8-4054-ec37-503bd72272d9"},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gr5hMHvmABmG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1606109858937,"user_tz":-540,"elapsed":44511,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"07ae1aba-abbf-4848-923e-3e21d2831bd7"},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Kf057Rw2yigs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606109858942,"user_tz":-540,"elapsed":44507,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"258942fc-22eb-4f26-d890-f1387a40ba6e"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 898515779366698215\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 14635519642575481322\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 17903030533481695088\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15695549568\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 11220831449103099891\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OPD7FiWCh0Pd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606109858947,"user_tz":-540,"elapsed":44499,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"b8d08cd6-4ceb-4d43-9657-f2ba3aee78ca"},"source":["!cat /proc/cpuinfo"],"execution_count":10,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 0\n","cpu cores\t: 2\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 79\n","model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2200.000\n","cache size\t: 56320 KB\n","physical id\t: 0\n","siblings\t: 4\n","core id\t\t: 1\n","cpu cores\t: 2\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n","bogomips\t: 4400.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"BeJ7UtuOEgWY","executionInfo":{"status":"ok","timestamp":1606109858948,"user_tz":-540,"elapsed":44498,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'FER'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 299 # sizes after cropping\n","super_size = 330 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 64\n","weight_decay = 1e-3\n","epochs = 70"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","executionInfo":{"status":"ok","timestamp":1606109858949,"user_tz":-540,"elapsed":44496,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmbsCoo_qXED","executionInfo":{"status":"ok","timestamp":1606109858953,"user_tz":-540,"elapsed":44497,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(44923)\n","    x_valid = np.zeros(5077)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53442983, 0.51355958, 0.46462564]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","executionInfo":{"status":"ok","timestamp":1606109858954,"user_tz":-540,"elapsed":44494,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0VGsPxccqXEI"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"id":"zUAUYE9eqXEJ","executionInfo":{"status":"ok","timestamp":1606109858955,"user_tz":-540,"elapsed":44493,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","executionInfo":{"status":"ok","timestamp":1606109858956,"user_tz":-540,"elapsed":44491,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"4vIFMllQqXEN","executionInfo":{"status":"ok","timestamp":1606109858959,"user_tz":-540,"elapsed":44491,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"o1nWsjrYqXEQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606109905010,"user_tz":-540,"elapsed":90533,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"ac84b75b-1c20-4f05-e4a2-f49723ae29fe"},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 44923\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 5077\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Found 28698 images belonging to 7 classes.\n","Found 3589 images belonging to 7 classes.\n","Found 3588 images belonging to 7 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original Inception-ResNet-V1"]},{"cell_type":"markdown","metadata":{"id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS"},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 60 :\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIV9crIRUmBc"},"source":["def conv2d_bn(x, filters, kernel_size, strides=1, padding='same', activation='relu', use_bias=False, name=None, weight_decay=weight_decay):\n","\n","    x = Conv2D(filters, kernel_size, strides=strides, padding=padding,  use_bias=use_bias, name=name, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    if not use_bias:\n","        bn_axis =  3\n","        bn_name = None if name is None else '{name}_bn'.format(name=name)\n","        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n","        \n","    if activation is not None:\n","        ac_name = None if name is None else '{name}_ac'.format(name=name)\n","        x = Activation(activation, name=ac_name)(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyMaexRzUl_x"},"source":["def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n"," \n","    if block_type == 'block35':\n","        branch_0 = conv2d_bn(x, 32, 1)\n","        branch_1 = conv2d_bn(x, 32, 1)\n","        branch_1 = conv2d_bn(branch_1, 32, 3)\n","        branch_2 = conv2d_bn(x, 32, 1)\n","        branch_2 = conv2d_bn(branch_2, 32, 3)\n","        branch_2 = conv2d_bn(branch_2, 32, 3)\n","        branches = [branch_0, branch_1, branch_2]\n","    elif block_type == 'block17':\n","        branch_0 = conv2d_bn(x, 128, 1)\n","        branch_1 = conv2d_bn(x, 128, 1)\n","        branch_1 = conv2d_bn(branch_1, 128, [1, 7])\n","        branch_1 = conv2d_bn(branch_1, 128, [7, 1])\n","        branches = [branch_0, branch_1]\n","    elif block_type == 'block8':\n","        branch_0 = conv2d_bn(x, 192, 1)\n","        branch_1 = conv2d_bn(x, 192, 1)\n","        branch_1 = conv2d_bn(branch_1, 192, [1, 3])\n","        branch_1 = conv2d_bn(branch_1, 192, [3, 1])\n","        branches = [branch_0, branch_1]\n","    else:\n","        raise ValueError('Unknown Inception-ResNet block type. '\n","                         'Expects \"block35\", \"block17\" or \"block8\", '\n","                         'but got: {block_type}'.format(block_type=block_type))\n","\n","    block_name = '{block_type}_{block_idx}'.format(block_type=block_type, block_idx=block_idx)\n","    channel_axis = 3\n","    mixed = Concatenate(axis=channel_axis, name='{block_name}_mixed'.format(block_name=block_name))(branches)\n","    up = conv2d_bn(mixed,\n","                   K.int_shape(x)[channel_axis],\n","                   1,\n","                   activation=None,\n","                   use_bias=True,\n","                   name='{block_name}_conv'.format(block_name=block_name))\n","\n","    x = Lambda(lambda inputs, scale_: inputs[0] + inputs[1] * scale_,\n","               output_shape=K.int_shape(x)[1:],\n","               arguments={'scale_': scale},\n","               name=block_name)([x, up])\n","    if activation is not None:\n","        x = Activation(activation, name='{block_name}_ac'.format(block_name=block_name))(x)\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-R2NfkqUl60"},"source":["def Inception_ResNet_v1(input_shape=None, weight_decay=weight_decay, classes=classes, name=None):\n"," \n","    img_input = Input(shape=input_shape)\n","\n","    # Stem block: 35 x 35 x 192\n","    x = conv2d_bn(img_input, 32, 3, strides=2, padding='valid')\n","    x = conv2d_bn(x, 32, 3, padding='valid')\n","    x = conv2d_bn(x, 64, 3)\n","    x = MaxPooling2D(3, strides=2)(x)\n","    x = conv2d_bn(x, 80, 1)\n","    x = conv2d_bn(x, 192, 3, padding='valid')\n","    x = conv2d_bn(x, 256, 3, strides=2, padding='valid')\n","\n","    channel_axis = 3\n","\n","    # 5x block35 (Inception-ResNet-A block): 35 x 35 x 320\n","    for block_idx in range(1, 6):\n","        x = inception_resnet_block(x,\n","                                   scale=0.17,\n","                                   block_type='block35',\n","                                   block_idx=block_idx)\n","\n","    # Mixed 6a (Reduction-A block): 17 x 17 \n","    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid')\n","    branch_1 = conv2d_bn(x, 192, 1)\n","    branch_1 = conv2d_bn(branch_1, 192, 3)\n","    branch_1 = conv2d_bn(branch_1, 256, 3, strides=2, padding='valid')\n","    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n","    branches = [branch_0, branch_1, branch_pool]\n","    x = Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n","\n","\n","    # 10x block17 (Inception-ResNet-B block): 17 x 17 x 960\n","    for block_idx in range(1, 11):\n","        x = inception_resnet_block(x,\n","                                   scale=0.1,\n","                                   block_type='block17',\n","                                   block_idx=block_idx)\n","\n","    # Mixed 7a (Reduction-B block): 8 x 8 \n","    branch_0 = conv2d_bn(x, 256, 1)\n","    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid')\n","    branch_1 = conv2d_bn(x, 256, 1)\n","    branch_1 = conv2d_bn(branch_1, 256, 3, strides=2, padding='valid')\n","    branch_2 = conv2d_bn(x, 256, 1)\n","    branch_2 = conv2d_bn(branch_2, 256, 3)\n","    branch_2 = conv2d_bn(branch_2, 256, 3, strides=2, padding='valid')\n","    branch_pool = MaxPooling2D(3, strides=2, padding='valid')(x)\n","    branches = [branch_0, branch_1, branch_2, branch_pool]\n","    x = Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n","\n","\n","    # 5x block8 (Inception-ResNet-C block): 8 x 8 x 1856\n","    for block_idx in range(1, 5):\n","        x = inception_resnet_block(x,\n","                                   scale=0.2,\n","                                   block_type='block8',\n","                                   block_idx=block_idx)\n","    x = inception_resnet_block(x,\n","                               scale=1.,\n","                               activation=None,\n","                               block_type='block8',\n","                               block_idx=10)\n","\n","\n","    x = GlobalAveragePooling2D(name='avg_pool')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(classes, use_bias=False, kernel_regularizer=l2(weight_decay), activation='softmax', name='predictions')(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`\n","    inputs = img_input\n","\n","    # Create model\n","    model = Model(inputs, x, name=name)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wtR2M5ELuTew"},"source":["### 2) Almost Original Inception-ResNet-V1\n"]},{"cell_type":"code","metadata":{"id":"IMgWGFKFuTe3"},"source":["model = Inception_ResNet_v1(input_sizes, classes=classes, name='Inception_ResNet_v1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Plblq9iL6HdJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605572062743,"user_tz":-540,"elapsed":132325,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"7a452b60-1dc5-4645-bd50-4455020af26f"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"Inception_ResNet_v1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 35, 35, 256)  442368      activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 35, 35, 256)  768         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 35, 35, 256)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 35, 35, 32)   8192        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 35, 35, 32)   96          conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 35, 35, 32)   0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 35, 35, 32)   8192        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 35, 35, 32)   9216        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 35, 35, 32)   96          conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 35, 35, 32)   96          conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 35, 35, 32)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 35, 35, 32)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 35, 35, 32)   8192        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 35, 35, 32)   9216        activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 35, 35, 32)   9216        activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 35, 35, 32)   96          conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 35, 35, 32)   96          conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 35, 35, 32)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 35, 35, 32)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","block35_1_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_6[0][0]               \n","                                                                 activation_8[0][0]               \n","                                                                 activation_11[0][0]              \n","__________________________________________________________________________________________________\n","block35_1_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_1_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_1 (Lambda)              (None, 35, 35, 256)  0           activation_5[0][0]               \n","                                                                 block35_1_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_1_ac (Activation)       (None, 35, 35, 256)  0           block35_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 35, 35, 32)   8192        block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 35, 35, 32)   96          conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 35, 35, 32)   8192        block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 35, 35, 32)   9216        activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 35, 35, 32)   96          conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 35, 35, 32)   96          conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 35, 35, 32)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 35, 35, 32)   8192        block35_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 35, 35, 32)   9216        activation_13[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 35, 35, 32)   9216        activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 35, 35, 32)   96          conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 35, 35, 32)   96          conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 35, 35, 32)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","block35_2_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_12[0][0]              \n","                                                                 activation_14[0][0]              \n","                                                                 activation_17[0][0]              \n","__________________________________________________________________________________________________\n","block35_2_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_2_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_2 (Lambda)              (None, 35, 35, 256)  0           block35_1_ac[0][0]               \n","                                                                 block35_2_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_2_ac (Activation)       (None, 35, 35, 256)  0           block35_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 35, 35, 32)   8192        block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 35, 35, 32)   96          conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 35, 35, 32)   8192        block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 35, 35, 32)   9216        activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 35, 35, 32)   96          conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 35, 35, 32)   96          conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 35, 35, 32)   0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 35, 35, 32)   8192        block35_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 35, 35, 32)   9216        activation_19[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 35, 35, 32)   9216        activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 35, 35, 32)   96          conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 35, 35, 32)   96          conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 35, 35, 32)   96          conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 35, 35, 32)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 35, 35, 32)   0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","block35_3_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_18[0][0]              \n","                                                                 activation_20[0][0]              \n","                                                                 activation_23[0][0]              \n","__________________________________________________________________________________________________\n","block35_3_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_3_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_3 (Lambda)              (None, 35, 35, 256)  0           block35_2_ac[0][0]               \n","                                                                 block35_3_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_3_ac (Activation)       (None, 35, 35, 256)  0           block35_3[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 35, 35, 32)   8192        block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 35, 35, 32)   96          conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 35, 35, 32)   8192        block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 35, 35, 32)   9216        activation_27[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 35, 35, 32)   96          conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 35, 35, 32)   96          conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 35, 35, 32)   0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 35, 35, 32)   8192        block35_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 35, 35, 32)   9216        activation_25[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 35, 35, 32)   9216        activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 35, 35, 32)   96          conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 35, 35, 32)   96          conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 35, 35, 32)   0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 35, 35, 32)   0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","block35_4_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_24[0][0]              \n","                                                                 activation_26[0][0]              \n","                                                                 activation_29[0][0]              \n","__________________________________________________________________________________________________\n","block35_4_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_4_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_4 (Lambda)              (None, 35, 35, 256)  0           block35_3_ac[0][0]               \n","                                                                 block35_4_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_4_ac (Activation)       (None, 35, 35, 256)  0           block35_4[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 35, 35, 32)   8192        block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 35, 35, 32)   96          conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 35, 35, 32)   8192        block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 35, 35, 32)   9216        activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 35, 35, 32)   96          conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 35, 35, 32)   96          conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 35, 35, 32)   0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 35, 35, 32)   8192        block35_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 35, 35, 32)   9216        activation_31[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 35, 35, 32)   9216        activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 35, 35, 32)   96          conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 35, 35, 32)   96          conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 35, 35, 32)   96          conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 35, 35, 32)   0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 35, 35, 32)   0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","block35_5_mixed (Concatenate)   (None, 35, 35, 96)   0           activation_30[0][0]              \n","                                                                 activation_32[0][0]              \n","                                                                 activation_35[0][0]              \n","__________________________________________________________________________________________________\n","block35_5_conv (Conv2D)         (None, 35, 35, 256)  24832       block35_5_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block35_5 (Lambda)              (None, 35, 35, 256)  0           block35_4_ac[0][0]               \n","                                                                 block35_5_conv[0][0]             \n","__________________________________________________________________________________________________\n","block35_5_ac (Activation)       (None, 35, 35, 256)  0           block35_5[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 35, 35, 192)  49152       block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 35, 35, 192)  576         conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 35, 35, 192)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 35, 35, 192)  331776      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 35, 35, 192)  576         conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 35, 35, 192)  0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 17, 17, 384)  884736      block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 17, 17, 256)  442368      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 17, 17, 384)  1152        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 17, 17, 256)  768         conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 17, 17, 384)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 17, 17, 256)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 17, 17, 256)  0           block35_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","mixed_6a (Concatenate)          (None, 17, 17, 896)  0           activation_36[0][0]              \n","                                                                 activation_39[0][0]              \n","                                                                 max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 17, 17, 128)  114688      mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 17, 17, 128)  384         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 17, 17, 128)  0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 17, 17, 128)  114688      activation_41[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 17, 17, 128)  384         conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 17, 17, 128)  0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 17, 17, 128)  114688      mixed_6a[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 17, 17, 128)  114688      activation_42[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 17, 17, 128)  384         conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 17, 17, 128)  384         conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 17, 17, 128)  0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 17, 17, 128)  0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","block17_1_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_40[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","block17_1_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_1_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_1 (Lambda)              (None, 17, 17, 896)  0           mixed_6a[0][0]                   \n","                                                                 block17_1_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_1_ac (Activation)       (None, 17, 17, 896)  0           block17_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 17, 17, 128)  114688      block17_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 17, 17, 128)  384         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 17, 17, 128)  0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 17, 17, 128)  114688      activation_45[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 17, 17, 128)  384         conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 17, 17, 128)  0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 17, 17, 128)  114688      block17_1_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 17, 17, 128)  114688      activation_46[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 17, 17, 128)  384         conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 17, 17, 128)  384         conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 17, 17, 128)  0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 17, 17, 128)  0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","block17_2_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_44[0][0]              \n","                                                                 activation_47[0][0]              \n","__________________________________________________________________________________________________\n","block17_2_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_2_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_2 (Lambda)              (None, 17, 17, 896)  0           block17_1_ac[0][0]               \n","                                                                 block17_2_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_2_ac (Activation)       (None, 17, 17, 896)  0           block17_2[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 17, 17, 128)  114688      block17_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 17, 17, 128)  384         conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 17, 17, 128)  0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 17, 17, 128)  114688      activation_49[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 17, 17, 128)  384         conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 17, 17, 128)  0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 17, 17, 128)  114688      block17_2_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 17, 17, 128)  114688      activation_50[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 17, 17, 128)  384         conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 17, 17, 128)  384         conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 17, 17, 128)  0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 17, 17, 128)  0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","block17_3_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_48[0][0]              \n","                                                                 activation_51[0][0]              \n","__________________________________________________________________________________________________\n","block17_3_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_3_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_3 (Lambda)              (None, 17, 17, 896)  0           block17_2_ac[0][0]               \n","                                                                 block17_3_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_3_ac (Activation)       (None, 17, 17, 896)  0           block17_3[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 17, 17, 128)  114688      block17_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_53 (BatchNo (None, 17, 17, 128)  384         conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","activation_53 (Activation)      (None, 17, 17, 128)  0           batch_normalization_53[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 17, 17, 128)  114688      activation_53[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_54 (BatchNo (None, 17, 17, 128)  384         conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","activation_54 (Activation)      (None, 17, 17, 128)  0           batch_normalization_54[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 17, 17, 128)  114688      block17_3_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 17, 17, 128)  114688      activation_54[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_52 (BatchNo (None, 17, 17, 128)  384         conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_55 (BatchNo (None, 17, 17, 128)  384         conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","activation_52 (Activation)      (None, 17, 17, 128)  0           batch_normalization_52[0][0]     \n","__________________________________________________________________________________________________\n","activation_55 (Activation)      (None, 17, 17, 128)  0           batch_normalization_55[0][0]     \n","__________________________________________________________________________________________________\n","block17_4_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_52[0][0]              \n","                                                                 activation_55[0][0]              \n","__________________________________________________________________________________________________\n","block17_4_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_4_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_4 (Lambda)              (None, 17, 17, 896)  0           block17_3_ac[0][0]               \n","                                                                 block17_4_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_4_ac (Activation)       (None, 17, 17, 896)  0           block17_4[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 17, 17, 128)  114688      block17_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 17, 17, 128)  384         conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","activation_57 (Activation)      (None, 17, 17, 128)  0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 17, 17, 128)  114688      activation_57[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 17, 17, 128)  384         conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","activation_58 (Activation)      (None, 17, 17, 128)  0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 17, 17, 128)  114688      block17_4_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, 17, 17, 128)  114688      activation_58[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_56 (BatchNo (None, 17, 17, 128)  384         conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 17, 17, 128)  384         conv2d_59[0][0]                  \n","__________________________________________________________________________________________________\n","activation_56 (Activation)      (None, 17, 17, 128)  0           batch_normalization_56[0][0]     \n","__________________________________________________________________________________________________\n","activation_59 (Activation)      (None, 17, 17, 128)  0           batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","block17_5_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_56[0][0]              \n","                                                                 activation_59[0][0]              \n","__________________________________________________________________________________________________\n","block17_5_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_5_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_5 (Lambda)              (None, 17, 17, 896)  0           block17_4_ac[0][0]               \n","                                                                 block17_5_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_5_ac (Activation)       (None, 17, 17, 896)  0           block17_5[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 17, 17, 128)  114688      block17_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 17, 17, 128)  384         conv2d_61[0][0]                  \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 17, 17, 128)  0           batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_62 (Conv2D)              (None, 17, 17, 128)  114688      activation_61[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 17, 17, 128)  384         conv2d_62[0][0]                  \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 17, 17, 128)  0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 17, 17, 128)  114688      block17_5_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, 17, 17, 128)  114688      activation_62[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 17, 17, 128)  384         conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 17, 17, 128)  384         conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 17, 17, 128)  0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 17, 17, 128)  0           batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","block17_6_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_60[0][0]              \n","                                                                 activation_63[0][0]              \n","__________________________________________________________________________________________________\n","block17_6_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_6_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_6 (Lambda)              (None, 17, 17, 896)  0           block17_5_ac[0][0]               \n","                                                                 block17_6_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_6_ac (Activation)       (None, 17, 17, 896)  0           block17_6[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_65 (Conv2D)              (None, 17, 17, 128)  114688      block17_6_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 17, 17, 128)  384         conv2d_65[0][0]                  \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 17, 17, 128)  0           batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_66 (Conv2D)              (None, 17, 17, 128)  114688      activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 17, 17, 128)  384         conv2d_66[0][0]                  \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 17, 17, 128)  0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_64 (Conv2D)              (None, 17, 17, 128)  114688      block17_6_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_67 (Conv2D)              (None, 17, 17, 128)  114688      activation_66[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 17, 17, 128)  384         conv2d_64[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 17, 17, 128)  384         conv2d_67[0][0]                  \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 17, 17, 128)  0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 17, 17, 128)  0           batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","block17_7_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_64[0][0]              \n","                                                                 activation_67[0][0]              \n","__________________________________________________________________________________________________\n","block17_7_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_7_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_7 (Lambda)              (None, 17, 17, 896)  0           block17_6_ac[0][0]               \n","                                                                 block17_7_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_7_ac (Activation)       (None, 17, 17, 896)  0           block17_7[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_69 (Conv2D)              (None, 17, 17, 128)  114688      block17_7_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 17, 17, 128)  384         conv2d_69[0][0]                  \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 17, 17, 128)  0           batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_70 (Conv2D)              (None, 17, 17, 128)  114688      activation_69[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 17, 17, 128)  384         conv2d_70[0][0]                  \n","__________________________________________________________________________________________________\n","activation_70 (Activation)      (None, 17, 17, 128)  0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_68 (Conv2D)              (None, 17, 17, 128)  114688      block17_7_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_71 (Conv2D)              (None, 17, 17, 128)  114688      activation_70[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 17, 17, 128)  384         conv2d_68[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 17, 17, 128)  384         conv2d_71[0][0]                  \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 17, 17, 128)  0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","activation_71 (Activation)      (None, 17, 17, 128)  0           batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","block17_8_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_68[0][0]              \n","                                                                 activation_71[0][0]              \n","__________________________________________________________________________________________________\n","block17_8_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_8_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_8 (Lambda)              (None, 17, 17, 896)  0           block17_7_ac[0][0]               \n","                                                                 block17_8_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_8_ac (Activation)       (None, 17, 17, 896)  0           block17_8[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_73 (Conv2D)              (None, 17, 17, 128)  114688      block17_8_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 17, 17, 128)  384         conv2d_73[0][0]                  \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 17, 17, 128)  0           batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_74 (Conv2D)              (None, 17, 17, 128)  114688      activation_73[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 17, 17, 128)  384         conv2d_74[0][0]                  \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 17, 17, 128)  0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_72 (Conv2D)              (None, 17, 17, 128)  114688      block17_8_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_75 (Conv2D)              (None, 17, 17, 128)  114688      activation_74[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 17, 17, 128)  384         conv2d_72[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 17, 17, 128)  384         conv2d_75[0][0]                  \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 17, 17, 128)  0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 17, 17, 128)  0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","block17_9_mixed (Concatenate)   (None, 17, 17, 256)  0           activation_72[0][0]              \n","                                                                 activation_75[0][0]              \n","__________________________________________________________________________________________________\n","block17_9_conv (Conv2D)         (None, 17, 17, 896)  230272      block17_9_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block17_9 (Lambda)              (None, 17, 17, 896)  0           block17_8_ac[0][0]               \n","                                                                 block17_9_conv[0][0]             \n","__________________________________________________________________________________________________\n","block17_9_ac (Activation)       (None, 17, 17, 896)  0           block17_9[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_77 (Conv2D)              (None, 17, 17, 128)  114688      block17_9_ac[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 17, 17, 128)  384         conv2d_77[0][0]                  \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 17, 17, 128)  0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_78 (Conv2D)              (None, 17, 17, 128)  114688      activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 17, 17, 128)  384         conv2d_78[0][0]                  \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 17, 17, 128)  0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_76 (Conv2D)              (None, 17, 17, 128)  114688      block17_9_ac[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_79 (Conv2D)              (None, 17, 17, 128)  114688      activation_78[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 17, 17, 128)  384         conv2d_76[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 17, 17, 128)  384         conv2d_79[0][0]                  \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 17, 17, 128)  0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 17, 17, 128)  0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","block17_10_mixed (Concatenate)  (None, 17, 17, 256)  0           activation_76[0][0]              \n","                                                                 activation_79[0][0]              \n","__________________________________________________________________________________________________\n","block17_10_conv (Conv2D)        (None, 17, 17, 896)  230272      block17_10_mixed[0][0]           \n","__________________________________________________________________________________________________\n","block17_10 (Lambda)             (None, 17, 17, 896)  0           block17_9_ac[0][0]               \n","                                                                 block17_10_conv[0][0]            \n","__________________________________________________________________________________________________\n","block17_10_ac (Activation)      (None, 17, 17, 896)  0           block17_10[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_84 (Conv2D)              (None, 17, 17, 256)  229376      block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 17, 17, 256)  768         conv2d_84[0][0]                  \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 17, 17, 256)  0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_80 (Conv2D)              (None, 17, 17, 256)  229376      block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_82 (Conv2D)              (None, 17, 17, 256)  229376      block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_85 (Conv2D)              (None, 17, 17, 256)  589824      activation_84[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 17, 17, 256)  768         conv2d_80[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 17, 17, 256)  768         conv2d_82[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 17, 17, 256)  768         conv2d_85[0][0]                  \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 17, 17, 256)  0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 17, 17, 256)  0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 17, 17, 256)  0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_81 (Conv2D)              (None, 8, 8, 384)    884736      activation_80[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_83 (Conv2D)              (None, 8, 8, 256)    589824      activation_82[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_86 (Conv2D)              (None, 8, 8, 256)    589824      activation_85[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 8, 8, 256)    768         conv2d_83[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 8, 8, 256)    768         conv2d_86[0][0]                  \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 8, 8, 256)    0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 8, 8, 256)    0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 896)    0           block17_10_ac[0][0]              \n","__________________________________________________________________________________________________\n","mixed_7a (Concatenate)          (None, 8, 8, 1792)   0           activation_81[0][0]              \n","                                                                 activation_83[0][0]              \n","                                                                 activation_86[0][0]              \n","                                                                 max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 8, 8, 192)    344064      mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 8, 8, 192)    576         conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 8, 8, 192)    0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 8, 8, 192)    110592      activation_88[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 8, 8, 192)    576         conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 8, 8, 192)    0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_87 (Conv2D)              (None, 8, 8, 192)    344064      mixed_7a[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 8, 8, 192)    110592      activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 8, 8, 192)    576         conv2d_87[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 8, 8, 192)    576         conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 8, 8, 192)    0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 8, 8, 192)    0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","block8_1_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_87[0][0]              \n","                                                                 activation_90[0][0]              \n","__________________________________________________________________________________________________\n","block8_1_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_1_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_1 (Lambda)               (None, 8, 8, 1792)   0           mixed_7a[0][0]                   \n","                                                                 block8_1_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_1_ac (Activation)        (None, 8, 8, 1792)   0           block8_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 8, 8, 192)    344064      block8_1_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 8, 8, 192)    576         conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 8, 8, 192)    0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 8, 8, 192)    110592      activation_92[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 8, 8, 192)    344064      block8_1_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 8, 8, 192)    110592      activation_93[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 8, 8, 192)    576         conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 8, 8, 192)    0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","block8_2_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_91[0][0]              \n","                                                                 activation_94[0][0]              \n","__________________________________________________________________________________________________\n","block8_2_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_2_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_2 (Lambda)               (None, 8, 8, 1792)   0           block8_1_ac[0][0]                \n","                                                                 block8_2_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_2_ac (Activation)        (None, 8, 8, 1792)   0           block8_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 8, 8, 192)    344064      block8_2_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 8, 8, 192)    576         conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 8, 8, 192)    0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 8, 8, 192)    110592      activation_96[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 8, 8, 192)    576         conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 8, 8, 192)    0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 8, 8, 192)    344064      block8_2_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 8, 8, 192)    110592      activation_97[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 8, 8, 192)    576         conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 8, 8, 192)    576         conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 8, 8, 192)    0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 8, 8, 192)    0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","block8_3_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_95[0][0]              \n","                                                                 activation_98[0][0]              \n","__________________________________________________________________________________________________\n","block8_3_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_3_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_3 (Lambda)               (None, 8, 8, 1792)   0           block8_2_ac[0][0]                \n","                                                                 block8_3_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_3_ac (Activation)        (None, 8, 8, 1792)   0           block8_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 8, 8, 192)    344064      block8_3_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 8, 8, 192)    576         conv2d_100[0][0]                 \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 8, 8, 192)    0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 8, 8, 192)    110592      activation_100[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 8, 8, 192)    576         conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 8, 8, 192)    0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 8, 8, 192)    344064      block8_3_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 8, 8, 192)    110592      activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 8, 8, 192)    576         conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 8, 8, 192)    576         conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 8, 8, 192)    0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 8, 8, 192)    0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","block8_4_mixed (Concatenate)    (None, 8, 8, 384)    0           activation_99[0][0]              \n","                                                                 activation_102[0][0]             \n","__________________________________________________________________________________________________\n","block8_4_conv (Conv2D)          (None, 8, 8, 1792)   689920      block8_4_mixed[0][0]             \n","__________________________________________________________________________________________________\n","block8_4 (Lambda)               (None, 8, 8, 1792)   0           block8_3_ac[0][0]                \n","                                                                 block8_4_conv[0][0]              \n","__________________________________________________________________________________________________\n","block8_4_ac (Activation)        (None, 8, 8, 1792)   0           block8_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 8, 8, 192)    344064      block8_4_ac[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 8, 8, 192)    576         conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 8, 8, 192)    0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_105 (Conv2D)             (None, 8, 8, 192)    110592      activation_104[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_105 (BatchN (None, 8, 8, 192)    576         conv2d_105[0][0]                 \n","__________________________________________________________________________________________________\n","activation_105 (Activation)     (None, 8, 8, 192)    0           batch_normalization_105[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 8, 8, 192)    344064      block8_4_ac[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_106 (Conv2D)             (None, 8, 8, 192)    110592      activation_105[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 8, 8, 192)    576         conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_106 (BatchN (None, 8, 8, 192)    576         conv2d_106[0][0]                 \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 8, 8, 192)    0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","activation_106 (Activation)     (None, 8, 8, 192)    0           batch_normalization_106[0][0]    \n","__________________________________________________________________________________________________\n","block8_10_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_103[0][0]             \n","                                                                 activation_106[0][0]             \n","__________________________________________________________________________________________________\n","block8_10_conv (Conv2D)         (None, 8, 8, 1792)   689920      block8_10_mixed[0][0]            \n","__________________________________________________________________________________________________\n","block8_10 (Lambda)              (None, 8, 8, 1792)   0           block8_4_ac[0][0]                \n","                                                                 block8_10_conv[0][0]             \n","__________________________________________________________________________________________________\n","avg_pool (GlobalAveragePooling2 (None, 1792)         0           block8_10[0][0]                  \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 1792)         0           avg_pool[0][0]                   \n","__________________________________________________________________________________________________\n","predictions (Dense)             (None, 7)            12544       dropout[0][0]                    \n","==================================================================================================\n","Total params: 20,989,392\n","Trainable params: 20,962,352\n","Non-trainable params: 27,040\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HflF2mp1EsHM"},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AsDrV7ONZBDr"},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XAwJuKTh6Kvy"},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N27iJUAkuTfC"},"source":["#optimizer = SGDW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes, nesterov=True, momentum=0.9)\n","optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',top5_acc,macro_f1score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"efoKrIVUuTfF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605628811792,"user_tz":-540,"elapsed":56881327,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"6a2c2e33-4e7c-4375-e22b-09dc4aa5e02a"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/70\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_5/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_9/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_7/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_10/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_6/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_8/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_11/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block35_1_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_15/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_13/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_16/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_12/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_14/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_17/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block35_2_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_21/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_19/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_22/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_18/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_20/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_23/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block35_3_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_27/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_25/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_28/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_24/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_26/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_29/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block35_4_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_33/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_31/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_34/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_30/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_32/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_35/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block35_5_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_37/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_38/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_36/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_39/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_41/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_42/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_40/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_43/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block17_1_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_45/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_46/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_44/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_47/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block17_2_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_49/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_50/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_48/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_51/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block17_3_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_53/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_54/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_52/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_55/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block17_4_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_57/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_58/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_56/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_59/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block17_5_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_61/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_62/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_60/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_63/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block17_6_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_65/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_66/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_64/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_67/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block17_7_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_69/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_70/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_68/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_71/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block17_8_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_73/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_74/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_72/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_75/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block17_9_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_77/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_78/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_76/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_79/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block17_10_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_84/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_80/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_82/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_85/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_81/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_83/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_86/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_88/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_89/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_87/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_90/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block8_1_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_92/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_93/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_91/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_94/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block8_2_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_96/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_97/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_95/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_98/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block8_3_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_100/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_101/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_99/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_102/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block8_4_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_104/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_105/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_103/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for conv2d_106/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for block8_10_conv/kernel:0\n","0.0(L1), 4.7245561370197044e-05(L2) weight decay set for predictions/kernel:0\n","448/448 [==============================] - ETA: 0s - loss: 2.0062 - accuracy: 0.2527 - top5_acc: 0.8865 - macro_f1score: 0.0385 \n","Epoch 00001: val_loss improved from inf to 18.68170, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.22545, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/001.h5\n","448/448 [==============================] - 7023s 16s/step - loss: 2.0062 - accuracy: 0.2527 - top5_acc: 0.8865 - macro_f1score: 0.0385 - val_loss: 18.6817 - val_accuracy: 0.2254 - val_top5_acc: 0.8295 - val_macro_f1score: 0.0920\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/70\n","448/448 [==============================] - ETA: 0s - loss: 1.4877 - accuracy: 0.4227 - top5_acc: 0.9517 - macro_f1score: 0.1818\n","Epoch 00002: val_loss improved from 18.68170 to 1.33790, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/002.h5\n","\n","Epoch 00002: val_accuracy improved from 0.22545 to 0.49191, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/002.h5\n","448/448 [==============================] - 734s 2s/step - loss: 1.4877 - accuracy: 0.4227 - top5_acc: 0.9517 - macro_f1score: 0.1818 - val_loss: 1.3379 - val_accuracy: 0.4919 - val_top5_acc: 0.9662 - val_macro_f1score: 0.2620\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/70\n","448/448 [==============================] - ETA: 0s - loss: 1.2747 - accuracy: 0.5182 - top5_acc: 0.9703 - macro_f1score: 0.2858\n","Epoch 00003: val_loss did not improve from 1.33790\n","\n","Epoch 00003: val_accuracy did not improve from 0.49191\n","448/448 [==============================] - 725s 2s/step - loss: 1.2747 - accuracy: 0.5182 - top5_acc: 0.9703 - macro_f1score: 0.2858 - val_loss: 1.3908 - val_accuracy: 0.4908 - val_top5_acc: 0.9729 - val_macro_f1score: 0.2874\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/70\n","448/448 [==============================] - ETA: 0s - loss: 1.1785 - accuracy: 0.5543 - top5_acc: 0.9768 - macro_f1score: 0.3429\n","Epoch 00004: val_loss improved from 1.33790 to 1.22823, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/004.h5\n","\n","Epoch 00004: val_accuracy improved from 0.49191 to 0.54213, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/004.h5\n","448/448 [==============================] - 731s 2s/step - loss: 1.1785 - accuracy: 0.5543 - top5_acc: 0.9768 - macro_f1score: 0.3429 - val_loss: 1.2282 - val_accuracy: 0.5421 - val_top5_acc: 0.9763 - val_macro_f1score: 0.3270\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/70\n","448/448 [==============================] - ETA: 0s - loss: 1.1125 - accuracy: 0.5812 - top5_acc: 0.9830 - macro_f1score: 0.3837\n","Epoch 00005: val_loss did not improve from 1.22823\n","\n","Epoch 00005: val_accuracy did not improve from 0.54213\n","448/448 [==============================] - 727s 2s/step - loss: 1.1125 - accuracy: 0.5812 - top5_acc: 0.9830 - macro_f1score: 0.3837 - val_loss: 1.2284 - val_accuracy: 0.5128 - val_top5_acc: 0.9791 - val_macro_f1score: 0.3368\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/70\n","448/448 [==============================] - ETA: 0s - loss: 1.0665 - accuracy: 0.5982 - top5_acc: 0.9843 - macro_f1score: 0.4150\n","Epoch 00006: val_loss did not improve from 1.22823\n","\n","Epoch 00006: val_accuracy did not improve from 0.54213\n","448/448 [==============================] - 732s 2s/step - loss: 1.0665 - accuracy: 0.5982 - top5_acc: 0.9843 - macro_f1score: 0.4150 - val_loss: 1.3145 - val_accuracy: 0.5204 - val_top5_acc: 0.9629 - val_macro_f1score: 0.3102\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/70\n","448/448 [==============================] - ETA: 0s - loss: 1.0446 - accuracy: 0.6060 - top5_acc: 0.9839 - macro_f1score: 0.4263\n","Epoch 00007: val_loss improved from 1.22823 to 1.11776, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/007.h5\n","\n","Epoch 00007: val_accuracy improved from 0.54213 to 0.55804, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/007.h5\n","448/448 [==============================] - 732s 2s/step - loss: 1.0446 - accuracy: 0.6060 - top5_acc: 0.9839 - macro_f1score: 0.4263 - val_loss: 1.1178 - val_accuracy: 0.5580 - val_top5_acc: 0.9869 - val_macro_f1score: 0.3949\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/70\n","448/448 [==============================] - ETA: 0s - loss: 1.0072 - accuracy: 0.6207 - top5_acc: 0.9872 - macro_f1score: 0.4535\n","Epoch 00008: val_loss improved from 1.11776 to 1.06330, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/008.h5\n","\n","Epoch 00008: val_accuracy improved from 0.55804 to 0.59961, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/008.h5\n","448/448 [==============================] - 739s 2s/step - loss: 1.0072 - accuracy: 0.6207 - top5_acc: 0.9872 - macro_f1score: 0.4535 - val_loss: 1.0633 - val_accuracy: 0.5996 - val_top5_acc: 0.9855 - val_macro_f1score: 0.4321\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/70\n","448/448 [==============================] - ETA: 0s - loss: 0.9722 - accuracy: 0.6344 - top5_acc: 0.9879 - macro_f1score: 0.4796\n","Epoch 00009: val_loss improved from 1.06330 to 1.02242, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/009.h5\n","\n","Epoch 00009: val_accuracy improved from 0.59961 to 0.61468, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/009.h5\n","448/448 [==============================] - 744s 2s/step - loss: 0.9722 - accuracy: 0.6344 - top5_acc: 0.9879 - macro_f1score: 0.4796 - val_loss: 1.0224 - val_accuracy: 0.6147 - val_top5_acc: 0.9886 - val_macro_f1score: 0.4474\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/70\n","448/448 [==============================] - ETA: 0s - loss: 0.9535 - accuracy: 0.6430 - top5_acc: 0.9895 - macro_f1score: 0.4919\n","Epoch 00010: val_loss did not improve from 1.02242\n","\n","Epoch 00010: val_accuracy improved from 0.61468 to 0.61719, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/010.h5\n","448/448 [==============================] - 740s 2s/step - loss: 0.9535 - accuracy: 0.6430 - top5_acc: 0.9895 - macro_f1score: 0.4919 - val_loss: 1.0305 - val_accuracy: 0.6172 - val_top5_acc: 0.9891 - val_macro_f1score: 0.4427\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/70\n","448/448 [==============================] - ETA: 0s - loss: 0.9244 - accuracy: 0.6532 - top5_acc: 0.9899 - macro_f1score: 0.5170\n","Epoch 00011: val_loss did not improve from 1.02242\n","\n","Epoch 00011: val_accuracy did not improve from 0.61719\n","448/448 [==============================] - 739s 2s/step - loss: 0.9244 - accuracy: 0.6532 - top5_acc: 0.9899 - macro_f1score: 0.5170 - val_loss: 1.0259 - val_accuracy: 0.6110 - val_top5_acc: 0.9869 - val_macro_f1score: 0.4747\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/70\n","448/448 [==============================] - ETA: 0s - loss: 0.9120 - accuracy: 0.6569 - top5_acc: 0.9910 - macro_f1score: 0.5177\n","Epoch 00012: val_loss did not improve from 1.02242\n","\n","Epoch 00012: val_accuracy did not improve from 0.61719\n","448/448 [==============================] - 732s 2s/step - loss: 0.9120 - accuracy: 0.6569 - top5_acc: 0.9910 - macro_f1score: 0.5177 - val_loss: 1.0563 - val_accuracy: 0.6097 - val_top5_acc: 0.9860 - val_macro_f1score: 0.4821\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/70\n","448/448 [==============================] - ETA: 0s - loss: 0.8857 - accuracy: 0.6682 - top5_acc: 0.9923 - macro_f1score: 0.5384\n","Epoch 00013: val_loss improved from 1.02242 to 1.01142, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/013.h5\n","\n","Epoch 00013: val_accuracy improved from 0.61719 to 0.63421, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/013.h5\n","448/448 [==============================] - 731s 2s/step - loss: 0.8857 - accuracy: 0.6682 - top5_acc: 0.9923 - macro_f1score: 0.5384 - val_loss: 1.0114 - val_accuracy: 0.6342 - val_top5_acc: 0.9886 - val_macro_f1score: 0.4925\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/70\n","448/448 [==============================] - ETA: 0s - loss: 0.8727 - accuracy: 0.6753 - top5_acc: 0.9920 - macro_f1score: 0.5461\n","Epoch 00014: val_loss did not improve from 1.01142\n","\n","Epoch 00014: val_accuracy did not improve from 0.63421\n","448/448 [==============================] - 735s 2s/step - loss: 0.8727 - accuracy: 0.6753 - top5_acc: 0.9920 - macro_f1score: 0.5461 - val_loss: 1.0394 - val_accuracy: 0.6150 - val_top5_acc: 0.9883 - val_macro_f1score: 0.4978\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/70\n","448/448 [==============================] - ETA: 0s - loss: 0.8440 - accuracy: 0.6871 - top5_acc: 0.9923 - macro_f1score: 0.5671\n","Epoch 00015: val_loss did not improve from 1.01142\n","\n","Epoch 00015: val_accuracy did not improve from 0.63421\n","448/448 [==============================] - 716s 2s/step - loss: 0.8440 - accuracy: 0.6871 - top5_acc: 0.9923 - macro_f1score: 0.5671 - val_loss: 1.0694 - val_accuracy: 0.6222 - val_top5_acc: 0.9849 - val_macro_f1score: 0.4986\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/70\n","448/448 [==============================] - ETA: 0s - loss: 0.8286 - accuracy: 0.6905 - top5_acc: 0.9934 - macro_f1score: 0.5782\n","Epoch 00016: val_loss did not improve from 1.01142\n","\n","Epoch 00016: val_accuracy did not improve from 0.63421\n","448/448 [==============================] - 722s 2s/step - loss: 0.8286 - accuracy: 0.6905 - top5_acc: 0.9934 - macro_f1score: 0.5782 - val_loss: 1.0429 - val_accuracy: 0.6161 - val_top5_acc: 0.9838 - val_macro_f1score: 0.4758\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/70\n","448/448 [==============================] - ETA: 0s - loss: 0.8024 - accuracy: 0.7048 - top5_acc: 0.9937 - macro_f1score: 0.5956\n","Epoch 00017: val_loss did not improve from 1.01142\n","\n","Epoch 00017: val_accuracy did not improve from 0.63421\n","448/448 [==============================] - 724s 2s/step - loss: 0.8024 - accuracy: 0.7048 - top5_acc: 0.9937 - macro_f1score: 0.5956 - val_loss: 1.1336 - val_accuracy: 0.5896 - val_top5_acc: 0.9858 - val_macro_f1score: 0.4703\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/70\n","448/448 [==============================] - ETA: 0s - loss: 0.7785 - accuracy: 0.7104 - top5_acc: 0.9943 - macro_f1score: 0.6026\n","Epoch 00018: val_loss improved from 1.01142 to 0.99661, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/018.h5\n","\n","Epoch 00018: val_accuracy improved from 0.63421 to 0.63951, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/018.h5\n","448/448 [==============================] - 732s 2s/step - loss: 0.7785 - accuracy: 0.7104 - top5_acc: 0.9943 - macro_f1score: 0.6026 - val_loss: 0.9966 - val_accuracy: 0.6395 - val_top5_acc: 0.9902 - val_macro_f1score: 0.5054\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/70\n","448/448 [==============================] - ETA: 0s - loss: 0.7656 - accuracy: 0.7174 - top5_acc: 0.9953 - macro_f1score: 0.6167\n","Epoch 00019: val_loss did not improve from 0.99661\n","\n","Epoch 00019: val_accuracy did not improve from 0.63951\n","448/448 [==============================] - 731s 2s/step - loss: 0.7656 - accuracy: 0.7174 - top5_acc: 0.9953 - macro_f1score: 0.6167 - val_loss: 1.0499 - val_accuracy: 0.6345 - val_top5_acc: 0.9866 - val_macro_f1score: 0.5111\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/70\n","448/448 [==============================] - ETA: 0s - loss: 0.7365 - accuracy: 0.7281 - top5_acc: 0.9948 - macro_f1score: 0.6324\n","Epoch 00020: val_loss improved from 0.99661 to 0.96924, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/020.h5\n","\n","Epoch 00020: val_accuracy improved from 0.63951 to 0.65569, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/020.h5\n","448/448 [==============================] - 736s 2s/step - loss: 0.7365 - accuracy: 0.7281 - top5_acc: 0.9948 - macro_f1score: 0.6324 - val_loss: 0.9692 - val_accuracy: 0.6557 - val_top5_acc: 0.9883 - val_macro_f1score: 0.5642\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/70\n","448/448 [==============================] - ETA: 0s - loss: 0.7256 - accuracy: 0.7325 - top5_acc: 0.9961 - macro_f1score: 0.6383\n","Epoch 00021: val_loss did not improve from 0.96924\n","\n","Epoch 00021: val_accuracy did not improve from 0.65569\n","448/448 [==============================] - 723s 2s/step - loss: 0.7256 - accuracy: 0.7325 - top5_acc: 0.9961 - macro_f1score: 0.6383 - val_loss: 0.9774 - val_accuracy: 0.6509 - val_top5_acc: 0.9880 - val_macro_f1score: 0.5317\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/70\n","448/448 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.7450 - top5_acc: 0.9957 - macro_f1score: 0.6579\n","Epoch 00022: val_loss did not improve from 0.96924\n","\n","Epoch 00022: val_accuracy did not improve from 0.65569\n","448/448 [==============================] - 738s 2s/step - loss: 0.6945 - accuracy: 0.7450 - top5_acc: 0.9957 - macro_f1score: 0.6579 - val_loss: 1.0702 - val_accuracy: 0.6328 - val_top5_acc: 0.9866 - val_macro_f1score: 0.5130\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/70\n","448/448 [==============================] - ETA: 0s - loss: 0.7105 - accuracy: 0.7352 - top5_acc: 0.9953 - macro_f1score: 0.6440\n","Epoch 00023: val_loss did not improve from 0.96924\n","\n","Epoch 00023: val_accuracy did not improve from 0.65569\n","448/448 [==============================] - 709s 2s/step - loss: 0.7105 - accuracy: 0.7352 - top5_acc: 0.9953 - macro_f1score: 0.6440 - val_loss: 1.1437 - val_accuracy: 0.5993 - val_top5_acc: 0.9838 - val_macro_f1score: 0.4901\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/70\n","448/448 [==============================] - ETA: 0s - loss: 0.6767 - accuracy: 0.7513 - top5_acc: 0.9964 - macro_f1score: 0.6664\n","Epoch 00024: val_loss did not improve from 0.96924\n","\n","Epoch 00024: val_accuracy did not improve from 0.65569\n","448/448 [==============================] - 714s 2s/step - loss: 0.6767 - accuracy: 0.7513 - top5_acc: 0.9964 - macro_f1score: 0.6664 - val_loss: 1.0694 - val_accuracy: 0.6336 - val_top5_acc: 0.9841 - val_macro_f1score: 0.5369\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/70\n","448/448 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.7604 - top5_acc: 0.9970 - macro_f1score: 0.6808\n","Epoch 00025: val_loss did not improve from 0.96924\n","\n","Epoch 00025: val_accuracy did not improve from 0.65569\n","448/448 [==============================] - 712s 2s/step - loss: 0.6463 - accuracy: 0.7604 - top5_acc: 0.9970 - macro_f1score: 0.6808 - val_loss: 1.1368 - val_accuracy: 0.6239 - val_top5_acc: 0.9891 - val_macro_f1score: 0.4903\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/70\n","448/448 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.7738 - top5_acc: 0.9972 - macro_f1score: 0.6970\n","Epoch 00026: val_loss did not improve from 0.96924\n","\n","Epoch 00026: val_accuracy did not improve from 0.65569\n","448/448 [==============================] - 709s 2s/step - loss: 0.6168 - accuracy: 0.7738 - top5_acc: 0.9972 - macro_f1score: 0.6970 - val_loss: 1.0266 - val_accuracy: 0.6554 - val_top5_acc: 0.9880 - val_macro_f1score: 0.5364\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/70\n","448/448 [==============================] - ETA: 0s - loss: 0.5945 - accuracy: 0.7842 - top5_acc: 0.9975 - macro_f1score: 0.7074\n","Epoch 00027: val_loss did not improve from 0.96924\n","\n","Epoch 00027: val_accuracy did not improve from 0.65569\n","448/448 [==============================] - 716s 2s/step - loss: 0.5945 - accuracy: 0.7842 - top5_acc: 0.9975 - macro_f1score: 0.7074 - val_loss: 1.0524 - val_accuracy: 0.6479 - val_top5_acc: 0.9869 - val_macro_f1score: 0.5581\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/70\n","448/448 [==============================] - ETA: 0s - loss: 0.5791 - accuracy: 0.7886 - top5_acc: 0.9976 - macro_f1score: 0.7117\n","Epoch 00028: val_loss did not improve from 0.96924\n","\n","Epoch 00028: val_accuracy did not improve from 0.65569\n","448/448 [==============================] - 714s 2s/step - loss: 0.5791 - accuracy: 0.7886 - top5_acc: 0.9976 - macro_f1score: 0.7117 - val_loss: 1.1011 - val_accuracy: 0.6532 - val_top5_acc: 0.9902 - val_macro_f1score: 0.5535\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/70\n","448/448 [==============================] - ETA: 0s - loss: 0.5594 - accuracy: 0.7960 - top5_acc: 0.9981 - macro_f1score: 0.7234\n","Epoch 00029: val_loss did not improve from 0.96924\n","\n","Epoch 00029: val_accuracy did not improve from 0.65569\n","448/448 [==============================] - 717s 2s/step - loss: 0.5594 - accuracy: 0.7960 - top5_acc: 0.9981 - macro_f1score: 0.7234 - val_loss: 1.0565 - val_accuracy: 0.6532 - val_top5_acc: 0.9897 - val_macro_f1score: 0.5862\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/70\n","448/448 [==============================] - ETA: 0s - loss: 0.5369 - accuracy: 0.8040 - top5_acc: 0.9977 - macro_f1score: 0.7323\n","Epoch 00030: val_loss did not improve from 0.96924\n","\n","Epoch 00030: val_accuracy improved from 0.65569 to 0.65681, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/030.h5\n","448/448 [==============================] - 722s 2s/step - loss: 0.5369 - accuracy: 0.8040 - top5_acc: 0.9977 - macro_f1score: 0.7323 - val_loss: 1.1043 - val_accuracy: 0.6568 - val_top5_acc: 0.9863 - val_macro_f1score: 0.5835\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/70\n","448/448 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8597 - top5_acc: 0.9991 - macro_f1score: 0.8017\n","Epoch 00031: val_loss did not improve from 0.96924\n","\n","Epoch 00031: val_accuracy improved from 0.65681 to 0.67634, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/031.h5\n","448/448 [==============================] - 717s 2s/step - loss: 0.3861 - accuracy: 0.8597 - top5_acc: 0.9991 - macro_f1score: 0.8017 - val_loss: 1.0996 - val_accuracy: 0.6763 - val_top5_acc: 0.9891 - val_macro_f1score: 0.6042\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/70\n","448/448 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.8840 - top5_acc: 0.9995 - macro_f1score: 0.8278\n","Epoch 00032: val_loss did not improve from 0.96924\n","\n","Epoch 00032: val_accuracy did not improve from 0.67634\n","448/448 [==============================] - 706s 2s/step - loss: 0.3218 - accuracy: 0.8840 - top5_acc: 0.9995 - macro_f1score: 0.8278 - val_loss: 1.1882 - val_accuracy: 0.6702 - val_top5_acc: 0.9902 - val_macro_f1score: 0.6067\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/70\n","448/448 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.8949 - top5_acc: 0.9996 - macro_f1score: 0.8375\n","Epoch 00033: val_loss did not improve from 0.96924\n","\n","Epoch 00033: val_accuracy did not improve from 0.67634\n","448/448 [==============================] - 708s 2s/step - loss: 0.2912 - accuracy: 0.8949 - top5_acc: 0.9996 - macro_f1score: 0.8375 - val_loss: 1.2181 - val_accuracy: 0.6752 - val_top5_acc: 0.9897 - val_macro_f1score: 0.6038\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/70\n","448/448 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.9023 - top5_acc: 0.9996 - macro_f1score: 0.8430\n","Epoch 00034: val_loss did not improve from 0.96924\n","\n","Epoch 00034: val_accuracy did not improve from 0.67634\n","448/448 [==============================] - 707s 2s/step - loss: 0.2707 - accuracy: 0.9023 - top5_acc: 0.9996 - macro_f1score: 0.8430 - val_loss: 1.2673 - val_accuracy: 0.6713 - val_top5_acc: 0.9891 - val_macro_f1score: 0.6048\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/70\n","448/448 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.9072 - top5_acc: 0.9998 - macro_f1score: 0.8508\n","Epoch 00035: val_loss did not improve from 0.96924\n","\n","Epoch 00035: val_accuracy did not improve from 0.67634\n","448/448 [==============================] - 720s 2s/step - loss: 0.2614 - accuracy: 0.9072 - top5_acc: 0.9998 - macro_f1score: 0.8508 - val_loss: 1.3168 - val_accuracy: 0.6641 - val_top5_acc: 0.9894 - val_macro_f1score: 0.5961\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/70\n","448/448 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.9081 - top5_acc: 0.9997 - macro_f1score: 0.8552\n","Epoch 00036: val_loss did not improve from 0.96924\n","\n","Epoch 00036: val_accuracy did not improve from 0.67634\n","448/448 [==============================] - 732s 2s/step - loss: 0.2521 - accuracy: 0.9081 - top5_acc: 0.9997 - macro_f1score: 0.8552 - val_loss: 1.3213 - val_accuracy: 0.6716 - val_top5_acc: 0.9883 - val_macro_f1score: 0.6005\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/70\n","448/448 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9181 - top5_acc: 0.9999 - macro_f1score: 0.8610\n","Epoch 00037: val_loss did not improve from 0.96924\n","\n","Epoch 00037: val_accuracy did not improve from 0.67634\n","448/448 [==============================] - 721s 2s/step - loss: 0.2285 - accuracy: 0.9181 - top5_acc: 0.9999 - macro_f1score: 0.8610 - val_loss: 1.3690 - val_accuracy: 0.6666 - val_top5_acc: 0.9886 - val_macro_f1score: 0.6111\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/70\n","448/448 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.9200 - top5_acc: 0.9997 - macro_f1score: 0.8662\n","Epoch 00038: val_loss did not improve from 0.96924\n","\n","Epoch 00038: val_accuracy did not improve from 0.67634\n","448/448 [==============================] - 713s 2s/step - loss: 0.2203 - accuracy: 0.9200 - top5_acc: 0.9997 - macro_f1score: 0.8662 - val_loss: 1.4034 - val_accuracy: 0.6738 - val_top5_acc: 0.9891 - val_macro_f1score: 0.6202\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/70\n","448/448 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9255 - top5_acc: 0.9998 - macro_f1score: 0.8723\n","Epoch 00039: val_loss did not improve from 0.96924\n","\n","Epoch 00039: val_accuracy did not improve from 0.67634\n","448/448 [==============================] - 714s 2s/step - loss: 0.2049 - accuracy: 0.9255 - top5_acc: 0.9998 - macro_f1score: 0.8723 - val_loss: 1.4934 - val_accuracy: 0.6722 - val_top5_acc: 0.9888 - val_macro_f1score: 0.6054\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/70\n","448/448 [==============================] - ETA: 0s - loss: 0.2025 - accuracy: 0.9270 - top5_acc: 1.0000 - macro_f1score: 0.8733\n","Epoch 00040: val_loss did not improve from 0.96924\n","\n","Epoch 00040: val_accuracy did not improve from 0.67634\n","448/448 [==============================] - 718s 2s/step - loss: 0.2025 - accuracy: 0.9270 - top5_acc: 1.0000 - macro_f1score: 0.8733 - val_loss: 1.4875 - val_accuracy: 0.6674 - val_top5_acc: 0.9894 - val_macro_f1score: 0.6063\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1917 - accuracy: 0.9310 - top5_acc: 0.9999 - macro_f1score: 0.8760\n","Epoch 00041: val_loss did not improve from 0.96924\n","\n","Epoch 00041: val_accuracy did not improve from 0.67634\n","448/448 [==============================] - 717s 2s/step - loss: 0.1917 - accuracy: 0.9310 - top5_acc: 0.9999 - macro_f1score: 0.8760 - val_loss: 1.5301 - val_accuracy: 0.6705 - val_top5_acc: 0.9886 - val_macro_f1score: 0.6010\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.9344 - top5_acc: 0.9999 - macro_f1score: 0.8795\n","Epoch 00042: val_loss did not improve from 0.96924\n","\n","Epoch 00042: val_accuracy did not improve from 0.67634\n","448/448 [==============================] - 724s 2s/step - loss: 0.1804 - accuracy: 0.9344 - top5_acc: 0.9999 - macro_f1score: 0.8795 - val_loss: 1.6038 - val_accuracy: 0.6724 - val_top5_acc: 0.9886 - val_macro_f1score: 0.6112\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.9376 - top5_acc: 1.0000 - macro_f1score: 0.8849\n","Epoch 00043: val_loss did not improve from 0.96924\n","\n","Epoch 00043: val_accuracy improved from 0.67634 to 0.67746, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/043.h5\n","448/448 [==============================] - 739s 2s/step - loss: 0.1768 - accuracy: 0.9376 - top5_acc: 1.0000 - macro_f1score: 0.8849 - val_loss: 1.5956 - val_accuracy: 0.6775 - val_top5_acc: 0.9866 - val_macro_f1score: 0.6088\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.9384 - top5_acc: 0.9999 - macro_f1score: 0.8831\n","Epoch 00044: val_loss did not improve from 0.96924\n","\n","Epoch 00044: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 741s 2s/step - loss: 0.1688 - accuracy: 0.9384 - top5_acc: 0.9999 - macro_f1score: 0.8831 - val_loss: 1.5575 - val_accuracy: 0.6775 - val_top5_acc: 0.9869 - val_macro_f1score: 0.6174\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9415 - top5_acc: 0.9999 - macro_f1score: 0.8893\n","Epoch 00045: val_loss did not improve from 0.96924\n","\n","Epoch 00045: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 741s 2s/step - loss: 0.1612 - accuracy: 0.9415 - top5_acc: 0.9999 - macro_f1score: 0.8893 - val_loss: 1.6280 - val_accuracy: 0.6730 - val_top5_acc: 0.9852 - val_macro_f1score: 0.6090\n","Learning rate:  0.0001\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 46/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9449 - top5_acc: 0.9999 - macro_f1score: 0.8918\n","Epoch 00046: val_loss did not improve from 0.96924\n","\n","Epoch 00046: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 734s 2s/step - loss: 0.1560 - accuracy: 0.9449 - top5_acc: 0.9999 - macro_f1score: 0.8918 - val_loss: 1.5991 - val_accuracy: 0.6682 - val_top5_acc: 0.9866 - val_macro_f1score: 0.6041\n","Learning rate:  0.0001\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 47/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.9461 - top5_acc: 1.0000 - macro_f1score: 0.8921\n","Epoch 00047: val_loss did not improve from 0.96924\n","\n","Epoch 00047: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 721s 2s/step - loss: 0.1492 - accuracy: 0.9461 - top5_acc: 1.0000 - macro_f1score: 0.8921 - val_loss: 1.6200 - val_accuracy: 0.6744 - val_top5_acc: 0.9866 - val_macro_f1score: 0.6149\n","Learning rate:  0.0001\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 48/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.9463 - top5_acc: 0.9999 - macro_f1score: 0.8876\n","Epoch 00048: val_loss did not improve from 0.96924\n","\n","Epoch 00048: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 710s 2s/step - loss: 0.1466 - accuracy: 0.9463 - top5_acc: 0.9999 - macro_f1score: 0.8876 - val_loss: 1.6722 - val_accuracy: 0.6694 - val_top5_acc: 0.9874 - val_macro_f1score: 0.6024\n","Learning rate:  0.0001\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 49/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.9503 - top5_acc: 1.0000 - macro_f1score: 0.8957\n","Epoch 00049: val_loss did not improve from 0.96924\n","\n","Epoch 00049: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 692s 2s/step - loss: 0.1394 - accuracy: 0.9503 - top5_acc: 1.0000 - macro_f1score: 0.8957 - val_loss: 1.7060 - val_accuracy: 0.6708 - val_top5_acc: 0.9872 - val_macro_f1score: 0.5994\n","Learning rate:  0.0001\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 50/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.9511 - top5_acc: 1.0000 - macro_f1score: 0.8943\n","Epoch 00050: val_loss did not improve from 0.96924\n","\n","Epoch 00050: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 696s 2s/step - loss: 0.1369 - accuracy: 0.9511 - top5_acc: 1.0000 - macro_f1score: 0.8943 - val_loss: 1.7503 - val_accuracy: 0.6749 - val_top5_acc: 0.9886 - val_macro_f1score: 0.6150\n","Learning rate:  0.0001\n","\n","Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 51/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9505 - top5_acc: 1.0000 - macro_f1score: 0.8973\n","Epoch 00051: val_loss did not improve from 0.96924\n","\n","Epoch 00051: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 695s 2s/step - loss: 0.1362 - accuracy: 0.9505 - top5_acc: 1.0000 - macro_f1score: 0.8973 - val_loss: 1.7175 - val_accuracy: 0.6735 - val_top5_acc: 0.9866 - val_macro_f1score: 0.6106\n","Learning rate:  0.0001\n","\n","Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 52/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9538 - top5_acc: 1.0000 - macro_f1score: 0.9002\n","Epoch 00052: val_loss did not improve from 0.96924\n","\n","Epoch 00052: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 689s 2s/step - loss: 0.1311 - accuracy: 0.9538 - top5_acc: 1.0000 - macro_f1score: 0.9002 - val_loss: 1.7438 - val_accuracy: 0.6688 - val_top5_acc: 0.9888 - val_macro_f1score: 0.6077\n","Learning rate:  0.0001\n","\n","Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 53/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.9548 - top5_acc: 1.0000 - macro_f1score: 0.8989\n","Epoch 00053: val_loss did not improve from 0.96924\n","\n","Epoch 00053: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 694s 2s/step - loss: 0.1258 - accuracy: 0.9548 - top5_acc: 1.0000 - macro_f1score: 0.8989 - val_loss: 1.7179 - val_accuracy: 0.6713 - val_top5_acc: 0.9900 - val_macro_f1score: 0.6156\n","Learning rate:  0.0001\n","\n","Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 54/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9553 - top5_acc: 1.0000 - macro_f1score: 0.8960\n","Epoch 00054: val_loss did not improve from 0.96924\n","\n","Epoch 00054: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 697s 2s/step - loss: 0.1236 - accuracy: 0.9553 - top5_acc: 1.0000 - macro_f1score: 0.8960 - val_loss: 1.8095 - val_accuracy: 0.6716 - val_top5_acc: 0.9863 - val_macro_f1score: 0.5968\n","Learning rate:  0.0001\n","\n","Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 55/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.9582 - top5_acc: 1.0000 - macro_f1score: 0.9028\n","Epoch 00055: val_loss did not improve from 0.96924\n","\n","Epoch 00055: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 701s 2s/step - loss: 0.1210 - accuracy: 0.9582 - top5_acc: 1.0000 - macro_f1score: 0.9028 - val_loss: 1.7633 - val_accuracy: 0.6727 - val_top5_acc: 0.9883 - val_macro_f1score: 0.6057\n","Learning rate:  0.0001\n","\n","Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 56/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9575 - top5_acc: 1.0000 - macro_f1score: 0.9042\n","Epoch 00056: val_loss did not improve from 0.96924\n","\n","Epoch 00056: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 704s 2s/step - loss: 0.1193 - accuracy: 0.9575 - top5_acc: 1.0000 - macro_f1score: 0.9042 - val_loss: 1.7304 - val_accuracy: 0.6772 - val_top5_acc: 0.9838 - val_macro_f1score: 0.6202\n","Learning rate:  0.0001\n","\n","Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 57/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9584 - top5_acc: 1.0000 - macro_f1score: 0.9048\n","Epoch 00057: val_loss did not improve from 0.96924\n","\n","Epoch 00057: val_accuracy did not improve from 0.67746\n","448/448 [==============================] - 708s 2s/step - loss: 0.1152 - accuracy: 0.9584 - top5_acc: 1.0000 - macro_f1score: 0.9048 - val_loss: 1.7436 - val_accuracy: 0.6694 - val_top5_acc: 0.9877 - val_macro_f1score: 0.6083\n","Learning rate:  0.0001\n","\n","Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 58/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9612 - top5_acc: 1.0000 - macro_f1score: 0.9064\n","Epoch 00058: val_loss did not improve from 0.96924\n","\n","Epoch 00058: val_accuracy improved from 0.67746 to 0.68108, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/058.h5\n","448/448 [==============================] - 707s 2s/step - loss: 0.1147 - accuracy: 0.9612 - top5_acc: 1.0000 - macro_f1score: 0.9064 - val_loss: 1.7630 - val_accuracy: 0.6811 - val_top5_acc: 0.9900 - val_macro_f1score: 0.6180\n","Learning rate:  0.0001\n","\n","Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 59/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9614 - top5_acc: 1.0000 - macro_f1score: 0.9073\n","Epoch 00059: val_loss did not improve from 0.96924\n","\n","Epoch 00059: val_accuracy did not improve from 0.68108\n","448/448 [==============================] - 707s 2s/step - loss: 0.1125 - accuracy: 0.9614 - top5_acc: 1.0000 - macro_f1score: 0.9073 - val_loss: 1.7213 - val_accuracy: 0.6761 - val_top5_acc: 0.9835 - val_macro_f1score: 0.6212\n","Learning rate:  0.0001\n","\n","Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 60/70\n","448/448 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9587 - top5_acc: 1.0000 - macro_f1score: 0.9055\n","Epoch 00060: val_loss did not improve from 0.96924\n","\n","Epoch 00060: val_accuracy did not improve from 0.68108\n","448/448 [==============================] - 707s 2s/step - loss: 0.1145 - accuracy: 0.9587 - top5_acc: 1.0000 - macro_f1score: 0.9055 - val_loss: 1.7979 - val_accuracy: 0.6794 - val_top5_acc: 0.9860 - val_macro_f1score: 0.6105\n","Learning rate:  1e-05\n","\n","Epoch 00061: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 61/70\n","448/448 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9689 - top5_acc: 1.0000 - macro_f1score: 0.9152\n","Epoch 00061: val_loss did not improve from 0.96924\n","\n","Epoch 00061: val_accuracy improved from 0.68108 to 0.68304, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/061.h5\n","448/448 [==============================] - 726s 2s/step - loss: 0.0883 - accuracy: 0.9689 - top5_acc: 1.0000 - macro_f1score: 0.9152 - val_loss: 1.7878 - val_accuracy: 0.6830 - val_top5_acc: 0.9897 - val_macro_f1score: 0.6263\n","Learning rate:  1e-05\n","\n","Epoch 00062: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 62/70\n","448/448 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9740 - top5_acc: 1.0000 - macro_f1score: 0.9219\n","Epoch 00062: val_loss did not improve from 0.96924\n","\n","Epoch 00062: val_accuracy improved from 0.68304 to 0.68415, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/062.h5\n","448/448 [==============================] - 715s 2s/step - loss: 0.0770 - accuracy: 0.9740 - top5_acc: 1.0000 - macro_f1score: 0.9219 - val_loss: 1.8380 - val_accuracy: 0.6842 - val_top5_acc: 0.9900 - val_macro_f1score: 0.6176\n","Learning rate:  1e-05\n","\n","Epoch 00063: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 63/70\n","448/448 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9758 - top5_acc: 1.0000 - macro_f1score: 0.9210\n","Epoch 00063: val_loss did not improve from 0.96924\n","\n","Epoch 00063: val_accuracy did not improve from 0.68415\n","448/448 [==============================] - 705s 2s/step - loss: 0.0718 - accuracy: 0.9758 - top5_acc: 1.0000 - macro_f1score: 0.9210 - val_loss: 1.8544 - val_accuracy: 0.6822 - val_top5_acc: 0.9883 - val_macro_f1score: 0.6172\n","Learning rate:  1e-05\n","\n","Epoch 00064: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 64/70\n","448/448 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9745 - top5_acc: 1.0000 - macro_f1score: 0.9201\n","Epoch 00064: val_loss did not improve from 0.96924\n","\n","Epoch 00064: val_accuracy did not improve from 0.68415\n","448/448 [==============================] - 706s 2s/step - loss: 0.0723 - accuracy: 0.9745 - top5_acc: 1.0000 - macro_f1score: 0.9201 - val_loss: 1.8588 - val_accuracy: 0.6842 - val_top5_acc: 0.9886 - val_macro_f1score: 0.6231\n","Learning rate:  1e-05\n","\n","Epoch 00065: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 65/70\n","448/448 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9739 - top5_acc: 1.0000 - macro_f1score: 0.9217\n","Epoch 00065: val_loss did not improve from 0.96924\n","\n","Epoch 00065: val_accuracy improved from 0.68415 to 0.68499, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/065.h5\n","448/448 [==============================] - 724s 2s/step - loss: 0.0737 - accuracy: 0.9739 - top5_acc: 1.0000 - macro_f1score: 0.9217 - val_loss: 1.8315 - val_accuracy: 0.6850 - val_top5_acc: 0.9886 - val_macro_f1score: 0.6151\n","Learning rate:  1e-05\n","\n","Epoch 00066: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 66/70\n","448/448 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9744 - top5_acc: 1.0000 - macro_f1score: 0.9200\n","Epoch 00066: val_loss did not improve from 0.96924\n","\n","Epoch 00066: val_accuracy did not improve from 0.68499\n","448/448 [==============================] - 720s 2s/step - loss: 0.0725 - accuracy: 0.9744 - top5_acc: 1.0000 - macro_f1score: 0.9200 - val_loss: 1.8167 - val_accuracy: 0.6808 - val_top5_acc: 0.9894 - val_macro_f1score: 0.6234\n","Learning rate:  1e-05\n","\n","Epoch 00067: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 67/70\n","448/448 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9723 - top5_acc: 1.0000 - macro_f1score: 0.9177\n","Epoch 00067: val_loss did not improve from 0.96924\n","\n","Epoch 00067: val_accuracy improved from 0.68499 to 0.68610, saving model to /content/drive/My Drive/Colab Notebooks/Paper/FER/No_GAN/model_output/1/Inception_ResNet_v1/067.h5\n","448/448 [==============================] - 716s 2s/step - loss: 0.0782 - accuracy: 0.9723 - top5_acc: 1.0000 - macro_f1score: 0.9177 - val_loss: 1.7825 - val_accuracy: 0.6861 - val_top5_acc: 0.9891 - val_macro_f1score: 0.6178\n","Learning rate:  1e-05\n","\n","Epoch 00068: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 68/70\n","448/448 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9752 - top5_acc: 1.0000 - macro_f1score: 0.9207\n","Epoch 00068: val_loss did not improve from 0.96924\n","\n","Epoch 00068: val_accuracy did not improve from 0.68610\n","448/448 [==============================] - 722s 2s/step - loss: 0.0747 - accuracy: 0.9752 - top5_acc: 1.0000 - macro_f1score: 0.9207 - val_loss: 1.7391 - val_accuracy: 0.6847 - val_top5_acc: 0.9886 - val_macro_f1score: 0.6191\n","Learning rate:  1e-05\n","\n","Epoch 00069: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 69/70\n","448/448 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9741 - top5_acc: 1.0000 - macro_f1score: 0.9130\n","Epoch 00069: val_loss did not improve from 0.96924\n","\n","Epoch 00069: val_accuracy did not improve from 0.68610\n","448/448 [==============================] - 717s 2s/step - loss: 0.0754 - accuracy: 0.9741 - top5_acc: 1.0000 - macro_f1score: 0.9130 - val_loss: 1.7312 - val_accuracy: 0.6819 - val_top5_acc: 0.9874 - val_macro_f1score: 0.6222\n","Learning rate:  1e-05\n","\n","Epoch 00070: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 70/70\n","448/448 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9726 - top5_acc: 1.0000 - macro_f1score: 0.9192\n","Epoch 00070: val_loss did not improve from 0.96924\n","\n","Epoch 00070: val_accuracy did not improve from 0.68610\n","448/448 [==============================] - 713s 2s/step - loss: 0.0810 - accuracy: 0.9726 - top5_acc: 1.0000 - macro_f1score: 0.9192 - val_loss: 1.6862 - val_accuracy: 0.6847 - val_top5_acc: 0.9880 - val_macro_f1score: 0.6123\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S8EgwffcuTfI"},"source":["### 3) Inception-ResNet-V1 Evaluate\n"]},{"cell_type":"code","metadata":{"id":"D7tz2zjeuTfL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605629672776,"user_tz":-540,"elapsed":57742305,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"30f50755-59ce-445a-e52f-70a6ca1334bf"},"source":["# 1. epoch=maximum\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["56/56 [==============================] - 842s 15s/step - loss: 1.7824 - accuracy: 0.6671 - top5_acc: 0.9838 - macro_f1score: 0.6108\n","[Test Loss: 1.7824 /  Test Top-1 Accuracy: 0.6671 / Test Top-5 Accuracy: 0.9838 / Test Macro f1: 0.6108]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PBq7ajsyuTfN"},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","top5_acc=history.history['top5_acc']\n","val_top5_acc=history.history['val_top5_acc']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,top5_acc,val_top5_acc,f1,val_f1]).T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFQNe0dfuTfP"},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, top5_acc, val_top5_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zsHYi8xGuTfT"},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'Inception_ResNet_v1.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXjdmTfLuTfW"},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]\n","top5_acc=data[:,5]\n","val_top5_acc=data[:,6]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEgWb_-DuTfY","colab":{"base_uri":"https://localhost:8080/","height":808},"executionInfo":{"status":"ok","timestamp":1605629674253,"user_tz":-540,"elapsed":57743718,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"0fac8e18-610a-4581-cd7f-0a894263cf7e"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training 1-Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation 1-Acc')\n","plt.title('Training and Validation Top-1 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[1:],top5_acc[1:],'b',label='Training 5-Acc')\n","plt.plot(epochs[1:],val_top5_acc[1:],'r',label='Validation 5-Acc')\n","plt.title('Training and Validation Top-5 Accuracy')\n","plt.legend()\n","plt.figure()\n","\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"0RgXbQzqwGoP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBSIISJWFFs4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a0z6BwcAulnw","executionInfo":{"status":"ok","timestamp":1606109925429,"user_tz":-540,"elapsed":979,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / Inception_Resnet_V1"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"VybLE8G1i99c","executionInfo":{"status":"ok","timestamp":1606109926363,"user_tz":-540,"elapsed":1890,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU510IB-SUak","executionInfo":{"status":"ok","timestamp":1606109926365,"user_tz":-540,"elapsed":1889,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["# top-5 accuracy 출력\n","import functools\n","top5_acc = functools.partial(ks.metrics.top_k_categorical_accuracy, k=5)\n","top5_acc.__name__ = 'top5_acc'"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pFcw51AuDG4","executionInfo":{"status":"ok","timestamp":1606109943904,"user_tz":-540,"elapsed":19426,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}}},"source":["model=load_model(os.path.join(dir,'model_output',number,'Inception_ResNet_v1','031.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"top5_acc\":top5_acc, \"AdamW\":AdamW})"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWlrnY9EuDG-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606111119548,"user_tz":-540,"elapsed":1195060,"user":{"displayName":"이동규","photoUrl":"","userId":"07323071725004325774"}},"outputId":"bf962e3b-f06d-463d-8348-fcfee734328a"},"source":["# 2. epoch=?\n","loss , acc, top5_acc, mf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Top-1 Accuracy: %.4f / Test Top-5 Accuracy: %.4f / Test Macro f1: %.4f]\\n' % (loss,acc,top5_acc,mf1))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["56/56 [==============================] - 1151s 21s/step - loss: 1.1539 - accuracy: 0.6705 - top5_acc: 0.9900 - macro_f1score: 0.5871\n","[Test Loss: 1.1539 /  Test Top-1 Accuracy: 0.6705 / Test Top-5 Accuracy: 0.9900 / Test Macro f1: 0.5871]\n","\n"],"name":"stdout"}]}]}