{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwVmRuFcUBkT"
   },
   "source": [
    "# [ResNext18]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0MMz6DhUBkW"
   },
   "source": [
    "*KU LeeDongGyu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ywk25Fr79dWe"
   },
   "source": [
    "## Contents\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSON5xiR9dWf"
   },
   "source": [
    "1. Data Preprocessing\n",
    "```\n",
    "1) Data Import\n",
    "2) Data Augmentation\n",
    "```\n",
    "2. Support Functions & Almost Original ResNext\n",
    "```\n",
    "1) Support Functions\n",
    "2) Almost orginal ResNext\n",
    "```\n",
    "3. ResNext18\n",
    "```\n",
    "1) ResNext18\n",
    "2) ResNext18 Evaluate\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U01q4o40UBkY"
   },
   "source": [
    "### Install Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjdygsS_UBke"
   },
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18269,
     "status": "ok",
     "timestamp": 1599313727174,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "o1tpIlBhXG2i",
    "outputId": "9524c6df-6f9c-491f-bbc9-d6212bbd5f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18696,
     "status": "ok",
     "timestamp": 1599313727612,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "IJdbC2nRXR6h",
    "outputId": "0f6e5a65-af32-4ef8-e77f-d5951e4f7d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/Paper\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/Colab Notebooks/Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I98omoQ8FF90"
   },
   "outputs": [],
   "source": [
    "from f1score import macro_f1score,weighted_f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKLMWqbuUBkf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l1,l2,l1_l2\n",
    "from tensorflow.keras.models import Model , load_model , Sequential\n",
    "from tensorflow.keras.utils import plot_model , to_categorical, get_file\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22330,
     "status": "ok",
     "timestamp": 1599313731282,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "cbiFovMgXTax",
    "outputId": "9290aaba-1535-4930-9c56-b4cf2aca3dde"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/Paper'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22318,
     "status": "ok",
     "timestamp": 1599313731283,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "AcT0A_iwEzaZ",
    "outputId": "75a030ef-5e3d-4498-9718-5d5e4a95dab6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28061,
     "status": "ok",
     "timestamp": 1599313737038,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "Gr5hMHvmABmG",
    "outputId": "cb625c50-bef2-4202-f19e-035f2f1f7d3b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28059,
     "status": "ok",
     "timestamp": 1599313737044,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "Kf057Rw2yigs",
    "outputId": "34ed29ef-fa9a-4286-d445-24b434599dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17747950093532087056\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9486320332485630417\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1229932852518163373\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15473775744\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9987426413755783624\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTXnS6_magkg"
   },
   "source": [
    "## 1. Data Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWigHOuzCRRj"
   },
   "source": [
    "### 1) Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BeJ7UtuOEgWY"
   },
   "outputs": [],
   "source": [
    "# 바꿔서 살펴 볼 것들\n",
    "# CALTECH, CIFAR100, FER, MIT\n",
    "data_name = 'CALTECH'\n",
    "gan_type = 'No_GAN'\n",
    "number = '1'\n",
    "size = 224 # sizes after cropping\n",
    "super_size = 256 # sizes before cropping \n",
    "input_sizes = (size,size,3)\n",
    "batch_sizes = 64\n",
    "weight_decay = 3e-3\n",
    "epochs = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPnWxfGzLOF6"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n",
    "# setting the seed number for random number generation for reproducibility.\n",
    "\n",
    "from numpy.random import seed\n",
    "import random\n",
    "\n",
    "\n",
    "if number=='1':\n",
    "    seed_num = 200225\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='2':\n",
    "    seed_num = 727\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='3':\n",
    "    seed_num = 115\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='4':\n",
    "    seed_num = 501\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='5':\n",
    "    seed_num = 517\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWc_XOgNpPlL"
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "\n",
    "if data_name=='FER' :\n",
    "    x_train =  np.zeros(28698)\n",
    "    x_valid = np.zeros(3589)\n",
    "    x_test = np.zeros(3588)\n",
    "    classes = 7 \n",
    "    tr_center = [0.50793296, 0.50793296, 0.50793296]\n",
    "elif data_name=='MIT':\n",
    "    x_train = np.zeros(12466)\n",
    "    x_valid = np.zeros(1564)\n",
    "    x_test = np.zeros(1590)\n",
    "    classes = 67 \n",
    "    tr_center = [0.47916578, 0.42029615, 0.36046057]\n",
    "elif data_name=='CALTECH':\n",
    "    x_train = np.zeros(24510)\n",
    "    x_valid = np.zeros(2980)\n",
    "    x_test = np.zeros(3118)\n",
    "    classes = 257\n",
    "    tr_center = [0.51397761, 0.49525248, 0.46555727]\n",
    "elif data_name=='CIFAR100':\n",
    "    x_train = np.zeros(39941)\n",
    "    x_valid = np.zeros(10059)\n",
    "    x_test = np.zeros(10000)\n",
    "    classes = 100\n",
    "    tr_center = [0.53393271, 0.51324147, 0.46450563]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQlStjHWt-jM"
   },
   "outputs": [],
   "source": [
    "dir = os.path.join(os.getcwd(),data_name,gan_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuLyOxlopPlV"
   },
   "source": [
    "### 2) Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sH3Y2hZBpPlV"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n",
    "\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EW0KZ6x9EBtf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
    "import glob\n",
    "\n",
    "# 데이터 전체에 대해 centering 진행함.\n",
    "\n",
    "def read_cal_image(img_path): \n",
    "    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n",
    "    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n",
    "\n",
    "    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n",
    "    x = np.mean(x, axis=(0,1))\n",
    "    \n",
    "    return np.hstack([x,y])\n",
    "\n",
    "def calculate_centered_mean(dataset_path,x_train=x_train):\n",
    "    num = len(x_train)\n",
    "    space = np.empty((num,4))\n",
    "    i=0\n",
    "\n",
    "    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n",
    "        space[i] = read_cal_image(p)\n",
    "        i += 1\n",
    "\n",
    "    ratio = space[:,3] / np.sum(space[:,3])\n",
    "\n",
    "    return np.average(space[:,0:3],axis=0,weights=ratio)\n",
    "\n",
    "\n",
    "# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n",
    "\n",
    "# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2JcGYwcpPla"
   },
   "outputs": [],
   "source": [
    "datagen_tr = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=[0.9,1.0],\n",
    "    fill_mode = 'nearest')\n",
    "datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n",
    "datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n",
    "\n",
    "# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n",
    "\n",
    "# 중심화 설정\n",
    "datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n",
    "datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n",
    "datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 89309,
     "status": "ok",
     "timestamp": 1599313798356,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "4fStY438pPlb",
    "outputId": "1a10498f-7d7d-4baf-8c60-9a73d9d66141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24509 images belonging to 257 classes.\n",
      "Found 2980 images belonging to 257 classes.\n",
      "Found 3118 images belonging to 257 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 39941\n",
    "train_generator= crop_generator(train_batches, size)\n",
    "valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 10059\n",
    "test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gn_DwVVV1qmT"
   },
   "source": [
    "## 2. Support Functions & Almost Original ResNext\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GrcgSgWh1qmT"
   },
   "source": [
    "### 1) Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA3sqFv_ZyBS"
   },
   "outputs": [],
   "source": [
    "# def lr_schedule(epoch):\n",
    "#     init_lr = 1e-4\n",
    "#     k = 0.04\n",
    "#     lr = init_lr * np.exp(-k*epoch)\n",
    "#     print('Learning rate: ', lr)\n",
    "#     return lr\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch < 60:\n",
    "        lr = lr\n",
    "    else :\n",
    "        lr = lr * 0.1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uY2LEhqW1qmX"
   },
   "outputs": [],
   "source": [
    "def resnext_layer(inputs, weight_decay=weight_decay, num_filters=16, kernel_size=(3,3), strides=(1,1),activation=None):\n",
    "\n",
    "    conv = Conv2D(num_filters,kernel_size=kernel_size,strides=strides, padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))\n",
    "    x = inputs\n",
    "    x = conv(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation is not None:\n",
    "        x = Activation(activation)(x) # conv-bn-activation\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IqNGAIi1qmZ"
   },
   "outputs": [],
   "source": [
    "def block_v1(input_shape, identi, num_filters, half=True, C = 32):\n",
    "\n",
    "    layer1=[0]*C\n",
    "    layer2=[0]*C\n",
    "\n",
    "    if half:\n",
    "        for i in range(C) :\n",
    "            layer1[i] = resnext_layer(input_shape, num_filters=num_filters // C, strides=(2, 2), activation='relu')\n",
    "            layer2[i] = resnext_layer(layer1[i], num_filters=num_filters // 2 , strides=(1, 1), activation=None)\n",
    "    else:\n",
    "        for i in range(C) :\n",
    "            layer1[i] = resnext_layer(input_shape, num_filters=num_filters //C, strides=(1, 1), activation='relu')\n",
    "            layer2[i] = resnext_layer(layer1[i], num_filters=num_filters // 2, strides=(1, 1), activation=None)\n",
    "        \n",
    "\n",
    "    res_2_1 = add(layer2)\n",
    "    res_2_2 = add([identi, res_2_1])  # block 2\n",
    "    output = Activation(\"relu\")(res_2_2)\n",
    "    return output\n",
    "\n",
    "\n",
    "def block_v2(input_shape, identi, num_filters, half=True , C = 32):\n",
    "    \n",
    "    layer1=[0]*C\n",
    "    layer2=[0]*C\n",
    "    layer3=[0]*C\n",
    "\n",
    "    if half:\n",
    "        for i in range(C):\n",
    "            layer1[i] = resnext_layer(input_shape, num_filters=num_filters // C, kernel_size=(1, 1), strides=(2, 2), activation='relu')\n",
    "            layer2[i] = resnext_layer(layer1[i], num_filters=num_filters // C, kernel_size=(3, 3), strides=(1, 1), activation='relu')\n",
    "            layer3[i] = resnext_layer(layer2[i], num_filters= num_filters * 2, kernel_size=(1, 1), strides=(1, 1), activation=None)\n",
    "    else:\n",
    "        for i in range(C):\n",
    "            layer1[i] = resnext_layer(input_shape, num_filters= num_filters // C, kernel_size=(1, 1), strides=(1, 1), activation='relu')\n",
    "            layer2[i] = resnext_layer(layer1[i], num_filters= num_filters // C, kernel_size=(3, 3), strides=(1, 1), activation='relu')\n",
    "            layer3[i] = resnext_layer(layer2[i], num_filters= num_filters * 2, kernel_size=(1, 1), strides=(1, 1), activation=None)\n",
    "\n",
    "    res_3_1 = add(layer3)\n",
    "    res_3_2 = add([identi, res_3_1])  # block 2\n",
    "    output = Activation(\"relu\")(res_3_2)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Lho4zoe1qmc"
   },
   "source": [
    "### 2) Almost Orginial ResNext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_KafJBn1qmd"
   },
   "outputs": [],
   "source": [
    "def ResNext(input_shape=(224, 224, 3), weight_decay=weight_decay, num_filters=128, C = 32, classes=1000, num_blocks=[0,0,0,0] ,version=None, name=None ):\n",
    "    # num_blocks 는 list로 받는 인자. conv3_x ~ conv5_x의 block의 수를 앞에서부터 차례로 넣어주면 된다.\n",
    "    # num_filters 는 초기의 filters를 의미한다.\n",
    "    \n",
    "    if len(num_blocks) != 4 :\n",
    "        raise NameError(\"Please input the number of blocks from conv2_x to conv5_x in the 'num_blocks' variable.\")\n",
    "\n",
    "    if version == \"v1\" : \n",
    "        block = block_v1\n",
    "    elif version == \"v2\": \n",
    "        block = block_v2\n",
    "    else :\n",
    "        raise NameError(\"Please input the string 'v1' or 'v2' in the 'version' variable. \")\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    layer1 = resnext_layer(inputs, num_filters=num_filters, strides=(2, 2), kernel_size=(7, 7), activation='relu')\n",
    "    cum_block = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool1/3x3_s2')(layer1)\n",
    "\n",
    "\n",
    "    for stack in range(4):\n",
    "        if stack == 0 :\n",
    "\n",
    "            if version == 'v2':\n",
    "                x = Conv2D(num_filters * 2, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(cum_block)\n",
    "                x = BatchNormalization()(x) # 모든 conv.뒤에는 bn을 적용.\n",
    "                cum_block = block(input_shape=cum_block, num_filters=num_filters, identi=x, half=False, C=C)\n",
    "\n",
    "            # resnext에서는 아래 if문 수정\n",
    "            if version != 'v2':\n",
    "                  num_filters = num_filters * 2\n",
    "                  new_num_blocks = num_blocks[stack]\n",
    "            else :\n",
    "                  new_num_blocks = num_blocks[stack]-1\n",
    "\n",
    "            for res_block in range(new_num_blocks):\n",
    "                cum_block = block(input_shape=cum_block, num_filters=num_filters , identi=cum_block, half=False, C=C)\n",
    "\n",
    "            # resnext에서는 아래 if문 추가\n",
    "            if version != 'v2':\n",
    "                    num_filters = num_filters // 2\n",
    "    \n",
    "        else:\n",
    "\n",
    "            # 이 아래는 conv3_x ~ conv5_x 까지.\n",
    "            num_filters *= 2\n",
    " \n",
    "            if version == 'v2':\n",
    "                x = Conv2D(num_filters * 2, kernel_size=(1, 1), strides=(2, 2), padding='valid', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(cum_block)  # block_v2라면, input에 해당하는 x를 덧셈이 가능하게 맞춰준다.\n",
    "                x = BatchNormalization()(x) # 모든 conv.뒤에는 bn을 적용.\n",
    "            else:\n",
    "                x = Conv2D(num_filters, (1, 1), strides=(2, 2), padding='valid', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(cum_block)  # identi_input 에 해당 // rxc가 각각 반토막남.\n",
    "                x = BatchNormalization()(x) # 모든 conv.뒤에는 bn을 적용.\n",
    "                #즉, 위 x는 결국 이어질 conv 층의 input임.\n",
    "\n",
    "            # resnext에서는 아래 if문 추가\n",
    "            if version != 'v2':\n",
    "                    num_filters = num_filters * 2\n",
    "\n",
    "            for res_block in range(num_blocks[stack]):\n",
    "                if res_block == 0:\n",
    "                    cum_block = block(input_shape=cum_block , num_filters = num_filters , identi=x, half=True, C=C) # block 갱신\n",
    "                else:\n",
    "                    cum_block = block(input_shape=cum_block , num_filters = num_filters , identi=cum_block , half=False, C=C) # block 갱신\n",
    "\n",
    "            # resnext에서는 아래 if문 추가\n",
    "            if version != 'v2':\n",
    "                    num_filters = num_filters // 2\n",
    "\n",
    "\n",
    "    # 마지막 1층\n",
    "    y = GlobalAveragePooling2D()(cum_block)\n",
    "    outputs = Dense(classes, activation='softmax')(y)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name = name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Y24Va7X1qmf"
   },
   "source": [
    "## 3. ResNext18\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wiva9k1w1qmg"
   },
   "source": [
    "### 1) ResNext18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WeiAeNmA1qmg"
   },
   "outputs": [],
   "source": [
    "# ResNext18\n",
    "model = ResNext(input_shape=input_sizes, classes=classes, num_filters=64, C=32, num_blocks=[2,2,2,2],version='v1',name='ResNext18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 104132,
     "status": "ok",
     "timestamp": 1599313813223,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "5w9jMQqhN1pv",
    "outputId": "830a27a6-04a6-46c8-fea1-90ac74e30f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNext18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool1/3x3_s2 (MaxPooling2D)     (None, 56, 56, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 56, 56, 4)    2308        pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 56, 56, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 4)    16          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 4)    16          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 56, 56, 4)    16          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 56, 4)    16          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 56, 56, 4)    16          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 56, 56, 4)    16          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 56, 56, 4)    16          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 56, 56, 4)    16          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 56, 56, 4)    16          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 56, 56, 4)    16          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 56, 56, 4)    16          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 56, 56, 4)    16          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 56, 56, 4)    16          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 56, 56, 4)    16          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 56, 56, 4)    16          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 56, 56, 4)    16          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 56, 56, 4)    16          conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 56, 56, 4)    16          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 56, 56, 4)    16          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 56, 56, 4)    16          conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 56, 56, 4)    16          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 56, 56, 4)    16          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 56, 56, 4)    16          conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 56, 56, 4)    16          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 56, 56, 4)    16          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 56, 56, 4)    16          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 56, 56, 4)    16          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 56, 56, 4)    16          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 56, 56, 4)    16          conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 56, 56, 4)    16          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 56, 56, 4)    16          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 4)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 4)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 4)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 4)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 4)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 4)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 4)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 4)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 4)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 4)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 56, 56, 4)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 56, 56, 4)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 56, 56, 4)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 56, 56, 4)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 56, 56, 4)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 56, 56, 4)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 56, 56, 4)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 56, 56, 4)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 56, 56, 4)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 56, 56, 4)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 56, 56, 4)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 56, 56, 4)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 56, 56, 4)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 56, 56, 4)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 56, 56, 4)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 56, 56, 4)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 56, 56, 4)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 56, 56, 4)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 56, 56, 4)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 56, 56, 4)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 56, 56, 4)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 56, 56, 4)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 64)   2368        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 64)   2368        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 64)   2368        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 56, 56, 64)   2368        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 56, 56, 64)   2368        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 56, 56, 64)   2368        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 56, 56, 64)   2368        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 56, 56, 64)   2368        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 56, 56, 64)   2368        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 56, 56, 64)   2368        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 56, 56, 64)   2368        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 56, 56, 64)   2368        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 56, 56, 64)   2368        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 56, 56, 64)   2368        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 56, 56, 64)   2368        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 56, 56, 64)   2368        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 56, 56, 64)   2368        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 56, 56, 64)   2368        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 56, 56, 64)   2368        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 56, 56, 64)   2368        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 56, 56, 64)   2368        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 56, 56, 64)   2368        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 56, 56, 64)   2368        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 56, 56, 64)   2368        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 56, 56, 64)   2368        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 56, 56, 64)   2368        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 56, 56, 64)   2368        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 56, 56, 64)   2368        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 56, 56, 64)   2368        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 56, 56, 64)   2368        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 56, 56, 64)   2368        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 56, 56, 64)   2368        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 56, 56, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 56, 56, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 56, 56, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 56, 56, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 56, 56, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 56, 56, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 56, 56, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 56, 56, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 56, 56, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 56, 56, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 56, 56, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 56, 56, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 56, 56, 64)   256         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 56, 56, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 56, 56, 64)   256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 56, 56, 64)   256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 56, 56, 64)   256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 56, 56, 64)   256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 56, 56, 64)   256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 56, 56, 64)   256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 56, 56, 64)   256         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 56, 56, 64)   256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 56, 56, 64)   256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 56, 56, 64)   256         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 56, 56, 64)   256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 56, 56, 64)   256         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 56, 56, 64)   256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 56, 56, 64)   256         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 56, 56, 64)   256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 56, 56, 64)   256         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "                                                                 batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "                                                                 batch_normalization_48[0][0]     \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "                                                                 batch_normalization_52[0][0]     \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "                                                                 batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_58[0][0]     \n",
      "                                                                 batch_normalization_60[0][0]     \n",
      "                                                                 batch_normalization_62[0][0]     \n",
      "                                                                 batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 64)   0           pool1/3x3_s2[0][0]               \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 56, 56, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 56, 56, 4)    2308        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 56, 56, 4)    16          conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 56, 56, 4)    16          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 56, 56, 4)    16          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 56, 56, 4)    16          conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 56, 56, 4)    16          conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 56, 56, 4)    16          conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 56, 56, 4)    16          conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 56, 56, 4)    16          conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 56, 56, 4)    16          conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 56, 56, 4)    16          conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 56, 56, 4)    16          conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 56, 56, 4)    16          conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 56, 56, 4)    16          conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 56, 56, 4)    16          conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 56, 56, 4)    16          conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 56, 56, 4)    16          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 56, 56, 4)    16          conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 56, 56, 4)    16          conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 56, 56, 4)    16          conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 56, 56, 4)    16          conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 56, 56, 4)    16          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 56, 56, 4)    16          conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 56, 56, 4)    16          conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 56, 56, 4)    16          conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 56, 56, 4)    16          conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 56, 56, 4)    16          conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 56, 56, 4)    16          conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 56, 56, 4)    16          conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 56, 56, 4)    16          conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 56, 56, 4)    16          conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 56, 56, 4)    16          conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 56, 56, 4)    16          conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 56, 56, 4)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 56, 56, 4)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 56, 56, 4)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 56, 56, 4)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 56, 56, 4)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 56, 56, 4)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 56, 56, 4)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 56, 56, 4)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 56, 56, 4)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 56, 56, 4)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 56, 56, 4)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 56, 56, 4)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 56, 56, 4)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 56, 56, 4)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 56, 56, 4)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 56, 56, 4)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 56, 56, 4)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 56, 56, 4)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 56, 56, 4)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 56, 56, 4)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 56, 56, 4)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 56, 56, 4)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 56, 56, 4)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 56, 56, 4)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 56, 56, 4)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 56, 56, 4)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 56, 56, 4)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 56, 56, 4)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 56, 56, 4)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 56, 56, 4)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 56, 56, 4)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 56, 56, 4)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 56, 56, 64)   2368        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 56, 56, 64)   2368        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 56, 56, 64)   2368        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 56, 56, 64)   2368        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 56, 56, 64)   2368        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 56, 56, 64)   2368        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 56, 56, 64)   2368        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 56, 56, 64)   2368        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 56, 56, 64)   2368        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 56, 56, 64)   2368        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 56, 56, 64)   2368        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 56, 56, 64)   2368        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 56, 56, 64)   2368        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 56, 56, 64)   2368        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 56, 56, 64)   2368        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 56, 56, 64)   2368        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 56, 56, 64)   2368        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 56, 56, 64)   2368        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 56, 56, 64)   2368        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 56, 56, 64)   2368        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 56, 56, 64)   2368        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 56, 56, 64)   2368        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 56, 56, 64)   2368        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 56, 56, 64)   2368        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 56, 56, 64)   2368        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 56, 56, 64)   2368        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 56, 56, 64)   2368        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 56, 56, 64)   2368        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 56, 56, 64)   2368        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 56, 56, 64)   2368        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 56, 56, 64)   2368        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 56, 56, 64)   2368        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 56, 56, 64)   256         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 56, 56, 64)   256         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 56, 56, 64)   256         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 56, 56, 64)   256         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 56, 56, 64)   256         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 56, 56, 64)   256         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 56, 56, 64)   256         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 56, 56, 64)   256         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 56, 56, 64)   256         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 56, 56, 64)   256         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 56, 56, 64)   256         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 56, 56, 64)   256         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 56, 56, 64)   256         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 56, 56, 64)   256         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 56, 56, 64)   256         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 56, 56, 64)   256         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 56, 56, 64)   256         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 56, 56, 64)   256         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 56, 56, 64)   256         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 56, 56, 64)   256         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 56, 56, 64)   256         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 56, 56, 64)   256         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 56, 56, 64)   256         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 56, 56, 64)   256         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 56, 56, 64)   256         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 56, 56, 64)   256         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 56, 56, 64)   256         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 56, 56, 64)   256         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 56, 56, 64)   256         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 56, 56, 64)   256         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 56, 56, 64)   256         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 56, 56, 64)   256         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 64)   0           batch_normalization_66[0][0]     \n",
      "                                                                 batch_normalization_68[0][0]     \n",
      "                                                                 batch_normalization_70[0][0]     \n",
      "                                                                 batch_normalization_72[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "                                                                 batch_normalization_76[0][0]     \n",
      "                                                                 batch_normalization_78[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_82[0][0]     \n",
      "                                                                 batch_normalization_84[0][0]     \n",
      "                                                                 batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_88[0][0]     \n",
      "                                                                 batch_normalization_90[0][0]     \n",
      "                                                                 batch_normalization_92[0][0]     \n",
      "                                                                 batch_normalization_94[0][0]     \n",
      "                                                                 batch_normalization_96[0][0]     \n",
      "                                                                 batch_normalization_98[0][0]     \n",
      "                                                                 batch_normalization_100[0][0]    \n",
      "                                                                 batch_normalization_102[0][0]    \n",
      "                                                                 batch_normalization_104[0][0]    \n",
      "                                                                 batch_normalization_106[0][0]    \n",
      "                                                                 batch_normalization_108[0][0]    \n",
      "                                                                 batch_normalization_110[0][0]    \n",
      "                                                                 batch_normalization_112[0][0]    \n",
      "                                                                 batch_normalization_114[0][0]    \n",
      "                                                                 batch_normalization_116[0][0]    \n",
      "                                                                 batch_normalization_118[0][0]    \n",
      "                                                                 batch_normalization_120[0][0]    \n",
      "                                                                 batch_normalization_122[0][0]    \n",
      "                                                                 batch_normalization_124[0][0]    \n",
      "                                                                 batch_normalization_126[0][0]    \n",
      "                                                                 batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 64)   0           activation_33[0][0]              \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 56, 56, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 28, 28, 8)    4616        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 28, 28, 8)    32          conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 28, 28, 8)    32          conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 28, 28, 8)    32          conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 28, 28, 8)    32          conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 28, 28, 8)    32          conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 28, 28, 8)    32          conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 28, 28, 8)    32          conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 28, 28, 8)    32          conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 28, 28, 8)    32          conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 28, 28, 8)    32          conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 28, 28, 8)    32          conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 28, 28, 8)    32          conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 28, 28, 8)    32          conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 28, 28, 8)    32          conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 28, 28, 8)    32          conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 28, 28, 8)    32          conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 28, 28, 8)    32          conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 28, 28, 8)    32          conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 28, 28, 8)    32          conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 28, 28, 8)    32          conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 28, 28, 8)    32          conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 28, 28, 8)    32          conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 28, 28, 8)    32          conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 28, 28, 8)    32          conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 28, 28, 8)    32          conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 28, 28, 8)    32          conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 28, 28, 8)    32          conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 28, 28, 8)    32          conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 28, 28, 8)    32          conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 28, 28, 8)    32          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 28, 28, 8)    32          conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 28, 28, 8)    32          conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 28, 28, 8)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 28, 28, 8)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 28, 28, 8)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 28, 28, 8)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 28, 28, 8)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 28, 28, 8)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 28, 28, 8)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 28, 28, 8)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 28, 28, 8)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 28, 28, 8)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 28, 28, 8)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 28, 28, 8)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 28, 28, 8)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 28, 28, 8)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 28, 28, 8)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 28, 28, 8)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 28, 28, 8)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 28, 28, 8)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 28, 28, 8)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 28, 28, 8)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 28, 28, 8)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 28, 28, 8)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 28, 28, 8)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 28, 28, 8)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 28, 28, 8)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 28, 28, 8)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 28, 28, 8)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 28, 28, 8)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 28, 28, 8)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 28, 28, 8)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 28, 28, 8)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 28, 28, 8)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 28, 28, 128)  9344        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 28, 28, 128)  9344        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 28, 28, 128)  9344        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 28, 28, 128)  9344        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 28, 28, 128)  9344        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 28, 28, 128)  9344        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 28, 28, 128)  9344        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 28, 28, 128)  9344        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 28, 28, 128)  9344        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 28, 28, 128)  9344        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 28, 28, 128)  9344        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 28, 28, 128)  9344        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 28, 28, 128)  9344        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 28, 28, 128)  9344        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 28, 28, 128)  9344        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 28, 28, 128)  9344        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 28, 28, 128)  9344        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 28, 28, 128)  9344        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 28, 28, 128)  9344        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 28, 28, 128)  9344        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 28, 28, 128)  9344        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 28, 28, 128)  9344        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 28, 28, 128)  9344        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 28, 28, 128)  9344        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 28, 28, 128)  9344        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 28, 28, 128)  9344        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 28, 28, 128)  9344        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 28, 28, 128)  9344        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 28, 28, 128)  9344        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 28, 28, 128)  9344        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 28, 28, 128)  9344        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 28, 28, 128)  9344        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 28, 28, 128)  8320        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 28, 28, 128)  512         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 28, 28, 128)  512         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 28, 28, 128)  512         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 28, 28, 128)  512         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 28, 28, 128)  512         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 28, 28, 128)  512         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 28, 28, 128)  512         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 28, 28, 128)  512         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 28, 28, 128)  512         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 28, 28, 128)  512         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 28, 28, 128)  512         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 28, 28, 128)  512         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 28, 28, 128)  512         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 28, 28, 128)  512         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 28, 28, 128)  512         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 28, 28, 128)  512         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 28, 28, 128)  512         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 28, 28, 128)  512         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 28, 28, 128)  512         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 28, 28, 128)  512         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 28, 28, 128)  512         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 28, 28, 128)  512         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 28, 28, 128)  512         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 28, 28, 128)  512         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 28, 28, 128)  512         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 28, 28, 128)  512         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 28, 28, 128)  512         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 28, 28, 128)  512         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 28, 28, 128)  512         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 28, 28, 128)  512         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 28, 28, 128)  512         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 28, 28, 128)  512         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 28, 28, 128)  512         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 128)  0           batch_normalization_131[0][0]    \n",
      "                                                                 batch_normalization_133[0][0]    \n",
      "                                                                 batch_normalization_135[0][0]    \n",
      "                                                                 batch_normalization_137[0][0]    \n",
      "                                                                 batch_normalization_139[0][0]    \n",
      "                                                                 batch_normalization_141[0][0]    \n",
      "                                                                 batch_normalization_143[0][0]    \n",
      "                                                                 batch_normalization_145[0][0]    \n",
      "                                                                 batch_normalization_147[0][0]    \n",
      "                                                                 batch_normalization_149[0][0]    \n",
      "                                                                 batch_normalization_151[0][0]    \n",
      "                                                                 batch_normalization_153[0][0]    \n",
      "                                                                 batch_normalization_155[0][0]    \n",
      "                                                                 batch_normalization_157[0][0]    \n",
      "                                                                 batch_normalization_159[0][0]    \n",
      "                                                                 batch_normalization_161[0][0]    \n",
      "                                                                 batch_normalization_163[0][0]    \n",
      "                                                                 batch_normalization_165[0][0]    \n",
      "                                                                 batch_normalization_167[0][0]    \n",
      "                                                                 batch_normalization_169[0][0]    \n",
      "                                                                 batch_normalization_171[0][0]    \n",
      "                                                                 batch_normalization_173[0][0]    \n",
      "                                                                 batch_normalization_175[0][0]    \n",
      "                                                                 batch_normalization_177[0][0]    \n",
      "                                                                 batch_normalization_179[0][0]    \n",
      "                                                                 batch_normalization_181[0][0]    \n",
      "                                                                 batch_normalization_183[0][0]    \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "                                                                 batch_normalization_187[0][0]    \n",
      "                                                                 batch_normalization_189[0][0]    \n",
      "                                                                 batch_normalization_191[0][0]    \n",
      "                                                                 batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 128)  0           batch_normalization_129[0][0]    \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 28, 28, 128)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 28, 28, 8)    9224        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 28, 28, 8)    32          conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 28, 28, 8)    32          conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 28, 28, 8)    32          conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 28, 28, 8)    32          conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 28, 28, 8)    32          conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 28, 28, 8)    32          conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 28, 28, 8)    32          conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 28, 28, 8)    32          conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 28, 28, 8)    32          conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 28, 28, 8)    32          conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 28, 28, 8)    32          conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 28, 28, 8)    32          conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 28, 28, 8)    32          conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 28, 28, 8)    32          conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 28, 28, 8)    32          conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 28, 28, 8)    32          conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 28, 28, 8)    32          conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 28, 28, 8)    32          conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 28, 28, 8)    32          conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 28, 28, 8)    32          conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 28, 28, 8)    32          conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 28, 28, 8)    32          conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 28, 28, 8)    32          conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 28, 28, 8)    32          conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 28, 28, 8)    32          conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 28, 28, 8)    32          conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 28, 28, 8)    32          conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 28, 28, 8)    32          conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 28, 28, 8)    32          conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 28, 28, 8)    32          conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 28, 28, 8)    32          conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 28, 28, 8)    32          conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 28, 28, 8)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 28, 28, 8)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 28, 28, 8)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 28, 28, 8)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 28, 28, 8)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 28, 28, 8)    0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 28, 28, 8)    0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 28, 28, 8)    0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 28, 28, 8)    0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 28, 28, 8)    0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 28, 28, 8)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 28, 28, 8)    0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 28, 28, 8)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 28, 28, 8)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 28, 28, 8)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 28, 28, 8)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 28, 28, 8)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 28, 28, 8)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 28, 28, 8)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 28, 28, 8)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 28, 28, 8)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 28, 28, 8)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 28, 28, 8)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 28, 28, 8)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 28, 28, 8)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 28, 28, 8)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 28, 28, 8)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 28, 28, 8)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 28, 28, 8)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 28, 28, 8)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 28, 28, 8)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 28, 28, 8)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 28, 28, 128)  9344        activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 28, 28, 128)  9344        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 28, 28, 128)  9344        activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 28, 28, 128)  9344        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 28, 28, 128)  9344        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 28, 28, 128)  9344        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 28, 28, 128)  9344        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 28, 28, 128)  9344        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 28, 28, 128)  9344        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 28, 28, 128)  9344        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 28, 28, 128)  9344        activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 28, 28, 128)  9344        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 28, 28, 128)  9344        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 28, 28, 128)  9344        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 28, 28, 128)  9344        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 28, 28, 128)  9344        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 28, 28, 128)  9344        activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 28, 28, 128)  9344        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 28, 28, 128)  9344        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 28, 28, 128)  9344        activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 28, 28, 128)  9344        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 28, 28, 128)  9344        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 28, 28, 128)  9344        activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 28, 28, 128)  9344        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 28, 28, 128)  9344        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 28, 28, 128)  9344        activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 28, 28, 128)  9344        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 28, 28, 128)  9344        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 28, 28, 128)  9344        activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 28, 28, 128)  9344        activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 28, 28, 128)  9344        activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 28, 28, 128)  9344        activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 28, 28, 128)  512         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 28, 28, 128)  512         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 28, 28, 128)  512         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 28, 28, 128)  512         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 28, 28, 128)  512         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 28, 28, 128)  512         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 28, 28, 128)  512         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 28, 28, 128)  512         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 28, 28, 128)  512         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 28, 28, 128)  512         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 28, 28, 128)  512         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 28, 28, 128)  512         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 28, 28, 128)  512         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 28, 28, 128)  512         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 28, 28, 128)  512         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 28, 28, 128)  512         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 28, 28, 128)  512         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 28, 28, 128)  512         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 28, 28, 128)  512         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 28, 28, 128)  512         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 28, 28, 128)  512         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 28, 28, 128)  512         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 28, 28, 128)  512         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 28, 28, 128)  512         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 28, 28, 128)  512         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 28, 28, 128)  512         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 28, 28, 128)  512         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 28, 28, 128)  512         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 28, 28, 128)  512         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 28, 28, 128)  512         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 28, 28, 128)  512         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 28, 28, 128)  512         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 128)  0           batch_normalization_195[0][0]    \n",
      "                                                                 batch_normalization_197[0][0]    \n",
      "                                                                 batch_normalization_199[0][0]    \n",
      "                                                                 batch_normalization_201[0][0]    \n",
      "                                                                 batch_normalization_203[0][0]    \n",
      "                                                                 batch_normalization_205[0][0]    \n",
      "                                                                 batch_normalization_207[0][0]    \n",
      "                                                                 batch_normalization_209[0][0]    \n",
      "                                                                 batch_normalization_211[0][0]    \n",
      "                                                                 batch_normalization_213[0][0]    \n",
      "                                                                 batch_normalization_215[0][0]    \n",
      "                                                                 batch_normalization_217[0][0]    \n",
      "                                                                 batch_normalization_219[0][0]    \n",
      "                                                                 batch_normalization_221[0][0]    \n",
      "                                                                 batch_normalization_223[0][0]    \n",
      "                                                                 batch_normalization_225[0][0]    \n",
      "                                                                 batch_normalization_227[0][0]    \n",
      "                                                                 batch_normalization_229[0][0]    \n",
      "                                                                 batch_normalization_231[0][0]    \n",
      "                                                                 batch_normalization_233[0][0]    \n",
      "                                                                 batch_normalization_235[0][0]    \n",
      "                                                                 batch_normalization_237[0][0]    \n",
      "                                                                 batch_normalization_239[0][0]    \n",
      "                                                                 batch_normalization_241[0][0]    \n",
      "                                                                 batch_normalization_243[0][0]    \n",
      "                                                                 batch_normalization_245[0][0]    \n",
      "                                                                 batch_normalization_247[0][0]    \n",
      "                                                                 batch_normalization_249[0][0]    \n",
      "                                                                 batch_normalization_251[0][0]    \n",
      "                                                                 batch_normalization_253[0][0]    \n",
      "                                                                 batch_normalization_255[0][0]    \n",
      "                                                                 batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 128)  0           activation_99[0][0]              \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 28, 28, 128)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 14, 14, 16)   18448       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 14, 14, 16)   64          conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 14, 14, 16)   64          conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 14, 14, 16)   64          conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 14, 14, 16)   64          conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 14, 14, 16)   64          conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 14, 14, 16)   64          conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 14, 14, 16)   64          conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 14, 14, 16)   64          conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 14, 14, 16)   64          conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 14, 14, 16)   64          conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 14, 14, 16)   64          conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 14, 14, 16)   64          conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 14, 14, 16)   64          conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 14, 14, 16)   64          conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 14, 14, 16)   64          conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 14, 14, 16)   64          conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 14, 14, 16)   64          conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 14, 14, 16)   64          conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 14, 14, 16)   64          conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 14, 14, 16)   64          conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 14, 14, 16)   64          conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 14, 14, 16)   64          conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 14, 14, 16)   64          conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 14, 14, 16)   64          conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 14, 14, 16)   64          conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 14, 14, 16)   64          conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 14, 14, 16)   64          conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 14, 14, 16)   64          conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 14, 14, 16)   64          conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 14, 14, 16)   64          conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 14, 14, 16)   64          conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 14, 14, 16)   64          conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 14, 14, 16)   0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 14, 14, 16)   0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 14, 14, 16)   0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 14, 14, 16)   0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 14, 14, 16)   0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 14, 14, 16)   0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 14, 14, 16)   0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 14, 14, 16)   0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 14, 14, 16)   0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 14, 14, 16)   0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 14, 14, 16)   0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 14, 14, 16)   0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 14, 14, 16)   0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 14, 14, 16)   0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 14, 14, 16)   0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 14, 14, 16)   0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 14, 14, 16)   0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 14, 14, 16)   0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 14, 14, 16)   0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 14, 14, 16)   0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 14, 14, 16)   0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 14, 14, 16)   0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 14, 14, 16)   0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 14, 14, 16)   0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 14, 14, 16)   0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 14, 14, 16)   0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 14, 14, 16)   0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 14, 14, 16)   0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 14, 14, 16)   0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 14, 14, 16)   0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 14, 14, 16)   0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 14, 14, 16)   0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 14, 14, 256)  37120       activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 14, 14, 256)  37120       activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 14, 14, 256)  37120       activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 14, 14, 256)  37120       activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 14, 14, 256)  37120       activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 14, 14, 256)  37120       activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 14, 14, 256)  37120       activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 14, 14, 256)  37120       activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 14, 14, 256)  37120       activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 14, 14, 256)  37120       activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 14, 14, 256)  37120       activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 14, 14, 256)  37120       activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 14, 14, 256)  37120       activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 14, 14, 256)  37120       activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 14, 14, 256)  37120       activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 14, 14, 256)  37120       activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 14, 14, 256)  37120       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 14, 14, 256)  37120       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 14, 14, 256)  37120       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 14, 14, 256)  37120       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 14, 14, 256)  37120       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 14, 14, 256)  37120       activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 14, 14, 256)  37120       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 14, 14, 256)  37120       activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 14, 14, 256)  37120       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 14, 14, 256)  37120       activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 14, 14, 256)  37120       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 14, 14, 256)  37120       activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 14, 14, 256)  37120       activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 14, 14, 256)  37120       activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 14, 14, 256)  37120       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 14, 14, 256)  37120       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 14, 14, 256)  33024       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 14, 14, 256)  1024        conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 14, 14, 256)  1024        conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 14, 14, 256)  1024        conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 14, 14, 256)  1024        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 14, 14, 256)  1024        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 14, 14, 256)  1024        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 14, 14, 256)  1024        conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 14, 14, 256)  1024        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 14, 14, 256)  1024        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 14, 14, 256)  1024        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 14, 14, 256)  1024        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 14, 14, 256)  1024        conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 14, 14, 256)  1024        conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 14, 14, 256)  1024        conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 14, 14, 256)  1024        conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 14, 14, 256)  1024        conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 14, 14, 256)  1024        conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 14, 14, 256)  1024        conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 14, 14, 256)  1024        conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 14, 14, 256)  1024        conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 14, 14, 256)  1024        conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 14, 14, 256)  1024        conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 14, 14, 256)  1024        conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 14, 14, 256)  1024        conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 14, 14, 256)  1024        conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 14, 14, 256)  1024        conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 14, 14, 256)  1024        conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 14, 14, 256)  1024        conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 14, 14, 256)  1024        conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 14, 14, 256)  1024        conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 14, 14, 256)  1024        conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 14, 14, 256)  1024        conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 14, 14, 256)  1024        conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 256)  0           batch_normalization_260[0][0]    \n",
      "                                                                 batch_normalization_262[0][0]    \n",
      "                                                                 batch_normalization_264[0][0]    \n",
      "                                                                 batch_normalization_266[0][0]    \n",
      "                                                                 batch_normalization_268[0][0]    \n",
      "                                                                 batch_normalization_270[0][0]    \n",
      "                                                                 batch_normalization_272[0][0]    \n",
      "                                                                 batch_normalization_274[0][0]    \n",
      "                                                                 batch_normalization_276[0][0]    \n",
      "                                                                 batch_normalization_278[0][0]    \n",
      "                                                                 batch_normalization_280[0][0]    \n",
      "                                                                 batch_normalization_282[0][0]    \n",
      "                                                                 batch_normalization_284[0][0]    \n",
      "                                                                 batch_normalization_286[0][0]    \n",
      "                                                                 batch_normalization_288[0][0]    \n",
      "                                                                 batch_normalization_290[0][0]    \n",
      "                                                                 batch_normalization_292[0][0]    \n",
      "                                                                 batch_normalization_294[0][0]    \n",
      "                                                                 batch_normalization_296[0][0]    \n",
      "                                                                 batch_normalization_298[0][0]    \n",
      "                                                                 batch_normalization_300[0][0]    \n",
      "                                                                 batch_normalization_302[0][0]    \n",
      "                                                                 batch_normalization_304[0][0]    \n",
      "                                                                 batch_normalization_306[0][0]    \n",
      "                                                                 batch_normalization_308[0][0]    \n",
      "                                                                 batch_normalization_310[0][0]    \n",
      "                                                                 batch_normalization_312[0][0]    \n",
      "                                                                 batch_normalization_314[0][0]    \n",
      "                                                                 batch_normalization_316[0][0]    \n",
      "                                                                 batch_normalization_318[0][0]    \n",
      "                                                                 batch_normalization_320[0][0]    \n",
      "                                                                 batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 256)  0           batch_normalization_258[0][0]    \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 14, 14, 256)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 14, 14, 16)   36880       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 14, 14, 16)   64          conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 14, 14, 16)   64          conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 14, 14, 16)   64          conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 14, 14, 16)   64          conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 14, 14, 16)   64          conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 14, 14, 16)   64          conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 14, 14, 16)   64          conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 14, 14, 16)   64          conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 14, 14, 16)   64          conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 14, 14, 16)   64          conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 14, 14, 16)   64          conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 14, 14, 16)   64          conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 14, 14, 16)   64          conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 14, 14, 16)   64          conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 14, 14, 16)   64          conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_353 (BatchN (None, 14, 14, 16)   64          conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_355 (BatchN (None, 14, 14, 16)   64          conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_357 (BatchN (None, 14, 14, 16)   64          conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_359 (BatchN (None, 14, 14, 16)   64          conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_361 (BatchN (None, 14, 14, 16)   64          conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_363 (BatchN (None, 14, 14, 16)   64          conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_365 (BatchN (None, 14, 14, 16)   64          conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_367 (BatchN (None, 14, 14, 16)   64          conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_369 (BatchN (None, 14, 14, 16)   64          conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_371 (BatchN (None, 14, 14, 16)   64          conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_373 (BatchN (None, 14, 14, 16)   64          conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_375 (BatchN (None, 14, 14, 16)   64          conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, 14, 14, 16)   64          conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, 14, 14, 16)   64          conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_381 (BatchN (None, 14, 14, 16)   64          conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_383 (BatchN (None, 14, 14, 16)   64          conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchN (None, 14, 14, 16)   64          conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 14, 14, 16)   0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 14, 14, 16)   0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 14, 14, 16)   0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 14, 14, 16)   0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 14, 14, 16)   0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 14, 14, 16)   0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 14, 14, 16)   0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 14, 14, 16)   0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 14, 14, 16)   0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 14, 14, 16)   0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 14, 14, 16)   0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 14, 14, 16)   0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 14, 14, 16)   0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 14, 14, 16)   0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 14, 14, 16)   0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 14, 14, 16)   0           batch_normalization_353[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 14, 14, 16)   0           batch_normalization_355[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 14, 14, 16)   0           batch_normalization_357[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 14, 14, 16)   0           batch_normalization_359[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 14, 14, 16)   0           batch_normalization_361[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 14, 14, 16)   0           batch_normalization_363[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 14, 14, 16)   0           batch_normalization_365[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 14, 14, 16)   0           batch_normalization_367[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 14, 14, 16)   0           batch_normalization_369[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 14, 14, 16)   0           batch_normalization_371[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 14, 14, 16)   0           batch_normalization_373[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 14, 14, 16)   0           batch_normalization_375[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 14, 14, 16)   0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 14, 14, 16)   0           batch_normalization_379[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 14, 14, 16)   0           batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 14, 14, 16)   0           batch_normalization_383[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 14, 14, 16)   0           batch_normalization_385[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 14, 14, 256)  37120       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 14, 14, 256)  37120       activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 14, 14, 256)  37120       activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 14, 14, 256)  37120       activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 14, 14, 256)  37120       activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 14, 14, 256)  37120       activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 14, 14, 256)  37120       activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 14, 14, 256)  37120       activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 14, 14, 256)  37120       activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 14, 14, 256)  37120       activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 14, 14, 256)  37120       activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 14, 14, 256)  37120       activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 14, 14, 256)  37120       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 14, 14, 256)  37120       activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 14, 14, 256)  37120       activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 14, 14, 256)  37120       activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 14, 14, 256)  37120       activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 14, 14, 256)  37120       activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 14, 14, 256)  37120       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 14, 14, 256)  37120       activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 14, 14, 256)  37120       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 14, 14, 256)  37120       activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 14, 14, 256)  37120       activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 14, 14, 256)  37120       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 14, 14, 256)  37120       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 14, 14, 256)  37120       activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 14, 14, 256)  37120       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 14, 14, 256)  37120       activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 14, 14, 256)  37120       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 14, 14, 256)  37120       activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 14, 14, 256)  37120       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 14, 14, 256)  37120       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 14, 14, 256)  1024        conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 14, 14, 256)  1024        conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 14, 14, 256)  1024        conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 14, 14, 256)  1024        conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 14, 14, 256)  1024        conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 14, 14, 256)  1024        conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 14, 14, 256)  1024        conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 14, 14, 256)  1024        conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 14, 14, 256)  1024        conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 14, 14, 256)  1024        conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 14, 14, 256)  1024        conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 14, 14, 256)  1024        conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 14, 14, 256)  1024        conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 14, 14, 256)  1024        conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 14, 14, 256)  1024        conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 14, 14, 256)  1024        conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_356 (BatchN (None, 14, 14, 256)  1024        conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_358 (BatchN (None, 14, 14, 256)  1024        conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_360 (BatchN (None, 14, 14, 256)  1024        conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_362 (BatchN (None, 14, 14, 256)  1024        conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_364 (BatchN (None, 14, 14, 256)  1024        conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_366 (BatchN (None, 14, 14, 256)  1024        conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_368 (BatchN (None, 14, 14, 256)  1024        conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_370 (BatchN (None, 14, 14, 256)  1024        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_372 (BatchN (None, 14, 14, 256)  1024        conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_374 (BatchN (None, 14, 14, 256)  1024        conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_376 (BatchN (None, 14, 14, 256)  1024        conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, 14, 14, 256)  1024        conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_380 (BatchN (None, 14, 14, 256)  1024        conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_382 (BatchN (None, 14, 14, 256)  1024        conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_384 (BatchN (None, 14, 14, 256)  1024        conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchN (None, 14, 14, 256)  1024        conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 256)  0           batch_normalization_324[0][0]    \n",
      "                                                                 batch_normalization_326[0][0]    \n",
      "                                                                 batch_normalization_328[0][0]    \n",
      "                                                                 batch_normalization_330[0][0]    \n",
      "                                                                 batch_normalization_332[0][0]    \n",
      "                                                                 batch_normalization_334[0][0]    \n",
      "                                                                 batch_normalization_336[0][0]    \n",
      "                                                                 batch_normalization_338[0][0]    \n",
      "                                                                 batch_normalization_340[0][0]    \n",
      "                                                                 batch_normalization_342[0][0]    \n",
      "                                                                 batch_normalization_344[0][0]    \n",
      "                                                                 batch_normalization_346[0][0]    \n",
      "                                                                 batch_normalization_348[0][0]    \n",
      "                                                                 batch_normalization_350[0][0]    \n",
      "                                                                 batch_normalization_352[0][0]    \n",
      "                                                                 batch_normalization_354[0][0]    \n",
      "                                                                 batch_normalization_356[0][0]    \n",
      "                                                                 batch_normalization_358[0][0]    \n",
      "                                                                 batch_normalization_360[0][0]    \n",
      "                                                                 batch_normalization_362[0][0]    \n",
      "                                                                 batch_normalization_364[0][0]    \n",
      "                                                                 batch_normalization_366[0][0]    \n",
      "                                                                 batch_normalization_368[0][0]    \n",
      "                                                                 batch_normalization_370[0][0]    \n",
      "                                                                 batch_normalization_372[0][0]    \n",
      "                                                                 batch_normalization_374[0][0]    \n",
      "                                                                 batch_normalization_376[0][0]    \n",
      "                                                                 batch_normalization_378[0][0]    \n",
      "                                                                 batch_normalization_380[0][0]    \n",
      "                                                                 batch_normalization_382[0][0]    \n",
      "                                                                 batch_normalization_384[0][0]    \n",
      "                                                                 batch_normalization_386[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 256)  0           activation_165[0][0]             \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 14, 14, 256)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_424 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_426 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_428 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_430 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_432 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_434 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_436 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_438 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_440 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_442 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_444 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_446 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_448 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_450 (Conv2D)             (None, 7, 7, 32)     73760       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, 7, 7, 32)     128         conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 7, 7, 32)     128         conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, 7, 7, 32)     128         conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, 7, 7, 32)     128         conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_396 (BatchN (None, 7, 7, 32)     128         conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, 7, 7, 32)     128         conv2d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, 7, 7, 32)     128         conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 7, 7, 32)     128         conv2d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 7, 7, 32)     128         conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 7, 7, 32)     128         conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 7, 7, 32)     128         conv2d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, 7, 7, 32)     128         conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, 7, 7, 32)     128         conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, 7, 7, 32)     128         conv2d_414[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, 7, 7, 32)     128         conv2d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, 7, 7, 32)     128         conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, 7, 7, 32)     128         conv2d_420[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_422 (BatchN (None, 7, 7, 32)     128         conv2d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_424 (BatchN (None, 7, 7, 32)     128         conv2d_424[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_426 (BatchN (None, 7, 7, 32)     128         conv2d_426[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_428 (BatchN (None, 7, 7, 32)     128         conv2d_428[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_430 (BatchN (None, 7, 7, 32)     128         conv2d_430[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_432 (BatchN (None, 7, 7, 32)     128         conv2d_432[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_434 (BatchN (None, 7, 7, 32)     128         conv2d_434[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchN (None, 7, 7, 32)     128         conv2d_436[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchN (None, 7, 7, 32)     128         conv2d_438[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchN (None, 7, 7, 32)     128         conv2d_440[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchN (None, 7, 7, 32)     128         conv2d_442[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchN (None, 7, 7, 32)     128         conv2d_444[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchN (None, 7, 7, 32)     128         conv2d_446[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchN (None, 7, 7, 32)     128         conv2d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_450 (BatchN (None, 7, 7, 32)     128         conv2d_450[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 7, 7, 32)     0           batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 7, 7, 32)     0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 7, 7, 32)     0           batch_normalization_392[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 7, 7, 32)     0           batch_normalization_394[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 7, 7, 32)     0           batch_normalization_396[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 7, 7, 32)     0           batch_normalization_398[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 7, 7, 32)     0           batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 7, 7, 32)     0           batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 7, 7, 32)     0           batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 7, 7, 32)     0           batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 7, 7, 32)     0           batch_normalization_408[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 7, 7, 32)     0           batch_normalization_410[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 7, 7, 32)     0           batch_normalization_412[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 7, 7, 32)     0           batch_normalization_414[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 7, 7, 32)     0           batch_normalization_416[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 32)     0           batch_normalization_418[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 7, 7, 32)     0           batch_normalization_420[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 7, 7, 32)     0           batch_normalization_422[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 32)     0           batch_normalization_424[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 32)     0           batch_normalization_426[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 32)     0           batch_normalization_428[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 32)     0           batch_normalization_430[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 32)     0           batch_normalization_432[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 32)     0           batch_normalization_434[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 32)     0           batch_normalization_436[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 32)     0           batch_normalization_438[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 32)     0           batch_normalization_440[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 32)     0           batch_normalization_442[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 32)     0           batch_normalization_444[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 32)     0           batch_normalization_446[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 32)     0           batch_normalization_448[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 32)     0           batch_normalization_450[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 7, 7, 512)    147968      activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, 7, 7, 512)    147968      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, 7, 7, 512)    147968      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 7, 7, 512)    147968      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 7, 7, 512)    147968      activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, 7, 7, 512)    147968      activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, 7, 7, 512)    147968      activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, 7, 7, 512)    147968      activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 7, 7, 512)    147968      activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 7, 7, 512)    147968      activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, 7, 7, 512)    147968      activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_411 (Conv2D)             (None, 7, 7, 512)    147968      activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, 7, 7, 512)    147968      activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, 7, 7, 512)    147968      activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, 7, 7, 512)    147968      activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, 7, 7, 512)    147968      activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, 7, 7, 512)    147968      activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_423 (Conv2D)             (None, 7, 7, 512)    147968      activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_425 (Conv2D)             (None, 7, 7, 512)    147968      activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_427 (Conv2D)             (None, 7, 7, 512)    147968      activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_429 (Conv2D)             (None, 7, 7, 512)    147968      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_431 (Conv2D)             (None, 7, 7, 512)    147968      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_433 (Conv2D)             (None, 7, 7, 512)    147968      activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_435 (Conv2D)             (None, 7, 7, 512)    147968      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_437 (Conv2D)             (None, 7, 7, 512)    147968      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_439 (Conv2D)             (None, 7, 7, 512)    147968      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_441 (Conv2D)             (None, 7, 7, 512)    147968      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_443 (Conv2D)             (None, 7, 7, 512)    147968      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_445 (Conv2D)             (None, 7, 7, 512)    147968      activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_447 (Conv2D)             (None, 7, 7, 512)    147968      activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_449 (Conv2D)             (None, 7, 7, 512)    147968      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_451 (Conv2D)             (None, 7, 7, 512)    147968      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 7, 7, 512)    131584      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, 7, 7, 512)    2048        conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 7, 7, 512)    2048        conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, 7, 7, 512)    2048        conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_395 (BatchN (None, 7, 7, 512)    2048        conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_397 (BatchN (None, 7, 7, 512)    2048        conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, 7, 7, 512)    2048        conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, 7, 7, 512)    2048        conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 7, 7, 512)    2048        conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 7, 7, 512)    2048        conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 7, 7, 512)    2048        conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, 7, 7, 512)    2048        conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, 7, 7, 512)    2048        conv2d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, 7, 7, 512)    2048        conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, 7, 7, 512)    2048        conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, 7, 7, 512)    2048        conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, 7, 7, 512)    2048        conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_421 (BatchN (None, 7, 7, 512)    2048        conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_423 (BatchN (None, 7, 7, 512)    2048        conv2d_423[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_425 (BatchN (None, 7, 7, 512)    2048        conv2d_425[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_427 (BatchN (None, 7, 7, 512)    2048        conv2d_427[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_429 (BatchN (None, 7, 7, 512)    2048        conv2d_429[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_431 (BatchN (None, 7, 7, 512)    2048        conv2d_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_433 (BatchN (None, 7, 7, 512)    2048        conv2d_433[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_435 (BatchN (None, 7, 7, 512)    2048        conv2d_435[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchN (None, 7, 7, 512)    2048        conv2d_437[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchN (None, 7, 7, 512)    2048        conv2d_439[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchN (None, 7, 7, 512)    2048        conv2d_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchN (None, 7, 7, 512)    2048        conv2d_443[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchN (None, 7, 7, 512)    2048        conv2d_445[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchN (None, 7, 7, 512)    2048        conv2d_447[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_449 (BatchN (None, 7, 7, 512)    2048        conv2d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_451 (BatchN (None, 7, 7, 512)    2048        conv2d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_387 (BatchN (None, 7, 7, 512)    2048        conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 7, 7, 512)    0           batch_normalization_389[0][0]    \n",
      "                                                                 batch_normalization_391[0][0]    \n",
      "                                                                 batch_normalization_393[0][0]    \n",
      "                                                                 batch_normalization_395[0][0]    \n",
      "                                                                 batch_normalization_397[0][0]    \n",
      "                                                                 batch_normalization_399[0][0]    \n",
      "                                                                 batch_normalization_401[0][0]    \n",
      "                                                                 batch_normalization_403[0][0]    \n",
      "                                                                 batch_normalization_405[0][0]    \n",
      "                                                                 batch_normalization_407[0][0]    \n",
      "                                                                 batch_normalization_409[0][0]    \n",
      "                                                                 batch_normalization_411[0][0]    \n",
      "                                                                 batch_normalization_413[0][0]    \n",
      "                                                                 batch_normalization_415[0][0]    \n",
      "                                                                 batch_normalization_417[0][0]    \n",
      "                                                                 batch_normalization_419[0][0]    \n",
      "                                                                 batch_normalization_421[0][0]    \n",
      "                                                                 batch_normalization_423[0][0]    \n",
      "                                                                 batch_normalization_425[0][0]    \n",
      "                                                                 batch_normalization_427[0][0]    \n",
      "                                                                 batch_normalization_429[0][0]    \n",
      "                                                                 batch_normalization_431[0][0]    \n",
      "                                                                 batch_normalization_433[0][0]    \n",
      "                                                                 batch_normalization_435[0][0]    \n",
      "                                                                 batch_normalization_437[0][0]    \n",
      "                                                                 batch_normalization_439[0][0]    \n",
      "                                                                 batch_normalization_441[0][0]    \n",
      "                                                                 batch_normalization_443[0][0]    \n",
      "                                                                 batch_normalization_445[0][0]    \n",
      "                                                                 batch_normalization_447[0][0]    \n",
      "                                                                 batch_normalization_449[0][0]    \n",
      "                                                                 batch_normalization_451[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 512)    0           batch_normalization_387[0][0]    \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 512)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_452 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_474 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_476 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_478 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_480 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_482 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_484 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_486 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_488 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_510 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_512 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_514 (Conv2D)             (None, 7, 7, 32)     147488      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_452 (BatchN (None, 7, 7, 32)     128         conv2d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_454 (BatchN (None, 7, 7, 32)     128         conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_456 (BatchN (None, 7, 7, 32)     128         conv2d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_458 (BatchN (None, 7, 7, 32)     128         conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_460 (BatchN (None, 7, 7, 32)     128         conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_462 (BatchN (None, 7, 7, 32)     128         conv2d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_464 (BatchN (None, 7, 7, 32)     128         conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_466 (BatchN (None, 7, 7, 32)     128         conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_468 (BatchN (None, 7, 7, 32)     128         conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_470 (BatchN (None, 7, 7, 32)     128         conv2d_470[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_472 (BatchN (None, 7, 7, 32)     128         conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_474 (BatchN (None, 7, 7, 32)     128         conv2d_474[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_476 (BatchN (None, 7, 7, 32)     128         conv2d_476[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_478 (BatchN (None, 7, 7, 32)     128         conv2d_478[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_480 (BatchN (None, 7, 7, 32)     128         conv2d_480[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_482 (BatchN (None, 7, 7, 32)     128         conv2d_482[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_484 (BatchN (None, 7, 7, 32)     128         conv2d_484[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_486 (BatchN (None, 7, 7, 32)     128         conv2d_486[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_488 (BatchN (None, 7, 7, 32)     128         conv2d_488[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_490 (BatchN (None, 7, 7, 32)     128         conv2d_490[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_492 (BatchN (None, 7, 7, 32)     128         conv2d_492[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_494 (BatchN (None, 7, 7, 32)     128         conv2d_494[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_496 (BatchN (None, 7, 7, 32)     128         conv2d_496[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_498 (BatchN (None, 7, 7, 32)     128         conv2d_498[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_500 (BatchN (None, 7, 7, 32)     128         conv2d_500[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_502 (BatchN (None, 7, 7, 32)     128         conv2d_502[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_504 (BatchN (None, 7, 7, 32)     128         conv2d_504[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_506 (BatchN (None, 7, 7, 32)     128         conv2d_506[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_508 (BatchN (None, 7, 7, 32)     128         conv2d_508[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_510 (BatchN (None, 7, 7, 32)     128         conv2d_510[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_512 (BatchN (None, 7, 7, 32)     128         conv2d_512[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_514 (BatchN (None, 7, 7, 32)     128         conv2d_514[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 32)     0           batch_normalization_452[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 32)     0           batch_normalization_454[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 32)     0           batch_normalization_456[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 32)     0           batch_normalization_458[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 32)     0           batch_normalization_460[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 32)     0           batch_normalization_462[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 32)     0           batch_normalization_464[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 32)     0           batch_normalization_466[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 32)     0           batch_normalization_468[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 32)     0           batch_normalization_470[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 32)     0           batch_normalization_472[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 32)     0           batch_normalization_474[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 32)     0           batch_normalization_476[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 32)     0           batch_normalization_478[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 32)     0           batch_normalization_480[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 32)     0           batch_normalization_482[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 32)     0           batch_normalization_484[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 32)     0           batch_normalization_486[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 32)     0           batch_normalization_488[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 32)     0           batch_normalization_490[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 32)     0           batch_normalization_492[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 32)     0           batch_normalization_494[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 32)     0           batch_normalization_496[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 32)     0           batch_normalization_498[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 32)     0           batch_normalization_500[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 32)     0           batch_normalization_502[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 7, 7, 32)     0           batch_normalization_504[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 7, 7, 32)     0           batch_normalization_506[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 7, 7, 32)     0           batch_normalization_508[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 7, 7, 32)     0           batch_normalization_510[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 7, 7, 32)     0           batch_normalization_512[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 7, 7, 32)     0           batch_normalization_514[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_453 (Conv2D)             (None, 7, 7, 512)    147968      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, 7, 7, 512)    147968      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, 7, 7, 512)    147968      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, 7, 7, 512)    147968      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, 7, 7, 512)    147968      activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, 7, 7, 512)    147968      activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 7, 7, 512)    147968      activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 7, 7, 512)    147968      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 7, 7, 512)    147968      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 7, 7, 512)    147968      activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_473 (Conv2D)             (None, 7, 7, 512)    147968      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_475 (Conv2D)             (None, 7, 7, 512)    147968      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_477 (Conv2D)             (None, 7, 7, 512)    147968      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_479 (Conv2D)             (None, 7, 7, 512)    147968      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_481 (Conv2D)             (None, 7, 7, 512)    147968      activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_483 (Conv2D)             (None, 7, 7, 512)    147968      activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_485 (Conv2D)             (None, 7, 7, 512)    147968      activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_487 (Conv2D)             (None, 7, 7, 512)    147968      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_489 (Conv2D)             (None, 7, 7, 512)    147968      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)             (None, 7, 7, 512)    147968      activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)             (None, 7, 7, 512)    147968      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)             (None, 7, 7, 512)    147968      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)             (None, 7, 7, 512)    147968      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)             (None, 7, 7, 512)    147968      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)             (None, 7, 7, 512)    147968      activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)             (None, 7, 7, 512)    147968      activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)             (None, 7, 7, 512)    147968      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)             (None, 7, 7, 512)    147968      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_509 (Conv2D)             (None, 7, 7, 512)    147968      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_511 (Conv2D)             (None, 7, 7, 512)    147968      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_513 (Conv2D)             (None, 7, 7, 512)    147968      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_515 (Conv2D)             (None, 7, 7, 512)    147968      activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_453 (BatchN (None, 7, 7, 512)    2048        conv2d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_455 (BatchN (None, 7, 7, 512)    2048        conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_457 (BatchN (None, 7, 7, 512)    2048        conv2d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_459 (BatchN (None, 7, 7, 512)    2048        conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_461 (BatchN (None, 7, 7, 512)    2048        conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_463 (BatchN (None, 7, 7, 512)    2048        conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_465 (BatchN (None, 7, 7, 512)    2048        conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_467 (BatchN (None, 7, 7, 512)    2048        conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_469 (BatchN (None, 7, 7, 512)    2048        conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_471 (BatchN (None, 7, 7, 512)    2048        conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_473 (BatchN (None, 7, 7, 512)    2048        conv2d_473[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_475 (BatchN (None, 7, 7, 512)    2048        conv2d_475[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_477 (BatchN (None, 7, 7, 512)    2048        conv2d_477[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_479 (BatchN (None, 7, 7, 512)    2048        conv2d_479[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_481 (BatchN (None, 7, 7, 512)    2048        conv2d_481[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_483 (BatchN (None, 7, 7, 512)    2048        conv2d_483[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_485 (BatchN (None, 7, 7, 512)    2048        conv2d_485[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_487 (BatchN (None, 7, 7, 512)    2048        conv2d_487[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_489 (BatchN (None, 7, 7, 512)    2048        conv2d_489[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_491 (BatchN (None, 7, 7, 512)    2048        conv2d_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_493 (BatchN (None, 7, 7, 512)    2048        conv2d_493[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_495 (BatchN (None, 7, 7, 512)    2048        conv2d_495[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_497 (BatchN (None, 7, 7, 512)    2048        conv2d_497[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_499 (BatchN (None, 7, 7, 512)    2048        conv2d_499[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_501 (BatchN (None, 7, 7, 512)    2048        conv2d_501[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_503 (BatchN (None, 7, 7, 512)    2048        conv2d_503[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_505 (BatchN (None, 7, 7, 512)    2048        conv2d_505[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_507 (BatchN (None, 7, 7, 512)    2048        conv2d_507[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_509 (BatchN (None, 7, 7, 512)    2048        conv2d_509[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_511 (BatchN (None, 7, 7, 512)    2048        conv2d_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_513 (BatchN (None, 7, 7, 512)    2048        conv2d_513[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_515 (BatchN (None, 7, 7, 512)    2048        conv2d_515[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 512)    0           batch_normalization_453[0][0]    \n",
      "                                                                 batch_normalization_455[0][0]    \n",
      "                                                                 batch_normalization_457[0][0]    \n",
      "                                                                 batch_normalization_459[0][0]    \n",
      "                                                                 batch_normalization_461[0][0]    \n",
      "                                                                 batch_normalization_463[0][0]    \n",
      "                                                                 batch_normalization_465[0][0]    \n",
      "                                                                 batch_normalization_467[0][0]    \n",
      "                                                                 batch_normalization_469[0][0]    \n",
      "                                                                 batch_normalization_471[0][0]    \n",
      "                                                                 batch_normalization_473[0][0]    \n",
      "                                                                 batch_normalization_475[0][0]    \n",
      "                                                                 batch_normalization_477[0][0]    \n",
      "                                                                 batch_normalization_479[0][0]    \n",
      "                                                                 batch_normalization_481[0][0]    \n",
      "                                                                 batch_normalization_483[0][0]    \n",
      "                                                                 batch_normalization_485[0][0]    \n",
      "                                                                 batch_normalization_487[0][0]    \n",
      "                                                                 batch_normalization_489[0][0]    \n",
      "                                                                 batch_normalization_491[0][0]    \n",
      "                                                                 batch_normalization_493[0][0]    \n",
      "                                                                 batch_normalization_495[0][0]    \n",
      "                                                                 batch_normalization_497[0][0]    \n",
      "                                                                 batch_normalization_499[0][0]    \n",
      "                                                                 batch_normalization_501[0][0]    \n",
      "                                                                 batch_normalization_503[0][0]    \n",
      "                                                                 batch_normalization_505[0][0]    \n",
      "                                                                 batch_normalization_507[0][0]    \n",
      "                                                                 batch_normalization_509[0][0]    \n",
      "                                                                 batch_normalization_511[0][0]    \n",
      "                                                                 batch_normalization_513[0][0]    \n",
      "                                                                 batch_normalization_515[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 512)    0           activation_231[0][0]             \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 7, 7, 512)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 257)          131841      global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 22,615,425\n",
      "Trainable params: 22,482,945\n",
      "Non-trainable params: 132,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwRlyWzi1qmm"
   },
   "outputs": [],
   "source": [
    "# 폴더 생성\n",
    "\n",
    "os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n",
    "os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VpmuikFpZ0D"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n",
    "import utils\n",
    "import optimizers_v2\n",
    "from utils import get_weight_decays, fill_dict_in_order\n",
    "from utils import reset_seeds, K_eval\n",
    "from optimizers_v2 import AdamW, NadamW, SGDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 104689,
     "status": "ok",
     "timestamp": 1599313813800,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "8wgOtwPW1qmp",
    "outputId": "8d99898f-ae08-4939-bd54-0eae5ad23c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cosine annealing learning rates\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model=model, use_cosine_annealing=True, total_iterations = len(x_train) // batch_sizes , eta_min = 1e-2)\n",
    "#optimizer = Adam()\n",
    "filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n",
    "                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n",
    "                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n",
    "                  LearningRateScheduler(lr_schedule,verbose=1)\n",
    "                  ]\n",
    "                  \n",
    "model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48415312,
     "status": "ok",
     "timestamp": 1599362124433,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "VmS0d9OS1qmr",
    "outputId": "a646f3c8-b356-467a-8e4e-eb500bf39b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 1/70\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_1/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_3/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_5/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_7/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_9/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_11/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_13/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_15/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_17/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_19/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_21/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_23/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_25/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_27/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_29/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_31/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_33/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_35/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_37/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_39/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_41/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_43/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_45/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_47/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_49/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_51/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_53/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_55/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_57/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_59/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_61/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_63/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_2/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_4/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_6/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_8/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_10/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_12/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_14/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_16/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_18/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_20/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_22/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_24/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_26/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_28/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_30/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_32/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_34/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_36/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_38/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_40/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_42/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_44/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_46/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_48/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_50/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_52/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_54/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_56/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_58/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_60/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_62/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_64/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_65/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_67/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_69/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_71/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_73/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_75/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_77/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_79/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_81/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_83/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_85/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_87/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_89/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_91/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_93/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_95/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_97/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_99/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_101/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_103/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_105/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_107/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_109/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_111/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_113/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_115/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_117/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_119/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_121/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_123/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_125/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_127/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_66/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_68/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_70/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_72/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_74/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_76/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_78/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_80/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_82/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_84/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_86/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_88/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_90/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_92/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_94/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_96/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_98/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_100/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_102/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_104/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_106/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_108/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_110/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_112/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_114/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_116/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_118/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_120/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_122/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_124/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_126/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_128/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_130/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_132/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_134/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_136/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_138/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_140/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_142/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_144/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_146/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_148/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_150/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_152/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_154/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_156/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_158/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_160/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_162/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_164/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_166/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_168/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_170/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_172/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_174/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_176/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_178/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_180/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_182/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_184/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_186/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_188/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_190/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_192/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_131/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_133/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_135/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_137/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_139/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_141/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_143/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_145/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_147/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_149/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_151/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_153/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_155/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_157/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_159/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_161/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_163/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_165/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_167/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_169/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_171/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_173/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_175/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_177/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_179/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_181/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_183/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_185/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_187/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_189/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_191/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_193/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_129/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_194/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_196/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_198/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_200/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_202/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_204/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_206/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_208/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_210/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_212/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_214/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_216/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_218/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_220/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_222/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_224/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_226/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_228/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_230/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_232/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_234/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_236/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_238/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_240/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_242/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_244/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_246/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_248/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_250/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_252/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_254/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_256/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_195/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_197/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_199/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_201/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_203/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_205/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_207/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_209/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_211/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_213/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_215/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_217/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_219/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_221/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_223/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_225/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_227/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_229/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_231/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_233/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_235/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_237/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_239/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_241/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_243/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_245/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_247/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_249/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_251/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_253/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_255/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_257/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_259/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_261/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_263/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_265/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_267/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_269/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_271/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_273/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_275/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_277/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_279/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_281/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_283/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_285/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_287/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_289/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_291/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_293/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_295/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_297/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_299/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_301/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_303/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_305/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_307/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_309/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_311/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_313/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_315/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_317/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_319/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_321/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_260/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_262/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_264/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_266/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_268/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_270/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_272/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_274/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_276/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_278/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_280/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_282/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_284/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_286/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_288/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_290/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_292/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_294/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_296/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_298/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_300/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_302/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_304/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_306/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_308/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_310/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_312/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_314/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_316/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_318/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_320/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_322/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_258/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_323/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_325/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_327/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_329/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_331/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_333/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_335/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_337/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_339/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_341/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_343/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_345/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_347/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_349/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_351/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_353/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_355/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_357/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_359/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_361/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_363/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_365/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_367/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_369/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_371/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_373/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_375/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_377/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_379/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_381/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_383/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_385/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_324/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_326/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_328/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_330/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_332/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_334/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_336/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_338/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_340/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_342/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_344/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_346/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_348/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_350/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_352/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_354/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_356/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_358/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_360/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_362/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_364/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_366/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_368/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_370/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_372/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_374/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_376/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_378/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_380/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_382/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_384/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_386/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_388/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_390/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_392/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_394/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_396/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_398/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_400/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_402/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_404/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_406/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_408/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_410/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_412/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_414/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_416/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_418/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_420/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_422/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_424/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_426/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_428/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_430/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_432/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_434/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_436/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_438/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_440/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_442/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_444/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_446/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_448/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_450/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_389/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_391/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_393/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_395/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_397/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_399/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_401/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_403/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_405/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_407/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_409/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_411/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_413/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_415/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_417/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_419/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_421/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_423/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_425/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_427/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_429/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_431/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_433/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_435/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_437/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_439/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_441/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_443/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_445/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_447/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_449/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_451/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_387/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_452/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_454/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_456/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_458/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_460/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_462/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_464/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_466/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_468/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_470/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_472/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_474/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_476/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_478/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_480/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_482/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_484/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_486/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_488/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_490/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_492/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_494/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_496/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_498/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_500/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_502/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_504/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_506/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_508/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_510/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_512/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_514/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_453/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_455/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_457/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_459/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_461/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_463/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_465/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_467/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_469/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_471/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_473/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_475/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_477/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_479/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_481/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_483/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_485/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_487/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_489/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_491/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_493/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_495/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_497/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_499/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_501/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_503/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_505/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_507/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_509/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_511/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_513/kernel:0\n",
      "0.0(L1), 0.0001534933543632123(L2) weight decay set for conv2d_515/kernel:0\n",
      "382/382 [==============================] - ETA: 0s - loss: 5.7186 - accuracy: 0.0906 - macro_f1score: 0.0021 - weighted_f1score: 6.0611e-05 \n",
      "Epoch 00001: val_loss improved from inf to 4.55079, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/001.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.13553, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/001.h5\n",
      "382/382 [==============================] - 11733s 31s/step - loss: 5.7186 - accuracy: 0.0906 - macro_f1score: 0.0021 - weighted_f1score: 6.0611e-05 - val_loss: 4.5508 - val_accuracy: 0.1355 - val_macro_f1score: 0.0050 - val_weighted_f1score: 1.4912e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 2/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.6826 - accuracy: 0.1212 - macro_f1score: 0.0046 - weighted_f1score: 1.3336e-04\n",
      "Epoch 00002: val_loss improved from 4.55079 to 4.27328, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/002.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.13553 to 0.16848, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/002.h5\n",
      "382/382 [==============================] - 494s 1s/step - loss: 4.6826 - accuracy: 0.1212 - macro_f1score: 0.0046 - weighted_f1score: 1.3336e-04 - val_loss: 4.2733 - val_accuracy: 0.1685 - val_macro_f1score: 0.0072 - val_weighted_f1score: 1.9715e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 3/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.3877 - accuracy: 0.1510 - macro_f1score: 0.0074 - weighted_f1score: 1.9904e-04\n",
      "Epoch 00003: val_loss improved from 4.27328 to 4.04766, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/003.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.16848 to 0.19056, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/003.h5\n",
      "382/382 [==============================] - 480s 1s/step - loss: 4.3877 - accuracy: 0.1510 - macro_f1score: 0.0074 - weighted_f1score: 1.9904e-04 - val_loss: 4.0477 - val_accuracy: 0.1906 - val_macro_f1score: 0.0092 - val_weighted_f1score: 2.4124e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 4/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.1083 - accuracy: 0.1864 - macro_f1score: 0.0096 - weighted_f1score: 2.5425e-04\n",
      "Epoch 00004: val_loss improved from 4.04766 to 3.83222, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/004.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.19056 to 0.22520, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/004.h5\n",
      "382/382 [==============================] - 476s 1s/step - loss: 4.1083 - accuracy: 0.1864 - macro_f1score: 0.0096 - weighted_f1score: 2.5425e-04 - val_loss: 3.8322 - val_accuracy: 0.2252 - val_macro_f1score: 0.0138 - val_weighted_f1score: 3.4047e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 5/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.8555 - accuracy: 0.2201 - macro_f1score: 0.0142 - weighted_f1score: 3.5120e-04\n",
      "Epoch 00005: val_loss improved from 3.83222 to 3.55383, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/005.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.22520 to 0.27514, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/005.h5\n",
      "382/382 [==============================] - 475s 1s/step - loss: 3.8555 - accuracy: 0.2201 - macro_f1score: 0.0142 - weighted_f1score: 3.5120e-04 - val_loss: 3.5538 - val_accuracy: 0.2751 - val_macro_f1score: 0.0192 - val_weighted_f1score: 4.4990e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 6/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.6300 - accuracy: 0.2476 - macro_f1score: 0.0185 - weighted_f1score: 4.3644e-04\n",
      "Epoch 00006: val_loss improved from 3.55383 to 3.39647, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/006.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.27514 to 0.30876, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/006.h5\n",
      "382/382 [==============================] - 473s 1s/step - loss: 3.6300 - accuracy: 0.2476 - macro_f1score: 0.0185 - weighted_f1score: 4.3644e-04 - val_loss: 3.3965 - val_accuracy: 0.3088 - val_macro_f1score: 0.0232 - val_weighted_f1score: 5.3759e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 7/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.4556 - accuracy: 0.2773 - macro_f1score: 0.0220 - weighted_f1score: 5.0411e-04\n",
      "Epoch 00007: val_loss improved from 3.39647 to 3.23970, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/007.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.30876 to 0.32643, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/007.h5\n",
      "382/382 [==============================] - 472s 1s/step - loss: 3.4556 - accuracy: 0.2773 - macro_f1score: 0.0220 - weighted_f1score: 5.0411e-04 - val_loss: 3.2397 - val_accuracy: 0.3264 - val_macro_f1score: 0.0295 - val_weighted_f1score: 6.4428e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 8/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.1989 - accuracy: 0.3174 - macro_f1score: 0.0286 - weighted_f1score: 6.2692e-04\n",
      "Epoch 00008: val_loss improved from 3.23970 to 3.06396, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/008.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.32643 to 0.35632, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/008.h5\n",
      "382/382 [==============================] - 475s 1s/step - loss: 3.1989 - accuracy: 0.3174 - macro_f1score: 0.0286 - weighted_f1score: 6.2692e-04 - val_loss: 3.0640 - val_accuracy: 0.3563 - val_macro_f1score: 0.0360 - val_weighted_f1score: 7.6901e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 9/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.9795 - accuracy: 0.3523 - macro_f1score: 0.0356 - weighted_f1score: 7.5772e-04\n",
      "Epoch 00009: val_loss improved from 3.06396 to 2.86600, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/009.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.35632 to 0.38791, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/009.h5\n",
      "382/382 [==============================] - 473s 1s/step - loss: 2.9795 - accuracy: 0.3523 - macro_f1score: 0.0356 - weighted_f1score: 7.5772e-04 - val_loss: 2.8660 - val_accuracy: 0.3879 - val_macro_f1score: 0.0451 - val_weighted_f1score: 9.3362e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 10/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.7953 - accuracy: 0.3803 - macro_f1score: 0.0407 - weighted_f1score: 8.5586e-04\n",
      "Epoch 00010: val_loss improved from 2.86600 to 2.70794, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/010.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.38791 to 0.40795, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/010.h5\n",
      "382/382 [==============================] - 485s 1s/step - loss: 2.7953 - accuracy: 0.3803 - macro_f1score: 0.0407 - weighted_f1score: 8.5586e-04 - val_loss: 2.7079 - val_accuracy: 0.4079 - val_macro_f1score: 0.0503 - val_weighted_f1score: 0.0010\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 11/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.5991 - accuracy: 0.4160 - macro_f1score: 0.0494 - weighted_f1score: 0.0010\n",
      "Epoch 00011: val_loss improved from 2.70794 to 2.61286, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/011.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.40795 to 0.42595, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/011.h5\n",
      "382/382 [==============================] - 497s 1s/step - loss: 2.5991 - accuracy: 0.4160 - macro_f1score: 0.0494 - weighted_f1score: 0.0010 - val_loss: 2.6129 - val_accuracy: 0.4260 - val_macro_f1score: 0.0560 - val_weighted_f1score: 0.0012\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 12/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.4272 - accuracy: 0.4450 - macro_f1score: 0.0557 - weighted_f1score: 0.0011\n",
      "Epoch 00012: val_loss improved from 2.61286 to 2.51974, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/012.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.42595 to 0.44803, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/012.h5\n",
      "382/382 [==============================] - 489s 1s/step - loss: 2.4272 - accuracy: 0.4450 - macro_f1score: 0.0557 - weighted_f1score: 0.0011 - val_loss: 2.5197 - val_accuracy: 0.4480 - val_macro_f1score: 0.0639 - val_weighted_f1score: 0.0013\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 13/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.2825 - accuracy: 0.4709 - macro_f1score: 0.0627 - weighted_f1score: 0.0013\n",
      "Epoch 00013: val_loss improved from 2.51974 to 2.44062, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/013.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.44803 to 0.46773, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/013.h5\n",
      "382/382 [==============================] - 467s 1s/step - loss: 2.2825 - accuracy: 0.4709 - macro_f1score: 0.0627 - weighted_f1score: 0.0013 - val_loss: 2.4406 - val_accuracy: 0.4677 - val_macro_f1score: 0.0675 - val_weighted_f1score: 0.0013\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 14/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.1240 - accuracy: 0.5035 - macro_f1score: 0.0704 - weighted_f1score: 0.0014\n",
      "Epoch 00014: val_loss improved from 2.44062 to 2.36540, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/014.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.46773 to 0.48607, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/014.h5\n",
      "382/382 [==============================] - 468s 1s/step - loss: 2.1240 - accuracy: 0.5035 - macro_f1score: 0.0704 - weighted_f1score: 0.0014 - val_loss: 2.3654 - val_accuracy: 0.4861 - val_macro_f1score: 0.0736 - val_weighted_f1score: 0.0015\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 15/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.0150 - accuracy: 0.5237 - macro_f1score: 0.0762 - weighted_f1score: 0.0015\n",
      "Epoch 00015: val_loss improved from 2.36540 to 2.31697, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/015.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.48607 to 0.49219, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/015.h5\n",
      "382/382 [==============================] - 473s 1s/step - loss: 2.0150 - accuracy: 0.5237 - macro_f1score: 0.0762 - weighted_f1score: 0.0015 - val_loss: 2.3170 - val_accuracy: 0.4922 - val_macro_f1score: 0.0784 - val_weighted_f1score: 0.0015\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 16/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.8872 - accuracy: 0.5487 - macro_f1score: 0.0821 - weighted_f1score: 0.0016\n",
      "Epoch 00016: val_loss improved from 2.31697 to 2.27791, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/016.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.49219 to 0.51325, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/016.h5\n",
      "382/382 [==============================] - 474s 1s/step - loss: 1.8872 - accuracy: 0.5487 - macro_f1score: 0.0821 - weighted_f1score: 0.0016 - val_loss: 2.2779 - val_accuracy: 0.5132 - val_macro_f1score: 0.0816 - val_weighted_f1score: 0.0016\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 17/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7466 - accuracy: 0.5727 - macro_f1score: 0.0896 - weighted_f1score: 0.0017\n",
      "Epoch 00017: val_loss improved from 2.27791 to 2.25118, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/017.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.51325\n",
      "382/382 [==============================] - 461s 1s/step - loss: 1.7466 - accuracy: 0.5727 - macro_f1score: 0.0896 - weighted_f1score: 0.0017 - val_loss: 2.2512 - val_accuracy: 0.5132 - val_macro_f1score: 0.0849 - val_weighted_f1score: 0.0016\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 18/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.6230 - accuracy: 0.5984 - macro_f1score: 0.0954 - weighted_f1score: 0.0018\n",
      "Epoch 00018: val_loss improved from 2.25118 to 2.21026, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/018.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.51325 to 0.52480, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/018.h5\n",
      "382/382 [==============================] - 482s 1s/step - loss: 1.6230 - accuracy: 0.5984 - macro_f1score: 0.0954 - weighted_f1score: 0.0018 - val_loss: 2.2103 - val_accuracy: 0.5248 - val_macro_f1score: 0.0858 - val_weighted_f1score: 0.0017\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 19/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.5307 - accuracy: 0.6180 - macro_f1score: 0.1018 - weighted_f1score: 0.0020\n",
      "Epoch 00019: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.52480 to 0.52548, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/019.h5\n",
      "382/382 [==============================] - 462s 1s/step - loss: 1.5307 - accuracy: 0.6180 - macro_f1score: 0.1018 - weighted_f1score: 0.0020 - val_loss: 2.2420 - val_accuracy: 0.5255 - val_macro_f1score: 0.0916 - val_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 20/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.4259 - accuracy: 0.6426 - macro_f1score: 0.1071 - weighted_f1score: 0.0021\n",
      "Epoch 00020: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.52548\n",
      "382/382 [==============================] - 450s 1s/step - loss: 1.4259 - accuracy: 0.6426 - macro_f1score: 0.1071 - weighted_f1score: 0.0021 - val_loss: 2.2834 - val_accuracy: 0.5146 - val_macro_f1score: 0.0901 - val_weighted_f1score: 0.0017\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 21/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.3230 - accuracy: 0.6665 - macro_f1score: 0.1146 - weighted_f1score: 0.0022\n",
      "Epoch 00021: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.52548 to 0.53193, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/021.h5\n",
      "382/382 [==============================] - 456s 1s/step - loss: 1.3230 - accuracy: 0.6665 - macro_f1score: 0.1146 - weighted_f1score: 0.0022 - val_loss: 2.2258 - val_accuracy: 0.5319 - val_macro_f1score: 0.0941 - val_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 22/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.2503 - accuracy: 0.6776 - macro_f1score: 0.1176 - weighted_f1score: 0.0022\n",
      "Epoch 00022: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.53193 to 0.54280, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/022.h5\n",
      "382/382 [==============================] - 457s 1s/step - loss: 1.2503 - accuracy: 0.6776 - macro_f1score: 0.1176 - weighted_f1score: 0.0022 - val_loss: 2.2296 - val_accuracy: 0.5428 - val_macro_f1score: 0.0967 - val_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 23/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.1646 - accuracy: 0.6947 - macro_f1score: 0.1232 - weighted_f1score: 0.0023\n",
      "Epoch 00023: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.54280\n",
      "382/382 [==============================] - 446s 1s/step - loss: 1.1646 - accuracy: 0.6947 - macro_f1score: 0.1232 - weighted_f1score: 0.0023 - val_loss: 2.3099 - val_accuracy: 0.5353 - val_macro_f1score: 0.0955 - val_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 24/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.0872 - accuracy: 0.7155 - macro_f1score: 0.1291 - weighted_f1score: 0.0024\n",
      "Epoch 00024: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.54280\n",
      "382/382 [==============================] - 432s 1s/step - loss: 1.0872 - accuracy: 0.7155 - macro_f1score: 0.1291 - weighted_f1score: 0.0024 - val_loss: 2.2568 - val_accuracy: 0.5397 - val_macro_f1score: 0.0989 - val_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 25/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.0296 - accuracy: 0.7280 - macro_f1score: 0.1317 - weighted_f1score: 0.0025\n",
      "Epoch 00025: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.54280\n",
      "382/382 [==============================] - 426s 1s/step - loss: 1.0296 - accuracy: 0.7280 - macro_f1score: 0.1317 - weighted_f1score: 0.0025 - val_loss: 2.3152 - val_accuracy: 0.5391 - val_macro_f1score: 0.0972 - val_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 26/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.9456 - accuracy: 0.7426 - macro_f1score: 0.1385 - weighted_f1score: 0.0026\n",
      "Epoch 00026: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.54280 to 0.54586, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/026.h5\n",
      "382/382 [==============================] - 438s 1s/step - loss: 0.9456 - accuracy: 0.7426 - macro_f1score: 0.1385 - weighted_f1score: 0.0026 - val_loss: 2.3609 - val_accuracy: 0.5459 - val_macro_f1score: 0.1025 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 27/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.8658 - accuracy: 0.7658 - macro_f1score: 0.1439 - weighted_f1score: 0.0027\n",
      "Epoch 00027: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.54586\n",
      "382/382 [==============================] - 425s 1s/step - loss: 0.8658 - accuracy: 0.7658 - macro_f1score: 0.1439 - weighted_f1score: 0.0027 - val_loss: 2.4546 - val_accuracy: 0.5442 - val_macro_f1score: 0.1034 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 28/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.8155 - accuracy: 0.7731 - macro_f1score: 0.1463 - weighted_f1score: 0.0027\n",
      "Epoch 00028: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.54586 to 0.55333, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/028.h5\n",
      "382/382 [==============================] - 435s 1s/step - loss: 0.8155 - accuracy: 0.7731 - macro_f1score: 0.1463 - weighted_f1score: 0.0027 - val_loss: 2.4359 - val_accuracy: 0.5533 - val_macro_f1score: 0.1026 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 29/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7640 - accuracy: 0.7890 - macro_f1score: 0.1504 - weighted_f1score: 0.0028\n",
      "Epoch 00029: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.55333\n",
      "382/382 [==============================] - 422s 1s/step - loss: 0.7640 - accuracy: 0.7890 - macro_f1score: 0.1504 - weighted_f1score: 0.0028 - val_loss: 2.4678 - val_accuracy: 0.5428 - val_macro_f1score: 0.1019 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 30/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.7995 - macro_f1score: 0.1538 - weighted_f1score: 0.0029\n",
      "Epoch 00030: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.55333 to 0.55503, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/030.h5\n",
      "382/382 [==============================] - 433s 1s/step - loss: 0.7153 - accuracy: 0.7995 - macro_f1score: 0.1538 - weighted_f1score: 0.0029 - val_loss: 2.4959 - val_accuracy: 0.5550 - val_macro_f1score: 0.1043 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 31/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.8061 - macro_f1score: 0.1572 - weighted_f1score: 0.0029\n",
      "Epoch 00031: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.55503\n",
      "382/382 [==============================] - 422s 1s/step - loss: 0.6884 - accuracy: 0.8061 - macro_f1score: 0.1572 - weighted_f1score: 0.0029 - val_loss: 2.5072 - val_accuracy: 0.5520 - val_macro_f1score: 0.1056 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 32/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6319 - accuracy: 0.8224 - macro_f1score: 0.1609 - weighted_f1score: 0.0030\n",
      "Epoch 00032: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.55503 to 0.55605, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/032.h5\n",
      "382/382 [==============================] - 448s 1s/step - loss: 0.6319 - accuracy: 0.8224 - macro_f1score: 0.1609 - weighted_f1score: 0.0030 - val_loss: 2.5391 - val_accuracy: 0.5560 - val_macro_f1score: 0.1057 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 33/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6019 - accuracy: 0.8255 - macro_f1score: 0.1623 - weighted_f1score: 0.0030\n",
      "Epoch 00033: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.55605\n",
      "382/382 [==============================] - 422s 1s/step - loss: 0.6019 - accuracy: 0.8255 - macro_f1score: 0.1623 - weighted_f1score: 0.0030 - val_loss: 2.6117 - val_accuracy: 0.5499 - val_macro_f1score: 0.1050 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 34/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.8368 - macro_f1score: 0.1660 - weighted_f1score: 0.0031\n",
      "Epoch 00034: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.55605\n",
      "382/382 [==============================] - 424s 1s/step - loss: 0.5657 - accuracy: 0.8368 - macro_f1score: 0.1660 - weighted_f1score: 0.0031 - val_loss: 2.5836 - val_accuracy: 0.5530 - val_macro_f1score: 0.1056 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 35/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.8407 - macro_f1score: 0.1670 - weighted_f1score: 0.0031\n",
      "Epoch 00035: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.55605\n",
      "382/382 [==============================] - 423s 1s/step - loss: 0.5534 - accuracy: 0.8407 - macro_f1score: 0.1670 - weighted_f1score: 0.0031 - val_loss: 2.5619 - val_accuracy: 0.5513 - val_macro_f1score: 0.1052 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 36/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.8526 - macro_f1score: 0.1702 - weighted_f1score: 0.0032\n",
      "Epoch 00036: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.55605\n",
      "382/382 [==============================] - 430s 1s/step - loss: 0.5170 - accuracy: 0.8526 - macro_f1score: 0.1702 - weighted_f1score: 0.0032 - val_loss: 2.6669 - val_accuracy: 0.5445 - val_macro_f1score: 0.1047 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 37/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.4913 - accuracy: 0.8547 - macro_f1score: 0.1720 - weighted_f1score: 0.0032\n",
      "Epoch 00037: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.55605\n",
      "382/382 [==============================] - 425s 1s/step - loss: 0.4913 - accuracy: 0.8547 - macro_f1score: 0.1720 - weighted_f1score: 0.0032 - val_loss: 2.7142 - val_accuracy: 0.5465 - val_macro_f1score: 0.1038 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 38/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.5212 - accuracy: 0.8511 - macro_f1score: 0.1692 - weighted_f1score: 0.0032\n",
      "Epoch 00038: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.55605\n",
      "382/382 [==============================] - 432s 1s/step - loss: 0.5212 - accuracy: 0.8511 - macro_f1score: 0.1692 - weighted_f1score: 0.0032 - val_loss: 2.6921 - val_accuracy: 0.5510 - val_macro_f1score: 0.1069 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 39/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.4595 - accuracy: 0.8631 - macro_f1score: 0.1741 - weighted_f1score: 0.0032\n",
      "Epoch 00039: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.55605\n",
      "382/382 [==============================] - 442s 1s/step - loss: 0.4595 - accuracy: 0.8631 - macro_f1score: 0.1741 - weighted_f1score: 0.0032 - val_loss: 2.7532 - val_accuracy: 0.5506 - val_macro_f1score: 0.1082 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 40/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.8682 - macro_f1score: 0.1748 - weighted_f1score: 0.0032\n",
      "Epoch 00040: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.55605\n",
      "382/382 [==============================] - 439s 1s/step - loss: 0.4481 - accuracy: 0.8682 - macro_f1score: 0.1748 - weighted_f1score: 0.0032 - val_loss: 2.7788 - val_accuracy: 0.5462 - val_macro_f1score: 0.1052 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 41/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.8724 - macro_f1score: 0.1761 - weighted_f1score: 0.0033\n",
      "Epoch 00041: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.55605\n",
      "382/382 [==============================] - 444s 1s/step - loss: 0.4318 - accuracy: 0.8724 - macro_f1score: 0.1761 - weighted_f1score: 0.0033 - val_loss: 2.7685 - val_accuracy: 0.5499 - val_macro_f1score: 0.1065 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 42/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.8740 - macro_f1score: 0.1763 - weighted_f1score: 0.0033\n",
      "Epoch 00042: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.55605\n",
      "382/382 [==============================] - 437s 1s/step - loss: 0.4261 - accuracy: 0.8740 - macro_f1score: 0.1763 - weighted_f1score: 0.0033 - val_loss: 2.7572 - val_accuracy: 0.5557 - val_macro_f1score: 0.1078 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 43/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.4001 - accuracy: 0.8794 - macro_f1score: 0.1781 - weighted_f1score: 0.0033\n",
      "Epoch 00043: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.55605 to 0.55842, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/043.h5\n",
      "382/382 [==============================] - 458s 1s/step - loss: 0.4001 - accuracy: 0.8794 - macro_f1score: 0.1781 - weighted_f1score: 0.0033 - val_loss: 2.7703 - val_accuracy: 0.5584 - val_macro_f1score: 0.1094 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 44/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8870 - macro_f1score: 0.1805 - weighted_f1score: 0.0033\n",
      "Epoch 00044: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.55842\n",
      "382/382 [==============================] - 433s 1s/step - loss: 0.3826 - accuracy: 0.8870 - macro_f1score: 0.1805 - weighted_f1score: 0.0033 - val_loss: 2.7967 - val_accuracy: 0.5560 - val_macro_f1score: 0.1073 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 45/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.8914 - macro_f1score: 0.1816 - weighted_f1score: 0.0034\n",
      "Epoch 00045: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.55842\n",
      "382/382 [==============================] - 433s 1s/step - loss: 0.3690 - accuracy: 0.8914 - macro_f1score: 0.1816 - weighted_f1score: 0.0034 - val_loss: 2.7968 - val_accuracy: 0.5571 - val_macro_f1score: 0.1079 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 46/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.8913 - macro_f1score: 0.1823 - weighted_f1score: 0.0034\n",
      "Epoch 00046: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.55842\n",
      "382/382 [==============================] - 426s 1s/step - loss: 0.3712 - accuracy: 0.8913 - macro_f1score: 0.1823 - weighted_f1score: 0.0034 - val_loss: 2.7484 - val_accuracy: 0.5571 - val_macro_f1score: 0.1094 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 47/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8941 - macro_f1score: 0.1825 - weighted_f1score: 0.0034\n",
      "Epoch 00047: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.55842\n",
      "382/382 [==============================] - 425s 1s/step - loss: 0.3594 - accuracy: 0.8941 - macro_f1score: 0.1825 - weighted_f1score: 0.0034 - val_loss: 2.8175 - val_accuracy: 0.5537 - val_macro_f1score: 0.1061 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 48/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.8952 - macro_f1score: 0.1830 - weighted_f1score: 0.0034\n",
      "Epoch 00048: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00048: val_accuracy improved from 0.55842 to 0.56284, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/048.h5\n",
      "382/382 [==============================] - 434s 1s/step - loss: 0.3545 - accuracy: 0.8952 - macro_f1score: 0.1830 - weighted_f1score: 0.0034 - val_loss: 2.7803 - val_accuracy: 0.5628 - val_macro_f1score: 0.1089 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 49/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.8962 - macro_f1score: 0.1841 - weighted_f1score: 0.0034\n",
      "Epoch 00049: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.56284\n",
      "382/382 [==============================] - 434s 1s/step - loss: 0.3490 - accuracy: 0.8962 - macro_f1score: 0.1841 - weighted_f1score: 0.0034 - val_loss: 2.8697 - val_accuracy: 0.5584 - val_macro_f1score: 0.1072 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 50/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.3284 - accuracy: 0.9026 - macro_f1score: 0.1855 - weighted_f1score: 0.0034\n",
      "Epoch 00050: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.56284\n",
      "382/382 [==============================] - 437s 1s/step - loss: 0.3284 - accuracy: 0.9026 - macro_f1score: 0.1855 - weighted_f1score: 0.0034 - val_loss: 2.8455 - val_accuracy: 0.5543 - val_macro_f1score: 0.1101 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 51/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9755 - macro_f1score: 0.2051 - weighted_f1score: 0.0038\n",
      "Epoch 00051: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.56284\n",
      "382/382 [==============================] - 435s 1s/step - loss: 0.0827 - accuracy: 0.9755 - macro_f1score: 0.2051 - weighted_f1score: 0.0038 - val_loss: 2.9649 - val_accuracy: 0.5618 - val_macro_f1score: 0.1105 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 52/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9823 - macro_f1score: 0.2078 - weighted_f1score: 0.0038\n",
      "Epoch 00052: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.56284 to 0.56556, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/052.h5\n",
      "382/382 [==============================] - 447s 1s/step - loss: 0.0600 - accuracy: 0.9823 - macro_f1score: 0.2078 - weighted_f1score: 0.0038 - val_loss: 3.0192 - val_accuracy: 0.5656 - val_macro_f1score: 0.1111 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 53/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9858 - macro_f1score: 0.2083 - weighted_f1score: 0.0038\n",
      "Epoch 00053: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.56556\n",
      "382/382 [==============================] - 442s 1s/step - loss: 0.0507 - accuracy: 0.9858 - macro_f1score: 0.2083 - weighted_f1score: 0.0038 - val_loss: 3.0767 - val_accuracy: 0.5645 - val_macro_f1score: 0.1128 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 54/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9872 - macro_f1score: 0.2085 - weighted_f1score: 0.0038\n",
      "Epoch 00054: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.56556 to 0.56760, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/054.h5\n",
      "382/382 [==============================] - 440s 1s/step - loss: 0.0429 - accuracy: 0.9872 - macro_f1score: 0.2085 - weighted_f1score: 0.0038 - val_loss: 3.1228 - val_accuracy: 0.5676 - val_macro_f1score: 0.1135 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 55/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9892 - macro_f1score: 0.2094 - weighted_f1score: 0.0038\n",
      "Epoch 00055: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.56760\n",
      "382/382 [==============================] - 436s 1s/step - loss: 0.0374 - accuracy: 0.9892 - macro_f1score: 0.2094 - weighted_f1score: 0.0038 - val_loss: 3.1323 - val_accuracy: 0.5628 - val_macro_f1score: 0.1110 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 56/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9903 - macro_f1score: 0.2100 - weighted_f1score: 0.0038\n",
      "Epoch 00056: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.56760\n",
      "382/382 [==============================] - 426s 1s/step - loss: 0.0352 - accuracy: 0.9903 - macro_f1score: 0.2100 - weighted_f1score: 0.0038 - val_loss: 3.1072 - val_accuracy: 0.5639 - val_macro_f1score: 0.1122 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 57/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9899 - macro_f1score: 0.2094 - weighted_f1score: 0.0038\n",
      "Epoch 00057: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.56760\n",
      "382/382 [==============================] - 432s 1s/step - loss: 0.0342 - accuracy: 0.9899 - macro_f1score: 0.2094 - weighted_f1score: 0.0038 - val_loss: 3.1350 - val_accuracy: 0.5669 - val_macro_f1score: 0.1111 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 58/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9924 - macro_f1score: 0.2100 - weighted_f1score: 0.0039\n",
      "Epoch 00058: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00058: val_accuracy improved from 0.56760 to 0.56861, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/058.h5\n",
      "382/382 [==============================] - 446s 1s/step - loss: 0.0282 - accuracy: 0.9924 - macro_f1score: 0.2100 - weighted_f1score: 0.0039 - val_loss: 3.1610 - val_accuracy: 0.5686 - val_macro_f1score: 0.1136 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 59/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9930 - macro_f1score: 0.2109 - weighted_f1score: 0.0039\n",
      "Epoch 00059: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00059: val_accuracy improved from 0.56861 to 0.57167, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/059.h5\n",
      "382/382 [==============================] - 445s 1s/step - loss: 0.0268 - accuracy: 0.9930 - macro_f1score: 0.2109 - weighted_f1score: 0.0039 - val_loss: 3.1867 - val_accuracy: 0.5717 - val_macro_f1score: 0.1139 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 60/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9927 - macro_f1score: 0.2104 - weighted_f1score: 0.0039\n",
      "Epoch 00060: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00060: val_accuracy improved from 0.57167 to 0.57439, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/060.h5\n",
      "382/382 [==============================] - 445s 1s/step - loss: 0.0276 - accuracy: 0.9927 - macro_f1score: 0.2104 - weighted_f1score: 0.0039 - val_loss: 3.1639 - val_accuracy: 0.5744 - val_macro_f1score: 0.1135 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 61/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9922 - macro_f1score: 0.2099 - weighted_f1score: 0.0039\n",
      "Epoch 00061: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.57439\n",
      "382/382 [==============================] - 442s 1s/step - loss: 0.0288 - accuracy: 0.9922 - macro_f1score: 0.2099 - weighted_f1score: 0.0039 - val_loss: 3.2292 - val_accuracy: 0.5659 - val_macro_f1score: 0.1135 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 62/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9932 - macro_f1score: 0.2109 - weighted_f1score: 0.0039\n",
      "Epoch 00062: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00062: val_accuracy improved from 0.57439 to 0.57948, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/062.h5\n",
      "382/382 [==============================] - 450s 1s/step - loss: 0.0252 - accuracy: 0.9932 - macro_f1score: 0.2109 - weighted_f1score: 0.0039 - val_loss: 3.1712 - val_accuracy: 0.5795 - val_macro_f1score: 0.1140 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 63/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9934 - macro_f1score: 0.2105 - weighted_f1score: 0.0039\n",
      "Epoch 00063: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00063: val_accuracy improved from 0.57948 to 0.58050, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/ResNext18/063.h5\n",
      "382/382 [==============================] - 449s 1s/step - loss: 0.0244 - accuracy: 0.9934 - macro_f1score: 0.2105 - weighted_f1score: 0.0039 - val_loss: 3.2551 - val_accuracy: 0.5805 - val_macro_f1score: 0.1156 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 64/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9933 - macro_f1score: 0.2093 - weighted_f1score: 0.0039\n",
      "Epoch 00064: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.58050\n",
      "382/382 [==============================] - 442s 1s/step - loss: 0.0246 - accuracy: 0.9933 - macro_f1score: 0.2093 - weighted_f1score: 0.0039 - val_loss: 3.2277 - val_accuracy: 0.5717 - val_macro_f1score: 0.1149 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 65/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9934 - macro_f1score: 0.2093 - weighted_f1score: 0.0039\n",
      "Epoch 00065: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.58050\n",
      "382/382 [==============================] - 442s 1s/step - loss: 0.0242 - accuracy: 0.9934 - macro_f1score: 0.2093 - weighted_f1score: 0.0039 - val_loss: 3.2197 - val_accuracy: 0.5727 - val_macro_f1score: 0.1133 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 66/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9921 - macro_f1score: 0.2100 - weighted_f1score: 0.0039\n",
      "Epoch 00066: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.58050\n",
      "382/382 [==============================] - 452s 1s/step - loss: 0.0268 - accuracy: 0.9921 - macro_f1score: 0.2100 - weighted_f1score: 0.0039 - val_loss: 3.2766 - val_accuracy: 0.5720 - val_macro_f1score: 0.1140 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 67/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9927 - macro_f1score: 0.2093 - weighted_f1score: 0.0039\n",
      "Epoch 00067: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.58050\n",
      "382/382 [==============================] - 443s 1s/step - loss: 0.0271 - accuracy: 0.9927 - macro_f1score: 0.2093 - weighted_f1score: 0.0039 - val_loss: 3.2295 - val_accuracy: 0.5774 - val_macro_f1score: 0.1144 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 68/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9933 - macro_f1score: 0.2110 - weighted_f1score: 0.0039\n",
      "Epoch 00068: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.58050\n",
      "382/382 [==============================] - 437s 1s/step - loss: 0.0245 - accuracy: 0.9933 - macro_f1score: 0.2110 - weighted_f1score: 0.0039 - val_loss: 3.2562 - val_accuracy: 0.5734 - val_macro_f1score: 0.1130 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 69/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9928 - macro_f1score: 0.2110 - weighted_f1score: 0.0039\n",
      "Epoch 00069: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.58050\n",
      "382/382 [==============================] - 436s 1s/step - loss: 0.0251 - accuracy: 0.9928 - macro_f1score: 0.2110 - weighted_f1score: 0.0039 - val_loss: 3.2617 - val_accuracy: 0.5713 - val_macro_f1score: 0.1112 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 70/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9939 - macro_f1score: 0.2109 - weighted_f1score: 0.0039\n",
      "Epoch 00070: val_loss did not improve from 2.21026\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.58050\n",
      "382/382 [==============================] - 436s 1s/step - loss: 0.0234 - accuracy: 0.9939 - macro_f1score: 0.2109 - weighted_f1score: 0.0039 - val_loss: 3.2454 - val_accuracy: 0.5690 - val_macro_f1score: 0.1112 - val_weighted_f1score: 0.0022\n"
     ]
    }
   ],
   "source": [
    "######## flow_from_directory\n",
    "history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAr6jLIR1qmu"
   },
   "source": [
    "### 2) ResNext18 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49667265,
     "status": "ok",
     "timestamp": 1599363376399,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "ZvKx1in81qmu",
    "outputId": "54370e45-27a8-4dec-eda3-64e8c22fcb34",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1204s 25s/step - loss: 3.3397 - accuracy: 0.5618 - macro_f1score: 0.1101 - weighted_f1score: 0.0021\n",
      "[Test Loss: 3.3397 /  Test Accuracy: 0.5618 / Test Macro f1: 0.1101 / Test Weighted f1: 0.0021]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. epoch=maximum\n",
    "loss , acc, mf1, wf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n",
    "print('[Test Loss: %.4f /  Test Accuracy: %.4f / Test Macro f1: %.4f / Test Weighted f1: %.4f]\\n' % (loss,acc,mf1,wf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fbdRXP391qmx"
   },
   "outputs": [],
   "source": [
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "f1=history.history['macro_f1score']\n",
    "val_f1=history.history['val_macro_f1score']\n",
    "epochs=range(1,len(acc)+1)\n",
    "\n",
    "data = np.array([epochs,loss,val_loss,acc,val_acc,f1,val_f1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gRtTWKDk1qm0"
   },
   "outputs": [],
   "source": [
    "# data save\n",
    "# epochs, loss, val_loss, acc, val_acc, f1, val_f1\n",
    "\n",
    "np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lB5x2Y_1qm3"
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'ResNext18.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQVReEQO1qm5"
   },
   "outputs": [],
   "source": [
    "epochs=data[:,0]\n",
    "loss=data[:,1]\n",
    "val_loss=data[:,2]\n",
    "acc=data[:,3]\n",
    "val_acc=data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49667808,
     "status": "ok",
     "timestamp": 1599363377116,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "16331884730664529787"
     },
     "user_tz": -540
    },
    "id": "kEBcd6Hx1qm8",
    "outputId": "f3d1c3da-72ab-4403-9974-5340ef218400"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs[1:],acc[1:],'b',label='Training Acc')\n",
    "plt.plot(epochs[1:],val_acc[1:],'r',label='Validation Acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n",
    "plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jkbe4ajm1qnG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLDgyUtp1qnJ"
   },
   "outputs": [],
   "source": [
    "# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / resnext18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(os.path.join(dir,'model_output',number,'ResNext18','026.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"weighted_f1score\":weighted_f1score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0IvhWkE1qnN"
   },
   "outputs": [],
   "source": [
    "# 2. epoch=?\n",
    "loss , acc, mf1, wf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n",
    "print('[Test Loss: %.4f /  Test Accuracy: %.4f / Test Macro f1: %.4f / Test Weighted f1: %.4f]\\n' % (loss,acc,mf1,wf1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "10.ResNext18.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
