{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Niut7KgwYC9f"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://sike6054.github.io/blog/paper/third-post/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwVmRuFcUBkT"
   },
   "source": [
    "# [Inception V2 & V3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0MMz6DhUBkW"
   },
   "source": [
    "*KU LeeDongGyu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ywk25Fr79dWe"
   },
   "source": [
    "## Contents\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSON5xiR9dWf"
   },
   "source": [
    "1. Data Preprocessing\n",
    "```\n",
    "1) Data Import\n",
    "2) Data Augmentation\n",
    "```\n",
    "2. Support Functions & Almost Original Inception-V2,V3 (Especially V3)\n",
    "```\n",
    "1) Support Functions\n",
    "2) Almost Original Inception-V2,V3 (Especially V3)\n",
    "3) Inception-V3 Evaluate\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U01q4o40UBkY"
   },
   "source": [
    "### Install Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjdygsS_UBke"
   },
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63949,
     "status": "ok",
     "timestamp": 1599313675025,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "o1tpIlBhXG2i",
    "outputId": "b93d23f6-e415-4b79-fed9-2af58c9c9781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63934,
     "status": "ok",
     "timestamp": 1599313675029,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "IJdbC2nRXR6h",
    "outputId": "d96e3385-5b1b-4590-ec59-f4420fe4d2fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/Paper\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/Colab Notebooks/Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I98omoQ8FF90"
   },
   "outputs": [],
   "source": [
    "from f1score import macro_f1score,weighted_f1score\n",
    "from smoothed_categorical_crossentropy import smoothed_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKLMWqbuUBkf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l1,l2,l1_l2\n",
    "from tensorflow.keras.models import Model , load_model , Sequential\n",
    "from tensorflow.keras.utils import plot_model , to_categorical, get_file\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67714,
     "status": "ok",
     "timestamp": 1599313678853,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "cbiFovMgXTax",
    "outputId": "51f696b4-152b-4269-e940-d9e56534359d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/Paper'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67699,
     "status": "ok",
     "timestamp": 1599313678854,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "AcT0A_iwEzaZ",
    "outputId": "762aee3b-6541-4eb2-8153-62193d7cebe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(ks.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73458,
     "status": "ok",
     "timestamp": 1599313684633,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "Gr5hMHvmABmG",
    "outputId": "38303695-182f-441f-f3a0-711a7cd63844"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73437,
     "status": "ok",
     "timestamp": 1599313684634,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "XnsLRqeZshyE",
    "outputId": "0a8b75a5-4782-407b-a6eb-3226def542a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6899574018505426412\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7418864200625936407\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16375801416786844217\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15695549568\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4302119121385573001\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTXnS6_magkg"
   },
   "source": [
    "## 1. Data Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWigHOuzCRRj"
   },
   "source": [
    "### 1) Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e7tXq8Uo6i7n"
   },
   "outputs": [],
   "source": [
    "# 바꿔서 살펴 볼 것들\n",
    "# CALTECH, CIFAR100, FER, MIT\n",
    "data_name = 'CALTECH'\n",
    "gan_type = 'No_GAN'\n",
    "number = '1'\n",
    "size = 299 # sizes after cropping\n",
    "super_size = 330 # sizes before cropping \n",
    "input_sizes = (size,size,3)\n",
    "batch_sizes = 64\n",
    "weight_decay = 0\n",
    "epochs = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPnWxfGzLOF6"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n",
    "# setting the seed number for random number generation for reproducibility.\n",
    "\n",
    "from numpy.random import seed\n",
    "import random\n",
    "\n",
    "\n",
    "if number=='1':\n",
    "    seed_num = 200225\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='2':\n",
    "    seed_num = 727\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='3':\n",
    "    seed_num = 115\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='4':\n",
    "    seed_num = 501\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='5':\n",
    "    seed_num = 517\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0mX9XhJp38S"
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "\n",
    "if data_name=='FER' :\n",
    "    x_train =  np.zeros(28698)\n",
    "    x_valid = np.zeros(3589)\n",
    "    x_test = np.zeros(3588)\n",
    "    classes = 7 \n",
    "    tr_center = [0.50793296, 0.50793296, 0.50793296]\n",
    "elif data_name=='MIT':\n",
    "    x_train = np.zeros(12466)\n",
    "    x_valid = np.zeros(1564)\n",
    "    x_test = np.zeros(1590)\n",
    "    classes = 67 \n",
    "    tr_center = [0.47916578, 0.42029615, 0.36046057]\n",
    "elif data_name=='CALTECH':\n",
    "    x_train = np.zeros(24510)\n",
    "    x_valid = np.zeros(2980)\n",
    "    x_test = np.zeros(3118)\n",
    "    classes = 257\n",
    "    tr_center = [0.51397761, 0.49525248, 0.46555727]\n",
    "elif data_name=='CIFAR100':\n",
    "    x_train = np.zeros(39941)\n",
    "    x_valid = np.zeros(10059)\n",
    "    x_test = np.zeros(10000)\n",
    "    classes = 100\n",
    "    tr_center = [0.53393271, 0.51324147, 0.46450563]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQlStjHWt-jM"
   },
   "outputs": [],
   "source": [
    "dir = os.path.join(os.getcwd(),data_name,gan_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceg0S7aKp38b"
   },
   "source": [
    "### 2) Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aTD7m_FRp38c"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n",
    "\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EW0KZ6x9EBtf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
    "import glob\n",
    "\n",
    "# 데이터 전체에 대해 centering 진행함.\n",
    "\n",
    "def read_cal_image(img_path): \n",
    "    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n",
    "    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n",
    "\n",
    "    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n",
    "    x = np.mean(x, axis=(0,1))\n",
    "    \n",
    "    return np.hstack([x,y])\n",
    "\n",
    "def calculate_centered_mean(dataset_path,x_train=x_train):\n",
    "    num = len(x_train)\n",
    "    space = np.empty((num,4))\n",
    "    i=0\n",
    "\n",
    "    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n",
    "        space[i] = read_cal_image(p)\n",
    "        i += 1\n",
    "\n",
    "    ratio = space[:,3] / np.sum(space[:,3])\n",
    "\n",
    "    return np.average(space[:,0:3],axis=0,weights=ratio)\n",
    "\n",
    "\n",
    "# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n",
    "\n",
    "# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRUFnlHG8dQ0"
   },
   "outputs": [],
   "source": [
    "datagen_tr = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=[0.9,1.0],\n",
    "    fill_mode = 'nearest')\n",
    "datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n",
    "datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n",
    "\n",
    "# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n",
    "\n",
    "# 중심화 설정\n",
    "datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n",
    "datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n",
    "datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RldjwO4M8_o"
   },
   "outputs": [],
   "source": [
    "# Inception-V2 & V3은 분류기가 2개이므로 imagedatagenerator 사용방법이 다소 다르다.\n",
    "# model.fit에 다중 input으로 들어갈 함수를 개인이 만들어서 사용해야 하며, 그 함수는 아래와 같다. \n",
    "# 매우 간단하다.\n",
    "\n",
    "#1. train data\n",
    "\n",
    "def generate_train_for_two(crop_length=size, batch_sizes = batch_sizes, super_size=super_size):\n",
    "\n",
    "      batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical')\n",
    "\n",
    "      while True:\n",
    "          batch_x, batch_y = next(batches)\n",
    "          batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "          for i in range(batch_x.shape[0]):\n",
    "              batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "          yield batch_crops, [batch_y,batch_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOMw3HckS2s7"
   },
   "outputs": [],
   "source": [
    "# 2. valid data\n",
    "\n",
    "def generate_valid_for_two(size=size, batch_sizes = batch_sizes):\n",
    "\n",
    "      batches_xy = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical')\n",
    "\n",
    "      while True:\n",
    "\n",
    "          batch_xy = batches_xy.next()\n",
    "          yield  batch_xy[0], [ batch_xy[1],batch_xy[1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9b1IYipXs77c"
   },
   "outputs": [],
   "source": [
    "# 3. test data\n",
    "\n",
    "def generate_test_for_two(size=size, batch_sizes = batch_sizes):\n",
    "\n",
    "      batches_xy = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical')\n",
    "\n",
    "      while True:\n",
    "\n",
    "          batch_xy = batches_xy.next()\n",
    "          yield  batch_xy[0], [ batch_xy[1],batch_xy[1] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1y7yDqL99c32"
   },
   "outputs": [],
   "source": [
    "# 위에서 쓰임\n",
    "# train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 39941\n",
    "# train_generator= crop_generator(train_batches, size)\n",
    "\n",
    "# valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 10059\n",
    "# test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "afa9Vvwdw1te"
   },
   "source": [
    "## 2. Support Functions & Almost Original Inception-V2,V3 (Especially V3)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iER-OGdBw1tf"
   },
   "source": [
    "### 1) Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA3sqFv_ZyBS"
   },
   "outputs": [],
   "source": [
    "# def lr_schedule(epoch):\n",
    "#     init_lr = 1e-4\n",
    "#     k = 0.04\n",
    "#     lr = init_lr * np.exp(-k*epoch)\n",
    "#     print('Learning rate: ', lr)\n",
    "#     return lr\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch < 60:\n",
    "        lr = lr\n",
    "    else :\n",
    "        lr = lr * 0.1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQbPLRiXYC93"
   },
   "outputs": [],
   "source": [
    "def smoothed_categorical_crossentropy(y_true, y_pred): \n",
    "    if smoothing_param > 0:\n",
    "        smooth_positives = 1.0 - smoothing_param \n",
    "        smooth_negatives = smoothing_param / classes \n",
    "        y_true = y_true * smooth_positives + smooth_negatives \n",
    "\n",
    "    return K.categorical_crossentropy(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLdWrNlBYC9l"
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, filters, kernel_size, weight_decay=weight_decay, padding='same', strides=1, activation='relu'):\n",
    "    x = Conv2D(filters, (kernel_size[0], kernel_size[1]), padding=padding, strides=strides, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if activation:\n",
    "        x = Activation(activation)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BAel4PLPYC9p"
   },
   "outputs": [],
   "source": [
    "def inception_f3(input_tensor, filter_channels, name=None):\n",
    "    filter_b1, filter_b2, filter_b3, filter_b4 = filter_channels\n",
    "    \n",
    "    branch_1 = conv2d_bn(input_tensor, filter_b1[0], (1, 1))\n",
    "    branch_1 = conv2d_bn(branch_1, filter_b1[1], (3, 3))\n",
    "    branch_1 = conv2d_bn(branch_1, filter_b1[2], (3, 3))\n",
    "    \n",
    "    branch_2 = conv2d_bn(input_tensor, filter_b2[0], (1, 1))\n",
    "    branch_2 = conv2d_bn(branch_2, filter_b2[1], (3, 3))\n",
    "    \n",
    "    branch_3 = MaxPooling2D((3, 3), strides=1, padding='same')(input_tensor)\n",
    "    branch_3 = conv2d_bn(branch_3, filter_b3, (1, 1))\n",
    "    \n",
    "    branch_4 = conv2d_bn(input_tensor, filter_b4, (1, 1))\n",
    "    \n",
    "    filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3, branch_4]) if not name==None else Concatenate()([branch_1, branch_2, branch_3, branch_4])\n",
    "    \n",
    "    return filter_concat\n",
    "\n",
    "def inception_f6(input_tensor, filter_channels, n=7, name=None):\n",
    "    filter_b1, filter_b2, filter_b3, filter_b4 = filter_channels\n",
    "    \n",
    "    branch_1 = conv2d_bn(input_tensor, filter_b1[0], (1, 1))\n",
    "    branch_1 = conv2d_bn(branch_1, filter_b1[1], (1, n))\n",
    "    branch_1 = conv2d_bn(branch_1, filter_b1[2], (n, 1))\n",
    "    branch_1 = conv2d_bn(branch_1, filter_b1[3], (1, n))\n",
    "    branch_1 = conv2d_bn(branch_1, filter_b1[4], (n, 1))\n",
    "    \n",
    "    branch_2 = conv2d_bn(input_tensor, filter_b2[0], (1, 1))\n",
    "    branch_2 = conv2d_bn(branch_2, filter_b2[1], (1, n))\n",
    "    branch_2 = conv2d_bn(branch_2, filter_b2[2], (n, 1))\n",
    "    \n",
    "    branch_3 = MaxPooling2D((3, 3), strides=1, padding='same')(input_tensor)\n",
    "    branch_3 = conv2d_bn(branch_3, filter_b3, (1, 1))\n",
    "    \n",
    "    branch_4 = conv2d_bn(input_tensor, filter_b4, (1, 1))\n",
    "    \n",
    "    filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3, branch_4]) if not name==None else Concatenate()([branch_1, branch_2, branch_3, branch_4])\n",
    "    \n",
    "    return filter_concat\n",
    "\n",
    "def inception_f10(input_tensor, filter_channels, name=None):\n",
    "    filter_b1, filter_b2, filter_b3, filter_b4 = filter_channels\n",
    "    \n",
    "    branch_1 = conv2d_bn(input_tensor, filter_b1[0], (1, 1))\n",
    "    branch_1 = conv2d_bn(branch_1, filter_b1[1], (3, 3))\n",
    "    branch_1a = conv2d_bn(branch_1, filter_b1[2][0], (1, 3))\n",
    "    branch_1b = conv2d_bn(branch_1, filter_b1[2][1], (3, 1))\n",
    "    branch_1 = Concatenate()([branch_1a, branch_1b])\n",
    "    \n",
    "    branch_2 = conv2d_bn(input_tensor, filter_b2[0], (1, 1))\n",
    "    branch_2a = conv2d_bn(branch_2, filter_b2[1][0], (1, 3))\n",
    "    branch_2b = conv2d_bn(branch_2, filter_b2[1][1], (3, 1))\n",
    "    branch_2 = Concatenate()([branch_2a, branch_2b])\n",
    "    \n",
    "    branch_3 = MaxPooling2D((3, 3), strides=1, padding='same')(input_tensor)\n",
    "    branch_3 = conv2d_bn(branch_3, filter_b3, (1, 1))\n",
    "    \n",
    "    branch_4 = conv2d_bn(input_tensor, filter_b4, (1, 1))\n",
    "    \n",
    "    filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3, branch_4]) if not name==None else Concatenate()([branch_1, branch_2, branch_3, branch_4])\n",
    "    \n",
    "    return filter_concat\n",
    "    \n",
    "def inception_dim_reduction(input_tensor, filter_channels, name=None):\n",
    "    filter_b1, filter_b2 = filter_channels\n",
    "    \n",
    "    branch_1 = conv2d_bn(input_tensor, filter_b1[0], (1, 1))\n",
    "    branch_1 = conv2d_bn(branch_1, filter_b1[1], (3, 3))\n",
    "    branch_1 = conv2d_bn(branch_1, filter_b1[2], (3, 3), strides=2)\n",
    "    \n",
    "    branch_2 = conv2d_bn(input_tensor, filter_b2[0], (1, 1))\n",
    "    branch_2 = conv2d_bn(branch_2, filter_b2[1], (3, 3), strides=2)\n",
    "    \n",
    "    branch_3 = MaxPooling2D((3, 3), strides=2, padding='same')(input_tensor)\n",
    "    \n",
    "    filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3]) if not name==None else Concatenate()([branch_1, branch_2, branch_3])\n",
    "    \n",
    "    return filter_concat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJixgnY7Z6j7"
   },
   "source": [
    "### 2) Almost Original Inception-V2,V3 (Especially V3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J516-iutYC9s"
   },
   "outputs": [],
   "source": [
    "def Inception_v3(model_input, name):\n",
    "    x = conv2d_bn(model_input, 32, (3, 3), padding='valid', strides=2) # (299, 299, 3) -> (149, 149, 32)\n",
    "    x = conv2d_bn(x, 32, (3, 3), padding='valid') # (147, 147, 32) -> (147, 147, 32)\n",
    "    x = conv2d_bn(x, 64, (3, 3), padding='same') # (147, 147, 32) -> (147, 147, 64)\n",
    "    \n",
    "    x = MaxPooling2D((3, 3), strides=2, padding='valid')(x) # (147, 147, 64) -> (73, 73, 64)\n",
    "    \n",
    "    x = conv2d_bn(x, 80, (3, 3), padding='valid') # (73, 73, 64) -> (71, 71, 80)\n",
    "    x = conv2d_bn(x, 192, (3, 3), padding='valid', strides=2) # (71, 71, 80) -> (35, 35, 192)\n",
    "    x = conv2d_bn(x, 288, (3, 3), padding='same') # (35, 35, 192) -> (35, 35, 288)\n",
    "    \n",
    "    x = inception_f3(x, [[64, 96, 96], [48, 64], 64 , 64]) # (35, 35, 288)\n",
    "    x = inception_f3(x, [[64, 96, 96], [48, 64], 64 , 64]) # (35, 35, 288)\n",
    "    x = inception_f3(x, [[64, 96, 96], [48, 64], 64 , 64], name='block_inception_f3') # (35, 35, 288)\n",
    "    \n",
    "    x = inception_dim_reduction(x, [[64, 96, 96], [256, 384]], name='block_reduction_1') # (35, 35, 288) -> (17, 17, 768)\n",
    "    \n",
    "    x = inception_f6(x, [[128, 128, 128, 128, 192], [128, 128, 192], 192, 192]) # (17, 17, 768)\n",
    "    x = inception_f6(x, [[160, 160, 160, 160, 192], [160, 160, 192], 192, 192]) # (17, 17, 768)\n",
    "    x = inception_f6(x, [[160, 160, 160, 160, 192], [160, 160, 192], 192, 192]) # (17, 17, 768)\n",
    "    x = inception_f6(x, [[192, 192, 192, 192, 192], [192, 192, 192], 192, 192]) # (17, 17, 768)\n",
    "    x_a = inception_f6(x, [[192, 192, 192, 192, 192], [192, 192, 192], 192, 192], name='block_inception_f6') # (17, 17, 768)\n",
    "    \n",
    "    x = inception_dim_reduction(x_a, [[128, 192, 192], [192, 320]], name='block_reduction_2') # (17, 17, 768) -> (8, 8, 1280)\n",
    "    \n",
    "    x = inception_f10(x, [[448, 384, [384, 384]], [384, [384, 384]], 192, 320]) # (8, 8, 1280) -> (8, 8, 2048)\n",
    "    x = inception_f10(x, [[448, 384, [384, 384]], [384, [384, 384]], 192, 320], name='block_inception_f10') # (8, 8, 2048)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "    \n",
    "    x = Dense(classes, activation=None)(x)\n",
    "    \n",
    "    model_output = Dense(classes, activation='softmax', name='main_classifier')(x) # 'softmax'\n",
    "    \n",
    "    # Auxiliary Classifier\n",
    "    auxiliary = AveragePooling2D((5, 5), strides=3, padding='valid')(x_a) # (17, 17, 768) -> (5, 5, 768)\n",
    "    auxiliary = conv2d_bn(auxiliary, 128, (1, 1)) # (5, 5, 768) -> (5, 5, 128)\n",
    "    \n",
    "    auxiliary = conv2d_bn(auxiliary, 1024, K.int_shape(auxiliary)[1:3], padding='valid') # (5, 5, 768) -> (1, 1, 1024)\n",
    "    auxiliary = Flatten()(auxiliary) # (1, 1, 1024)\n",
    "    auxiliary_output = Dense(classes, activation='softmax', name='auxiliary_classifier')(auxiliary)\n",
    "    \n",
    "    model = Model(model_input, [model_output, auxiliary_output],name=name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMlKGzMDOnOR"
   },
   "outputs": [],
   "source": [
    "smoothing_param = 0.1\n",
    "model_input = Input(shape=input_sizes)\n",
    "model = Inception_v3(model_input, name = \"Inception_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76212,
     "status": "ok",
     "timestamp": 1599313687761,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "0HuelUizNJWz",
    "outputId": "df058dc6-4f34-4582-fa9a-41e8f58db40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18496       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 71, 71, 80)   46160       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 71, 71, 80)   320         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 71, 71, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 35, 35, 192)  138432      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 35, 35, 192)  768         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 35, 35, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 288)  497952      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 288)  1152        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 288)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   18496       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 96)   55392       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 48)   13872       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 96)   384         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 48)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 96)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 48)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 288)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 96)   83040       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 64)   27712       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   18496       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 96)   384         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 96)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 35, 35, 288)  0           activation_8[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   18496       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 96)   55392       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 48)   13872       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 96)   384         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 48)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 96)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 288)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 96)   83040       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 64)   27712       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18496       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 96)   384         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 96)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 35, 35, 288)  0           activation_15[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18496       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 96)   55392       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 48)   13872       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 96)   384         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 48)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 96)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 35, 35, 288)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 96)   83040       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 64)   27712       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18496       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 96)   384         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 96)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_inception_f3 (Concatenate (None, 35, 35, 288)  0           activation_22[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18496       block_inception_f3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55392       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 256)  73984       block_inception_f3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   384         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 35, 35, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 256)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 18, 18, 96)   83040       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 18, 18, 384)  885120      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 18, 18, 96)   384         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 18, 18, 384)  1536        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 18, 18, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 18, 18, 384)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 18, 18, 288)  0           block_inception_f3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_reduction_1 (Concatenate) (None, 18, 18, 768)  0           activation_29[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 18, 18, 128)  98432       block_reduction_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 18, 18, 128)  512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 18, 18, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 18, 18, 128)  114816      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 18, 18, 128)  512         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 18, 18, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 18, 18, 128)  114816      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 18, 18, 128)  98432       block_reduction_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 18, 18, 128)  512         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 18, 18, 128)  512         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 18, 18, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 18, 18, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 18, 18, 128)  114816      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 18, 18, 128)  114816      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 18, 18, 128)  512         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 18, 18, 128)  512         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 18, 18, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 18, 18, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 18, 18, 768)  0           block_reduction_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 18, 18, 192)  172224      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 18, 18, 192)  172224      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 18, 18, 192)  147648      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 18, 18, 192)  147648      block_reduction_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 18, 18, 192)  768         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 18, 18, 192)  768         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 18, 18, 192)  768         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 18, 18, 192)  768         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 18, 18, 192)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 18, 18, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 18, 18, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 18, 18, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 18, 18, 768)  0           activation_36[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 18, 18, 160)  123040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 18, 18, 160)  640         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 18, 18, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 18, 18, 160)  179360      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 18, 18, 160)  640         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 18, 18, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 18, 18, 160)  179360      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 18, 18, 160)  123040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 18, 18, 160)  640         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 18, 18, 160)  640         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 18, 18, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 18, 18, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 18, 18, 160)  179360      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 18, 18, 160)  179360      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 18, 18, 160)  640         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 18, 18, 160)  640         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 18, 18, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 18, 18, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 18, 18, 768)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 18, 18, 192)  215232      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 18, 18, 192)  215232      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 18, 18, 192)  147648      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 18, 18, 192)  147648      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 18, 18, 192)  768         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 18, 18, 192)  768         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 18, 18, 192)  768         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 18, 18, 192)  768         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 18, 18, 192)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 18, 18, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 18, 18, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 18, 18, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 18, 18, 768)  0           activation_46[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 18, 18, 160)  123040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 18, 18, 160)  640         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 18, 18, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 18, 18, 160)  179360      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 18, 18, 160)  640         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 18, 18, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 18, 18, 160)  179360      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 18, 18, 160)  123040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 18, 18, 160)  640         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 18, 18, 160)  640         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 18, 18, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 18, 18, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 18, 18, 160)  179360      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 18, 18, 160)  179360      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 18, 18, 160)  640         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 18, 18, 160)  640         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 18, 18, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 18, 18, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 18, 18, 768)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 18, 18, 192)  215232      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 18, 18, 192)  215232      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 18, 18, 192)  147648      max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 18, 18, 192)  147648      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 18, 18, 192)  768         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 18, 18, 192)  768         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 18, 18, 192)  768         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 18, 18, 192)  768         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 18, 18, 192)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 18, 18, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 18, 18, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 18, 18, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 18, 18, 768)  0           activation_56[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 18, 18, 192)  147648      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 18, 18, 192)  768         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 18, 18, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 18, 18, 192)  258240      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 18, 18, 192)  768         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 18, 18, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 18, 18, 192)  258240      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 18, 18, 192)  147648      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 18, 18, 192)  768         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 18, 18, 192)  768         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 18, 18, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 18, 18, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 18, 18, 192)  258240      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 18, 18, 192)  258240      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 18, 18, 192)  768         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 18, 18, 192)  768         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 18, 18, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 18, 18, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 18, 18, 768)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 18, 18, 192)  258240      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 18, 18, 192)  258240      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 18, 18, 192)  147648      max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 18, 18, 192)  147648      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 18, 18, 192)  768         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 18, 18, 192)  768         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 18, 18, 192)  768         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 18, 18, 192)  768         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 18, 18, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 18, 18, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 18, 18, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 18, 18, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 18, 18, 768)  0           activation_66[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 18, 18, 192)  147648      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 18, 18, 192)  768         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 18, 18, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 18, 18, 192)  258240      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 18, 18, 192)  768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 18, 18, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 18, 18, 192)  258240      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 18, 18, 192)  147648      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 18, 18, 192)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 18, 18, 192)  768         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 18, 18, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 18, 18, 192)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 18, 18, 192)  258240      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 18, 18, 192)  258240      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 18, 18, 192)  768         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 18, 18, 192)  768         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 18, 18, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 18, 18, 192)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 18, 18, 768)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 18, 18, 192)  258240      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 18, 18, 192)  258240      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 18, 18, 192)  147648      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 18, 18, 192)  147648      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 18, 18, 192)  768         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 18, 18, 192)  768         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 18, 18, 192)  768         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 18, 18, 192)  768         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 18, 18, 192)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 18, 18, 192)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 18, 18, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 18, 18, 192)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_inception_f6 (Concatenate (None, 18, 18, 768)  0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "                                                                 activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 18, 18, 128)  98432       block_inception_f6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 18, 18, 128)  512         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 18, 18, 128)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 18, 18, 192)  221376      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 18, 18, 192)  147648      block_inception_f6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 18, 18, 192)  768         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 18, 18, 192)  768         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 18, 18, 192)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 18, 18, 192)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 9, 9, 192)    331968      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 9, 9, 320)    553280      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 9, 9, 192)    768         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 9, 9, 320)    1280        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 9, 9, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 9, 9, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 9, 9, 768)    0           block_inception_f6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_reduction_2 (Concatenate) (None, 9, 9, 1280)   0           activation_84[0][0]              \n",
      "                                                                 activation_86[0][0]              \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 9, 9, 448)    573888      block_reduction_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 9, 9, 448)    1792        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 9, 9, 448)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 9, 9, 384)    1548672     activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 9, 9, 384)    491904      block_reduction_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 9, 9, 384)    1536        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 9, 9, 384)    1536        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 9, 9, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 9, 9, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 9, 9, 384)    442752      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 9, 9, 384)    442752      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 9, 9, 384)    442752      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 9, 9, 384)    442752      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 9, 9, 1280)   0           block_reduction_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 9, 9, 384)    1536        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 9, 9, 384)    1536        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 9, 9, 384)    1536        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 9, 9, 384)    1536        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 9, 9, 192)    245952      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 9, 9, 320)    409920      block_reduction_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 9, 9, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 9, 9, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 9, 9, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 9, 9, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 9, 9, 192)    768         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 9, 9, 320)    1280        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 9, 9, 768)    0           activation_89[0][0]              \n",
      "                                                                 activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 9, 9, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 9, 9, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 9, 9, 320)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 9, 9, 2048)   0           concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 9, 9, 448)    917952      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 9, 9, 448)    1792        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 9, 9, 448)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 9, 9, 384)    1548672     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 9, 9, 384)    786816      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 9, 9, 384)    1536        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 9, 9, 384)    1536        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 9, 9, 384)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 9, 9, 384)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 9, 9, 384)    442752      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 9, 9, 384)    442752      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 9, 9, 384)    442752      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 9, 9, 384)    442752      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 9, 9, 2048)   0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 5, 5, 768)    0           block_inception_f6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 9, 9, 384)    1536        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 9, 9, 384)    1536        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 9, 9, 384)    1536        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 9, 9, 384)    1536        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 9, 9, 192)    393408      max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 9, 9, 320)    655680      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 5, 5, 128)    98432       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 9, 9, 384)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 9, 9, 384)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 9, 9, 384)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 9, 9, 384)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 9, 9, 192)    768         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 9, 9, 320)    1280        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 5, 5, 128)    512         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 9, 9, 768)    0           activation_98[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 9, 9, 768)    0           activation_101[0][0]             \n",
      "                                                                 activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 9, 9, 192)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 9, 9, 320)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 5, 5, 128)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_inception_f10 (Concatenat (None, 9, 9, 2048)   0           concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 1, 1, 1024)   3277824     activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           block_inception_f10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 1, 1, 1024)   4096        conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 1, 1, 1024)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 257)          526593      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "main_classifier (Dense)         (None, 257)          66306       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "auxiliary_classifier (Dense)    (None, 257)          263425      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 28,270,820\n",
      "Trainable params: 28,229,604\n",
      "Non-trainable params: 41,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7y_Xv7AZ7LAx"
   },
   "outputs": [],
   "source": [
    "# 폴더 생성\n",
    "\n",
    "os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n",
    "os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkXMQdc2Fmpo"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n",
    "import utils\n",
    "import optimizers_v2\n",
    "from utils import get_weight_decays, fill_dict_in_order\n",
    "from utils import reset_seeds, K_eval\n",
    "from optimizers_v2 import AdamW, NadamW, SGDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78661,
     "status": "ok",
     "timestamp": 1599313690257,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "QoWLeggG6dBf",
    "outputId": "7783315d-480f-4745-e792-aa811ed673bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cosine annealing learning rates\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model=model, use_cosine_annealing=True, total_iterations = len(x_train) // batch_sizes , eta_min = 1e-2)\n",
    "#optimizer = Adam()\n",
    "filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n",
    "                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n",
    "                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n",
    "                  LearningRateScheduler(lr_schedule,verbose=1)\n",
    "                  ]\n",
    "\n",
    "model.compile(optimizer, loss={'main_classifier' : smoothed_categorical_crossentropy, 'auxiliary_classifier' : smoothed_categorical_crossentropy},\n",
    "                loss_weights={'main_classifier' : 1.0, 'auxiliary_classifier' : 0.4}, metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54950625,
     "status": "ok",
     "timestamp": 1599368562253,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "H9pnv0cw6dBm",
    "outputId": "114bd164-6f22-478f-80ad-4b3bb4e256a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24509 images belonging to 257 classes.\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 1/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 7.3886 - main_classifier_loss: 5.3562 - auxiliary_classifier_loss: 5.0809 - main_classifier_accuracy: 0.0702 - main_classifier_macro_f1score: 0.0017 - main_classifier_weighted_f1score: 5.2462e-05 - auxiliary_classifier_accuracy: 0.0996 - auxiliary_classifier_macro_f1score: 0.0031 - auxiliary_classifier_weighted_f1score: 9.3860e-05 Found 2980 images belonging to 257 classes.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.86846, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/001.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 13820s 36s/step - loss: 7.3886 - main_classifier_loss: 5.3562 - auxiliary_classifier_loss: 5.0809 - main_classifier_accuracy: 0.0702 - main_classifier_macro_f1score: 0.0017 - main_classifier_weighted_f1score: 5.2462e-05 - auxiliary_classifier_accuracy: 0.0996 - auxiliary_classifier_macro_f1score: 0.0031 - auxiliary_classifier_weighted_f1score: 9.3860e-05 - val_loss: 6.8685 - val_main_classifier_loss: 4.9970 - val_auxiliary_classifier_loss: 4.6786 - val_main_classifier_accuracy: 0.0924 - val_main_classifier_macro_f1score: 0.0039 - val_main_classifier_weighted_f1score: 1.1309e-04 - val_auxiliary_classifier_accuracy: 0.1379 - val_auxiliary_classifier_macro_f1score: 0.0053 - val_auxiliary_classifier_weighted_f1score: 1.6667e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 2/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 6.8569 - main_classifier_loss: 4.9831 - auxiliary_classifier_loss: 4.6847 - main_classifier_accuracy: 0.1007 - main_classifier_macro_f1score: 0.0043 - main_classifier_weighted_f1score: 1.2791e-04 - auxiliary_classifier_accuracy: 0.1486 - auxiliary_classifier_macro_f1score: 0.0070 - auxiliary_classifier_weighted_f1score: 1.9863e-04\n",
      "Epoch 00002: val_loss improved from 6.86846 to 6.58958, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/002.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 609s 2s/step - loss: 6.8569 - main_classifier_loss: 4.9831 - auxiliary_classifier_loss: 4.6847 - main_classifier_accuracy: 0.1007 - main_classifier_macro_f1score: 0.0043 - main_classifier_weighted_f1score: 1.2791e-04 - auxiliary_classifier_accuracy: 0.1486 - auxiliary_classifier_macro_f1score: 0.0070 - auxiliary_classifier_weighted_f1score: 1.9863e-04 - val_loss: 6.5896 - val_main_classifier_loss: 4.7912 - val_auxiliary_classifier_loss: 4.4959 - val_main_classifier_accuracy: 0.1274 - val_main_classifier_macro_f1score: 0.0053 - val_main_classifier_weighted_f1score: 1.6923e-04 - val_auxiliary_classifier_accuracy: 0.1902 - val_auxiliary_classifier_macro_f1score: 0.0085 - val_auxiliary_classifier_weighted_f1score: 2.3802e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 3/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 6.5736 - main_classifier_loss: 4.8010 - auxiliary_classifier_loss: 4.4313 - main_classifier_accuracy: 0.1184 - main_classifier_macro_f1score: 0.0061 - main_classifier_weighted_f1score: 1.7240e-04 - auxiliary_classifier_accuracy: 0.1785 - auxiliary_classifier_macro_f1score: 0.0095 - auxiliary_classifier_weighted_f1score: 2.5327e-04\n",
      "Epoch 00003: val_loss improved from 6.58958 to 6.17510, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/003.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 606s 2s/step - loss: 6.5736 - main_classifier_loss: 4.8010 - auxiliary_classifier_loss: 4.4313 - main_classifier_accuracy: 0.1184 - main_classifier_macro_f1score: 0.0061 - main_classifier_weighted_f1score: 1.7240e-04 - auxiliary_classifier_accuracy: 0.1785 - auxiliary_classifier_macro_f1score: 0.0095 - auxiliary_classifier_weighted_f1score: 2.5327e-04 - val_loss: 6.1751 - val_main_classifier_loss: 4.5299 - val_auxiliary_classifier_loss: 4.1129 - val_main_classifier_accuracy: 0.1461 - val_main_classifier_macro_f1score: 0.0076 - val_main_classifier_weighted_f1score: 2.2497e-04 - val_auxiliary_classifier_accuracy: 0.2395 - val_auxiliary_classifier_macro_f1score: 0.0120 - val_auxiliary_classifier_weighted_f1score: 3.1770e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 4/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 6.3127 - main_classifier_loss: 4.6441 - auxiliary_classifier_loss: 4.1713 - main_classifier_accuracy: 0.1345 - main_classifier_macro_f1score: 0.0071 - main_classifier_weighted_f1score: 2.0435e-04 - auxiliary_classifier_accuracy: 0.2160 - auxiliary_classifier_macro_f1score: 0.0122 - auxiliary_classifier_weighted_f1score: 3.1520e-04\n",
      "Epoch 00004: val_loss improved from 6.17510 to 5.94811, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/004.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 602s 2s/step - loss: 6.3127 - main_classifier_loss: 4.6441 - auxiliary_classifier_loss: 4.1713 - main_classifier_accuracy: 0.1345 - main_classifier_macro_f1score: 0.0071 - main_classifier_weighted_f1score: 2.0435e-04 - auxiliary_classifier_accuracy: 0.2160 - auxiliary_classifier_macro_f1score: 0.0122 - auxiliary_classifier_weighted_f1score: 3.1520e-04 - val_loss: 5.9481 - val_main_classifier_loss: 4.3810 - val_auxiliary_classifier_loss: 3.9177 - val_main_classifier_accuracy: 0.1719 - val_main_classifier_macro_f1score: 0.0077 - val_main_classifier_weighted_f1score: 2.3282e-04 - val_auxiliary_classifier_accuracy: 0.2714 - val_auxiliary_classifier_macro_f1score: 0.0177 - val_auxiliary_classifier_weighted_f1score: 4.2824e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 5/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 6.1196 - main_classifier_loss: 4.5257 - auxiliary_classifier_loss: 3.9847 - main_classifier_accuracy: 0.1489 - main_classifier_macro_f1score: 0.0080 - main_classifier_weighted_f1score: 2.2374e-04 - auxiliary_classifier_accuracy: 0.2455 - auxiliary_classifier_macro_f1score: 0.0149 - auxiliary_classifier_weighted_f1score: 3.6617e-04\n",
      "Epoch 00005: val_loss improved from 5.94811 to 5.74499, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/005.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 606s 2s/step - loss: 6.1196 - main_classifier_loss: 4.5257 - auxiliary_classifier_loss: 3.9847 - main_classifier_accuracy: 0.1489 - main_classifier_macro_f1score: 0.0080 - main_classifier_weighted_f1score: 2.2374e-04 - auxiliary_classifier_accuracy: 0.2455 - auxiliary_classifier_macro_f1score: 0.0149 - auxiliary_classifier_weighted_f1score: 3.6617e-04 - val_loss: 5.7450 - val_main_classifier_loss: 4.2444 - val_auxiliary_classifier_loss: 3.7514 - val_main_classifier_accuracy: 0.1936 - val_main_classifier_macro_f1score: 0.0088 - val_main_classifier_weighted_f1score: 2.5008e-04 - val_auxiliary_classifier_accuracy: 0.2945 - val_auxiliary_classifier_macro_f1score: 0.0198 - val_auxiliary_classifier_weighted_f1score: 4.7947e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 6/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 5.9112 - main_classifier_loss: 4.3971 - auxiliary_classifier_loss: 3.7851 - main_classifier_accuracy: 0.1685 - main_classifier_macro_f1score: 0.0087 - main_classifier_weighted_f1score: 2.4621e-04 - auxiliary_classifier_accuracy: 0.2810 - auxiliary_classifier_macro_f1score: 0.0194 - auxiliary_classifier_weighted_f1score: 4.5315e-04\n",
      "Epoch 00006: val_loss improved from 5.74499 to 5.56515, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/006.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 596s 2s/step - loss: 5.9112 - main_classifier_loss: 4.3971 - auxiliary_classifier_loss: 3.7851 - main_classifier_accuracy: 0.1685 - main_classifier_macro_f1score: 0.0087 - main_classifier_weighted_f1score: 2.4621e-04 - auxiliary_classifier_accuracy: 0.2810 - auxiliary_classifier_macro_f1score: 0.0194 - auxiliary_classifier_weighted_f1score: 4.5315e-04 - val_loss: 5.5652 - val_main_classifier_loss: 4.1197 - val_auxiliary_classifier_loss: 3.6136 - val_main_classifier_accuracy: 0.2164 - val_main_classifier_macro_f1score: 0.0094 - val_main_classifier_weighted_f1score: 2.6789e-04 - val_auxiliary_classifier_accuracy: 0.3274 - val_auxiliary_classifier_macro_f1score: 0.0270 - val_auxiliary_classifier_weighted_f1score: 6.0590e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 7/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 5.7547 - main_classifier_loss: 4.2926 - auxiliary_classifier_loss: 3.6554 - main_classifier_accuracy: 0.1798 - main_classifier_macro_f1score: 0.0091 - main_classifier_weighted_f1score: 2.5671e-04 - auxiliary_classifier_accuracy: 0.3076 - auxiliary_classifier_macro_f1score: 0.0222 - auxiliary_classifier_weighted_f1score: 5.1260e-04\n",
      "Epoch 00007: val_loss improved from 5.56515 to 5.34467, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/007.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 603s 2s/step - loss: 5.7547 - main_classifier_loss: 4.2926 - auxiliary_classifier_loss: 3.6554 - main_classifier_accuracy: 0.1798 - main_classifier_macro_f1score: 0.0091 - main_classifier_weighted_f1score: 2.5671e-04 - auxiliary_classifier_accuracy: 0.3076 - auxiliary_classifier_macro_f1score: 0.0222 - auxiliary_classifier_weighted_f1score: 5.1260e-04 - val_loss: 5.3447 - val_main_classifier_loss: 3.9625 - val_auxiliary_classifier_loss: 3.4553 - val_main_classifier_accuracy: 0.2395 - val_main_classifier_macro_f1score: 0.0120 - val_main_classifier_weighted_f1score: 3.2557e-04 - val_auxiliary_classifier_accuracy: 0.3601 - val_auxiliary_classifier_macro_f1score: 0.0336 - val_auxiliary_classifier_weighted_f1score: 7.1122e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 8/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 5.5055 - main_classifier_loss: 4.1298 - auxiliary_classifier_loss: 3.4391 - main_classifier_accuracy: 0.2103 - main_classifier_macro_f1score: 0.0110 - main_classifier_weighted_f1score: 3.0217e-04 - auxiliary_classifier_accuracy: 0.3537 - auxiliary_classifier_macro_f1score: 0.0286 - auxiliary_classifier_weighted_f1score: 6.3022e-04\n",
      "Epoch 00008: val_loss improved from 5.34467 to 5.13481, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/008.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 601s 2s/step - loss: 5.5055 - main_classifier_loss: 4.1298 - auxiliary_classifier_loss: 3.4391 - main_classifier_accuracy: 0.2103 - main_classifier_macro_f1score: 0.0110 - main_classifier_weighted_f1score: 3.0217e-04 - auxiliary_classifier_accuracy: 0.3537 - auxiliary_classifier_macro_f1score: 0.0286 - auxiliary_classifier_weighted_f1score: 6.3022e-04 - val_loss: 5.1348 - val_main_classifier_loss: 3.8091 - val_auxiliary_classifier_loss: 3.3142 - val_main_classifier_accuracy: 0.2819 - val_main_classifier_macro_f1score: 0.0132 - val_main_classifier_weighted_f1score: 3.5075e-04 - val_auxiliary_classifier_accuracy: 0.3981 - val_auxiliary_classifier_macro_f1score: 0.0386 - val_auxiliary_classifier_weighted_f1score: 8.1599e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 9/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 5.2917 - main_classifier_loss: 3.9843 - auxiliary_classifier_loss: 3.2686 - main_classifier_accuracy: 0.2304 - main_classifier_macro_f1score: 0.0126 - main_classifier_weighted_f1score: 3.3312e-04 - auxiliary_classifier_accuracy: 0.3848 - auxiliary_classifier_macro_f1score: 0.0342 - auxiliary_classifier_weighted_f1score: 7.3134e-04\n",
      "Epoch 00009: val_loss improved from 5.13481 to 4.94520, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/009.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 598s 2s/step - loss: 5.2917 - main_classifier_loss: 3.9843 - auxiliary_classifier_loss: 3.2686 - main_classifier_accuracy: 0.2304 - main_classifier_macro_f1score: 0.0126 - main_classifier_weighted_f1score: 3.3312e-04 - auxiliary_classifier_accuracy: 0.3848 - auxiliary_classifier_macro_f1score: 0.0342 - auxiliary_classifier_weighted_f1score: 7.3134e-04 - val_loss: 4.9452 - val_main_classifier_loss: 3.6719 - val_auxiliary_classifier_loss: 3.1832 - val_main_classifier_accuracy: 0.3077 - val_main_classifier_macro_f1score: 0.0164 - val_main_classifier_weighted_f1score: 4.1620e-04 - val_auxiliary_classifier_accuracy: 0.4229 - val_auxiliary_classifier_macro_f1score: 0.0443 - val_auxiliary_classifier_weighted_f1score: 9.2905e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 10/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 5.1470 - main_classifier_loss: 3.8898 - auxiliary_classifier_loss: 3.1429 - main_classifier_accuracy: 0.2507 - main_classifier_macro_f1score: 0.0136 - main_classifier_weighted_f1score: 3.4972e-04 - auxiliary_classifier_accuracy: 0.4152 - auxiliary_classifier_macro_f1score: 0.0389 - auxiliary_classifier_weighted_f1score: 8.1048e-04\n",
      "Epoch 00010: val_loss improved from 4.94520 to 4.82499, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/010.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 594s 2s/step - loss: 5.1470 - main_classifier_loss: 3.8898 - auxiliary_classifier_loss: 3.1429 - main_classifier_accuracy: 0.2507 - main_classifier_macro_f1score: 0.0136 - main_classifier_weighted_f1score: 3.4972e-04 - auxiliary_classifier_accuracy: 0.4152 - auxiliary_classifier_macro_f1score: 0.0389 - auxiliary_classifier_weighted_f1score: 8.1048e-04 - val_loss: 4.8250 - val_main_classifier_loss: 3.5814 - val_auxiliary_classifier_loss: 3.1089 - val_main_classifier_accuracy: 0.3213 - val_main_classifier_macro_f1score: 0.0180 - val_main_classifier_weighted_f1score: 4.3179e-04 - val_auxiliary_classifier_accuracy: 0.4412 - val_auxiliary_classifier_macro_f1score: 0.0479 - val_auxiliary_classifier_weighted_f1score: 9.9271e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 11/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.9526 - main_classifier_loss: 3.7590 - auxiliary_classifier_loss: 2.9841 - main_classifier_accuracy: 0.2754 - main_classifier_macro_f1score: 0.0158 - main_classifier_weighted_f1score: 3.9218e-04 - auxiliary_classifier_accuracy: 0.4497 - auxiliary_classifier_macro_f1score: 0.0452 - auxiliary_classifier_weighted_f1score: 9.2669e-04\n",
      "Epoch 00011: val_loss improved from 4.82499 to 4.68928, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/011.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 596s 2s/step - loss: 4.9526 - main_classifier_loss: 3.7590 - auxiliary_classifier_loss: 2.9841 - main_classifier_accuracy: 0.2754 - main_classifier_macro_f1score: 0.0158 - main_classifier_weighted_f1score: 3.9218e-04 - auxiliary_classifier_accuracy: 0.4497 - auxiliary_classifier_macro_f1score: 0.0452 - auxiliary_classifier_weighted_f1score: 9.2669e-04 - val_loss: 4.6893 - val_main_classifier_loss: 3.4822 - val_auxiliary_classifier_loss: 3.0176 - val_main_classifier_accuracy: 0.3454 - val_main_classifier_macro_f1score: 0.0214 - val_main_classifier_weighted_f1score: 5.1030e-04 - val_auxiliary_classifier_accuracy: 0.4558 - val_auxiliary_classifier_macro_f1score: 0.0537 - val_auxiliary_classifier_weighted_f1score: 0.0011\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 12/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.7845 - main_classifier_loss: 3.6456 - auxiliary_classifier_loss: 2.8473 - main_classifier_accuracy: 0.3024 - main_classifier_macro_f1score: 0.0181 - main_classifier_weighted_f1score: 4.4543e-04 - auxiliary_classifier_accuracy: 0.4818 - auxiliary_classifier_macro_f1score: 0.0517 - auxiliary_classifier_weighted_f1score: 0.0010\n",
      "Epoch 00012: val_loss improved from 4.68928 to 4.55467, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/012.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 597s 2s/step - loss: 4.7845 - main_classifier_loss: 3.6456 - auxiliary_classifier_loss: 2.8473 - main_classifier_accuracy: 0.3024 - main_classifier_macro_f1score: 0.0181 - main_classifier_weighted_f1score: 4.4543e-04 - auxiliary_classifier_accuracy: 0.4818 - auxiliary_classifier_macro_f1score: 0.0517 - auxiliary_classifier_weighted_f1score: 0.0010 - val_loss: 4.5547 - val_main_classifier_loss: 3.3809 - val_auxiliary_classifier_loss: 2.9344 - val_main_classifier_accuracy: 0.3689 - val_main_classifier_macro_f1score: 0.0242 - val_main_classifier_weighted_f1score: 5.6083e-04 - val_auxiliary_classifier_accuracy: 0.4810 - val_auxiliary_classifier_macro_f1score: 0.0587 - val_auxiliary_classifier_weighted_f1score: 0.0012\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 13/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 5.0078 - main_classifier_loss: 3.7992 - auxiliary_classifier_loss: 3.0213 - main_classifier_accuracy: 0.2699 - main_classifier_macro_f1score: 0.0153 - main_classifier_weighted_f1score: 3.7582e-04 - auxiliary_classifier_accuracy: 0.4414 - auxiliary_classifier_macro_f1score: 0.0436 - auxiliary_classifier_weighted_f1score: 8.8953e-04\n",
      "Epoch 00013: val_loss did not improve from 4.55467\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 592s 2s/step - loss: 5.0078 - main_classifier_loss: 3.7992 - auxiliary_classifier_loss: 3.0213 - main_classifier_accuracy: 0.2699 - main_classifier_macro_f1score: 0.0153 - main_classifier_weighted_f1score: 3.7582e-04 - auxiliary_classifier_accuracy: 0.4414 - auxiliary_classifier_macro_f1score: 0.0436 - auxiliary_classifier_weighted_f1score: 8.8953e-04 - val_loss: 4.6621 - val_main_classifier_loss: 3.4489 - val_auxiliary_classifier_loss: 3.0332 - val_main_classifier_accuracy: 0.3522 - val_main_classifier_macro_f1score: 0.0229 - val_main_classifier_weighted_f1score: 5.4132e-04 - val_auxiliary_classifier_accuracy: 0.4603 - val_auxiliary_classifier_macro_f1score: 0.0550 - val_auxiliary_classifier_weighted_f1score: 0.0011\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 14/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.6649 - main_classifier_loss: 3.5674 - auxiliary_classifier_loss: 2.7436 - main_classifier_accuracy: 0.3163 - main_classifier_macro_f1score: 0.0200 - main_classifier_weighted_f1score: 4.8043e-04 - auxiliary_classifier_accuracy: 0.5066 - auxiliary_classifier_macro_f1score: 0.0564 - auxiliary_classifier_weighted_f1score: 0.0011\n",
      "Epoch 00014: val_loss improved from 4.55467 to 4.45664, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/014.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 594s 2s/step - loss: 4.6649 - main_classifier_loss: 3.5674 - auxiliary_classifier_loss: 2.7436 - main_classifier_accuracy: 0.3163 - main_classifier_macro_f1score: 0.0200 - main_classifier_weighted_f1score: 4.8043e-04 - auxiliary_classifier_accuracy: 0.5066 - auxiliary_classifier_macro_f1score: 0.0564 - auxiliary_classifier_weighted_f1score: 0.0011 - val_loss: 4.4566 - val_main_classifier_loss: 3.2942 - val_auxiliary_classifier_loss: 2.9061 - val_main_classifier_accuracy: 0.3964 - val_main_classifier_macro_f1score: 0.0264 - val_main_classifier_weighted_f1score: 6.1370e-04 - val_auxiliary_classifier_accuracy: 0.4857 - val_auxiliary_classifier_macro_f1score: 0.0608 - val_auxiliary_classifier_weighted_f1score: 0.0012\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 15/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.4955 - main_classifier_loss: 3.4458 - auxiliary_classifier_loss: 2.6242 - main_classifier_accuracy: 0.3435 - main_classifier_macro_f1score: 0.0237 - main_classifier_weighted_f1score: 5.4534e-04 - auxiliary_classifier_accuracy: 0.5364 - auxiliary_classifier_macro_f1score: 0.0627 - auxiliary_classifier_weighted_f1score: 0.0012\n",
      "Epoch 00015: val_loss improved from 4.45664 to 4.35658, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/015.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 589s 2s/step - loss: 4.4955 - main_classifier_loss: 3.4458 - auxiliary_classifier_loss: 2.6242 - main_classifier_accuracy: 0.3435 - main_classifier_macro_f1score: 0.0237 - main_classifier_weighted_f1score: 5.4534e-04 - auxiliary_classifier_accuracy: 0.5364 - auxiliary_classifier_macro_f1score: 0.0627 - auxiliary_classifier_weighted_f1score: 0.0012 - val_loss: 4.3566 - val_main_classifier_loss: 3.2149 - val_auxiliary_classifier_loss: 2.8542 - val_main_classifier_accuracy: 0.4113 - val_main_classifier_macro_f1score: 0.0323 - val_main_classifier_weighted_f1score: 7.1616e-04 - val_auxiliary_classifier_accuracy: 0.5092 - val_auxiliary_classifier_macro_f1score: 0.0657 - val_auxiliary_classifier_weighted_f1score: 0.0013\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 16/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.3843 - main_classifier_loss: 3.3799 - auxiliary_classifier_loss: 2.5109 - main_classifier_accuracy: 0.3647 - main_classifier_macro_f1score: 0.0265 - main_classifier_weighted_f1score: 5.8967e-04 - auxiliary_classifier_accuracy: 0.5674 - auxiliary_classifier_macro_f1score: 0.0686 - auxiliary_classifier_weighted_f1score: 0.0014\n",
      "Epoch 00016: val_loss improved from 4.35658 to 4.27951, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/016.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 589s 2s/step - loss: 4.3843 - main_classifier_loss: 3.3799 - auxiliary_classifier_loss: 2.5109 - main_classifier_accuracy: 0.3647 - main_classifier_macro_f1score: 0.0265 - main_classifier_weighted_f1score: 5.8967e-04 - auxiliary_classifier_accuracy: 0.5674 - auxiliary_classifier_macro_f1score: 0.0686 - auxiliary_classifier_weighted_f1score: 0.0014 - val_loss: 4.2795 - val_main_classifier_loss: 3.1567 - val_auxiliary_classifier_loss: 2.8072 - val_main_classifier_accuracy: 0.4310 - val_main_classifier_macro_f1score: 0.0346 - val_main_classifier_weighted_f1score: 7.7336e-04 - val_auxiliary_classifier_accuracy: 0.5153 - val_auxiliary_classifier_macro_f1score: 0.0689 - val_auxiliary_classifier_weighted_f1score: 0.0014\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 17/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.2728 - main_classifier_loss: 3.2989 - auxiliary_classifier_loss: 2.4349 - main_classifier_accuracy: 0.3828 - main_classifier_macro_f1score: 0.0291 - main_classifier_weighted_f1score: 6.4507e-04 - auxiliary_classifier_accuracy: 0.5888 - auxiliary_classifier_macro_f1score: 0.0730 - auxiliary_classifier_weighted_f1score: 0.0014\n",
      "Epoch 00017: val_loss improved from 4.27951 to 4.19275, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/017.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 588s 2s/step - loss: 4.2728 - main_classifier_loss: 3.2989 - auxiliary_classifier_loss: 2.4349 - main_classifier_accuracy: 0.3828 - main_classifier_macro_f1score: 0.0291 - main_classifier_weighted_f1score: 6.4507e-04 - auxiliary_classifier_accuracy: 0.5888 - auxiliary_classifier_macro_f1score: 0.0730 - auxiliary_classifier_weighted_f1score: 0.0014 - val_loss: 4.1927 - val_main_classifier_loss: 3.0855 - val_auxiliary_classifier_loss: 2.7682 - val_main_classifier_accuracy: 0.4511 - val_main_classifier_macro_f1score: 0.0397 - val_main_classifier_weighted_f1score: 8.3756e-04 - val_auxiliary_classifier_accuracy: 0.5319 - val_auxiliary_classifier_macro_f1score: 0.0739 - val_auxiliary_classifier_weighted_f1score: 0.0014\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 18/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.1386 - main_classifier_loss: 3.2057 - auxiliary_classifier_loss: 2.3323 - main_classifier_accuracy: 0.4040 - main_classifier_macro_f1score: 0.0334 - main_classifier_weighted_f1score: 7.1720e-04 - auxiliary_classifier_accuracy: 0.6148 - auxiliary_classifier_macro_f1score: 0.0798 - auxiliary_classifier_weighted_f1score: 0.0016\n",
      "Epoch 00018: val_loss improved from 4.19275 to 4.10080, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/018.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 589s 2s/step - loss: 4.1386 - main_classifier_loss: 3.2057 - auxiliary_classifier_loss: 2.3323 - main_classifier_accuracy: 0.4040 - main_classifier_macro_f1score: 0.0334 - main_classifier_weighted_f1score: 7.1720e-04 - auxiliary_classifier_accuracy: 0.6148 - auxiliary_classifier_macro_f1score: 0.0798 - auxiliary_classifier_weighted_f1score: 0.0016 - val_loss: 4.1008 - val_main_classifier_loss: 3.0128 - val_auxiliary_classifier_loss: 2.7200 - val_main_classifier_accuracy: 0.4620 - val_main_classifier_macro_f1score: 0.0414 - val_main_classifier_weighted_f1score: 8.6687e-04 - val_auxiliary_classifier_accuracy: 0.5380 - val_auxiliary_classifier_macro_f1score: 0.0757 - val_auxiliary_classifier_weighted_f1score: 0.0015\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 19/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.0115 - main_classifier_loss: 3.1143 - auxiliary_classifier_loss: 2.2430 - main_classifier_accuracy: 0.4255 - main_classifier_macro_f1score: 0.0364 - main_classifier_weighted_f1score: 7.7764e-04 - auxiliary_classifier_accuracy: 0.6425 - auxiliary_classifier_macro_f1score: 0.0856 - auxiliary_classifier_weighted_f1score: 0.0017\n",
      "Epoch 00019: val_loss improved from 4.10080 to 4.03562, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/019.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 590s 2s/step - loss: 4.0115 - main_classifier_loss: 3.1143 - auxiliary_classifier_loss: 2.2430 - main_classifier_accuracy: 0.4255 - main_classifier_macro_f1score: 0.0364 - main_classifier_weighted_f1score: 7.7764e-04 - auxiliary_classifier_accuracy: 0.6425 - auxiliary_classifier_macro_f1score: 0.0856 - auxiliary_classifier_weighted_f1score: 0.0017 - val_loss: 4.0356 - val_main_classifier_loss: 2.9591 - val_auxiliary_classifier_loss: 2.6913 - val_main_classifier_accuracy: 0.4718 - val_main_classifier_macro_f1score: 0.0457 - val_main_classifier_weighted_f1score: 9.5047e-04 - val_auxiliary_classifier_accuracy: 0.5486 - val_auxiliary_classifier_macro_f1score: 0.0779 - val_auxiliary_classifier_weighted_f1score: 0.0015\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 20/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.9056 - main_classifier_loss: 3.0396 - auxiliary_classifier_loss: 2.1648 - main_classifier_accuracy: 0.4451 - main_classifier_macro_f1score: 0.0394 - main_classifier_weighted_f1score: 8.3722e-04 - auxiliary_classifier_accuracy: 0.6617 - auxiliary_classifier_macro_f1score: 0.0904 - auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Epoch 00020: val_loss improved from 4.03562 to 3.98020, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/020.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 591s 2s/step - loss: 3.9056 - main_classifier_loss: 3.0396 - auxiliary_classifier_loss: 2.1648 - main_classifier_accuracy: 0.4451 - main_classifier_macro_f1score: 0.0394 - main_classifier_weighted_f1score: 8.3722e-04 - auxiliary_classifier_accuracy: 0.6617 - auxiliary_classifier_macro_f1score: 0.0904 - auxiliary_classifier_weighted_f1score: 0.0018 - val_loss: 3.9802 - val_main_classifier_loss: 2.9117 - val_auxiliary_classifier_loss: 2.6713 - val_main_classifier_accuracy: 0.4891 - val_main_classifier_macro_f1score: 0.0482 - val_main_classifier_weighted_f1score: 9.9501e-04 - val_auxiliary_classifier_accuracy: 0.5554 - val_auxiliary_classifier_macro_f1score: 0.0828 - val_auxiliary_classifier_weighted_f1score: 0.0016\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 21/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.8049 - main_classifier_loss: 2.9654 - auxiliary_classifier_loss: 2.0985 - main_classifier_accuracy: 0.4633 - main_classifier_macro_f1score: 0.0430 - main_classifier_weighted_f1score: 9.0012e-04 - auxiliary_classifier_accuracy: 0.6851 - auxiliary_classifier_macro_f1score: 0.0956 - auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Epoch 00021: val_loss improved from 3.98020 to 3.92442, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/021.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 591s 2s/step - loss: 3.8049 - main_classifier_loss: 2.9654 - auxiliary_classifier_loss: 2.0985 - main_classifier_accuracy: 0.4633 - main_classifier_macro_f1score: 0.0430 - main_classifier_weighted_f1score: 9.0012e-04 - auxiliary_classifier_accuracy: 0.6851 - auxiliary_classifier_macro_f1score: 0.0956 - auxiliary_classifier_weighted_f1score: 0.0018 - val_loss: 3.9244 - val_main_classifier_loss: 2.8655 - val_auxiliary_classifier_loss: 2.6474 - val_main_classifier_accuracy: 0.5020 - val_main_classifier_macro_f1score: 0.0521 - val_main_classifier_weighted_f1score: 0.0011 - val_auxiliary_classifier_accuracy: 0.5649 - val_auxiliary_classifier_macro_f1score: 0.0843 - val_auxiliary_classifier_weighted_f1score: 0.0016\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 22/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.7391 - main_classifier_loss: 2.9223 - auxiliary_classifier_loss: 2.0421 - main_classifier_accuracy: 0.4777 - main_classifier_macro_f1score: 0.0452 - main_classifier_weighted_f1score: 9.4297e-04 - auxiliary_classifier_accuracy: 0.6985 - auxiliary_classifier_macro_f1score: 0.0989 - auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Epoch 00022: val_loss improved from 3.92442 to 3.87747, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/022.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 593s 2s/step - loss: 3.7391 - main_classifier_loss: 2.9223 - auxiliary_classifier_loss: 2.0421 - main_classifier_accuracy: 0.4777 - main_classifier_macro_f1score: 0.0452 - main_classifier_weighted_f1score: 9.4297e-04 - auxiliary_classifier_accuracy: 0.6985 - auxiliary_classifier_macro_f1score: 0.0989 - auxiliary_classifier_weighted_f1score: 0.0019 - val_loss: 3.8775 - val_main_classifier_loss: 2.8177 - val_auxiliary_classifier_loss: 2.6495 - val_main_classifier_accuracy: 0.5109 - val_main_classifier_macro_f1score: 0.0551 - val_main_classifier_weighted_f1score: 0.0011 - val_auxiliary_classifier_accuracy: 0.5615 - val_auxiliary_classifier_macro_f1score: 0.0858 - val_auxiliary_classifier_weighted_f1score: 0.0017\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 23/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.6384 - main_classifier_loss: 2.8492 - auxiliary_classifier_loss: 1.9729 - main_classifier_accuracy: 0.4963 - main_classifier_macro_f1score: 0.0492 - main_classifier_weighted_f1score: 0.0010 - auxiliary_classifier_accuracy: 0.7179 - auxiliary_classifier_macro_f1score: 0.1065 - auxiliary_classifier_weighted_f1score: 0.0020\n",
      "Epoch 00023: val_loss improved from 3.87747 to 3.82308, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/023.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 591s 2s/step - loss: 3.6384 - main_classifier_loss: 2.8492 - auxiliary_classifier_loss: 1.9729 - main_classifier_accuracy: 0.4963 - main_classifier_macro_f1score: 0.0492 - main_classifier_weighted_f1score: 0.0010 - auxiliary_classifier_accuracy: 0.7179 - auxiliary_classifier_macro_f1score: 0.1065 - auxiliary_classifier_weighted_f1score: 0.0020 - val_loss: 3.8231 - val_main_classifier_loss: 2.7780 - val_auxiliary_classifier_loss: 2.6126 - val_main_classifier_accuracy: 0.5241 - val_main_classifier_macro_f1score: 0.0594 - val_main_classifier_weighted_f1score: 0.0012 - val_auxiliary_classifier_accuracy: 0.5771 - val_auxiliary_classifier_macro_f1score: 0.0878 - val_auxiliary_classifier_weighted_f1score: 0.0017\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 24/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.5602 - main_classifier_loss: 2.7937 - auxiliary_classifier_loss: 1.9162 - main_classifier_accuracy: 0.5073 - main_classifier_macro_f1score: 0.0521 - main_classifier_weighted_f1score: 0.0011 - auxiliary_classifier_accuracy: 0.7365 - auxiliary_classifier_macro_f1score: 0.1098 - auxiliary_classifier_weighted_f1score: 0.0021\n",
      "Epoch 00024: val_loss improved from 3.82308 to 3.79752, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/024.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 591s 2s/step - loss: 3.5602 - main_classifier_loss: 2.7937 - auxiliary_classifier_loss: 1.9162 - main_classifier_accuracy: 0.5073 - main_classifier_macro_f1score: 0.0521 - main_classifier_weighted_f1score: 0.0011 - auxiliary_classifier_accuracy: 0.7365 - auxiliary_classifier_macro_f1score: 0.1098 - auxiliary_classifier_weighted_f1score: 0.0021 - val_loss: 3.7975 - val_main_classifier_loss: 2.7506 - val_auxiliary_classifier_loss: 2.6172 - val_main_classifier_accuracy: 0.5312 - val_main_classifier_macro_f1score: 0.0617 - val_main_classifier_weighted_f1score: 0.0013 - val_auxiliary_classifier_accuracy: 0.5751 - val_auxiliary_classifier_macro_f1score: 0.0889 - val_auxiliary_classifier_weighted_f1score: 0.0017\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 25/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.4634 - main_classifier_loss: 2.7204 - auxiliary_classifier_loss: 1.8576 - main_classifier_accuracy: 0.5297 - main_classifier_macro_f1score: 0.0567 - main_classifier_weighted_f1score: 0.0011 - auxiliary_classifier_accuracy: 0.7550 - auxiliary_classifier_macro_f1score: 0.1156 - auxiliary_classifier_weighted_f1score: 0.0022\n",
      "Epoch 00025: val_loss improved from 3.79752 to 3.73091, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/025.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 590s 2s/step - loss: 3.4634 - main_classifier_loss: 2.7204 - auxiliary_classifier_loss: 1.8576 - main_classifier_accuracy: 0.5297 - main_classifier_macro_f1score: 0.0567 - main_classifier_weighted_f1score: 0.0011 - auxiliary_classifier_accuracy: 0.7550 - auxiliary_classifier_macro_f1score: 0.1156 - auxiliary_classifier_weighted_f1score: 0.0022 - val_loss: 3.7309 - val_main_classifier_loss: 2.7043 - val_auxiliary_classifier_loss: 2.5664 - val_main_classifier_accuracy: 0.5411 - val_main_classifier_macro_f1score: 0.0654 - val_main_classifier_weighted_f1score: 0.0013 - val_auxiliary_classifier_accuracy: 0.5866 - val_auxiliary_classifier_macro_f1score: 0.0912 - val_auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 26/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.3692 - main_classifier_loss: 2.6497 - auxiliary_classifier_loss: 1.7988 - main_classifier_accuracy: 0.5449 - main_classifier_macro_f1score: 0.0609 - main_classifier_weighted_f1score: 0.0012 - auxiliary_classifier_accuracy: 0.7750 - auxiliary_classifier_macro_f1score: 0.1205 - auxiliary_classifier_weighted_f1score: 0.0023\n",
      "Epoch 00026: val_loss improved from 3.73091 to 3.71375, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/026.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 586s 2s/step - loss: 3.3692 - main_classifier_loss: 2.6497 - auxiliary_classifier_loss: 1.7988 - main_classifier_accuracy: 0.5449 - main_classifier_macro_f1score: 0.0609 - main_classifier_weighted_f1score: 0.0012 - auxiliary_classifier_accuracy: 0.7750 - auxiliary_classifier_macro_f1score: 0.1205 - auxiliary_classifier_weighted_f1score: 0.0023 - val_loss: 3.7138 - val_main_classifier_loss: 2.6875 - val_auxiliary_classifier_loss: 2.5656 - val_main_classifier_accuracy: 0.5445 - val_main_classifier_macro_f1score: 0.0659 - val_main_classifier_weighted_f1score: 0.0013 - val_auxiliary_classifier_accuracy: 0.5859 - val_auxiliary_classifier_macro_f1score: 0.0920 - val_auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 27/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.3112 - main_classifier_loss: 2.6079 - auxiliary_classifier_loss: 1.7581 - main_classifier_accuracy: 0.5573 - main_classifier_macro_f1score: 0.0627 - main_classifier_weighted_f1score: 0.0013 - auxiliary_classifier_accuracy: 0.7856 - auxiliary_classifier_macro_f1score: 0.1231 - auxiliary_classifier_weighted_f1score: 0.0023\n",
      "Epoch 00027: val_loss improved from 3.71375 to 3.67146, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/027.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 585s 2s/step - loss: 3.3112 - main_classifier_loss: 2.6079 - auxiliary_classifier_loss: 1.7581 - main_classifier_accuracy: 0.5573 - main_classifier_macro_f1score: 0.0627 - main_classifier_weighted_f1score: 0.0013 - auxiliary_classifier_accuracy: 0.7856 - auxiliary_classifier_macro_f1score: 0.1231 - auxiliary_classifier_weighted_f1score: 0.0023 - val_loss: 3.6715 - val_main_classifier_loss: 2.6504 - val_auxiliary_classifier_loss: 2.5526 - val_main_classifier_accuracy: 0.5547 - val_main_classifier_macro_f1score: 0.0714 - val_main_classifier_weighted_f1score: 0.0014 - val_auxiliary_classifier_accuracy: 0.5856 - val_auxiliary_classifier_macro_f1score: 0.0949 - val_auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 28/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.2288 - main_classifier_loss: 2.5463 - auxiliary_classifier_loss: 1.7062 - main_classifier_accuracy: 0.5740 - main_classifier_macro_f1score: 0.0676 - main_classifier_weighted_f1score: 0.0013 - auxiliary_classifier_accuracy: 0.8053 - auxiliary_classifier_macro_f1score: 0.1288 - auxiliary_classifier_weighted_f1score: 0.0024\n",
      "Epoch 00028: val_loss improved from 3.67146 to 3.65553, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/028.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 585s 2s/step - loss: 3.2288 - main_classifier_loss: 2.5463 - auxiliary_classifier_loss: 1.7062 - main_classifier_accuracy: 0.5740 - main_classifier_macro_f1score: 0.0676 - main_classifier_weighted_f1score: 0.0013 - auxiliary_classifier_accuracy: 0.8053 - auxiliary_classifier_macro_f1score: 0.1288 - auxiliary_classifier_weighted_f1score: 0.0024 - val_loss: 3.6555 - val_main_classifier_loss: 2.6362 - val_auxiliary_classifier_loss: 2.5483 - val_main_classifier_accuracy: 0.5571 - val_main_classifier_macro_f1score: 0.0758 - val_main_classifier_weighted_f1score: 0.0015 - val_auxiliary_classifier_accuracy: 0.5931 - val_auxiliary_classifier_macro_f1score: 0.0980 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 29/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.2060 - main_classifier_loss: 2.5292 - auxiliary_classifier_loss: 1.6921 - main_classifier_accuracy: 0.5766 - main_classifier_macro_f1score: 0.0697 - main_classifier_weighted_f1score: 0.0014 - auxiliary_classifier_accuracy: 0.8080 - auxiliary_classifier_macro_f1score: 0.1309 - auxiliary_classifier_weighted_f1score: 0.0025\n",
      "Epoch 00029: val_loss did not improve from 3.65553\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 582s 2s/step - loss: 3.2060 - main_classifier_loss: 2.5292 - auxiliary_classifier_loss: 1.6921 - main_classifier_accuracy: 0.5766 - main_classifier_macro_f1score: 0.0697 - main_classifier_weighted_f1score: 0.0014 - auxiliary_classifier_accuracy: 0.8080 - auxiliary_classifier_macro_f1score: 0.1309 - auxiliary_classifier_weighted_f1score: 0.0025 - val_loss: 3.6814 - val_main_classifier_loss: 2.6500 - val_auxiliary_classifier_loss: 2.5785 - val_main_classifier_accuracy: 0.5493 - val_main_classifier_macro_f1score: 0.0725 - val_main_classifier_weighted_f1score: 0.0015 - val_auxiliary_classifier_accuracy: 0.5954 - val_auxiliary_classifier_macro_f1score: 0.0937 - val_auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 30/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.0687 - main_classifier_loss: 2.4260 - auxiliary_classifier_loss: 1.6069 - main_classifier_accuracy: 0.6102 - main_classifier_macro_f1score: 0.0757 - main_classifier_weighted_f1score: 0.0015 - auxiliary_classifier_accuracy: 0.8371 - auxiliary_classifier_macro_f1score: 0.1389 - auxiliary_classifier_weighted_f1score: 0.0026\n",
      "Epoch 00030: val_loss improved from 3.65553 to 3.61108, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/030.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 583s 2s/step - loss: 3.0687 - main_classifier_loss: 2.4260 - auxiliary_classifier_loss: 1.6069 - main_classifier_accuracy: 0.6102 - main_classifier_macro_f1score: 0.0757 - main_classifier_weighted_f1score: 0.0015 - auxiliary_classifier_accuracy: 0.8371 - auxiliary_classifier_macro_f1score: 0.1389 - auxiliary_classifier_weighted_f1score: 0.0026 - val_loss: 3.6111 - val_main_classifier_loss: 2.5975 - val_auxiliary_classifier_loss: 2.5341 - val_main_classifier_accuracy: 0.5744 - val_main_classifier_macro_f1score: 0.0765 - val_main_classifier_weighted_f1score: 0.0015 - val_auxiliary_classifier_accuracy: 0.5944 - val_auxiliary_classifier_macro_f1score: 0.0975 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 31/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.0084 - main_classifier_loss: 2.3782 - auxiliary_classifier_loss: 1.5756 - main_classifier_accuracy: 0.6237 - main_classifier_macro_f1score: 0.0792 - main_classifier_weighted_f1score: 0.0016 - auxiliary_classifier_accuracy: 0.8503 - auxiliary_classifier_macro_f1score: 0.1411 - auxiliary_classifier_weighted_f1score: 0.0027\n",
      "Epoch 00031: val_loss improved from 3.61108 to 3.56555, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/031.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 584s 2s/step - loss: 3.0084 - main_classifier_loss: 2.3782 - auxiliary_classifier_loss: 1.5756 - main_classifier_accuracy: 0.6237 - main_classifier_macro_f1score: 0.0792 - main_classifier_weighted_f1score: 0.0016 - auxiliary_classifier_accuracy: 0.8503 - auxiliary_classifier_macro_f1score: 0.1411 - auxiliary_classifier_weighted_f1score: 0.0027 - val_loss: 3.5655 - val_main_classifier_loss: 2.5590 - val_auxiliary_classifier_loss: 2.5164 - val_main_classifier_accuracy: 0.5836 - val_main_classifier_macro_f1score: 0.0797 - val_main_classifier_weighted_f1score: 0.0016 - val_auxiliary_classifier_accuracy: 0.6036 - val_auxiliary_classifier_macro_f1score: 0.0989 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 32/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.9404 - main_classifier_loss: 2.3242 - auxiliary_classifier_loss: 1.5404 - main_classifier_accuracy: 0.6373 - main_classifier_macro_f1score: 0.0830 - main_classifier_weighted_f1score: 0.0016 - auxiliary_classifier_accuracy: 0.8586 - auxiliary_classifier_macro_f1score: 0.1450 - auxiliary_classifier_weighted_f1score: 0.0027\n",
      "Epoch 00032: val_loss did not improve from 3.56555\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 591s 2s/step - loss: 2.9404 - main_classifier_loss: 2.3242 - auxiliary_classifier_loss: 1.5404 - main_classifier_accuracy: 0.6373 - main_classifier_macro_f1score: 0.0830 - main_classifier_weighted_f1score: 0.0016 - auxiliary_classifier_accuracy: 0.8586 - auxiliary_classifier_macro_f1score: 0.1450 - auxiliary_classifier_weighted_f1score: 0.0027 - val_loss: 3.5689 - val_main_classifier_loss: 2.5600 - val_auxiliary_classifier_loss: 2.5223 - val_main_classifier_accuracy: 0.5781 - val_main_classifier_macro_f1score: 0.0805 - val_main_classifier_weighted_f1score: 0.0016 - val_auxiliary_classifier_accuracy: 0.6005 - val_auxiliary_classifier_macro_f1score: 0.0985 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 33/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.8801 - main_classifier_loss: 2.2764 - auxiliary_classifier_loss: 1.5092 - main_classifier_accuracy: 0.6488 - main_classifier_macro_f1score: 0.0858 - main_classifier_weighted_f1score: 0.0017 - auxiliary_classifier_accuracy: 0.8697 - auxiliary_classifier_macro_f1score: 0.1484 - auxiliary_classifier_weighted_f1score: 0.0028\n",
      "Epoch 00033: val_loss improved from 3.56555 to 3.52441, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/033.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 597s 2s/step - loss: 2.8801 - main_classifier_loss: 2.2764 - auxiliary_classifier_loss: 1.5092 - main_classifier_accuracy: 0.6488 - main_classifier_macro_f1score: 0.0858 - main_classifier_weighted_f1score: 0.0017 - auxiliary_classifier_accuracy: 0.8697 - auxiliary_classifier_macro_f1score: 0.1484 - auxiliary_classifier_weighted_f1score: 0.0028 - val_loss: 3.5244 - val_main_classifier_loss: 2.5250 - val_auxiliary_classifier_loss: 2.4986 - val_main_classifier_accuracy: 0.5883 - val_main_classifier_macro_f1score: 0.0834 - val_main_classifier_weighted_f1score: 0.0016 - val_auxiliary_classifier_accuracy: 0.6067 - val_auxiliary_classifier_macro_f1score: 0.0996 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 34/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.0016 - main_classifier_loss: 2.3774 - auxiliary_classifier_loss: 1.5607 - main_classifier_accuracy: 0.6249 - main_classifier_macro_f1score: 0.0801 - main_classifier_weighted_f1score: 0.0016 - auxiliary_classifier_accuracy: 0.8540 - auxiliary_classifier_macro_f1score: 0.1441 - auxiliary_classifier_weighted_f1score: 0.0027\n",
      "Epoch 00034: val_loss did not improve from 3.52441\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 595s 2s/step - loss: 3.0016 - main_classifier_loss: 2.3774 - auxiliary_classifier_loss: 1.5607 - main_classifier_accuracy: 0.6249 - main_classifier_macro_f1score: 0.0801 - main_classifier_weighted_f1score: 0.0016 - auxiliary_classifier_accuracy: 0.8540 - auxiliary_classifier_macro_f1score: 0.1441 - auxiliary_classifier_weighted_f1score: 0.0027 - val_loss: 3.5739 - val_main_classifier_loss: 2.5623 - val_auxiliary_classifier_loss: 2.5290 - val_main_classifier_accuracy: 0.5887 - val_main_classifier_macro_f1score: 0.0831 - val_main_classifier_weighted_f1score: 0.0016 - val_auxiliary_classifier_accuracy: 0.6019 - val_auxiliary_classifier_macro_f1score: 0.0999 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 35/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.0640 - main_classifier_loss: 2.4229 - auxiliary_classifier_loss: 1.6028 - main_classifier_accuracy: 0.6080 - main_classifier_macro_f1score: 0.0774 - main_classifier_weighted_f1score: 0.0015 - auxiliary_classifier_accuracy: 0.8370 - auxiliary_classifier_macro_f1score: 0.1396 - auxiliary_classifier_weighted_f1score: 0.0026\n",
      "Epoch 00035: val_loss did not improve from 3.52441\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 597s 2s/step - loss: 3.0640 - main_classifier_loss: 2.4229 - auxiliary_classifier_loss: 1.6028 - main_classifier_accuracy: 0.6080 - main_classifier_macro_f1score: 0.0774 - main_classifier_weighted_f1score: 0.0015 - auxiliary_classifier_accuracy: 0.8370 - auxiliary_classifier_macro_f1score: 0.1396 - auxiliary_classifier_weighted_f1score: 0.0026 - val_loss: 3.5701 - val_main_classifier_loss: 2.5459 - val_auxiliary_classifier_loss: 2.5605 - val_main_classifier_accuracy: 0.5808 - val_main_classifier_macro_f1score: 0.0825 - val_main_classifier_weighted_f1score: 0.0016 - val_auxiliary_classifier_accuracy: 0.5995 - val_auxiliary_classifier_macro_f1score: 0.0978 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 36/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.8397 - main_classifier_loss: 2.2527 - auxiliary_classifier_loss: 1.4676 - main_classifier_accuracy: 0.6548 - main_classifier_macro_f1score: 0.0891 - main_classifier_weighted_f1score: 0.0017 - auxiliary_classifier_accuracy: 0.8828 - auxiliary_classifier_macro_f1score: 0.1533 - auxiliary_classifier_weighted_f1score: 0.0029\n",
      "Epoch 00036: val_loss improved from 3.52441 to 3.51676, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/036.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 600s 2s/step - loss: 2.8397 - main_classifier_loss: 2.2527 - auxiliary_classifier_loss: 1.4676 - main_classifier_accuracy: 0.6548 - main_classifier_macro_f1score: 0.0891 - main_classifier_weighted_f1score: 0.0017 - auxiliary_classifier_accuracy: 0.8828 - auxiliary_classifier_macro_f1score: 0.1533 - auxiliary_classifier_weighted_f1score: 0.0029 - val_loss: 3.5168 - val_main_classifier_loss: 2.5069 - val_auxiliary_classifier_loss: 2.5247 - val_main_classifier_accuracy: 0.5951 - val_main_classifier_macro_f1score: 0.0865 - val_main_classifier_weighted_f1score: 0.0017 - val_auxiliary_classifier_accuracy: 0.6036 - val_auxiliary_classifier_macro_f1score: 0.0988 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 37/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.7598 - main_classifier_loss: 2.1873 - auxiliary_classifier_loss: 1.4310 - main_classifier_accuracy: 0.6767 - main_classifier_macro_f1score: 0.0930 - main_classifier_weighted_f1score: 0.0018 - auxiliary_classifier_accuracy: 0.8983 - auxiliary_classifier_macro_f1score: 0.1577 - auxiliary_classifier_weighted_f1score: 0.0029\n",
      "Epoch 00037: val_loss improved from 3.51676 to 3.48801, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/037.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 600s 2s/step - loss: 2.7598 - main_classifier_loss: 2.1873 - auxiliary_classifier_loss: 1.4310 - main_classifier_accuracy: 0.6767 - main_classifier_macro_f1score: 0.0930 - main_classifier_weighted_f1score: 0.0018 - auxiliary_classifier_accuracy: 0.8983 - auxiliary_classifier_macro_f1score: 0.1577 - auxiliary_classifier_weighted_f1score: 0.0029 - val_loss: 3.4880 - val_main_classifier_loss: 2.4848 - val_auxiliary_classifier_loss: 2.5081 - val_main_classifier_accuracy: 0.6050 - val_main_classifier_macro_f1score: 0.0881 - val_main_classifier_weighted_f1score: 0.0017 - val_auxiliary_classifier_accuracy: 0.6060 - val_auxiliary_classifier_macro_f1score: 0.1012 - val_auxiliary_classifier_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 38/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.6778 - main_classifier_loss: 2.1178 - auxiliary_classifier_loss: 1.4000 - main_classifier_accuracy: 0.6970 - main_classifier_macro_f1score: 0.0979 - main_classifier_weighted_f1score: 0.0019 - auxiliary_classifier_accuracy: 0.9072 - auxiliary_classifier_macro_f1score: 0.1617 - auxiliary_classifier_weighted_f1score: 0.0030\n",
      "Epoch 00038: val_loss did not improve from 3.48801\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 599s 2s/step - loss: 2.6778 - main_classifier_loss: 2.1178 - auxiliary_classifier_loss: 1.4000 - main_classifier_accuracy: 0.6970 - main_classifier_macro_f1score: 0.0979 - main_classifier_weighted_f1score: 0.0019 - auxiliary_classifier_accuracy: 0.9072 - auxiliary_classifier_macro_f1score: 0.1617 - auxiliary_classifier_weighted_f1score: 0.0030 - val_loss: 3.5115 - val_main_classifier_loss: 2.4986 - val_auxiliary_classifier_loss: 2.5324 - val_main_classifier_accuracy: 0.5992 - val_main_classifier_macro_f1score: 0.0899 - val_main_classifier_weighted_f1score: 0.0018 - val_auxiliary_classifier_accuracy: 0.6002 - val_auxiliary_classifier_macro_f1score: 0.0988 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 39/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.6282 - main_classifier_loss: 2.0776 - auxiliary_classifier_loss: 1.3766 - main_classifier_accuracy: 0.7080 - main_classifier_macro_f1score: 0.1016 - main_classifier_weighted_f1score: 0.0020 - auxiliary_classifier_accuracy: 0.9122 - auxiliary_classifier_macro_f1score: 0.1643 - auxiliary_classifier_weighted_f1score: 0.0031\n",
      "Epoch 00039: val_loss improved from 3.48801 to 3.48776, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/039.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 604s 2s/step - loss: 2.6282 - main_classifier_loss: 2.0776 - auxiliary_classifier_loss: 1.3766 - main_classifier_accuracy: 0.7080 - main_classifier_macro_f1score: 0.1016 - main_classifier_weighted_f1score: 0.0020 - auxiliary_classifier_accuracy: 0.9122 - auxiliary_classifier_macro_f1score: 0.1643 - auxiliary_classifier_weighted_f1score: 0.0031 - val_loss: 3.4878 - val_main_classifier_loss: 2.4751 - val_auxiliary_classifier_loss: 2.5318 - val_main_classifier_accuracy: 0.6029 - val_main_classifier_macro_f1score: 0.0899 - val_main_classifier_weighted_f1score: 0.0018 - val_auxiliary_classifier_accuracy: 0.6033 - val_auxiliary_classifier_macro_f1score: 0.0985 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 40/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.5834 - main_classifier_loss: 2.0390 - auxiliary_classifier_loss: 1.3609 - main_classifier_accuracy: 0.7186 - main_classifier_macro_f1score: 0.1044 - main_classifier_weighted_f1score: 0.0020 - auxiliary_classifier_accuracy: 0.9180 - auxiliary_classifier_macro_f1score: 0.1666 - auxiliary_classifier_weighted_f1score: 0.0031\n",
      "Epoch 00040: val_loss improved from 3.48776 to 3.43775, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/040.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 604s 2s/step - loss: 2.5834 - main_classifier_loss: 2.0390 - auxiliary_classifier_loss: 1.3609 - main_classifier_accuracy: 0.7186 - main_classifier_macro_f1score: 0.1044 - main_classifier_weighted_f1score: 0.0020 - auxiliary_classifier_accuracy: 0.9180 - auxiliary_classifier_macro_f1score: 0.1666 - auxiliary_classifier_weighted_f1score: 0.0031 - val_loss: 3.4377 - val_main_classifier_loss: 2.4387 - val_auxiliary_classifier_loss: 2.4976 - val_main_classifier_accuracy: 0.6172 - val_main_classifier_macro_f1score: 0.0945 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6158 - val_auxiliary_classifier_macro_f1score: 0.1001 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 41/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.5468 - main_classifier_loss: 2.0084 - auxiliary_classifier_loss: 1.3462 - main_classifier_accuracy: 0.7272 - main_classifier_macro_f1score: 0.1074 - main_classifier_weighted_f1score: 0.0021 - auxiliary_classifier_accuracy: 0.9244 - auxiliary_classifier_macro_f1score: 0.1674 - auxiliary_classifier_weighted_f1score: 0.0031\n",
      "Epoch 00041: val_loss did not improve from 3.43775\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 600s 2s/step - loss: 2.5468 - main_classifier_loss: 2.0084 - auxiliary_classifier_loss: 1.3462 - main_classifier_accuracy: 0.7272 - main_classifier_macro_f1score: 0.1074 - main_classifier_weighted_f1score: 0.0021 - auxiliary_classifier_accuracy: 0.9244 - auxiliary_classifier_macro_f1score: 0.1674 - auxiliary_classifier_weighted_f1score: 0.0031 - val_loss: 3.4674 - val_main_classifier_loss: 2.4548 - val_auxiliary_classifier_loss: 2.5314 - val_main_classifier_accuracy: 0.6104 - val_main_classifier_macro_f1score: 0.0924 - val_main_classifier_weighted_f1score: 0.0018 - val_auxiliary_classifier_accuracy: 0.6124 - val_auxiliary_classifier_macro_f1score: 0.0995 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 42/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.4916 - main_classifier_loss: 1.9605 - auxiliary_classifier_loss: 1.3277 - main_classifier_accuracy: 0.7408 - main_classifier_macro_f1score: 0.1101 - main_classifier_weighted_f1score: 0.0021 - auxiliary_classifier_accuracy: 0.9294 - auxiliary_classifier_macro_f1score: 0.1698 - auxiliary_classifier_weighted_f1score: 0.0032\n",
      "Epoch 00042: val_loss did not improve from 3.43775\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 600s 2s/step - loss: 2.4916 - main_classifier_loss: 1.9605 - auxiliary_classifier_loss: 1.3277 - main_classifier_accuracy: 0.7408 - main_classifier_macro_f1score: 0.1101 - main_classifier_weighted_f1score: 0.0021 - auxiliary_classifier_accuracy: 0.9294 - auxiliary_classifier_macro_f1score: 0.1698 - auxiliary_classifier_weighted_f1score: 0.0032 - val_loss: 3.4526 - val_main_classifier_loss: 2.4517 - val_auxiliary_classifier_loss: 2.5022 - val_main_classifier_accuracy: 0.6158 - val_main_classifier_macro_f1score: 0.0955 - val_main_classifier_weighted_f1score: 0.0018 - val_auxiliary_classifier_accuracy: 0.6118 - val_auxiliary_classifier_macro_f1score: 0.1004 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 43/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.4604 - main_classifier_loss: 1.9349 - auxiliary_classifier_loss: 1.3138 - main_classifier_accuracy: 0.7498 - main_classifier_macro_f1score: 0.1129 - main_classifier_weighted_f1score: 0.0022 - auxiliary_classifier_accuracy: 0.9329 - auxiliary_classifier_macro_f1score: 0.1722 - auxiliary_classifier_weighted_f1score: 0.0032\n",
      "Epoch 00043: val_loss did not improve from 3.43775\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 596s 2s/step - loss: 2.4604 - main_classifier_loss: 1.9349 - auxiliary_classifier_loss: 1.3138 - main_classifier_accuracy: 0.7498 - main_classifier_macro_f1score: 0.1129 - main_classifier_weighted_f1score: 0.0022 - auxiliary_classifier_accuracy: 0.9329 - auxiliary_classifier_macro_f1score: 0.1722 - auxiliary_classifier_weighted_f1score: 0.0032 - val_loss: 3.4403 - val_main_classifier_loss: 2.4369 - val_auxiliary_classifier_loss: 2.5084 - val_main_classifier_accuracy: 0.6114 - val_main_classifier_macro_f1score: 0.0934 - val_main_classifier_weighted_f1score: 0.0018 - val_auxiliary_classifier_accuracy: 0.6128 - val_auxiliary_classifier_macro_f1score: 0.1010 - val_auxiliary_classifier_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 44/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.4052 - main_classifier_loss: 1.8856 - auxiliary_classifier_loss: 1.2990 - main_classifier_accuracy: 0.7624 - main_classifier_macro_f1score: 0.1178 - main_classifier_weighted_f1score: 0.0022 - auxiliary_classifier_accuracy: 0.9372 - auxiliary_classifier_macro_f1score: 0.1748 - auxiliary_classifier_weighted_f1score: 0.0032\n",
      "Epoch 00044: val_loss did not improve from 3.43775\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 585s 2s/step - loss: 2.4052 - main_classifier_loss: 1.8856 - auxiliary_classifier_loss: 1.2990 - main_classifier_accuracy: 0.7624 - main_classifier_macro_f1score: 0.1178 - main_classifier_weighted_f1score: 0.0022 - auxiliary_classifier_accuracy: 0.9372 - auxiliary_classifier_macro_f1score: 0.1748 - auxiliary_classifier_weighted_f1score: 0.0032 - val_loss: 3.4499 - val_main_classifier_loss: 2.4390 - val_auxiliary_classifier_loss: 2.5274 - val_main_classifier_accuracy: 0.6179 - val_main_classifier_macro_f1score: 0.0965 - val_main_classifier_weighted_f1score: 0.0018 - val_auxiliary_classifier_accuracy: 0.6107 - val_auxiliary_classifier_macro_f1score: 0.1025 - val_auxiliary_classifier_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 45/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.3728 - main_classifier_loss: 1.8588 - auxiliary_classifier_loss: 1.2850 - main_classifier_accuracy: 0.7741 - main_classifier_macro_f1score: 0.1200 - main_classifier_weighted_f1score: 0.0023 - auxiliary_classifier_accuracy: 0.9416 - auxiliary_classifier_macro_f1score: 0.1758 - auxiliary_classifier_weighted_f1score: 0.0033\n",
      "Epoch 00045: val_loss did not improve from 3.43775\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 586s 2s/step - loss: 2.3728 - main_classifier_loss: 1.8588 - auxiliary_classifier_loss: 1.2850 - main_classifier_accuracy: 0.7741 - main_classifier_macro_f1score: 0.1200 - main_classifier_weighted_f1score: 0.0023 - auxiliary_classifier_accuracy: 0.9416 - auxiliary_classifier_macro_f1score: 0.1758 - auxiliary_classifier_weighted_f1score: 0.0033 - val_loss: 3.4436 - val_main_classifier_loss: 2.4399 - val_auxiliary_classifier_loss: 2.5092 - val_main_classifier_accuracy: 0.6189 - val_main_classifier_macro_f1score: 0.0970 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6104 - val_auxiliary_classifier_macro_f1score: 0.1002 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 46/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.3653 - main_classifier_loss: 1.8512 - auxiliary_classifier_loss: 1.2851 - main_classifier_accuracy: 0.7755 - main_classifier_macro_f1score: 0.1208 - main_classifier_weighted_f1score: 0.0023 - auxiliary_classifier_accuracy: 0.9426 - auxiliary_classifier_macro_f1score: 0.1762 - auxiliary_classifier_weighted_f1score: 0.0033\n",
      "Epoch 00046: val_loss did not improve from 3.43775\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 585s 2s/step - loss: 2.3653 - main_classifier_loss: 1.8512 - auxiliary_classifier_loss: 1.2851 - main_classifier_accuracy: 0.7755 - main_classifier_macro_f1score: 0.1208 - main_classifier_weighted_f1score: 0.0023 - auxiliary_classifier_accuracy: 0.9426 - auxiliary_classifier_macro_f1score: 0.1762 - auxiliary_classifier_weighted_f1score: 0.0033 - val_loss: 3.4572 - val_main_classifier_loss: 2.4487 - val_auxiliary_classifier_loss: 2.5214 - val_main_classifier_accuracy: 0.6138 - val_main_classifier_macro_f1score: 0.0967 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6080 - val_auxiliary_classifier_macro_f1score: 0.0991 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 47/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.3096 - main_classifier_loss: 1.8038 - auxiliary_classifier_loss: 1.2646 - main_classifier_accuracy: 0.7898 - main_classifier_macro_f1score: 0.1251 - main_classifier_weighted_f1score: 0.0024 - auxiliary_classifier_accuracy: 0.9485 - auxiliary_classifier_macro_f1score: 0.1788 - auxiliary_classifier_weighted_f1score: 0.0033\n",
      "Epoch 00047: val_loss improved from 3.43775 to 3.42244, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/047.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 586s 2s/step - loss: 2.3096 - main_classifier_loss: 1.8038 - auxiliary_classifier_loss: 1.2646 - main_classifier_accuracy: 0.7898 - main_classifier_macro_f1score: 0.1251 - main_classifier_weighted_f1score: 0.0024 - auxiliary_classifier_accuracy: 0.9485 - auxiliary_classifier_macro_f1score: 0.1788 - auxiliary_classifier_weighted_f1score: 0.0033 - val_loss: 3.4224 - val_main_classifier_loss: 2.4197 - val_auxiliary_classifier_loss: 2.5069 - val_main_classifier_accuracy: 0.6243 - val_main_classifier_macro_f1score: 0.0984 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6128 - val_auxiliary_classifier_macro_f1score: 0.1012 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 48/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.2767 - main_classifier_loss: 1.7751 - auxiliary_classifier_loss: 1.2541 - main_classifier_accuracy: 0.7981 - main_classifier_macro_f1score: 0.1271 - main_classifier_weighted_f1score: 0.0024 - auxiliary_classifier_accuracy: 0.9522 - auxiliary_classifier_macro_f1score: 0.1805 - auxiliary_classifier_weighted_f1score: 0.0033\n",
      "Epoch 00048: val_loss did not improve from 3.42244\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 582s 2s/step - loss: 2.2767 - main_classifier_loss: 1.7751 - auxiliary_classifier_loss: 1.2541 - main_classifier_accuracy: 0.7981 - main_classifier_macro_f1score: 0.1271 - main_classifier_weighted_f1score: 0.0024 - auxiliary_classifier_accuracy: 0.9522 - auxiliary_classifier_macro_f1score: 0.1805 - auxiliary_classifier_weighted_f1score: 0.0033 - val_loss: 3.4250 - val_main_classifier_loss: 2.4207 - val_auxiliary_classifier_loss: 2.5110 - val_main_classifier_accuracy: 0.6209 - val_main_classifier_macro_f1score: 0.0981 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6043 - val_auxiliary_classifier_macro_f1score: 0.1008 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 49/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.2447 - main_classifier_loss: 1.7454 - auxiliary_classifier_loss: 1.2483 - main_classifier_accuracy: 0.8110 - main_classifier_macro_f1score: 0.1295 - main_classifier_weighted_f1score: 0.0024 - auxiliary_classifier_accuracy: 0.9532 - auxiliary_classifier_macro_f1score: 0.1806 - auxiliary_classifier_weighted_f1score: 0.0033\n",
      "Epoch 00049: val_loss improved from 3.42244 to 3.41745, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/049.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 583s 2s/step - loss: 2.2447 - main_classifier_loss: 1.7454 - auxiliary_classifier_loss: 1.2483 - main_classifier_accuracy: 0.8110 - main_classifier_macro_f1score: 0.1295 - main_classifier_weighted_f1score: 0.0024 - auxiliary_classifier_accuracy: 0.9532 - auxiliary_classifier_macro_f1score: 0.1806 - auxiliary_classifier_weighted_f1score: 0.0033 - val_loss: 3.4175 - val_main_classifier_loss: 2.4196 - val_auxiliary_classifier_loss: 2.4947 - val_main_classifier_accuracy: 0.6216 - val_main_classifier_macro_f1score: 0.0999 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6155 - val_auxiliary_classifier_macro_f1score: 0.1020 - val_auxiliary_classifier_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 50/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.1919 - main_classifier_loss: 1.6996 - auxiliary_classifier_loss: 1.2309 - main_classifier_accuracy: 0.8218 - main_classifier_macro_f1score: 0.1348 - main_classifier_weighted_f1score: 0.0025 - auxiliary_classifier_accuracy: 0.9571 - auxiliary_classifier_macro_f1score: 0.1823 - auxiliary_classifier_weighted_f1score: 0.0034\n",
      "Epoch 00050: val_loss improved from 3.41745 to 3.41020, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/050.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 584s 2s/step - loss: 2.1919 - main_classifier_loss: 1.6996 - auxiliary_classifier_loss: 1.2309 - main_classifier_accuracy: 0.8218 - main_classifier_macro_f1score: 0.1348 - main_classifier_weighted_f1score: 0.0025 - auxiliary_classifier_accuracy: 0.9571 - auxiliary_classifier_macro_f1score: 0.1823 - auxiliary_classifier_weighted_f1score: 0.0034 - val_loss: 3.4102 - val_main_classifier_loss: 2.4159 - val_auxiliary_classifier_loss: 2.4858 - val_main_classifier_accuracy: 0.6155 - val_main_classifier_macro_f1score: 0.0985 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6135 - val_auxiliary_classifier_macro_f1score: 0.1000 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 51/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.9567 - main_classifier_loss: 1.4992 - auxiliary_classifier_loss: 1.1437 - main_classifier_accuracy: 0.8940 - main_classifier_macro_f1score: 0.1558 - main_classifier_weighted_f1score: 0.0029 - auxiliary_classifier_accuracy: 0.9821 - auxiliary_classifier_macro_f1score: 0.1961 - auxiliary_classifier_weighted_f1score: 0.0036\n",
      "Epoch 00051: val_loss improved from 3.41020 to 3.38432, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/051.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 587s 2s/step - loss: 1.9567 - main_classifier_loss: 1.4992 - auxiliary_classifier_loss: 1.1437 - main_classifier_accuracy: 0.8940 - main_classifier_macro_f1score: 0.1558 - main_classifier_weighted_f1score: 0.0029 - auxiliary_classifier_accuracy: 0.9821 - auxiliary_classifier_macro_f1score: 0.1961 - auxiliary_classifier_weighted_f1score: 0.0036 - val_loss: 3.3843 - val_main_classifier_loss: 2.3952 - val_auxiliary_classifier_loss: 2.4728 - val_main_classifier_accuracy: 0.6260 - val_main_classifier_macro_f1score: 0.0993 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6182 - val_auxiliary_classifier_macro_f1score: 0.0985 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 52/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.9082 - main_classifier_loss: 1.4581 - auxiliary_classifier_loss: 1.1253 - main_classifier_accuracy: 0.9089 - main_classifier_macro_f1score: 0.1602 - main_classifier_weighted_f1score: 0.0030 - auxiliary_classifier_accuracy: 0.9862 - auxiliary_classifier_macro_f1score: 0.1973 - auxiliary_classifier_weighted_f1score: 0.0036\n",
      "Epoch 00052: val_loss improved from 3.38432 to 3.37404, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/052.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 585s 2s/step - loss: 1.9082 - main_classifier_loss: 1.4581 - auxiliary_classifier_loss: 1.1253 - main_classifier_accuracy: 0.9089 - main_classifier_macro_f1score: 0.1602 - main_classifier_weighted_f1score: 0.0030 - auxiliary_classifier_accuracy: 0.9862 - auxiliary_classifier_macro_f1score: 0.1973 - auxiliary_classifier_weighted_f1score: 0.0036 - val_loss: 3.3740 - val_main_classifier_loss: 2.3864 - val_auxiliary_classifier_loss: 2.4691 - val_main_classifier_accuracy: 0.6301 - val_main_classifier_macro_f1score: 0.1002 - val_main_classifier_weighted_f1score: 0.0020 - val_auxiliary_classifier_accuracy: 0.6213 - val_auxiliary_classifier_macro_f1score: 0.0974 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 53/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.8804 - main_classifier_loss: 1.4326 - auxiliary_classifier_loss: 1.1195 - main_classifier_accuracy: 0.9172 - main_classifier_macro_f1score: 0.1633 - main_classifier_weighted_f1score: 0.0030 - auxiliary_classifier_accuracy: 0.9872 - auxiliary_classifier_macro_f1score: 0.1981 - auxiliary_classifier_weighted_f1score: 0.0036\n",
      "Epoch 00053: val_loss improved from 3.37404 to 3.37377, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/053.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 587s 2s/step - loss: 1.8804 - main_classifier_loss: 1.4326 - auxiliary_classifier_loss: 1.1195 - main_classifier_accuracy: 0.9172 - main_classifier_macro_f1score: 0.1633 - main_classifier_weighted_f1score: 0.0030 - auxiliary_classifier_accuracy: 0.9872 - auxiliary_classifier_macro_f1score: 0.1981 - auxiliary_classifier_weighted_f1score: 0.0036 - val_loss: 3.3738 - val_main_classifier_loss: 2.3897 - val_auxiliary_classifier_loss: 2.4603 - val_main_classifier_accuracy: 0.6308 - val_main_classifier_macro_f1score: 0.1015 - val_main_classifier_weighted_f1score: 0.0020 - val_auxiliary_classifier_accuracy: 0.6209 - val_auxiliary_classifier_macro_f1score: 0.0987 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 54/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.8702 - main_classifier_loss: 1.4253 - auxiliary_classifier_loss: 1.1124 - main_classifier_accuracy: 0.9183 - main_classifier_macro_f1score: 0.1635 - main_classifier_weighted_f1score: 0.0031 - auxiliary_classifier_accuracy: 0.9889 - auxiliary_classifier_macro_f1score: 0.1980 - auxiliary_classifier_weighted_f1score: 0.0036\n",
      "Epoch 00054: val_loss did not improve from 3.37377\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 584s 2s/step - loss: 1.8702 - main_classifier_loss: 1.4253 - auxiliary_classifier_loss: 1.1124 - main_classifier_accuracy: 0.9183 - main_classifier_macro_f1score: 0.1635 - main_classifier_weighted_f1score: 0.0031 - auxiliary_classifier_accuracy: 0.9889 - auxiliary_classifier_macro_f1score: 0.1980 - auxiliary_classifier_weighted_f1score: 0.0036 - val_loss: 3.3746 - val_main_classifier_loss: 2.3895 - val_auxiliary_classifier_loss: 2.4626 - val_main_classifier_accuracy: 0.6298 - val_main_classifier_macro_f1score: 0.0999 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6155 - val_auxiliary_classifier_macro_f1score: 0.0959 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 55/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.8453 - main_classifier_loss: 1.4017 - auxiliary_classifier_loss: 1.1088 - main_classifier_accuracy: 0.9274 - main_classifier_macro_f1score: 0.1670 - main_classifier_weighted_f1score: 0.0031 - auxiliary_classifier_accuracy: 0.9893 - auxiliary_classifier_macro_f1score: 0.1989 - auxiliary_classifier_weighted_f1score: 0.0036\n",
      "Epoch 00055: val_loss did not improve from 3.37377\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 583s 2s/step - loss: 1.8453 - main_classifier_loss: 1.4017 - auxiliary_classifier_loss: 1.1088 - main_classifier_accuracy: 0.9274 - main_classifier_macro_f1score: 0.1670 - main_classifier_weighted_f1score: 0.0031 - auxiliary_classifier_accuracy: 0.9893 - auxiliary_classifier_macro_f1score: 0.1989 - auxiliary_classifier_weighted_f1score: 0.0036 - val_loss: 3.3763 - val_main_classifier_loss: 2.3904 - val_auxiliary_classifier_loss: 2.4649 - val_main_classifier_accuracy: 0.6315 - val_main_classifier_macro_f1score: 0.1001 - val_main_classifier_weighted_f1score: 0.0020 - val_auxiliary_classifier_accuracy: 0.6233 - val_auxiliary_classifier_macro_f1score: 0.0952 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 56/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.8416 - main_classifier_loss: 1.3997 - auxiliary_classifier_loss: 1.1047 - main_classifier_accuracy: 0.9277 - main_classifier_macro_f1score: 0.1667 - main_classifier_weighted_f1score: 0.0031 - auxiliary_classifier_accuracy: 0.9892 - auxiliary_classifier_macro_f1score: 0.1988 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00056: val_loss did not improve from 3.37377\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 583s 2s/step - loss: 1.8416 - main_classifier_loss: 1.3997 - auxiliary_classifier_loss: 1.1047 - main_classifier_accuracy: 0.9277 - main_classifier_macro_f1score: 0.1667 - main_classifier_weighted_f1score: 0.0031 - auxiliary_classifier_accuracy: 0.9892 - auxiliary_classifier_macro_f1score: 0.1988 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3758 - val_main_classifier_loss: 2.3947 - val_auxiliary_classifier_loss: 2.4526 - val_main_classifier_accuracy: 0.6328 - val_main_classifier_macro_f1score: 0.1024 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6253 - val_auxiliary_classifier_macro_f1score: 0.0964 - val_auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 57/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.8229 - main_classifier_loss: 1.3833 - auxiliary_classifier_loss: 1.0990 - main_classifier_accuracy: 0.9334 - main_classifier_macro_f1score: 0.1687 - main_classifier_weighted_f1score: 0.0031 - auxiliary_classifier_accuracy: 0.9906 - auxiliary_classifier_macro_f1score: 0.1995 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00057: val_loss did not improve from 3.37377\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 583s 2s/step - loss: 1.8229 - main_classifier_loss: 1.3833 - auxiliary_classifier_loss: 1.0990 - main_classifier_accuracy: 0.9334 - main_classifier_macro_f1score: 0.1687 - main_classifier_weighted_f1score: 0.0031 - auxiliary_classifier_accuracy: 0.9906 - auxiliary_classifier_macro_f1score: 0.1995 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3773 - val_main_classifier_loss: 2.3918 - val_auxiliary_classifier_loss: 2.4637 - val_main_classifier_accuracy: 0.6345 - val_main_classifier_macro_f1score: 0.0997 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6223 - val_auxiliary_classifier_macro_f1score: 0.0962 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 58/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.8102 - main_classifier_loss: 1.3721 - auxiliary_classifier_loss: 1.0952 - main_classifier_accuracy: 0.9370 - main_classifier_macro_f1score: 0.1705 - main_classifier_weighted_f1score: 0.0032 - auxiliary_classifier_accuracy: 0.9914 - auxiliary_classifier_macro_f1score: 0.1998 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00058: val_loss improved from 3.37377 to 3.36899, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/058.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 583s 2s/step - loss: 1.8102 - main_classifier_loss: 1.3721 - auxiliary_classifier_loss: 1.0952 - main_classifier_accuracy: 0.9370 - main_classifier_macro_f1score: 0.1705 - main_classifier_weighted_f1score: 0.0032 - auxiliary_classifier_accuracy: 0.9914 - auxiliary_classifier_macro_f1score: 0.1998 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3690 - val_main_classifier_loss: 2.3888 - val_auxiliary_classifier_loss: 2.4506 - val_main_classifier_accuracy: 0.6365 - val_main_classifier_macro_f1score: 0.0993 - val_main_classifier_weighted_f1score: 0.0020 - val_auxiliary_classifier_accuracy: 0.6284 - val_auxiliary_classifier_macro_f1score: 0.0946 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 59/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.8002 - main_classifier_loss: 1.3634 - auxiliary_classifier_loss: 1.0922 - main_classifier_accuracy: 0.9386 - main_classifier_macro_f1score: 0.1712 - main_classifier_weighted_f1score: 0.0032 - auxiliary_classifier_accuracy: 0.9920 - auxiliary_classifier_macro_f1score: 0.1998 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00059: val_loss did not improve from 3.36899\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 582s 2s/step - loss: 1.8002 - main_classifier_loss: 1.3634 - auxiliary_classifier_loss: 1.0922 - main_classifier_accuracy: 0.9386 - main_classifier_macro_f1score: 0.1712 - main_classifier_weighted_f1score: 0.0032 - auxiliary_classifier_accuracy: 0.9920 - auxiliary_classifier_macro_f1score: 0.1998 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3774 - val_main_classifier_loss: 2.3981 - val_auxiliary_classifier_loss: 2.4482 - val_main_classifier_accuracy: 0.6315 - val_main_classifier_macro_f1score: 0.0997 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6311 - val_auxiliary_classifier_macro_f1score: 0.0945 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 60/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7859 - main_classifier_loss: 1.3505 - auxiliary_classifier_loss: 1.0885 - main_classifier_accuracy: 0.9425 - main_classifier_macro_f1score: 0.1729 - main_classifier_weighted_f1score: 0.0032 - auxiliary_classifier_accuracy: 0.9920 - auxiliary_classifier_macro_f1score: 0.2008 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00060: val_loss did not improve from 3.36899\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 580s 2s/step - loss: 1.7859 - main_classifier_loss: 1.3505 - auxiliary_classifier_loss: 1.0885 - main_classifier_accuracy: 0.9425 - main_classifier_macro_f1score: 0.1729 - main_classifier_weighted_f1score: 0.0032 - auxiliary_classifier_accuracy: 0.9920 - auxiliary_classifier_macro_f1score: 0.2008 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3818 - val_main_classifier_loss: 2.4028 - val_auxiliary_classifier_loss: 2.4477 - val_main_classifier_accuracy: 0.6304 - val_main_classifier_macro_f1score: 0.1014 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6315 - val_auxiliary_classifier_macro_f1score: 0.0959 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 61/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7814 - main_classifier_loss: 1.3472 - auxiliary_classifier_loss: 1.0856 - main_classifier_accuracy: 0.9441 - main_classifier_macro_f1score: 0.1721 - main_classifier_weighted_f1score: 0.0032 - auxiliary_classifier_accuracy: 0.9931 - auxiliary_classifier_macro_f1score: 0.2004 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00061: val_loss did not improve from 3.36899\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 583s 2s/step - loss: 1.7814 - main_classifier_loss: 1.3472 - auxiliary_classifier_loss: 1.0856 - main_classifier_accuracy: 0.9441 - main_classifier_macro_f1score: 0.1721 - main_classifier_weighted_f1score: 0.0032 - auxiliary_classifier_accuracy: 0.9931 - auxiliary_classifier_macro_f1score: 0.2004 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3813 - val_main_classifier_loss: 2.4021 - val_auxiliary_classifier_loss: 2.4478 - val_main_classifier_accuracy: 0.6318 - val_main_classifier_macro_f1score: 0.1039 - val_main_classifier_weighted_f1score: 0.0020 - val_auxiliary_classifier_accuracy: 0.6260 - val_auxiliary_classifier_macro_f1score: 0.0961 - val_auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 62/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7647 - main_classifier_loss: 1.3329 - auxiliary_classifier_loss: 1.0797 - main_classifier_accuracy: 0.9503 - main_classifier_macro_f1score: 0.1751 - main_classifier_weighted_f1score: 0.0032 - auxiliary_classifier_accuracy: 0.9939 - auxiliary_classifier_macro_f1score: 0.2014 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00062: val_loss did not improve from 3.36899\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 585s 2s/step - loss: 1.7647 - main_classifier_loss: 1.3329 - auxiliary_classifier_loss: 1.0797 - main_classifier_accuracy: 0.9503 - main_classifier_macro_f1score: 0.1751 - main_classifier_weighted_f1score: 0.0032 - auxiliary_classifier_accuracy: 0.9939 - auxiliary_classifier_macro_f1score: 0.2014 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3873 - val_main_classifier_loss: 2.4076 - val_auxiliary_classifier_loss: 2.4491 - val_main_classifier_accuracy: 0.6325 - val_main_classifier_macro_f1score: 0.1002 - val_main_classifier_weighted_f1score: 0.0020 - val_auxiliary_classifier_accuracy: 0.6260 - val_auxiliary_classifier_macro_f1score: 0.0949 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 63/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7640 - main_classifier_loss: 1.3312 - auxiliary_classifier_loss: 1.0821 - main_classifier_accuracy: 0.9504 - main_classifier_macro_f1score: 0.1753 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9927 - auxiliary_classifier_macro_f1score: 0.2009 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00063: val_loss did not improve from 3.36899\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 588s 2s/step - loss: 1.7640 - main_classifier_loss: 1.3312 - auxiliary_classifier_loss: 1.0821 - main_classifier_accuracy: 0.9504 - main_classifier_macro_f1score: 0.1753 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9927 - auxiliary_classifier_macro_f1score: 0.2009 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3719 - val_main_classifier_loss: 2.3977 - val_auxiliary_classifier_loss: 2.4355 - val_main_classifier_accuracy: 0.6342 - val_main_classifier_macro_f1score: 0.1014 - val_main_classifier_weighted_f1score: 0.0020 - val_auxiliary_classifier_accuracy: 0.6267 - val_auxiliary_classifier_macro_f1score: 0.0970 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 64/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7544 - main_classifier_loss: 1.3234 - auxiliary_classifier_loss: 1.0775 - main_classifier_accuracy: 0.9527 - main_classifier_macro_f1score: 0.1755 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9932 - auxiliary_classifier_macro_f1score: 0.2006 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00064: val_loss did not improve from 3.36899\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 593s 2s/step - loss: 1.7544 - main_classifier_loss: 1.3234 - auxiliary_classifier_loss: 1.0775 - main_classifier_accuracy: 0.9527 - main_classifier_macro_f1score: 0.1755 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9932 - auxiliary_classifier_macro_f1score: 0.2006 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3862 - val_main_classifier_loss: 2.4100 - val_auxiliary_classifier_loss: 2.4404 - val_main_classifier_accuracy: 0.6352 - val_main_classifier_macro_f1score: 0.1012 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6253 - val_auxiliary_classifier_macro_f1score: 0.0948 - val_auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 65/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7500 - main_classifier_loss: 1.3186 - auxiliary_classifier_loss: 1.0784 - main_classifier_accuracy: 0.9526 - main_classifier_macro_f1score: 0.1766 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9928 - auxiliary_classifier_macro_f1score: 0.2018 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00065: val_loss did not improve from 3.36899\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 600s 2s/step - loss: 1.7500 - main_classifier_loss: 1.3186 - auxiliary_classifier_loss: 1.0784 - main_classifier_accuracy: 0.9526 - main_classifier_macro_f1score: 0.1766 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9928 - auxiliary_classifier_macro_f1score: 0.2018 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3845 - val_main_classifier_loss: 2.4066 - val_auxiliary_classifier_loss: 2.4448 - val_main_classifier_accuracy: 0.6291 - val_main_classifier_macro_f1score: 0.0995 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6253 - val_auxiliary_classifier_macro_f1score: 0.0941 - val_auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 66/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7446 - main_classifier_loss: 1.3149 - auxiliary_classifier_loss: 1.0744 - main_classifier_accuracy: 0.9561 - main_classifier_macro_f1score: 0.1771 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9939 - auxiliary_classifier_macro_f1score: 0.2023 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00066: val_loss improved from 3.36899 to 3.36482, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v3/066.h5\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 602s 2s/step - loss: 1.7446 - main_classifier_loss: 1.3149 - auxiliary_classifier_loss: 1.0744 - main_classifier_accuracy: 0.9561 - main_classifier_macro_f1score: 0.1771 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9939 - auxiliary_classifier_macro_f1score: 0.2023 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3648 - val_main_classifier_loss: 2.3917 - val_auxiliary_classifier_loss: 2.4328 - val_main_classifier_accuracy: 0.6342 - val_main_classifier_macro_f1score: 0.1008 - val_main_classifier_weighted_f1score: 0.0020 - val_auxiliary_classifier_accuracy: 0.6328 - val_auxiliary_classifier_macro_f1score: 0.0940 - val_auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 67/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7273 - main_classifier_loss: 1.2992 - auxiliary_classifier_loss: 1.0702 - main_classifier_accuracy: 0.9600 - main_classifier_macro_f1score: 0.1791 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9942 - auxiliary_classifier_macro_f1score: 0.2027 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00067: val_loss did not improve from 3.36482\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 606s 2s/step - loss: 1.7273 - main_classifier_loss: 1.2992 - auxiliary_classifier_loss: 1.0702 - main_classifier_accuracy: 0.9600 - main_classifier_macro_f1score: 0.1791 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9942 - auxiliary_classifier_macro_f1score: 0.2027 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3869 - val_main_classifier_loss: 2.4090 - val_auxiliary_classifier_loss: 2.4446 - val_main_classifier_accuracy: 0.6318 - val_main_classifier_macro_f1score: 0.1009 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6321 - val_auxiliary_classifier_macro_f1score: 0.0948 - val_auxiliary_classifier_weighted_f1score: 0.0018\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 68/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7248 - main_classifier_loss: 1.2972 - auxiliary_classifier_loss: 1.0691 - main_classifier_accuracy: 0.9593 - main_classifier_macro_f1score: 0.1792 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9948 - auxiliary_classifier_macro_f1score: 0.2026 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00068: val_loss did not improve from 3.36482\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 610s 2s/step - loss: 1.7248 - main_classifier_loss: 1.2972 - auxiliary_classifier_loss: 1.0691 - main_classifier_accuracy: 0.9593 - main_classifier_macro_f1score: 0.1792 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9948 - auxiliary_classifier_macro_f1score: 0.2026 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3677 - val_main_classifier_loss: 2.3959 - val_auxiliary_classifier_loss: 2.4296 - val_main_classifier_accuracy: 0.6386 - val_main_classifier_macro_f1score: 0.1009 - val_main_classifier_weighted_f1score: 0.0020 - val_auxiliary_classifier_accuracy: 0.6335 - val_auxiliary_classifier_macro_f1score: 0.0954 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 69/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7184 - main_classifier_loss: 1.2918 - auxiliary_classifier_loss: 1.0665 - main_classifier_accuracy: 0.9623 - main_classifier_macro_f1score: 0.1797 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9941 - auxiliary_classifier_macro_f1score: 0.2026 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00069: val_loss did not improve from 3.36482\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 603s 2s/step - loss: 1.7184 - main_classifier_loss: 1.2918 - auxiliary_classifier_loss: 1.0665 - main_classifier_accuracy: 0.9623 - main_classifier_macro_f1score: 0.1797 - main_classifier_weighted_f1score: 0.0033 - auxiliary_classifier_accuracy: 0.9941 - auxiliary_classifier_macro_f1score: 0.2026 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3742 - val_main_classifier_loss: 2.4012 - val_auxiliary_classifier_loss: 2.4324 - val_main_classifier_accuracy: 0.6379 - val_main_classifier_macro_f1score: 0.1020 - val_main_classifier_weighted_f1score: 0.0020 - val_auxiliary_classifier_accuracy: 0.6301 - val_auxiliary_classifier_macro_f1score: 0.0965 - val_auxiliary_classifier_weighted_f1score: 0.0019\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 70/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7078 - main_classifier_loss: 1.2826 - auxiliary_classifier_loss: 1.0632 - main_classifier_accuracy: 0.9635 - main_classifier_macro_f1score: 0.1812 - main_classifier_weighted_f1score: 0.0034 - auxiliary_classifier_accuracy: 0.9951 - auxiliary_classifier_macro_f1score: 0.2034 - auxiliary_classifier_weighted_f1score: 0.0037\n",
      "Epoch 00070: val_loss did not improve from 3.36482\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "382/382 [==============================] - 592s 2s/step - loss: 1.7078 - main_classifier_loss: 1.2826 - auxiliary_classifier_loss: 1.0632 - main_classifier_accuracy: 0.9635 - main_classifier_macro_f1score: 0.1812 - main_classifier_weighted_f1score: 0.0034 - auxiliary_classifier_accuracy: 0.9951 - auxiliary_classifier_macro_f1score: 0.2034 - auxiliary_classifier_weighted_f1score: 0.0037 - val_loss: 3.3749 - val_main_classifier_loss: 2.4002 - val_auxiliary_classifier_loss: 2.4368 - val_main_classifier_accuracy: 0.6365 - val_main_classifier_macro_f1score: 0.1019 - val_main_classifier_weighted_f1score: 0.0019 - val_auxiliary_classifier_accuracy: 0.6304 - val_auxiliary_classifier_macro_f1score: 0.0948 - val_auxiliary_classifier_weighted_f1score: 0.0018\n"
     ]
    }
   ],
   "source": [
    "######## flow_from_directory\n",
    "#history = model.fit_generator(generate_train_for_three(), steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = generate_valid_for_three(), epochs=epochs , verbose=1 , callbacks = callbacks_list,validation_steps=int(len(x_valid)/batch_sizes))\n",
    "history = model.fit(generate_train_for_two(), steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = generate_valid_for_two(), epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W3hAqJFKvqie"
   },
   "source": [
    "### 3) Inception-V3 Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56458742,
     "status": "ok",
     "timestamp": 1599370070424,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "lzlSLAHashy7",
    "outputId": "70c2f0be-658a-47a1-841c-39b51a8ed6ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3118 images belonging to 257 classes.\n",
      "48/48 [==============================] - 1414s 29s/step - loss: 3.4086 - main_classifier_loss: 2.4199 - auxiliary_classifier_loss: 2.4718 - main_classifier_accuracy: 0.6159 - main_classifier_macro_f1score: 0.0977 - main_classifier_weighted_f1score: 0.0019 - auxiliary_classifier_accuracy: 0.6123 - auxiliary_classifier_macro_f1score: 0.0931 - auxiliary_classifier_weighted_f1score: 0.0018\n",
      "[Test Loss: 3.4086 /  Test Accuracy: 0.6123 / Test Macro f1: 0.0931 / Test Weighted f1: 0.0018]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. epoch=maximum\n",
    "#var = model.evaluate_generator(generate_test_for_three(),steps=int(len(x_test)/batch_sizes))\n",
    "var = model.evaluate(generate_test_for_two(),steps=int(len(x_test)/batch_sizes))\n",
    "print('[Test Loss: %.4f /  Test Accuracy: %.4f / Test Macro f1: %.4f / Test Weighted f1: %.4f]\\n' % (var[0],var[-3],var[-2],var[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEnJuikCshy9"
   },
   "outputs": [],
   "source": [
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "acc=history.history['main_classifier_accuracy']\n",
    "val_acc=history.history['val_main_classifier_accuracy']\n",
    "f1=history.history['main_classifier_macro_f1score']\n",
    "val_f1=history.history['val_main_classifier_macro_f1score']\n",
    "epochs=range(1,len(acc)+1)\n",
    "\n",
    "data = np.array([epochs,loss,val_loss,acc,val_acc,f1,val_f1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lahSxDTLshzA"
   },
   "outputs": [],
   "source": [
    "# data save\n",
    "# epochs, loss, val_loss, acc, val_acc, f1, val_f1\n",
    "\n",
    "np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PbOX0IVhshzC"
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'Inception_v3.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TPBmEA9shzF"
   },
   "outputs": [],
   "source": [
    "epochs=data[:,0]\n",
    "loss=data[:,1]\n",
    "val_loss=data[:,2]\n",
    "acc=data[:,3]\n",
    "val_acc=data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56459410,
     "status": "ok",
     "timestamp": 1599370071184,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "WwHA4ZwDshzH",
    "outputId": "b743185b-d49d-423b-86d3-fcaa1c9081cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs[1:],acc[1:],'b',label='Training Acc')\n",
    "plt.plot(epochs[1:],val_acc[1:],'r',label='Validation Acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n",
    "plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QspPlLSl8KRQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbRXBuh88KT_"
   },
   "outputs": [],
   "source": [
    "# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(os.path.join(dir,'model_output',number,'Inception_v3','023.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"weighted_f1score\":weighted_f1score, \"smoothed_categorical_crossentropy\":smoothed_categorical_crossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWlrnY9EuDG-"
   },
   "outputs": [],
   "source": [
    "# 2. epoch=?\n",
    "smoothing_param = 0.1\n",
    "var = model.evaluate(generate_test_for_two(),steps=int(len(x_test)/batch_sizes))\n",
    "print('[Test Loss: %.4f /  Test Accuracy: %.4f / Test Macro f1: %.4f / Test Weighted f1: %.4f]\\n' % (var[0],var[3],var[4],var[5]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "6.Inception V3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
