{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-OCKgEwJfTn"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://sike6054.github.io/blog/paper/fourth-post/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwVmRuFcUBkT"
   },
   "source": [
    "# [Inception ResNet V2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0MMz6DhUBkW"
   },
   "source": [
    "*KU LeeDongGyu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ywk25Fr79dWe"
   },
   "source": [
    "## Contents\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSON5xiR9dWf"
   },
   "source": [
    "1. Data Preprocessing\n",
    "```\n",
    "1) Data Import\n",
    "2) Data Augmentation\n",
    "```\n",
    "2. Support Functions & Almost Original Inception-ResNet-V2\n",
    "```\n",
    "1) Support Functions\n",
    "2) Almost Original Inception-ResNet-V2\n",
    "3) Inception-ResNet-V2 Evaluate\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U01q4o40UBkY"
   },
   "source": [
    "### Install Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjdygsS_UBke"
   },
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67772,
     "status": "ok",
     "timestamp": 1599313683175,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "03303793760957673272"
     },
     "user_tz": -540
    },
    "id": "o1tpIlBhXG2i",
    "outputId": "581941fd-a4c6-4675-8e50-968c3abaabad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67759,
     "status": "ok",
     "timestamp": 1599313683179,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "03303793760957673272"
     },
     "user_tz": -540
    },
    "id": "IJdbC2nRXR6h",
    "outputId": "b737f087-896c-442c-b8e6-6321921e559d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/Paper\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/Colab Notebooks/Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I98omoQ8FF90"
   },
   "outputs": [],
   "source": [
    "from f1score import macro_f1score,weighted_f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKLMWqbuUBkf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l1,l2,l1_l2\n",
    "from tensorflow.keras.models import Model , load_model , Sequential\n",
    "from tensorflow.keras.utils import plot_model , to_categorical, get_file\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71554,
     "status": "ok",
     "timestamp": 1599313687036,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "03303793760957673272"
     },
     "user_tz": -540
    },
    "id": "cbiFovMgXTax",
    "outputId": "63903ebc-329b-405e-8a53-a3f21ba28ff6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/Paper'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71530,
     "status": "ok",
     "timestamp": 1599313687037,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "03303793760957673272"
     },
     "user_tz": -540
    },
    "id": "AcT0A_iwEzaZ",
    "outputId": "85dae951-f912-4904-85ca-6c30a108b9b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(ks.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 77156,
     "status": "ok",
     "timestamp": 1599313692691,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "03303793760957673272"
     },
     "user_tz": -540
    },
    "id": "Gr5hMHvmABmG",
    "outputId": "356c654f-df0c-4db2-ed62-797e0419a53a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 77142,
     "status": "ok",
     "timestamp": 1599313692694,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "03303793760957673272"
     },
     "user_tz": -540
    },
    "id": "Kf057Rw2yigs",
    "outputId": "829d1879-fd16-4070-9762-7425d984c851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8708459786653217116\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14413153837712783414\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3272266250227178891\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15473775744\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15683494784506545828\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTXnS6_magkg"
   },
   "source": [
    "## 1. Data Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWigHOuzCRRj"
   },
   "source": [
    "### 1) Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BeJ7UtuOEgWY"
   },
   "outputs": [],
   "source": [
    "# 바꿔서 살펴 볼 것들\n",
    "# CALTECH, CIFAR100, FER, MIT\n",
    "data_name = 'CALTECH'\n",
    "gan_type = 'No_GAN'\n",
    "number = '1'\n",
    "size = 299 # sizes after cropping\n",
    "super_size = 330 # sizes before cropping \n",
    "input_sizes = (size,size,3)\n",
    "batch_sizes = 32\n",
    "weight_decay = 1e-3\n",
    "epochs = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPnWxfGzLOF6"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n",
    "# setting the seed number for random number generation for reproducibility.\n",
    "\n",
    "from numpy.random import seed\n",
    "import random\n",
    "\n",
    "\n",
    "if number=='1':\n",
    "    seed_num = 200225\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='2':\n",
    "    seed_num = 727\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='3':\n",
    "    seed_num = 115\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='4':\n",
    "    seed_num = 501\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='5':\n",
    "    seed_num = 517\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmFJMXETpKFW"
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "\n",
    "if data_name=='FER' :\n",
    "    x_train =  np.zeros(28698)\n",
    "    x_valid = np.zeros(3589)\n",
    "    x_test = np.zeros(3588)\n",
    "    classes = 7 \n",
    "    tr_center = [0.50793296, 0.50793296, 0.50793296]\n",
    "elif data_name=='MIT':\n",
    "    x_train = np.zeros(12466)\n",
    "    x_valid = np.zeros(1564)\n",
    "    x_test = np.zeros(1590)\n",
    "    classes = 67 \n",
    "    tr_center = [0.47916578, 0.42029615, 0.36046057]\n",
    "elif data_name=='CALTECH':\n",
    "    x_train = np.zeros(24510)\n",
    "    x_valid = np.zeros(2980)\n",
    "    x_test = np.zeros(3118)\n",
    "    classes = 257\n",
    "    tr_center = [0.51397761, 0.49525248, 0.46555727]\n",
    "elif data_name=='CIFAR100':\n",
    "    x_train = np.zeros(39941)\n",
    "    x_valid = np.zeros(10059)\n",
    "    x_test = np.zeros(10000)\n",
    "    classes = 100\n",
    "    tr_center = [0.53393271, 0.51324147, 0.46450563]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQlStjHWt-jM"
   },
   "outputs": [],
   "source": [
    "dir = os.path.join(os.getcwd(),data_name,gan_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8v29_oXpKFa"
   },
   "source": [
    "### 2) Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-eSf1NktpKFb"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n",
    "\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EW0KZ6x9EBtf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
    "import glob\n",
    "\n",
    "# 데이터 전체에 대해 centering 진행함.\n",
    "\n",
    "def read_cal_image(img_path): \n",
    "    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n",
    "    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n",
    "\n",
    "    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n",
    "    x = np.mean(x, axis=(0,1))\n",
    "    \n",
    "    return np.hstack([x,y])\n",
    "\n",
    "def calculate_centered_mean(dataset_path,x_train=x_train):\n",
    "    num = len(x_train)\n",
    "    space = np.empty((num,4))\n",
    "    i=0\n",
    "\n",
    "    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n",
    "        space[i] = read_cal_image(p)\n",
    "        i += 1\n",
    "\n",
    "    ratio = space[:,3] / np.sum(space[:,3])\n",
    "\n",
    "    return np.average(space[:,0:3],axis=0,weights=ratio)\n",
    "\n",
    "\n",
    "# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n",
    "\n",
    "# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-0KLhu5WpKFe"
   },
   "outputs": [],
   "source": [
    "datagen_tr = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=[0.9,1.0],\n",
    "    fill_mode = 'nearest')\n",
    "datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n",
    "datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n",
    "\n",
    "# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n",
    "\n",
    "# 중심화 설정\n",
    "datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n",
    "datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n",
    "datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 138624,
     "status": "ok",
     "timestamp": 1599313754251,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "03303793760957673272"
     },
     "user_tz": -540
    },
    "id": "u3v_aI9cpKFg",
    "outputId": "c7d74ea3-5af4-4bfa-96e2-1e4c8ab22d97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24509 images belonging to 257 classes.\n",
      "Found 2980 images belonging to 257 classes.\n",
      "Found 3118 images belonging to 257 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 39941\n",
    "train_generator= crop_generator(train_batches, size)\n",
    "valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 10059\n",
    "test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "afa9Vvwdw1te"
   },
   "source": [
    "## 2. Support Functions & Almost Original Inception-ResNet-V2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iER-OGdBw1tf"
   },
   "source": [
    "### 1) Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA3sqFv_ZyBS"
   },
   "outputs": [],
   "source": [
    "# def lr_schedule(epoch):\n",
    "#     init_lr = 1e-4\n",
    "#     k = 0.04\n",
    "#     lr = init_lr * np.exp(-k*epoch)\n",
    "#     print('Learning rate: ', lr)\n",
    "#     return lr\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch < 60:\n",
    "        lr = lr\n",
    "    else :\n",
    "        lr = lr * 0.1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C5tMfvOYJfTv"
   },
   "outputs": [],
   "source": [
    "def Scaling_Residual(Inception, scale):\n",
    "    x = Lambda(lambda Inception, scale: Inception * scale, arguments={'scale': scale})(Inception)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6kBvFXBQJfTs"
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, filters, kernel_size, weight_decay=weight_decay, padding='same', strides=1, activation='relu'):\n",
    "    x = Conv2D(filters, (kernel_size[0], kernel_size[1]), padding=padding, strides=strides, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if activation:\n",
    "        x = Activation(activation)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSpLizyDnwKj"
   },
   "outputs": [],
   "source": [
    "def Stem(input_tensor, version=None, name=None):\n",
    "    if version == 'Inception-v4' or version == 'Inception-ResNet-v2':\n",
    "        x = conv2d_bn(input_tensor, 32, (3, 3), padding='valid', strides=2) # 299x299x3 -> 149x149x32\n",
    "        x = conv2d_bn(x, 32, (3, 3), padding='valid') # 149x149x32 -> 147x147x32\n",
    "        x = conv2d_bn(x, 64, (3, 3)) # 147x147x32 -> 147x147x64\n",
    "        \n",
    "        branch_1 = MaxPooling2D((3, 3), padding='valid', strides=2)(x)\n",
    "        branch_2 = conv2d_bn(x, 96, (3, 3), padding='valid', strides=2)\n",
    "        x = Concatenate()([branch_1, branch_2]) # 73x73x160\n",
    "        \n",
    "        branch_1 = conv2d_bn(x, 64, (1, 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 96, (3, 3), padding='valid')\n",
    "        branch_2 = conv2d_bn(x, 64, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 64, (7, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 64, (1, 7))\n",
    "        branch_2 = conv2d_bn(branch_2, 96, (3, 3), padding='valid')\n",
    "        x = Concatenate()([branch_1, branch_2]) # 71x71x192\n",
    "        \n",
    "        branch_1 = conv2d_bn(x, 192, (3, 3), padding='valid', strides=2) # Fig.4 is wrong\n",
    "        branch_2 = MaxPooling2D((3, 3), padding='valid', strides=2)(x)\n",
    "        x = Concatenate(name=name)([branch_1, branch_2]) if name else Concatenate()([branch_1, branch_2]) # 35x35x384\n",
    "        \n",
    "    elif version == 'Inception-ResNet-v1':\n",
    "        x = conv2d_bn(input_tensor, 32, (3, 3), padding='valid', strides=2) # 299x299x3 -> 149x149x32\n",
    "        x = conv2d_bn(x, 32, (3, 3), padding='valid') # 149x149x32 -> 147x147x32\n",
    "        x = conv2d_bn(x, 64, (3, 3)) # 147x147x32 -> 147x147x64\n",
    "        \n",
    "        x = MaxPooling2D((3, 3), strides=2, padding='valid')(x) # 147x147x64 -> 73x73x64\n",
    "        \n",
    "        x = conv2d_bn(x, 80, (1, 1)) # 73x73x64 -> 73x73x80\n",
    "        x = conv2d_bn(x, 192, (3, 3), padding='valid') # 73x73x80 -> 71x71x192U\n",
    "        x = conv2d_bn(x, 256, (3, 3), padding='valid', strides=2) # 71x71x192 -> 35x35x256\n",
    "        \n",
    "    else:\n",
    "        return None # Kill ^^\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jv3Qz57XJfTy"
   },
   "outputs": [],
   "source": [
    "def Inception_ResNet_A(input_tensor, scale=0.1, version=None, name=None):   \n",
    "    if version == 'Inception-ResNet-v1':\n",
    "        branch_1 = conv2d_bn(input_tensor, 32, (1, 1))\n",
    "    \n",
    "        branch_2 = conv2d_bn(input_tensor, 32, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 32, (3, 3))\n",
    "        \n",
    "        branch_3 = conv2d_bn(input_tensor, 32, (1, 1))\n",
    "        branch_3 = conv2d_bn(branch_3, 32, (3, 3))\n",
    "        branch_3 = conv2d_bn(branch_3, 32, (3, 3))\n",
    "        \n",
    "        branches = Concatenate()([branch_1, branch_2, branch_3])\n",
    "        Inception = conv2d_bn(branches, 256, (1, 1), activation=None)\n",
    "    \n",
    "    elif version == 'Inception-ResNet-v2':\n",
    "        branch_1 = conv2d_bn(input_tensor, 32, (1, 1))\n",
    "    \n",
    "        branch_2 = conv2d_bn(input_tensor, 32, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 32, (3, 3))\n",
    "        \n",
    "        branch_3 = conv2d_bn(input_tensor, 32, (1, 1))\n",
    "        branch_3 = conv2d_bn(branch_3, 48, (3, 3))\n",
    "        branch_3 = conv2d_bn(branch_3, 64, (3, 3))\n",
    "        \n",
    "        branches = Concatenate()([branch_1, branch_2, branch_3])\n",
    "        Inception = conv2d_bn(branches, 384, (1, 1), activation=None)\n",
    "    \n",
    "    else:\n",
    "        return None # Kill ^^\n",
    "    \n",
    "    scaled_activation = Scaling_Residual(Inception, scale=scale)\n",
    "    \n",
    "    residual_connection = Add(name=name)([input_tensor, scaled_activation]) if name else Add()([input_tensor, scaled_activation])\n",
    "    \n",
    "    return residual_connection\n",
    "\n",
    "def Inception_ResNet_B(input_tensor, scale=0.1, version=None, name=None):\n",
    "    if version == 'Inception-ResNet-v1':\n",
    "        branch_1 = conv2d_bn(input_tensor, 128, (1, 1))\n",
    "        \n",
    "        branch_2 = conv2d_bn(input_tensor, 128, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 128, (1, 7))\n",
    "        branch_2 = conv2d_bn(branch_2, 128, (7, 1))\n",
    "        \n",
    "        branches = Concatenate()([branch_1, branch_2])\n",
    "        Inception = conv2d_bn(branches, 896, (1, 1), activation=None)\n",
    "    \n",
    "    elif version == 'Inception-ResNet-v2':\n",
    "        branch_1 = conv2d_bn(input_tensor, 192, (1, 1))\n",
    "        \n",
    "        branch_2 = conv2d_bn(input_tensor, 128, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 160, (1, 7))\n",
    "        branch_2 = conv2d_bn(branch_2, 192, (7, 1))\n",
    "        \n",
    "        branches = Concatenate()([branch_1, branch_2])\n",
    "        Inception = conv2d_bn(branches, 1152, (1, 1), activation=None) # Fig.17 is wrong\n",
    "    \n",
    "    else:\n",
    "        return None # Kill ^^\n",
    "    \n",
    "    scaled_activation = Scaling_Residual(Inception, scale=scale)\n",
    "    \n",
    "    residual_connection = Add(name=name)([input_tensor, scaled_activation]) if name else Add()([input_tensor, scaled_activation])\n",
    "    \n",
    "    return residual_connection\n",
    "\n",
    "def Inception_ResNet_C(input_tensor, scale=0.1, version=None, name=None):    \n",
    "    if version == 'Inception-ResNet-v1':\n",
    "        branch_1 = conv2d_bn(input_tensor, 192, (1, 1))\n",
    "        \n",
    "        branch_2 = conv2d_bn(input_tensor, 192, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 192, (1, 3))\n",
    "        branch_2 = conv2d_bn(branch_2, 192, (3, 1))\n",
    "        \n",
    "        branches = Concatenate()([branch_1, branch_2])\n",
    "        Inception = conv2d_bn(branches, 1792, (1, 1), activation=None)\n",
    "    \n",
    "    elif version == 'Inception-ResNet-v2':\n",
    "        branch_1 = conv2d_bn(input_tensor, 192, (1, 1))\n",
    "        \n",
    "        branch_2 = conv2d_bn(input_tensor, 192, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 224, (1, 3))\n",
    "        branch_2 = conv2d_bn(branch_2, 256, (3, 1))\n",
    "        \n",
    "        branches = Concatenate()([branch_1, branch_2])\n",
    "        Inception = conv2d_bn(branches, 2144, (1, 1), activation=None) # Fig.19 is wrong\n",
    "    \n",
    "    else:\n",
    "        return None # Kill ^^\n",
    "    \n",
    "    scaled_activation = Scaling_Residual(Inception, scale=scale)\n",
    "    \n",
    "    residual_connection = Add(name=name)([input_tensor, scaled_activation]) if name else Add()([input_tensor, scaled_activation])\n",
    "    \n",
    "    return residual_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "595ZdLJbJfT2"
   },
   "outputs": [],
   "source": [
    "reduction_table = {'Inception-v4' : [192, 224, 256, 384],\n",
    "                   'Inception-ResNet-v1' : [192, 192, 256, 384],\n",
    "                   'Inception-ResNet-v2' : [256, 256, 384, 384]}\n",
    "\n",
    "def Reduction_A(input_tensor, version=None, name=None):\n",
    "    k, l, m, n = reduction_table[version]\n",
    "\n",
    "    branch_1 = MaxPooling2D((3, 3), padding='valid', strides=2)(input_tensor)\n",
    "\n",
    "    branch_2 = conv2d_bn(input_tensor, n, (3, 3), padding='valid', strides=2)\n",
    "\n",
    "    branch_3 = conv2d_bn(input_tensor, k, (1, 1))\n",
    "    branch_3 = conv2d_bn(branch_3, l, (3, 3))\n",
    "    branch_3 = conv2d_bn(branch_3, m, (3, 3), padding='valid', strides=2)\n",
    "\n",
    "    filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3]) if name else Concatenate()([branch_1, branch_2, branch_3])\n",
    "\n",
    "    return filter_concat\n",
    "\n",
    "def Reduction_B(input_tensor, version=None, name=None):\n",
    "    if version == 'Inception-v4':\n",
    "        branch_1 = MaxPooling2D((3, 3), padding='valid', strides=2)(input_tensor)\n",
    "    \n",
    "        branch_2 = conv2d_bn(input_tensor, 192, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 192, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        branch_3 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_3 = conv2d_bn(branch_3, 256, (1, 7))\n",
    "        branch_3 = conv2d_bn(branch_3, 320, (7, 1))\n",
    "        branch_3 = conv2d_bn(branch_3, 320, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3]) if name else Concatenate()([branch_1, branch_2, branch_3])\n",
    "\n",
    "    elif version == 'Inception-ResNet-v1':\n",
    "        branch_1 = MaxPooling2D((3, 3), padding='valid', strides=2)(input_tensor)\n",
    "    \n",
    "        branch_2 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 384, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        branch_3 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_3 = conv2d_bn(branch_3, 256, (3, 3), padding='valid', strides=2)\n",
    "        \n",
    "        branch_4 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_4 = conv2d_bn(branch_4, 256, (3, 3))\n",
    "        branch_4 = conv2d_bn(branch_4, 256, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3, branch_4]) if name else Concatenate()([branch_1, branch_2, branch_3, branch_4])\n",
    "\n",
    "    elif version == 'Inception-ResNet-v2':\n",
    "        branch_1 = MaxPooling2D((3, 3), padding='valid', strides=2)(input_tensor)\n",
    "    \n",
    "        branch_2 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 384, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        branch_3 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_3 = conv2d_bn(branch_3, 288, (3, 3), padding='valid', strides=2)\n",
    "        \n",
    "        branch_4 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_4 = conv2d_bn(branch_4, 288, (3, 3))\n",
    "        branch_4 = conv2d_bn(branch_4, 320, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3, branch_4]) if name else Concatenate()([branch_1, branch_2, branch_3, branch_4])\n",
    "    \n",
    "    else:\n",
    "        return None # Kill ^^\n",
    "    \n",
    "    return filter_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYJU3L_tJfT5"
   },
   "outputs": [],
   "source": [
    "def Inception_ResNet(model_input, version='Inception-ResNet-v2', classes=1000, name='Inception_ResNet_v2'):    \n",
    "    x = Stem(model_input, version=version, name='Stem')\n",
    "    # Inception-ResNet-v1 : (299, 299, 3) -> (35, 35, 256)\n",
    "    # Inception-ResNet-v2 : (299, 299, 3) -> (35, 35, 384)\n",
    "    \n",
    "    for i in range(5):\n",
    "        x = Inception_ResNet_A(x, scale=0.17, version=version, name='Inception-ResNet-A-'+str(i+1))\n",
    "        # Inception-ResNet-v1 : (35, 35, 256)\n",
    "        # Inception-ResNet-v2 : (35, 35, 384)\n",
    "        \n",
    "    x = Reduction_A(x, version=version, name='Reduction-A')\n",
    "    # Inception-ResNet-v1 : (35, 35, 256) -> (17, 17, 896)\n",
    "    # Inception-ResNet-v2 : (35, 35, 384) -> (17, 17, 1152)\n",
    "    \n",
    "    for i in range(10):\n",
    "        x = Inception_ResNet_B(x, scale=0.1, version=version, name='Inception-ResNet-B-'+str(i+1))\n",
    "        # Inception-ResNet-v1 : (17, 17, 896)\n",
    "        # Inception-ResNet-v2 : (17, 17, 1152)\n",
    "\n",
    "    x = Reduction_B(x, version=version, name='Reduction-B')\n",
    "    # Inception-ResNet-v1 : (17, 17, 896) -> (8, 8, 1792)\n",
    "    # Inception-ResNet-v2 : (17, 17, 1152) -> (8, 8, 2144)\n",
    "    \n",
    "    for i in range(5):\n",
    "        x = Inception_ResNet_C(x, scale=0.2, version=version, name='Inception-ResNet-C-'+str(i+1))\n",
    "        # Inception-ResNet-v1 : (8, 8, 1792)\n",
    "        # Inception-ResNet-v2 : (8, 8, 2144)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # Inception-ResNet-v1 : (1792)\n",
    "    # Inception-ResNet-v2 : (2144)\n",
    "    \n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    model_output = Dense(classes, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(model_input, model_output, name=name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJixgnY7Z6j7"
   },
   "source": [
    "### 2) Almost Original Inception-ResNet-V2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5YOrZ2rhneyq"
   },
   "outputs": [],
   "source": [
    "# weight_decay는 inception-v3의 weight decay임. - 튜닝해볼 것\n",
    "\n",
    "model_input = Input(shape=input_sizes)\n",
    "model = Inception_ResNet(model_input, version='Inception-ResNet-v2', classes=classes, name='Inception_ResNet_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 143504,
     "status": "ok",
     "timestamp": 1599313759216,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "03303793760957673272"
     },
     "user_tz": -540
    },
    "id": "0HuelUizNJWz",
    "outputId": "6d0b214c-60c8-43fb-aaa9-977329bb529c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Inception_ResNet_v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18496       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 96)   55392       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 96)   384         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 96)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 73, 73, 160)  0           max_pooling2d[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 73, 73, 64)   10304       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 73, 73, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 73, 73, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 73, 73, 64)   28736       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 73, 73, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 73, 73, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 64)   10304       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 73, 73, 64)   28736       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 73, 73, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 73, 73, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 96)   55392       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 71, 71, 96)   55392       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 96)   384         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 71, 71, 96)   384         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 96)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 71, 71, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 71, 71, 192)  0           activation_5[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 192)  331968      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 192)  768         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 192)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stem (Concatenate)              (None, 35, 35, 384)  0           activation_10[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 32)   12320       Stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 32)   128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   12320       Stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 48)   13872       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 48)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 48)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   12320       Stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 32)   9248        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   27712       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 35, 35, 128)  0           activation_11[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 384)  49536       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 384)  1536        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 35, 35, 384)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 384)  0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-A-1 (Add)      (None, 35, 35, 384)  0           Stem[0][0]                       \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 32)   128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 48)   13872       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 32)   128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 48)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 32)   9248        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   27712       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 32)   128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 32)   128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 32)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 35, 35, 128)  0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 384)  49536       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 384)  1536        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 35, 35, 384)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 384)  0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-A-2 (Add)      (None, 35, 35, 384)  0           Inception-ResNet-A-1[0][0]       \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 32)   128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 32)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 48)   13872       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 32)   128         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 48)   192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 48)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 32)   9248        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 64)   27712       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 32)   128         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 32)   128         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 35, 35, 64)   256         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 35, 35, 128)  0           activation_25[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 35, 35, 384)  49536       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 35, 35, 384)  1536        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 35, 35, 384)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 384)  0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-A-3 (Add)      (None, 35, 35, 384)  0           Inception-ResNet-A-2[0][0]       \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 35, 35, 32)   128         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 32)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 35, 35, 48)   13872       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 35, 35, 32)   128         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 35, 35, 48)   192         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 48)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 35, 35, 32)   9248        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 35, 35, 64)   27712       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 35, 35, 32)   128         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 35, 35, 32)   128         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 35, 35, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 32)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 35, 35, 128)  0           activation_32[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 384)  49536       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 384)  1536        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 35, 35, 384)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 384)  0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-A-4 (Add)      (None, 35, 35, 384)  0           Inception-ResNet-A-3[0][0]       \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 35, 35, 32)   128         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 35, 35, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 48)   13872       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 35, 35, 32)   128         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 35, 35, 48)   192         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 35, 35, 48)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 35, 35, 32)   12320       Inception-ResNet-A-4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 32)   9248        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 64)   27712       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 35, 35, 32)   128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 35, 35, 32)   128         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 35, 35, 64)   256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 35, 35, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 32)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 35, 35, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 35, 35, 128)  0           activation_39[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 35, 35, 384)  49536       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 35, 35, 384)  1536        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 35, 35, 384)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 35, 35, 384)  0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-A-5 (Add)      (None, 35, 35, 384)  0           Inception-ResNet-A-4[0][0]       \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 35, 35, 256)  98560       Inception-ResNet-A-5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 35, 35, 256)  1024        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 35, 35, 256)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 35, 35, 256)  590080      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 35, 35, 256)  1024        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 35, 35, 256)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 384)  1327488     Inception-ResNet-A-5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 384)  885120      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 384)  1536        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 384)  1536        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 384)  0           Inception-ResNet-A-5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 384)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 384)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Reduction-A (Concatenate)       (None, 17, 17, 1152) 0           max_pooling2d_2[0][0]            \n",
      "                                                                 activation_46[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 128)  147584      Reduction-A[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 128)  512         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 128)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  143520      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  640         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  221376      Reduction-A[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215232      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  768         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  768         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 17, 17, 384)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 1152) 443520      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 1152) 4608        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 17, 17, 1152) 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 1152) 0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-B-1 (Add)      (None, 17, 17, 1152) 0           Reduction-A[0][0]                \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 128)  147584      Inception-ResNet-B-1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 128)  512         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 128)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  143520      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  640         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 192)  221376      Inception-ResNet-B-1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215232      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 192)  768         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  768         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 192)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 17, 17, 384)  0           activation_55[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 1152) 443520      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 1152) 4608        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 17, 17, 1152) 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 1152) 0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-B-2 (Add)      (None, 17, 17, 1152) 0           Inception-ResNet-B-1[0][0]       \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 128)  147584      Inception-ResNet-B-2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 128)  512         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 128)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 160)  143520      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 160)  640         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 160)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  221376      Inception-ResNet-B-2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  215232      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  768         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  768         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 17, 17, 384)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 1152) 443520      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 1152) 4608        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 17, 17, 1152) 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 1152) 0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-B-3 (Add)      (None, 17, 17, 1152) 0           Inception-ResNet-B-2[0][0]       \n",
      "                                                                 activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 128)  147584      Inception-ResNet-B-3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 128)  512         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 128)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 160)  143520      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 160)  640         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 160)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  221376      Inception-ResNet-B-3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  215232      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  768         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  768         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 17, 17, 384)  0           activation_65[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 1152) 443520      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 1152) 4608        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 17, 17, 1152) 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 1152) 0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-B-4 (Add)      (None, 17, 17, 1152) 0           Inception-ResNet-B-3[0][0]       \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 128)  147584      Inception-ResNet-B-4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 128)  512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 160)  143520      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 160)  640         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 160)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  221376      Inception-ResNet-B-4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  215232      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  768         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 17, 17, 384)  0           activation_70[0][0]              \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 1152) 443520      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 1152) 4608        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 17, 17, 1152) 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 1152) 0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-B-5 (Add)      (None, 17, 17, 1152) 0           Inception-ResNet-B-4[0][0]       \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 128)  147584      Inception-ResNet-B-5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 17, 17, 128)  512         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 128)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 160)  143520      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 17, 17, 160)  640         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 160)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 192)  221376      Inception-ResNet-B-5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 192)  215232      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 192)  768         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 17, 17, 192)  768         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 192)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 17, 17, 384)  0           activation_75[0][0]              \n",
      "                                                                 activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 1152) 443520      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 17, 17, 1152) 4608        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 17, 17, 1152) 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 1152) 0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-B-6 (Add)      (None, 17, 17, 1152) 0           Inception-ResNet-B-5[0][0]       \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 128)  147584      Inception-ResNet-B-6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 17, 17, 128)  512         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 128)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 160)  143520      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 17, 17, 160)  640         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 160)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 192)  221376      Inception-ResNet-B-6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 192)  215232      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 17, 17, 192)  768         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 17, 17, 192)  768         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 192)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 17, 17, 384)  0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 1152) 443520      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 17, 17, 1152) 4608        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 17, 17, 1152) 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 1152) 0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-B-7 (Add)      (None, 17, 17, 1152) 0           Inception-ResNet-B-6[0][0]       \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 128)  147584      Inception-ResNet-B-7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 17, 17, 128)  512         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 128)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 160)  143520      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 17, 17, 160)  640         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 17, 17, 160)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 192)  221376      Inception-ResNet-B-7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 192)  215232      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 17, 17, 192)  768         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 17, 17, 192)  768         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 192)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 17, 17, 384)  0           activation_85[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 1152) 443520      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 17, 17, 1152) 4608        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 17, 17, 1152) 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 17, 17, 1152) 0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-B-8 (Add)      (None, 17, 17, 1152) 0           Inception-ResNet-B-7[0][0]       \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 128)  147584      Inception-ResNet-B-8[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 17, 17, 128)  512         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 17, 17, 128)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 160)  143520      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 17, 17, 160)  640         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 17, 17, 160)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 192)  221376      Inception-ResNet-B-8[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 192)  215232      activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 17, 17, 192)  768         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 17, 17, 192)  768         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 17, 17, 192)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 17, 17, 192)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 17, 17, 384)  0           activation_90[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 1152) 443520      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 17, 17, 1152) 4608        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 17, 17, 1152) 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 17, 17, 1152) 0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-B-9 (Add)      (None, 17, 17, 1152) 0           Inception-ResNet-B-8[0][0]       \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 128)  147584      Inception-ResNet-B-9[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 17, 17, 128)  512         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 17, 17, 128)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 160)  143520      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 17, 17, 160)  640         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 17, 17, 160)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 192)  221376      Inception-ResNet-B-9[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 192)  215232      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 17, 17, 192)  768         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 17, 17, 192)  768         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 17, 17, 192)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 17, 17, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 17, 17, 384)  0           activation_95[0][0]              \n",
      "                                                                 activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 1152) 443520      concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 17, 17, 1152) 4608        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 17, 17, 1152) 0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 17, 17, 1152) 0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-B-10 (Add)     (None, 17, 17, 1152) 0           Inception-ResNet-B-9[0][0]       \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 256)  295168      Inception-ResNet-B-10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 17, 17, 256)  1024        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 17, 17, 256)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 256)  295168      Inception-ResNet-B-10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 256)  295168      Inception-ResNet-B-10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 288)  663840      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 17, 17, 256)  1024        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 17, 17, 256)  1024        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 17, 17, 288)  1152        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 17, 17, 256)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 17, 17, 256)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 17, 17, 288)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 8, 8, 384)    885120      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 8, 8, 288)    663840      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 8, 8, 320)    829760      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 8, 8, 384)    1536        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 8, 8, 288)    1152        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 8, 8, 320)    1280        conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 1152)   0           Inception-ResNet-B-10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 8, 8, 384)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 8, 8, 288)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 8, 8, 320)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Reduction-B (Concatenate)       (None, 8, 8, 2144)   0           max_pooling2d_3[0][0]            \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 8, 8, 192)    411840      Reduction-B[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 8, 8, 192)    768         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 8, 8, 192)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 8, 8, 224)    129248      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 8, 8, 224)    896         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 8, 8, 224)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 8, 8, 192)    411840      Reduction-B[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 8, 8, 256)    172288      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 8, 8, 192)    768         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 8, 8, 256)    1024        conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 8, 8, 192)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 8, 8, 256)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 8, 8, 448)    0           activation_107[0][0]             \n",
      "                                                                 activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 8, 8, 2144)   962656      concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 8, 8, 2144)   8576        conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 8, 8, 2144)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 8, 8, 2144)   0           lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-C-1 (Add)      (None, 8, 8, 2144)   0           Reduction-B[0][0]                \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 8, 8, 192)    411840      Inception-ResNet-C-1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 8, 8, 192)    768         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 8, 8, 192)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 224)    129248      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 8, 8, 224)    896         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 8, 8, 224)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 8, 8, 192)    411840      Inception-ResNet-C-1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 8, 256)    172288      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 8, 8, 192)    768         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 8, 8, 256)    1024        conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 8, 8, 192)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 8, 8, 256)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 8, 8, 448)    0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 8, 8, 2144)   962656      concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 8, 8, 2144)   8576        conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 8, 8, 2144)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 8, 8, 2144)   0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-C-2 (Add)      (None, 8, 8, 2144)   0           Inception-ResNet-C-1[0][0]       \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 8, 8, 192)    411840      Inception-ResNet-C-2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, 8, 192)    768         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 8, 8, 192)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 8, 224)    129248      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 8, 224)    896         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 8, 8, 224)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 8, 8, 192)    411840      Inception-ResNet-C-2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 8, 8, 256)    172288      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 8, 8, 192)    768         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 8, 256)    1024        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 8, 8, 192)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 8, 8, 256)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 8, 8, 448)    0           activation_117[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, 8, 2144)   962656      concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 8, 2144)   8576        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 8, 8, 2144)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 8, 8, 2144)   0           lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-C-3 (Add)      (None, 8, 8, 2144)   0           Inception-ResNet-C-2[0][0]       \n",
      "                                                                 activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 8, 192)    411840      Inception-ResNet-C-3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, 8, 192)    768         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 8, 8, 192)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 8, 8, 224)    129248      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 8, 8, 224)    896         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 8, 8, 224)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 8, 192)    411840      Inception-ResNet-C-3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 8, 8, 256)    172288      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 8, 192)    768         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 8, 8, 256)    1024        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 8, 8, 192)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 8, 8, 256)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 8, 8, 448)    0           activation_122[0][0]             \n",
      "                                                                 activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 8, 8, 2144)   962656      concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 8, 8, 2144)   8576        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 8, 8, 2144)   0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 8, 8, 2144)   0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-C-4 (Add)      (None, 8, 8, 2144)   0           Inception-ResNet-C-3[0][0]       \n",
      "                                                                 activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 8, 8, 192)    411840      Inception-ResNet-C-4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 8, 8, 192)    768         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 8, 8, 192)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 8, 224)    129248      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 8, 8, 224)    896         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 8, 8, 224)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 8, 8, 192)    411840      Inception-ResNet-C-4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 8, 8, 256)    172288      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 8, 8, 192)    768         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 8, 8, 256)    1024        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 8, 8, 192)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 8, 8, 256)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 8, 8, 448)    0           activation_127[0][0]             \n",
      "                                                                 activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 8, 8, 2144)   962656      concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 8, 8, 2144)   8576        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 8, 8, 2144)   0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 8, 8, 2144)   0           lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inception-ResNet-C-5 (Add)      (None, 8, 8, 2144)   0           Inception-ResNet-C-4[0][0]       \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2144)         0           Inception-ResNet-C-5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2144)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 257)          551265      dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 30,986,129\n",
      "Trainable params: 30,904,945\n",
      "Non-trainable params: 81,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNCT3g8eE6vT"
   },
   "outputs": [],
   "source": [
    "# 폴더 생성\n",
    "\n",
    "os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n",
    "os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3uJNxsK7bp1E"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n",
    "import utils\n",
    "import optimizers_v2\n",
    "from utils import get_weight_decays, fill_dict_in_order\n",
    "from utils import reset_seeds, K_eval\n",
    "from optimizers_v2 import AdamW, NadamW, SGDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 144309,
     "status": "ok",
     "timestamp": 1599313760062,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "03303793760957673272"
     },
     "user_tz": -540
    },
    "id": "QoWLeggG6dBf",
    "outputId": "734bf406-2f27-4701-dfef-d523208ffc6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cosine annealing learning rates\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model=model, use_cosine_annealing=True, total_iterations = len(x_train) // batch_sizes , eta_min = 1e-2)\n",
    "#optimizer = Adam()\n",
    "filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n",
    "                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n",
    "                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n",
    "                  LearningRateScheduler(lr_schedule,verbose=1)\n",
    "                  ]\n",
    "                  \n",
    "model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "H9pnv0cw6dBm",
    "outputId": "ab0a0782-e345-4ecf-98e3-cd93f979e980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 1/70\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_1/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_2/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_3/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_6/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_7/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_4/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_8/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_5/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_9/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_10/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_14/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_12/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_15/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_11/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_13/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_16/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_17/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_21/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_19/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_22/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_18/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_20/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_23/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_24/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_28/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_26/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_29/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_25/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_27/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_30/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_31/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_35/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_33/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_36/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_32/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_34/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_37/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_38/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_42/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_40/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_43/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_39/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_41/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_44/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_45/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_47/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_48/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_46/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_49/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_51/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_52/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_50/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_53/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_54/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_56/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_57/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_55/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_58/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_59/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_61/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_62/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_60/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_63/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_64/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_66/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_67/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_65/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_68/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_69/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_71/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_72/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_70/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_73/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_74/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_76/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_77/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_75/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_78/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_79/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_81/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_82/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_80/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_83/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_84/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_86/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_87/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_85/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_88/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_89/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_91/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_92/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_90/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_93/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_94/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_96/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_97/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_95/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_98/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_99/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_104/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_100/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_102/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_105/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_101/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_103/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_106/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_108/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_109/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_107/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_110/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_111/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_113/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_114/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_112/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_115/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_116/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_118/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_119/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_117/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_120/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_121/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_123/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_124/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_122/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_125/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_126/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_128/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_129/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_127/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_130/kernel:0\n",
      "0.0(L1), 3.6155078020383335e-05(L2) weight decay set for conv2d_131/kernel:0\n",
      "765/765 [==============================] - ETA: 0s - loss: 5.5060 - accuracy: 0.0751 - macro_f1score: 4.6743e-04 - weighted_f1score: 1.8136e-05 \n",
      "Epoch 00001: val_loss improved from inf to 5.20403, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/001.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.11022, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/001.h5\n",
      "765/765 [==============================] - 13610s 18s/step - loss: 5.5060 - accuracy: 0.0751 - macro_f1score: 4.6743e-04 - weighted_f1score: 1.8136e-05 - val_loss: 5.2040 - val_accuracy: 0.1102 - val_macro_f1score: 4.3234e-04 - val_weighted_f1score: 1.7215e-05\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 2/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 4.8757 - accuracy: 0.1091 - macro_f1score: 0.0017 - weighted_f1score: 7.1771e-05\n",
      "Epoch 00002: val_loss improved from 5.20403 to 4.91613, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/002.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.11022 to 0.14617, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/002.h5\n",
      "765/765 [==============================] - 728s 952ms/step - loss: 4.8757 - accuracy: 0.1091 - macro_f1score: 0.0017 - weighted_f1score: 7.1771e-05 - val_loss: 4.9161 - val_accuracy: 0.1462 - val_macro_f1score: 0.0028 - val_weighted_f1score: 1.2438e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 3/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 4.5112 - accuracy: 0.1397 - macro_f1score: 0.0038 - weighted_f1score: 1.6527e-04\n",
      "Epoch 00003: val_loss improved from 4.91613 to 4.22687, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/003.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.14617 to 0.18548, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/003.h5\n",
      "765/765 [==============================] - 722s 944ms/step - loss: 4.5112 - accuracy: 0.1397 - macro_f1score: 0.0038 - weighted_f1score: 1.6527e-04 - val_loss: 4.2269 - val_accuracy: 0.1855 - val_macro_f1score: 0.0055 - val_weighted_f1score: 2.4052e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 4/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 4.3126 - accuracy: 0.1611 - macro_f1score: 0.0051 - weighted_f1score: 2.1503e-04\n",
      "Epoch 00004: val_loss improved from 4.22687 to 3.99857, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/004.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.18548 to 0.20901, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/004.h5\n",
      "765/765 [==============================] - 720s 941ms/step - loss: 4.3126 - accuracy: 0.1611 - macro_f1score: 0.0051 - weighted_f1score: 2.1503e-04 - val_loss: 3.9986 - val_accuracy: 0.2090 - val_macro_f1score: 0.0076 - val_weighted_f1score: 3.1048e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 5/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 4.0811 - accuracy: 0.1868 - macro_f1score: 0.0066 - weighted_f1score: 2.7098e-04\n",
      "Epoch 00005: val_loss improved from 3.99857 to 3.76415, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/005.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.20901 to 0.23891, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/005.h5\n",
      "765/765 [==============================] - 714s 933ms/step - loss: 4.0811 - accuracy: 0.1868 - macro_f1score: 0.0066 - weighted_f1score: 2.7098e-04 - val_loss: 3.7642 - val_accuracy: 0.2389 - val_macro_f1score: 0.0083 - val_weighted_f1score: 3.5164e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 6/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 3.8474 - accuracy: 0.2147 - macro_f1score: 0.0082 - weighted_f1score: 3.3138e-04\n",
      "Epoch 00006: val_loss improved from 3.76415 to 3.54542, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/006.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.23891 to 0.27621, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/006.h5\n",
      "765/765 [==============================] - 711s 929ms/step - loss: 3.8474 - accuracy: 0.2147 - macro_f1score: 0.0082 - weighted_f1score: 3.3138e-04 - val_loss: 3.5454 - val_accuracy: 0.2762 - val_macro_f1score: 0.0110 - val_weighted_f1score: 4.4017e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 7/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 3.6298 - accuracy: 0.2417 - macro_f1score: 0.0100 - weighted_f1score: 3.9943e-04\n",
      "Epoch 00007: val_loss improved from 3.54542 to 3.31532, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/007.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.27621 to 0.29872, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/007.h5\n",
      "765/765 [==============================] - 712s 931ms/step - loss: 3.6298 - accuracy: 0.2417 - macro_f1score: 0.0100 - weighted_f1score: 3.9943e-04 - val_loss: 3.3153 - val_accuracy: 0.2987 - val_macro_f1score: 0.0141 - val_weighted_f1score: 5.3790e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 8/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 3.4214 - accuracy: 0.2770 - macro_f1score: 0.0122 - weighted_f1score: 4.8367e-04\n",
      "Epoch 00008: val_loss did not improve from 3.31532\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.29872 to 0.33065, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/008.h5\n",
      "765/765 [==============================] - 701s 917ms/step - loss: 3.4214 - accuracy: 0.2770 - macro_f1score: 0.0122 - weighted_f1score: 4.8367e-04 - val_loss: 3.4774 - val_accuracy: 0.3306 - val_macro_f1score: 0.0171 - val_weighted_f1score: 6.4411e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 9/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 3.2974 - accuracy: 0.2924 - macro_f1score: 0.0141 - weighted_f1score: 5.3647e-04\n",
      "Epoch 00009: val_loss improved from 3.31532 to 3.20737, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/009.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.33065 to 0.35450, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/009.h5\n",
      "765/765 [==============================] - 715s 935ms/step - loss: 3.2974 - accuracy: 0.2924 - macro_f1score: 0.0141 - weighted_f1score: 5.3647e-04 - val_loss: 3.2074 - val_accuracy: 0.3545 - val_macro_f1score: 0.0199 - val_weighted_f1score: 7.3393e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 10/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 3.1271 - accuracy: 0.3244 - macro_f1score: 0.0167 - weighted_f1score: 6.2551e-04\n",
      "Epoch 00010: val_loss improved from 3.20737 to 2.93182, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/010.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.35450 to 0.37634, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/010.h5\n",
      "765/765 [==============================] - 700s 916ms/step - loss: 3.1271 - accuracy: 0.3244 - macro_f1score: 0.0167 - weighted_f1score: 6.2551e-04 - val_loss: 2.9318 - val_accuracy: 0.3763 - val_macro_f1score: 0.0216 - val_weighted_f1score: 8.1046e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 11/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 2.9492 - accuracy: 0.3510 - macro_f1score: 0.0191 - weighted_f1score: 7.1467e-04\n",
      "Epoch 00011: val_loss improved from 2.93182 to 2.79606, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/011.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.37634 to 0.39483, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/011.h5\n",
      "765/765 [==============================] - 694s 907ms/step - loss: 2.9492 - accuracy: 0.3510 - macro_f1score: 0.0191 - weighted_f1score: 7.1467e-04 - val_loss: 2.7961 - val_accuracy: 0.3948 - val_macro_f1score: 0.0250 - val_weighted_f1score: 9.2351e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 12/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 2.8191 - accuracy: 0.3695 - macro_f1score: 0.0215 - weighted_f1score: 7.9098e-04\n",
      "Epoch 00012: val_loss improved from 2.79606 to 2.67757, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/012.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.39483 to 0.41734, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/012.h5\n",
      "765/765 [==============================] - 696s 910ms/step - loss: 2.8191 - accuracy: 0.3695 - macro_f1score: 0.0215 - weighted_f1score: 7.9098e-04 - val_loss: 2.6776 - val_accuracy: 0.4173 - val_macro_f1score: 0.0271 - val_weighted_f1score: 9.8257e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 13/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 2.6882 - accuracy: 0.3950 - macro_f1score: 0.0241 - weighted_f1score: 8.8310e-04\n",
      "Epoch 00013: val_loss improved from 2.67757 to 2.54930, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/013.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.41734 to 0.43952, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/013.h5\n",
      "765/765 [==============================] - 699s 914ms/step - loss: 2.6882 - accuracy: 0.3950 - macro_f1score: 0.0241 - weighted_f1score: 8.8310e-04 - val_loss: 2.5493 - val_accuracy: 0.4395 - val_macro_f1score: 0.0304 - val_weighted_f1score: 0.0011\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 14/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 2.5673 - accuracy: 0.4183 - macro_f1score: 0.0270 - weighted_f1score: 9.7604e-04\n",
      "Epoch 00014: val_loss did not improve from 2.54930\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.43952 to 0.45464, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/014.h5\n",
      "765/765 [==============================] - 702s 918ms/step - loss: 2.5673 - accuracy: 0.4183 - macro_f1score: 0.0270 - weighted_f1score: 9.7604e-04 - val_loss: 2.5669 - val_accuracy: 0.4546 - val_macro_f1score: 0.0323 - val_weighted_f1score: 0.0012\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 15/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 2.4471 - accuracy: 0.4416 - macro_f1score: 0.0293 - weighted_f1score: 0.0011\n",
      "Epoch 00015: val_loss improved from 2.54930 to 2.39626, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/015.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.45464 to 0.47581, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/015.h5\n",
      "765/765 [==============================] - 706s 922ms/step - loss: 2.4471 - accuracy: 0.4416 - macro_f1score: 0.0293 - weighted_f1score: 0.0011 - val_loss: 2.3963 - val_accuracy: 0.4758 - val_macro_f1score: 0.0353 - val_weighted_f1score: 0.0013\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 16/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 2.3339 - accuracy: 0.4625 - macro_f1score: 0.0318 - weighted_f1score: 0.0011\n",
      "Epoch 00016: val_loss improved from 2.39626 to 2.35983, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/016.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.47581 to 0.48118, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/016.h5\n",
      "765/765 [==============================] - 701s 917ms/step - loss: 2.3339 - accuracy: 0.4625 - macro_f1score: 0.0318 - weighted_f1score: 0.0011 - val_loss: 2.3598 - val_accuracy: 0.4812 - val_macro_f1score: 0.0374 - val_weighted_f1score: 0.0013\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 17/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 2.2250 - accuracy: 0.4784 - macro_f1score: 0.0344 - weighted_f1score: 0.0012\n",
      "Epoch 00017: val_loss improved from 2.35983 to 2.30019, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/017.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.48118 to 0.50437, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/017.h5\n",
      "765/765 [==============================] - 720s 941ms/step - loss: 2.2250 - accuracy: 0.4784 - macro_f1score: 0.0344 - weighted_f1score: 0.0012 - val_loss: 2.3002 - val_accuracy: 0.5044 - val_macro_f1score: 0.0398 - val_weighted_f1score: 0.0014\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 18/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 2.1256 - accuracy: 0.5002 - macro_f1score: 0.0373 - weighted_f1score: 0.0013\n",
      "Epoch 00018: val_loss did not improve from 2.30019\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.50437 to 0.51478, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/018.h5\n",
      "765/765 [==============================] - 713s 932ms/step - loss: 2.1256 - accuracy: 0.5002 - macro_f1score: 0.0373 - weighted_f1score: 0.0013 - val_loss: 2.3690 - val_accuracy: 0.5148 - val_macro_f1score: 0.0419 - val_weighted_f1score: 0.0015\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 19/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 2.0234 - accuracy: 0.5190 - macro_f1score: 0.0404 - weighted_f1score: 0.0014\n",
      "Epoch 00019: val_loss did not improve from 2.30019\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.51478 to 0.52352, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/019.h5\n",
      "765/765 [==============================] - 706s 923ms/step - loss: 2.0234 - accuracy: 0.5190 - macro_f1score: 0.0404 - weighted_f1score: 0.0014 - val_loss: 2.3604 - val_accuracy: 0.5235 - val_macro_f1score: 0.0436 - val_weighted_f1score: 0.0016\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 20/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.9240 - accuracy: 0.5387 - macro_f1score: 0.0429 - weighted_f1score: 0.0015\n",
      "Epoch 00020: val_loss did not improve from 2.30019\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.52352 to 0.52453, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/020.h5\n",
      "765/765 [==============================] - 707s 924ms/step - loss: 1.9240 - accuracy: 0.5387 - macro_f1score: 0.0429 - weighted_f1score: 0.0015 - val_loss: 2.5971 - val_accuracy: 0.5245 - val_macro_f1score: 0.0450 - val_weighted_f1score: 0.0016\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 21/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.8468 - accuracy: 0.5532 - macro_f1score: 0.0449 - weighted_f1score: 0.0016\n",
      "Epoch 00021: val_loss improved from 2.30019 to 2.25102, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/021.h5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.52453 to 0.53293, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/021.h5\n",
      "765/765 [==============================] - 712s 931ms/step - loss: 1.8468 - accuracy: 0.5532 - macro_f1score: 0.0449 - weighted_f1score: 0.0016 - val_loss: 2.2510 - val_accuracy: 0.5329 - val_macro_f1score: 0.0463 - val_weighted_f1score: 0.0017\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 22/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.7560 - accuracy: 0.5665 - macro_f1score: 0.0475 - weighted_f1score: 0.0017\n",
      "Epoch 00022: val_loss improved from 2.25102 to 2.23078, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/022.h5\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.53293 to 0.54133, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/022.h5\n",
      "765/765 [==============================] - 710s 928ms/step - loss: 1.7560 - accuracy: 0.5665 - macro_f1score: 0.0475 - weighted_f1score: 0.0017 - val_loss: 2.2308 - val_accuracy: 0.5413 - val_macro_f1score: 0.0480 - val_weighted_f1score: 0.0017\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 23/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.6823 - accuracy: 0.5874 - macro_f1score: 0.0495 - weighted_f1score: 0.0017\n",
      "Epoch 00023: val_loss did not improve from 2.23078\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.54133 to 0.55813, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/023.h5\n",
      "765/765 [==============================] - 710s 928ms/step - loss: 1.6823 - accuracy: 0.5874 - macro_f1score: 0.0495 - weighted_f1score: 0.0017 - val_loss: 2.2507 - val_accuracy: 0.5581 - val_macro_f1score: 0.0509 - val_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 24/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.6025 - accuracy: 0.6033 - macro_f1score: 0.0523 - weighted_f1score: 0.0018\n",
      "Epoch 00024: val_loss improved from 2.23078 to 2.03805, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/024.h5\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.55813 to 0.56250, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/024.h5\n",
      "765/765 [==============================] - 718s 938ms/step - loss: 1.6025 - accuracy: 0.6033 - macro_f1score: 0.0523 - weighted_f1score: 0.0018 - val_loss: 2.0381 - val_accuracy: 0.5625 - val_macro_f1score: 0.0518 - val_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 25/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.5251 - accuracy: 0.6199 - macro_f1score: 0.0548 - weighted_f1score: 0.0019\n",
      "Epoch 00025: val_loss did not improve from 2.03805\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.56250\n",
      "765/765 [==============================] - 707s 925ms/step - loss: 1.5251 - accuracy: 0.6199 - macro_f1score: 0.0548 - weighted_f1score: 0.0019 - val_loss: 2.2957 - val_accuracy: 0.5622 - val_macro_f1score: 0.0519 - val_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 26/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.4852 - accuracy: 0.6266 - macro_f1score: 0.0560 - weighted_f1score: 0.0019\n",
      "Epoch 00026: val_loss improved from 2.03805 to 2.02173, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/026.h5\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.56250 to 0.57090, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/026.h5\n",
      "765/765 [==============================] - 717s 937ms/step - loss: 1.4852 - accuracy: 0.6266 - macro_f1score: 0.0560 - weighted_f1score: 0.0019 - val_loss: 2.0217 - val_accuracy: 0.5709 - val_macro_f1score: 0.0541 - val_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 27/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.4114 - accuracy: 0.6406 - macro_f1score: 0.0582 - weighted_f1score: 0.0020\n",
      "Epoch 00027: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.57090 to 0.57392, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/027.h5\n",
      "765/765 [==============================] - 710s 928ms/step - loss: 1.4114 - accuracy: 0.6406 - macro_f1score: 0.0582 - weighted_f1score: 0.0020 - val_loss: 2.1044 - val_accuracy: 0.5739 - val_macro_f1score: 0.0548 - val_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 28/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.3496 - accuracy: 0.6567 - macro_f1score: 0.0600 - weighted_f1score: 0.0021\n",
      "Epoch 00028: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.57392\n",
      "765/765 [==============================] - 705s 922ms/step - loss: 1.3496 - accuracy: 0.6567 - macro_f1score: 0.0600 - weighted_f1score: 0.0021 - val_loss: 2.2153 - val_accuracy: 0.5696 - val_macro_f1score: 0.0548 - val_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 29/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.2661 - accuracy: 0.6713 - macro_f1score: 0.0632 - weighted_f1score: 0.0022\n",
      "Epoch 00029: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.57392 to 0.58837, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/029.h5\n",
      "765/765 [==============================] - 714s 933ms/step - loss: 1.2661 - accuracy: 0.6713 - macro_f1score: 0.0632 - weighted_f1score: 0.0022 - val_loss: 2.2132 - val_accuracy: 0.5884 - val_macro_f1score: 0.0572 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 30/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.2333 - accuracy: 0.6787 - macro_f1score: 0.0644 - weighted_f1score: 0.0022\n",
      "Epoch 00030: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.58837\n",
      "765/765 [==============================] - 725s 948ms/step - loss: 1.2333 - accuracy: 0.6787 - macro_f1score: 0.0644 - weighted_f1score: 0.0022 - val_loss: 2.1119 - val_accuracy: 0.5827 - val_macro_f1score: 0.0562 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 31/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.1881 - accuracy: 0.6930 - macro_f1score: 0.0661 - weighted_f1score: 0.0023\n",
      "Epoch 00031: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.58837\n",
      "765/765 [==============================] - 748s 977ms/step - loss: 1.1881 - accuracy: 0.6930 - macro_f1score: 0.0661 - weighted_f1score: 0.0023 - val_loss: 2.0707 - val_accuracy: 0.5837 - val_macro_f1score: 0.0581 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 32/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.1139 - accuracy: 0.7061 - macro_f1score: 0.0680 - weighted_f1score: 0.0024\n",
      "Epoch 00032: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.58837 to 0.59274, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/032.h5\n",
      "765/765 [==============================] - 733s 958ms/step - loss: 1.1139 - accuracy: 0.7061 - macro_f1score: 0.0680 - weighted_f1score: 0.0024 - val_loss: 2.2000 - val_accuracy: 0.5927 - val_macro_f1score: 0.0577 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 33/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.0604 - accuracy: 0.7183 - macro_f1score: 0.0701 - weighted_f1score: 0.0024\n",
      "Epoch 00033: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.59274 to 0.59812, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/033.h5\n",
      "765/765 [==============================] - 713s 932ms/step - loss: 1.0604 - accuracy: 0.7183 - macro_f1score: 0.0701 - weighted_f1score: 0.0024 - val_loss: 2.0984 - val_accuracy: 0.5981 - val_macro_f1score: 0.0596 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 34/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 1.0205 - accuracy: 0.7277 - macro_f1score: 0.0713 - weighted_f1score: 0.0025\n",
      "Epoch 00034: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.59812 to 0.60551, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/034.h5\n",
      "765/765 [==============================] - 712s 931ms/step - loss: 1.0205 - accuracy: 0.7277 - macro_f1score: 0.0713 - weighted_f1score: 0.0025 - val_loss: 2.3096 - val_accuracy: 0.6055 - val_macro_f1score: 0.0591 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 35/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.9804 - accuracy: 0.7345 - macro_f1score: 0.0725 - weighted_f1score: 0.0025\n",
      "Epoch 00035: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.60551\n",
      "765/765 [==============================] - 714s 933ms/step - loss: 0.9804 - accuracy: 0.7345 - macro_f1score: 0.0725 - weighted_f1score: 0.0025 - val_loss: 2.1288 - val_accuracy: 0.5978 - val_macro_f1score: 0.0592 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 36/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.9440 - accuracy: 0.7474 - macro_f1score: 0.0746 - weighted_f1score: 0.0026\n",
      "Epoch 00036: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.60551\n",
      "765/765 [==============================] - 714s 933ms/step - loss: 0.9440 - accuracy: 0.7474 - macro_f1score: 0.0746 - weighted_f1score: 0.0026 - val_loss: 2.0490 - val_accuracy: 0.6055 - val_macro_f1score: 0.0600 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 37/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.8736 - accuracy: 0.7621 - macro_f1score: 0.0767 - weighted_f1score: 0.0026\n",
      "Epoch 00037: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.60551\n",
      "765/765 [==============================] - 711s 929ms/step - loss: 0.8736 - accuracy: 0.7621 - macro_f1score: 0.0767 - weighted_f1score: 0.0026 - val_loss: 2.2032 - val_accuracy: 0.5961 - val_macro_f1score: 0.0612 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 38/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.8383 - accuracy: 0.7689 - macro_f1score: 0.0782 - weighted_f1score: 0.0027\n",
      "Epoch 00038: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.60551\n",
      "765/765 [==============================] - 713s 932ms/step - loss: 0.8383 - accuracy: 0.7689 - macro_f1score: 0.0782 - weighted_f1score: 0.0027 - val_loss: 2.2372 - val_accuracy: 0.6042 - val_macro_f1score: 0.0613 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 39/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.8033 - accuracy: 0.7778 - macro_f1score: 0.0795 - weighted_f1score: 0.0027\n",
      "Epoch 00039: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.60551\n",
      "765/765 [==============================] - 716s 936ms/step - loss: 0.8033 - accuracy: 0.7778 - macro_f1score: 0.0795 - weighted_f1score: 0.0027 - val_loss: 2.2234 - val_accuracy: 0.6018 - val_macro_f1score: 0.0609 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 40/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.7680 - accuracy: 0.7866 - macro_f1score: 0.0814 - weighted_f1score: 0.0028\n",
      "Epoch 00040: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00040: val_accuracy improved from 0.60551 to 0.60853, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/040.h5\n",
      "765/765 [==============================] - 719s 940ms/step - loss: 0.7680 - accuracy: 0.7866 - macro_f1score: 0.0814 - weighted_f1score: 0.0028 - val_loss: 2.1409 - val_accuracy: 0.6085 - val_macro_f1score: 0.0612 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 41/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.7317 - accuracy: 0.7954 - macro_f1score: 0.0816 - weighted_f1score: 0.0028\n",
      "Epoch 00041: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.60853 to 0.61492, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/041.h5\n",
      "765/765 [==============================] - 720s 942ms/step - loss: 0.7317 - accuracy: 0.7954 - macro_f1score: 0.0816 - weighted_f1score: 0.0028 - val_loss: 2.1140 - val_accuracy: 0.6149 - val_macro_f1score: 0.0630 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 42/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.8063 - macro_f1score: 0.0834 - weighted_f1score: 0.0029\n",
      "Epoch 00042: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.61492\n",
      "765/765 [==============================] - 713s 932ms/step - loss: 0.6972 - accuracy: 0.8063 - macro_f1score: 0.0834 - weighted_f1score: 0.0029 - val_loss: 3.5907 - val_accuracy: 0.6102 - val_macro_f1score: 0.0623 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 43/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.8079 - macro_f1score: 0.0842 - weighted_f1score: 0.0029\n",
      "Epoch 00043: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.61492\n",
      "765/765 [==============================] - 711s 930ms/step - loss: 0.6856 - accuracy: 0.8079 - macro_f1score: 0.0842 - weighted_f1score: 0.0029 - val_loss: 2.0848 - val_accuracy: 0.6106 - val_macro_f1score: 0.0637 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 44/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.6507 - accuracy: 0.8169 - macro_f1score: 0.0853 - weighted_f1score: 0.0029\n",
      "Epoch 00044: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.61492\n",
      "765/765 [==============================] - 701s 917ms/step - loss: 0.6507 - accuracy: 0.8169 - macro_f1score: 0.0853 - weighted_f1score: 0.0029 - val_loss: 2.1383 - val_accuracy: 0.6119 - val_macro_f1score: 0.0631 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 45/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.6065 - accuracy: 0.8273 - macro_f1score: 0.0873 - weighted_f1score: 0.0030\n",
      "Epoch 00045: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.61492 to 0.61828, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/045.h5\n",
      "765/765 [==============================] - 708s 926ms/step - loss: 0.6065 - accuracy: 0.8273 - macro_f1score: 0.0873 - weighted_f1score: 0.0030 - val_loss: 2.1281 - val_accuracy: 0.6183 - val_macro_f1score: 0.0641 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 46/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.5945 - accuracy: 0.8302 - macro_f1score: 0.0879 - weighted_f1score: 0.0030\n",
      "Epoch 00046: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.61828 to 0.61996, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/046.h5\n",
      "765/765 [==============================] - 719s 940ms/step - loss: 0.5945 - accuracy: 0.8302 - macro_f1score: 0.0879 - weighted_f1score: 0.0030 - val_loss: 2.3438 - val_accuracy: 0.6200 - val_macro_f1score: 0.0653 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 47/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.8400 - macro_f1score: 0.0891 - weighted_f1score: 0.0031\n",
      "Epoch 00047: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.61996 to 0.62030, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/047.h5\n",
      "765/765 [==============================] - 707s 924ms/step - loss: 0.5671 - accuracy: 0.8400 - macro_f1score: 0.0891 - weighted_f1score: 0.0031 - val_loss: 2.1662 - val_accuracy: 0.6203 - val_macro_f1score: 0.0644 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 48/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.5587 - accuracy: 0.8417 - macro_f1score: 0.0893 - weighted_f1score: 0.0031\n",
      "Epoch 00048: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.62030\n",
      "765/765 [==============================] - 712s 931ms/step - loss: 0.5587 - accuracy: 0.8417 - macro_f1score: 0.0893 - weighted_f1score: 0.0031 - val_loss: 2.7634 - val_accuracy: 0.6163 - val_macro_f1score: 0.0640 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 49/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.5343 - accuracy: 0.8471 - macro_f1score: 0.0906 - weighted_f1score: 0.0031\n",
      "Epoch 00049: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.62030\n",
      "765/765 [==============================] - 707s 924ms/step - loss: 0.5343 - accuracy: 0.8471 - macro_f1score: 0.0906 - weighted_f1score: 0.0031 - val_loss: 2.4492 - val_accuracy: 0.6146 - val_macro_f1score: 0.0642 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 50/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.5205 - accuracy: 0.8479 - macro_f1score: 0.0906 - weighted_f1score: 0.0031\n",
      "Epoch 00050: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00050: val_accuracy improved from 0.62030 to 0.62634, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/050.h5\n",
      "765/765 [==============================] - 703s 918ms/step - loss: 0.5205 - accuracy: 0.8479 - macro_f1score: 0.0906 - weighted_f1score: 0.0031 - val_loss: 2.4347 - val_accuracy: 0.6263 - val_macro_f1score: 0.0652 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 51/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9450 - macro_f1score: 0.1050 - weighted_f1score: 0.0036\n",
      "Epoch 00051: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.62634\n",
      "765/765 [==============================] - 708s 926ms/step - loss: 0.2078 - accuracy: 0.9450 - macro_f1score: 0.1050 - weighted_f1score: 0.0036 - val_loss: 2.6053 - val_accuracy: 0.6250 - val_macro_f1score: 0.0668 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 52/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.9540 - macro_f1score: 0.1061 - weighted_f1score: 0.0036\n",
      "Epoch 00052: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.62634 to 0.62870, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/052.h5\n",
      "765/765 [==============================] - 716s 935ms/step - loss: 0.1784 - accuracy: 0.9540 - macro_f1score: 0.1061 - weighted_f1score: 0.0036 - val_loss: 2.8137 - val_accuracy: 0.6287 - val_macro_f1score: 0.0657 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 53/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.9598 - macro_f1score: 0.1071 - weighted_f1score: 0.0037\n",
      "Epoch 00053: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00053: val_accuracy improved from 0.62870 to 0.62937, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/053.h5\n",
      "765/765 [==============================] - 718s 938ms/step - loss: 0.1573 - accuracy: 0.9598 - macro_f1score: 0.1071 - weighted_f1score: 0.0037 - val_loss: 3.1094 - val_accuracy: 0.6294 - val_macro_f1score: 0.0669 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 54/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9651 - macro_f1score: 0.1083 - weighted_f1score: 0.0037\n",
      "Epoch 00054: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.62937\n",
      "765/765 [==============================] - 707s 924ms/step - loss: 0.1402 - accuracy: 0.9651 - macro_f1score: 0.1083 - weighted_f1score: 0.0037 - val_loss: 3.1325 - val_accuracy: 0.6267 - val_macro_f1score: 0.0662 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 55/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.9687 - macro_f1score: 0.1085 - weighted_f1score: 0.0037\n",
      "Epoch 00055: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.62937\n",
      "765/765 [==============================] - 703s 919ms/step - loss: 0.1293 - accuracy: 0.9687 - macro_f1score: 0.1085 - weighted_f1score: 0.0037 - val_loss: 3.1731 - val_accuracy: 0.6250 - val_macro_f1score: 0.0662 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 56/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9700 - macro_f1score: 0.1093 - weighted_f1score: 0.0037\n",
      "Epoch 00056: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.62937\n",
      "765/765 [==============================] - 703s 919ms/step - loss: 0.1211 - accuracy: 0.9700 - macro_f1score: 0.1093 - weighted_f1score: 0.0037 - val_loss: 3.4611 - val_accuracy: 0.6260 - val_macro_f1score: 0.0664 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 57/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9713 - macro_f1score: 0.1097 - weighted_f1score: 0.0037\n",
      "Epoch 00057: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.62937\n",
      "765/765 [==============================] - 702s 917ms/step - loss: 0.1148 - accuracy: 0.9713 - macro_f1score: 0.1097 - weighted_f1score: 0.0037 - val_loss: 3.0758 - val_accuracy: 0.6287 - val_macro_f1score: 0.0675 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 58/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.9728 - macro_f1score: 0.1092 - weighted_f1score: 0.0037\n",
      "Epoch 00058: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.62937\n",
      "765/765 [==============================] - 700s 915ms/step - loss: 0.1075 - accuracy: 0.9728 - macro_f1score: 0.1092 - weighted_f1score: 0.0037 - val_loss: 2.9146 - val_accuracy: 0.6267 - val_macro_f1score: 0.0671 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 59/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9770 - macro_f1score: 0.1106 - weighted_f1score: 0.0038\n",
      "Epoch 00059: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.62937\n",
      "765/765 [==============================] - 696s 910ms/step - loss: 0.0979 - accuracy: 0.9770 - macro_f1score: 0.1106 - weighted_f1score: 0.0038 - val_loss: 3.0301 - val_accuracy: 0.6247 - val_macro_f1score: 0.0669 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 60/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9792 - macro_f1score: 0.1108 - weighted_f1score: 0.0038\n",
      "Epoch 00060: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00060: val_accuracy improved from 0.62937 to 0.63105, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_ResNet_v2/060.h5\n",
      "765/765 [==============================] - 702s 917ms/step - loss: 0.0897 - accuracy: 0.9792 - macro_f1score: 0.1108 - weighted_f1score: 0.0038 - val_loss: 2.8436 - val_accuracy: 0.6310 - val_macro_f1score: 0.0676 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 61/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9795 - macro_f1score: 0.1110 - weighted_f1score: 0.0038\n",
      "Epoch 00061: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.63105\n",
      "765/765 [==============================] - 701s 916ms/step - loss: 0.0843 - accuracy: 0.9795 - macro_f1score: 0.1110 - weighted_f1score: 0.0038 - val_loss: 2.9135 - val_accuracy: 0.6247 - val_macro_f1score: 0.0675 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 62/70\n",
      "765/765 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9808 - macro_f1score: 0.1113 - weighted_f1score: 0.0038\n",
      "Epoch 00062: val_loss did not improve from 2.02173\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.63105\n",
      "765/765 [==============================] - 705s 921ms/step - loss: 0.0799 - accuracy: 0.9808 - macro_f1score: 0.1113 - weighted_f1score: 0.0038 - val_loss: 3.1427 - val_accuracy: 0.6260 - val_macro_f1score: 0.0668 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 63/70\n",
      "161/765 [=====>........................] - ETA: 9:01 - loss: 0.0797 - accuracy: 0.9814 - macro_f1score: 0.1111 - weighted_f1score: 0.0038"
     ]
    }
   ],
   "source": [
    "######## flow_from_directory\n",
    "history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jhTx3Gm8-FhB"
   },
   "source": [
    "### 3) Inception-ResNet-V2 Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRiw3ebD-FhC"
   },
   "outputs": [],
   "source": [
    "# 1. epoch=maximum\n",
    "loss , acc, mf1, wf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n",
    "print('[Test Loss: %.4f /  Test Accuracy: %.4f / Test Macro f1: %.4f / Test Weighted f1: %.4f]\\n' % (loss,acc,mf1,wf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWPdDUWI-FhG"
   },
   "outputs": [],
   "source": [
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "f1=history.history['macro_f1score']\n",
    "val_f1=history.history['val_macro_f1score']\n",
    "epochs=range(1,len(acc)+1)\n",
    "\n",
    "data = np.array([epochs,loss,val_loss,acc,val_acc,f1,val_f1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yp2_HCXHyihu"
   },
   "outputs": [],
   "source": [
    "# data save\n",
    "# epochs, loss, val_loss, acc, val_acc, f1, val_f1\n",
    "\n",
    "np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpEXLWpmyihx"
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'Inception_ResNet_v2.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1UoLe1oyihz"
   },
   "outputs": [],
   "source": [
    "epochs=data[:,0]\n",
    "loss=data[:,1]\n",
    "val_loss=data[:,2]\n",
    "acc=data[:,3]\n",
    "val_acc=data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ITeu5vTyih3"
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs[1:],acc[1:],'b',label='Training Acc')\n",
    "plt.plot(epochs[1:],val_acc[1:],'r',label='Validation Acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n",
    "plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RmXQw95FFrY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-opNS8oXFHdB"
   },
   "outputs": [],
   "source": [
    "# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / inception_resnet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-38Ov61FHdE"
   },
   "outputs": [],
   "source": [
    "model=load_model(os.path.join(dir,'model_output',number,'Inception_ResNet_v2','005.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"weighted_f1score\":weighted_f1score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxpCFriTFHdG"
   },
   "outputs": [],
   "source": [
    "# 2. epoch=?\n",
    "loss , acc, mf1, wf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n",
    "print('[Test Loss: %.4f /  Test Accuracy: %.4f / Test Macro f1: %.4f / Test Weighted f1: %.4f]\\n' % (loss,acc,mf1,wf1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "9.Inception Resnet V2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
