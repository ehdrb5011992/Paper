{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQxOsz9NMP5j"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://sike6054.github.io/blog/paper/fourth-post/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwVmRuFcUBkT"
   },
   "source": [
    "\n",
    "# [Inception V4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0MMz6DhUBkW"
   },
   "source": [
    "*KU LeeDongGyu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ywk25Fr79dWe"
   },
   "source": [
    "## Contents\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSON5xiR9dWf"
   },
   "source": [
    "1. Data Preprocessing\n",
    "```\n",
    "1) Data Import\n",
    "2) Data Augmentation\n",
    "```\n",
    "2. Support Functions & Almost Original Inception-V4\n",
    "```\n",
    "1) Support Functions\n",
    "2) Almost Original Inception-V4\n",
    "3) Inception-V4 Evaluate\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U01q4o40UBkY"
   },
   "source": [
    "### Install Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjdygsS_UBke"
   },
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57678,
     "status": "ok",
     "timestamp": 1599313798592,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "o1tpIlBhXG2i",
    "outputId": "32da1831-c7c7-4ebe-966c-17f004c451f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57646,
     "status": "ok",
     "timestamp": 1599313798593,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "IJdbC2nRXR6h",
    "outputId": "68031e0d-c781-499a-fc5d-bd30a28f759c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/Paper\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/Colab Notebooks/Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I98omoQ8FF90"
   },
   "outputs": [],
   "source": [
    "from f1score import macro_f1score,weighted_f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKLMWqbuUBkf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l1,l2,l1_l2\n",
    "from tensorflow.keras.models import Model , load_model , Sequential\n",
    "from tensorflow.keras.utils import plot_model , to_categorical, get_file\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60714,
     "status": "ok",
     "timestamp": 1599313801739,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "cbiFovMgXTax",
    "outputId": "aaf525b0-e147-4480-866d-57dad0125ee7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/Paper'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60681,
     "status": "ok",
     "timestamp": 1599313801746,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "AcT0A_iwEzaZ",
    "outputId": "90365e1f-b47c-409d-eb2a-9ec63488125a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(ks.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66645,
     "status": "ok",
     "timestamp": 1599313807760,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "Gr5hMHvmABmG",
    "outputId": "27828d5f-88e8-4ebd-b577-c5dfa656cac6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66614,
     "status": "ok",
     "timestamp": 1599313807767,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "loV7fj_TsisK",
    "outputId": "ed419877-05a3-499c-9a6f-b4b2dade9a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17342351393446928870\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1972000495367998198\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15839451641025462541\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15695549568\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16085306577901989505\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTXnS6_magkg"
   },
   "source": [
    "## 1. Data Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWigHOuzCRRj"
   },
   "source": [
    "### 1) Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZmG2x1e-HrA"
   },
   "outputs": [],
   "source": [
    "# 바꿔서 살펴 볼 것들\n",
    "# CALTECH, CIFAR100, FER, MIT\n",
    "data_name = 'CALTECH'\n",
    "gan_type = 'No_GAN'\n",
    "number = '1'\n",
    "size = 299 # sizes after cropping\n",
    "super_size = 330 # sizes before cropping \n",
    "input_sizes = (size,size,3)\n",
    "batch_sizes = 64\n",
    "weight_decay = 0\n",
    "epochs = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPnWxfGzLOF6"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n",
    "# setting the seed number for random number generation for reproducibility.\n",
    "\n",
    "from numpy.random import seed\n",
    "import random\n",
    "\n",
    "\n",
    "if number=='1':\n",
    "    seed_num = 200225\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='2':\n",
    "    seed_num = 727\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='3':\n",
    "    seed_num = 115\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='4':\n",
    "    seed_num = 501\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "elif number=='5':\n",
    "    seed_num = 517\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "    random.seed(seed_num)\n",
    "    seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jk4wlZCZqUAy"
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "\n",
    "if data_name=='FER' :\n",
    "    x_train =  np.zeros(28698)\n",
    "    x_valid = np.zeros(3589)\n",
    "    x_test = np.zeros(3588)\n",
    "    classes = 7 \n",
    "    tr_center = [0.50793296, 0.50793296, 0.50793296]\n",
    "elif data_name=='MIT':\n",
    "    x_train = np.zeros(12466)\n",
    "    x_valid = np.zeros(1564)\n",
    "    x_test = np.zeros(1590)\n",
    "    classes = 67 \n",
    "    tr_center = [0.47916578, 0.42029615, 0.36046057]\n",
    "elif data_name=='CALTECH':\n",
    "    x_train = np.zeros(24510)\n",
    "    x_valid = np.zeros(2980)\n",
    "    x_test = np.zeros(3118)\n",
    "    classes = 257\n",
    "    tr_center = [0.51397761, 0.49525248, 0.46555727]\n",
    "elif data_name=='CIFAR100':\n",
    "    x_train = np.zeros(39941)\n",
    "    x_valid = np.zeros(10059)\n",
    "    x_test = np.zeros(10000)\n",
    "    classes = 100\n",
    "    tr_center = [0.53393271, 0.51324147, 0.46450563]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQlStjHWt-jM"
   },
   "outputs": [],
   "source": [
    "dir = os.path.join(os.getcwd(),data_name,gan_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sO311mbMqUA3"
   },
   "source": [
    "### 2) Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BYS2_kmqUA3"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n",
    "\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EW0KZ6x9EBtf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
    "import glob\n",
    "\n",
    "# 데이터 전체에 대해 centering 진행함.\n",
    "\n",
    "def read_cal_image(img_path): \n",
    "    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n",
    "    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n",
    "\n",
    "    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n",
    "    x = np.mean(x, axis=(0,1))\n",
    "    \n",
    "    return np.hstack([x,y])\n",
    "\n",
    "def calculate_centered_mean(dataset_path,x_train=x_train):\n",
    "    num = len(x_train)\n",
    "    space = np.empty((num,4))\n",
    "    i=0\n",
    "\n",
    "    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n",
    "        space[i] = read_cal_image(p)\n",
    "        i += 1\n",
    "\n",
    "    ratio = space[:,3] / np.sum(space[:,3])\n",
    "\n",
    "    return np.average(space[:,0:3],axis=0,weights=ratio)\n",
    "\n",
    "\n",
    "# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n",
    "\n",
    "# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r44S02leqUA7"
   },
   "outputs": [],
   "source": [
    "datagen_tr = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=[0.9,1.0],\n",
    "    fill_mode = 'nearest')\n",
    "datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n",
    "datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n",
    "\n",
    "# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n",
    "\n",
    "# 중심화 설정\n",
    "datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n",
    "datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n",
    "datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 129919,
     "status": "ok",
     "timestamp": 1599313871266,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "kGCjZdO5qUA9",
    "outputId": "44e2218d-1209-499e-bab4-caff9d0d1ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24509 images belonging to 257 classes.\n",
      "Found 2980 images belonging to 257 classes.\n",
      "Found 3118 images belonging to 257 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 39941\n",
    "train_generator= crop_generator(train_batches, size)\n",
    "valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 10059\n",
    "test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "afa9Vvwdw1te"
   },
   "source": [
    "## 2. Support Functions & Almost Original Inception-V4\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iER-OGdBw1tf"
   },
   "source": [
    "### 1) Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wjxS_kxnHN89"
   },
   "outputs": [],
   "source": [
    "# def lr_schedule(epoch):\n",
    "#     init_lr = 1e-4\n",
    "#     k = 0.04\n",
    "#     lr = init_lr * np.exp(-k*epoch)\n",
    "#     print('Learning rate: ', lr)\n",
    "#     return lr\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch < 60:\n",
    "        lr = lr\n",
    "    else :\n",
    "        lr = lr * 0.1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OX5FOx4eMP5o"
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, filters, kernel_size, weight_decay=weight_decay, padding='same', strides=1, activation='relu'):\n",
    "    x = Conv2D(filters, (kernel_size[0], kernel_size[1]), padding=padding, strides=strides, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)    \n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if activation:\n",
    "        x = Activation(activation)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53Kh12kyMP5t"
   },
   "outputs": [],
   "source": [
    "def Stem(input_tensor, version=None, name=None):\n",
    "    if version == 'Inception-v4' or version == 'Inception-ResNet-v2':\n",
    "        x = conv2d_bn(input_tensor, 32, (3, 3), padding='valid', strides=2) # 299x299x3 -> 149x149x32\n",
    "        x = conv2d_bn(x, 32, (3, 3), padding='valid') # 149x149x32 -> 147x147x32\n",
    "        x = conv2d_bn(x, 64, (3, 3)) # 147x147x32 -> 147x147x64\n",
    "        \n",
    "        branch_1 = MaxPooling2D((3, 3), padding='valid', strides=2)(x)\n",
    "        branch_2 = conv2d_bn(x, 96, (3, 3), padding='valid', strides=2)\n",
    "        x = Concatenate()([branch_1, branch_2]) # 73x73x160\n",
    "        \n",
    "        branch_1 = conv2d_bn(x, 64, (1, 1))\n",
    "        branch_1 = conv2d_bn(branch_1, 96, (3, 3), padding='valid')\n",
    "        branch_2 = conv2d_bn(x, 64, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 64, (7, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 64, (1, 7))\n",
    "        branch_2 = conv2d_bn(branch_2, 96, (3, 3), padding='valid')\n",
    "        x = Concatenate()([branch_1, branch_2]) # 71x71x192\n",
    "        \n",
    "        branch_1 = conv2d_bn(x, 192, (3, 3), padding='valid', strides=2) # Fig.4 is wrong\n",
    "        branch_2 = MaxPooling2D((3, 3), padding='valid', strides=2)(x)\n",
    "        x = Concatenate(name=name)([branch_1, branch_2]) if name else Concatenate()([branch_1, branch_2]) # 35x35x384\n",
    "        \n",
    "    elif version == 'Inception-ResNet-v1':\n",
    "        x = conv2d_bn(input_tensor, 32, (3, 3), padding='valid', strides=2) # 299x299x3 -> 149x149x32\n",
    "        x = conv2d_bn(x, 32, (3, 3), padding='valid') # 149x149x32 -> 147x147x32\n",
    "        x = conv2d_bn(x, 64, (3, 3)) # 147x147x32 -> 147x147x64\n",
    "        \n",
    "        x = MaxPooling2D((3, 3), strides=2, padding='valid')(x) # 147x147x64 -> 73x73x64\n",
    "        \n",
    "        x = conv2d_bn(x, 80, (1, 1)) # 73x73x64 -> 73x73x80\n",
    "        x = conv2d_bn(x, 192, (3, 3), padding='valid') # 73x73x80 -> 71x71x192U\n",
    "        x = conv2d_bn(x, 256, (3, 3), padding='valid', strides=2) # 71x71x192 -> 35x35x256\n",
    "        \n",
    "    else:\n",
    "        return None # Kill ^^\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Trvt_SNtMP5w"
   },
   "outputs": [],
   "source": [
    "def Inception_A(input_tensor, name=None):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=1, padding='same')(input_tensor)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, (1, 1))\n",
    "    \n",
    "    branch_2 = conv2d_bn(input_tensor, 96, (1, 1))\n",
    "\n",
    "    branch_3 = conv2d_bn(input_tensor, 64, (1, 1))\n",
    "    branch_3 = conv2d_bn(branch_3, 96, (3, 3))\n",
    "    \n",
    "    branch_4 = conv2d_bn(input_tensor, 64, (1, 1))\n",
    "    branch_4 = conv2d_bn(branch_4, 96, (3, 3))\n",
    "    branch_4 = conv2d_bn(branch_4, 96, (3, 3))\n",
    "    \n",
    "    filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3, branch_4]) if name else Concatenate()([branch_1, branch_2, branch_3, branch_4])\n",
    "    \n",
    "    return filter_concat\n",
    "\n",
    "def Inception_B(input_tensor, name=None):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=1, padding='same')(input_tensor)\n",
    "    branch_1 = conv2d_bn(branch_1, 128, (1, 1))\n",
    "    \n",
    "    branch_2 = conv2d_bn(input_tensor, 384, (1, 1))\n",
    "    \n",
    "    branch_3 = conv2d_bn(input_tensor, 192, (1, 1))\n",
    "    branch_3 = conv2d_bn(branch_3, 224, (1, 7))\n",
    "    branch_3 = conv2d_bn(branch_3, 256, (7, 1)) # Fig.6 is wrong\n",
    "    \n",
    "    branch_4 = conv2d_bn(input_tensor, 192, (1, 1))\n",
    "    branch_4 = conv2d_bn(branch_4, 192, (1, 7))\n",
    "    branch_4 = conv2d_bn(branch_4, 224, (7, 1))\n",
    "    branch_4 = conv2d_bn(branch_4, 224, (1, 7))\n",
    "    branch_4 = conv2d_bn(branch_4, 256, (7, 1))\n",
    "    \n",
    "    filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3, branch_4]) if name else Concatenate()([branch_1, branch_2, branch_3, branch_4])\n",
    "    \n",
    "    return filter_concat\n",
    "\n",
    "def Inception_C(input_tensor, name=None):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=1, padding='same')(input_tensor)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, (1, 1))\n",
    "    \n",
    "    branch_2 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "\n",
    "    branch_3 = conv2d_bn(input_tensor, 384, (1, 1))\n",
    "    branch_3a = conv2d_bn(branch_3, 256, (1, 3))\n",
    "    branch_3b = conv2d_bn(branch_3, 256, (3, 1))\n",
    "    branch_3 = Concatenate()([branch_3a, branch_3b])\n",
    "    \n",
    "    branch_4 = conv2d_bn(input_tensor, 384, (1, 1))\n",
    "    branch_4 = conv2d_bn(branch_4, 448, (1, 3))\n",
    "    branch_4 = conv2d_bn(branch_4, 512, (3, 1))\n",
    "    branch_4a = conv2d_bn(branch_4, 256, (1, 3))\n",
    "    branch_4b = conv2d_bn(branch_4, 256, (3, 1))\n",
    "    branch_4 = Concatenate()([branch_4a, branch_4b])\n",
    "    \n",
    "    filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3, branch_4]) if name else Concatenate()([branch_1, branch_2, branch_3, branch_4])\n",
    "    \n",
    "    return filter_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-h_WTblMP5z"
   },
   "outputs": [],
   "source": [
    "reduction_table = {'Inception-v4' : [192, 224, 256, 384],\n",
    "                   'Inception-ResNet-v1' : [192, 192, 256, 384],\n",
    "                   'Inception-ResNet-v2' : [256, 256, 384, 384]}\n",
    "\n",
    "def Reduction_A(input_tensor, version=None, name=None):\n",
    "    k, l, m, n = reduction_table[version]\n",
    "\n",
    "    branch_1 = MaxPooling2D((3, 3), padding='valid', strides=2)(input_tensor)\n",
    "\n",
    "    branch_2 = conv2d_bn(input_tensor, n, (3, 3), padding='valid', strides=2)\n",
    "\n",
    "    branch_3 = conv2d_bn(input_tensor, k, (1, 1))\n",
    "    branch_3 = conv2d_bn(branch_3, l, (3, 3))\n",
    "    branch_3 = conv2d_bn(branch_3, m, (3, 3), padding='valid', strides=2)\n",
    "\n",
    "    filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3]) if name else Concatenate()([branch_1, branch_2, branch_3])\n",
    "\n",
    "    return filter_concat\n",
    "\n",
    "def Reduction_B(input_tensor, version=None, name=None):\n",
    "    if version == 'Inception-v4':\n",
    "        branch_1 = MaxPooling2D((3, 3), padding='valid', strides=2)(input_tensor)\n",
    "    \n",
    "        branch_2 = conv2d_bn(input_tensor, 192, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 192, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        branch_3 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_3 = conv2d_bn(branch_3, 256, (1, 7))\n",
    "        branch_3 = conv2d_bn(branch_3, 320, (7, 1))\n",
    "        branch_3 = conv2d_bn(branch_3, 320, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3]) if name else Concatenate()([branch_1, branch_2, branch_3])\n",
    "\n",
    "    elif version == 'Inception-ResNet-v1':\n",
    "        branch_1 = MaxPooling2D((3, 3), padding='valid', strides=2)(input_tensor)\n",
    "    \n",
    "        branch_2 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 384, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        branch_3 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_3 = conv2d_bn(branch_3, 256, (3, 3), padding='valid', strides=2)\n",
    "        \n",
    "        branch_4 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_4 = conv2d_bn(branch_4, 256, (3, 3))\n",
    "        branch_4 = conv2d_bn(branch_4, 256, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3, branch_4]) if name else Concatenate()([branch_1, branch_2, branch_3, branch_4])\n",
    "\n",
    "    elif version == 'Inception-ResNet-v2':\n",
    "        branch_1 = MaxPooling2D((3, 3), padding='valid', strides=2)(input_tensor)\n",
    "    \n",
    "        branch_2 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_2 = conv2d_bn(branch_2, 384, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        branch_3 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_3 = conv2d_bn(branch_3, 288, (3, 3), padding='valid', strides=2)\n",
    "        \n",
    "        branch_4 = conv2d_bn(input_tensor, 256, (1, 1))\n",
    "        branch_4 = conv2d_bn(branch_4, 288, (3, 3))\n",
    "        branch_4 = conv2d_bn(branch_4, 320, (3, 3), padding='valid', strides=2)\n",
    "    \n",
    "        filter_concat = Concatenate(name=name)([branch_1, branch_2, branch_3, branch_4]) if name else Concatenate()([branch_1, branch_2, branch_3, branch_4])\n",
    "    \n",
    "    else:\n",
    "        return None # Kill ^^\n",
    "    \n",
    "    return filter_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJixgnY7Z6j7"
   },
   "source": [
    "### 2) Almost Original Inception-V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQ-qQyx5MP53"
   },
   "outputs": [],
   "source": [
    "def Inception_v4(model_input, classes=1000, name='Inception_v4'):\n",
    "    version = 'Inception-v4'\n",
    "    \n",
    "    x = Stem(model_input, version=version, name='Stem') # (299, 299, 3) -> (35, 35, 384)\n",
    "    \n",
    "    for i in range(4):\n",
    "        x = Inception_A(x, name='Inception-A-'+str(i+1)) # (35, 35, 384)\n",
    "    \n",
    "    x = Reduction_A(x, version=version, name='Reduction-A') # (35, 35, 384) -> (17, 17, 1024)\n",
    "    \n",
    "    for i in range(7):\n",
    "        x = Inception_B(x, name='Inception-B-'+str(i+1)) # (17, 17, 1024)\n",
    "\n",
    "    x = Reduction_B(x, version=version, name='Reduction-B') # (17, 17, 1024) -> (8, 8, 1536)\n",
    "    \n",
    "    for i in range(3):\n",
    "        x = Inception_C(x, name='Inception-C-'+str(i+1)) # (8, 8, 1536)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x) # (1536)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    model_output = Dense(classes, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(model_input, model_output, name=name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "11LgAhywJfUE"
   },
   "outputs": [],
   "source": [
    "# weight_decay는 inception-v3의 weight decay임. - 튜닝해볼 것\n",
    "\n",
    "model_input = Input(shape=input_sizes)\n",
    "model = Inception_v4(model_input, classes=classes, name='Inception_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 134012,
     "status": "ok",
     "timestamp": 1599313875543,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "0HuelUizNJWz",
    "outputId": "5ff02b8a-61b6-4f31-aebb-4110ad0543b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Inception_v4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18496       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 96)   55392       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 96)   384         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 96)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 73, 73, 160)  0           max_pooling2d[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 73, 73, 64)   10304       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 73, 73, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 73, 73, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 73, 73, 64)   28736       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 73, 73, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 73, 73, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 64)   10304       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 73, 73, 64)   28736       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 73, 73, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 73, 73, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 96)   55392       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 71, 71, 96)   55392       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 96)   384         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 71, 71, 96)   384         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 96)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 71, 71, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 71, 71, 192)  0           activation_5[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 192)  331968      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 192)  768         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 192)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stem (Concatenate)              (None, 35, 35, 384)  0           activation_10[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   24640       Stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   24640       Stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55392       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   384         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 384)  0           Stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   36960       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 96)   36960       Stem[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 96)   55392       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   83040       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   384         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 96)   384         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 96)   384         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   384         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 96)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 96)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Inception-A-1 (Concatenate)     (None, 35, 35, 384)  0           activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   24640       Inception-A-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   24640       Inception-A-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55392       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   384         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 384)  0           Inception-A-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   36960       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 96)   36960       Inception-A-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 96)   55392       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   83040       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   384         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 96)   384         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 96)   384         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   384         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 96)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 96)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Inception-A-2 (Concatenate)     (None, 35, 35, 384)  0           activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 64)   24640       Inception-A-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   24640       Inception-A-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 96)   55392       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 35, 35, 96)   384         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 384)  0           Inception-A-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   36960       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 96)   36960       Inception-A-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55392       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 35, 35, 96)   83040       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   384         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 96)   384         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   384         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 35, 35, 96)   384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 96)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 96)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Inception-A-3 (Concatenate)     (None, 35, 35, 384)  0           activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 35, 35, 64)   24640       Inception-A-3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 35, 35, 64)   256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 35, 35, 64)   24640       Inception-A-3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 35, 35, 96)   55392       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 35, 35, 64)   256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 35, 35, 96)   384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 384)  0           Inception-A-3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 96)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 35, 35, 96)   36960       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 35, 35, 96)   36960       Inception-A-3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 35, 35, 96)   55392       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 96)   83040       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 35, 35, 96)   384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 35, 35, 96)   384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 35, 35, 96)   384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 96)   384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 96)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 96)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 96)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 96)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Inception-A-4 (Concatenate)     (None, 35, 35, 384)  0           activation_32[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 192)  73920       Inception-A-4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 35, 35, 192)  768         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 224)  387296      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 35, 35, 224)  896         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 224)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 384)  1327488     Inception-A-4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 256)  516352      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 384)  1536        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 256)  1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 384)  0           Inception-A-4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 384)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Reduction-A (Concatenate)       (None, 17, 17, 1024) 0           max_pooling2d_2[0][0]            \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  196800      Reduction-A[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  768         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  258240      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  768         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 192)  196800      Reduction-A[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 224)  301280      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 192)  768         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 224)  896         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 192)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 224)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 224)  301280      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 224)  351456      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 224)  896         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 224)  896         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 1024) 0           Reduction-A[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 224)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 224)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 128)  131200      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 384)  393600      Reduction-A[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 256)  401664      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 256)  401664      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 128)  512         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 384)  1536        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 256)  1024        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 256)  1024        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 128)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 384)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 256)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 256)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Inception-B-1 (Concatenate)     (None, 17, 17, 1024) 0           activation_43[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  196800      Inception-B-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  768         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  258240      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  768         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 192)  196800      Inception-B-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 224)  301280      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 192)  768         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 224)  896         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 192)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 224)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 224)  301280      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 224)  351456      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 224)  896         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 224)  896         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 1024) 0           Inception-B-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 224)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 224)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 128)  131200      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 384)  393600      Inception-B-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 256)  401664      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 256)  401664      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 128)  512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 384)  1536        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 256)  1024        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 384)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 256)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 256)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Inception-B-2 (Concatenate)     (None, 17, 17, 1024) 0           activation_53[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  196800      Inception-B-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  768         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258240      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  768         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  196800      Inception-B-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 224)  301280      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  768         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 224)  896         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 224)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 224)  301280      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 224)  351456      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 224)  896         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 224)  896         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 1024) 0           Inception-B-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 224)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 224)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 128)  131200      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 384)  393600      Inception-B-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 256)  401664      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 256)  401664      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 128)  512         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 384)  1536        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 256)  1024        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 256)  1024        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 128)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 384)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 256)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 256)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Inception-B-3 (Concatenate)     (None, 17, 17, 1024) 0           activation_63[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_67[0][0]              \n",
      "                                                                 activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 192)  196800      Inception-B-3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 17, 17, 192)  768         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 192)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 192)  258240      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 17, 17, 192)  768         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 192)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 192)  196800      Inception-B-3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 224)  301280      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 192)  768         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 17, 17, 224)  896         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 224)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 224)  301280      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 224)  351456      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 17, 17, 224)  896         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 17, 17, 224)  896         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 1024) 0           Inception-B-3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 224)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 224)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 128)  131200      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 384)  393600      Inception-B-3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 256)  401664      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 256)  401664      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 128)  512         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 384)  1536        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 17, 17, 256)  1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 17, 17, 256)  1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 128)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 384)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 256)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 256)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Inception-B-4 (Concatenate)     (None, 17, 17, 1024) 0           activation_73[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "                                                                 activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 192)  196800      Inception-B-4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 17, 17, 192)  768         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 192)  258240      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 17, 17, 192)  768         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 17, 17, 192)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 192)  196800      Inception-B-4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 224)  301280      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 17, 17, 192)  768         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 17, 17, 224)  896         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 192)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 17, 17, 224)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 224)  301280      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 224)  351456      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 17, 17, 224)  896         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 17, 17, 224)  896         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 17, 17, 1024) 0           Inception-B-4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 224)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 17, 17, 224)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 128)  131200      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 384)  393600      Inception-B-4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 256)  401664      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 256)  401664      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 17, 17, 128)  512         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 17, 17, 384)  1536        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 17, 17, 256)  1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 17, 17, 256)  1024        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 128)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 384)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 17, 17, 256)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 17, 17, 256)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Inception-B-5 (Concatenate)     (None, 17, 17, 1024) 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 192)  196800      Inception-B-5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 17, 17, 192)  768         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 17, 17, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 192)  258240      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 17, 17, 192)  768         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 17, 17, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 192)  196800      Inception-B-5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 224)  301280      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 17, 17, 192)  768         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 17, 17, 224)  896         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 17, 17, 192)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 17, 17, 224)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 224)  301280      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 17, 17, 224)  351456      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 17, 17, 224)  896         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 17, 17, 224)  896         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 17, 17, 1024) 0           Inception-B-5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 17, 17, 224)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 17, 17, 224)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 128)  131200      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 384)  393600      Inception-B-5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 256)  401664      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 256)  401664      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 17, 17, 128)  512         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 17, 17, 384)  1536        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 17, 17, 256)  1024        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 17, 17, 256)  1024        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 17, 17, 128)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 17, 17, 384)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 17, 17, 256)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 17, 17, 256)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Inception-B-6 (Concatenate)     (None, 17, 17, 1024) 0           activation_93[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "                                                                 activation_97[0][0]              \n",
      "                                                                 activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 17, 17, 192)  196800      Inception-B-6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 17, 17, 192)  768         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 17, 17, 192)  258240      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 17, 17, 192)  768         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 17, 17, 192)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 192)  196800      Inception-B-6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 17, 17, 224)  301280      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 17, 17, 192)  768         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 17, 17, 224)  896         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 17, 17, 192)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 17, 17, 224)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 17, 17, 224)  301280      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 17, 17, 224)  351456      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 17, 17, 224)  896         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 17, 17, 224)  896         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 17, 17, 1024) 0           Inception-B-6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 17, 17, 224)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 17, 17, 224)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 17, 17, 128)  131200      average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 384)  393600      Inception-B-6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 17, 17, 256)  401664      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 17, 17, 256)  401664      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 17, 17, 128)  512         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 17, 17, 384)  1536        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 17, 17, 256)  1024        conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 17, 17, 256)  1024        conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 17, 17, 128)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 17, 17, 384)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 17, 17, 256)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 17, 17, 256)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Inception-B-7 (Concatenate)     (None, 17, 17, 1024) 0           activation_103[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 17, 17, 256)  262400      Inception-B-7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 17, 17, 256)  1024        conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 17, 17, 256)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 17, 17, 256)  459008      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 17, 17, 256)  1024        conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 17, 17, 256)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 17, 17, 192)  196800      Inception-B-7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 17, 17, 320)  573760      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 17, 17, 192)  768         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 17, 17, 320)  1280        conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 17, 17, 192)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 17, 17, 320)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 192)    331968      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 8, 8, 320)    921920      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 8, 8, 192)    768         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, 8, 320)    1280        conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 1024)   0           Inception-B-7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 8, 8, 192)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 8, 8, 320)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Reduction-B (Concatenate)       (None, 8, 8, 1536)   0           max_pooling2d_3[0][0]            \n",
      "                                                                 activation_114[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 8, 8, 384)    590208      Reduction-B[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 8, 8, 384)    1536        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 8, 8, 384)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 8, 8, 448)    516544      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 8, 8, 448)    1792        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 8, 8, 448)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, 8, 384)    590208      Reduction-B[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 8, 8, 512)    688640      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 8, 384)    1536        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 8, 8, 512)    2048        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 8, 8, 384)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 8, 8, 512)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 8, 8, 1536)   0           Reduction-B[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 8, 256)    295168      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 8, 256)    295168      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 8, 8, 256)    393472      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 8, 8, 256)    393472      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 8, 256)    393472      average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 8, 8, 256)    393472      Reduction-B[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 8, 256)    1024        conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, 8, 256)    1024        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 8, 8, 256)    1024        conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 8, 8, 256)    1024        conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 8, 256)    1024        conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 8, 256)    1024        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 8, 8, 256)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 8, 8, 256)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 8, 8, 256)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 8, 8, 256)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 8, 8, 256)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 8, 8, 256)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 512)    0           activation_122[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 512)    0           activation_127[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Inception-C-1 (Concatenate)     (None, 8, 8, 1536)   0           activation_119[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 8, 8, 384)    590208      Inception-C-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 8, 8, 384)    1536        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 8, 8, 384)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 8, 8, 448)    516544      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 8, 8, 448)    1792        conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 8, 8, 448)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 8, 8, 384)    590208      Inception-C-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 8, 8, 512)    688640      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 8, 8, 384)    1536        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 8, 8, 512)    2048        conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 8, 8, 384)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 8, 8, 512)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 8, 8, 1536)   0           Inception-C-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 8, 8, 256)    295168      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 8, 8, 256)    295168      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 8, 8, 256)    393472      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 8, 8, 256)    393472      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 8, 256)    393472      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 8, 8, 256)    393472      Inception-C-1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 8, 8, 256)    1024        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 8, 8, 256)    1024        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 8, 8, 256)    1024        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 8, 8, 256)    1024        conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 8, 8, 256)    1024        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 8, 8, 256)    1024        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 8, 8, 256)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 8, 8, 256)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 8, 8, 256)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 8, 8, 256)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 8, 8, 256)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 8, 8, 256)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 512)    0           activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 512)    0           activation_137[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Inception-C-2 (Concatenate)     (None, 8, 8, 1536)   0           activation_129[0][0]             \n",
      "                                                                 activation_130[0][0]             \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 8, 8, 384)    590208      Inception-C-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 8, 8, 384)    1536        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 8, 8, 384)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 8, 8, 448)    516544      activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 8, 8, 448)    1792        conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 8, 8, 448)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 8, 8, 384)    590208      Inception-C-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 8, 8, 512)    688640      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 8, 8, 384)    1536        conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 8, 8, 512)    2048        conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 8, 8, 384)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 8, 8, 512)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 8, 8, 1536)   0           Inception-C-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 8, 8, 256)    295168      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 8, 8, 256)    295168      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 8, 8, 256)    393472      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 8, 8, 256)    393472      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 8, 8, 256)    393472      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 8, 8, 256)    393472      Inception-C-2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 8, 8, 256)    1024        conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 8, 8, 256)    1024        conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 8, 8, 256)    1024        conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 8, 8, 256)    1024        conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 8, 8, 256)    1024        conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 8, 8, 256)    1024        conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 8, 8, 256)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 8, 8, 256)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 8, 8, 256)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 8, 8, 256)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 8, 8, 256)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 8, 8, 256)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8, 8, 512)    0           activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 8, 512)    0           activation_147[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Inception-C-3 (Concatenate)     (None, 8, 8, 1536)   0           activation_139[0][0]             \n",
      "                                                                 activation_140[0][0]             \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1536)         0           Inception-C-3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1536)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 257)          395009      dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 41,632,577\n",
      "Trainable params: 41,569,409\n",
      "Non-trainable params: 63,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGb5hss2NoiV"
   },
   "outputs": [],
   "source": [
    "# 폴더 생성\n",
    "\n",
    "os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n",
    "os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lVl6LDW0JgGs"
   },
   "outputs": [],
   "source": [
    "# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n",
    "import utils\n",
    "import optimizers_v2\n",
    "from utils import get_weight_decays, fill_dict_in_order\n",
    "from utils import reset_seeds, K_eval\n",
    "from optimizers_v2 import AdamW, NadamW, SGDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 134491,
     "status": "ok",
     "timestamp": 1599313876088,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "QoWLeggG6dBf",
    "outputId": "b985cd95-fbd3-4f84-ab21-0b9633602905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cosine annealing learning rates\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model=model, use_cosine_annealing=True, total_iterations = len(x_train) // batch_sizes , eta_min = 1e-2)\n",
    "#optimizer = Adam()\n",
    "filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n",
    "                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n",
    "                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n",
    "                  LearningRateScheduler(lr_schedule,verbose=1)\n",
    "                  ]\n",
    "                  \n",
    "model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55144523,
     "status": "ok",
     "timestamp": 1599368886136,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "H9pnv0cw6dBm",
    "outputId": "108bc599-6c9d-4f10-ec46-e24e86d1daa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 1/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 5.2447 - accuracy: 0.0588 - macro_f1score: 4.6773e-04 - weighted_f1score: 1.3505e-05 \n",
      "Epoch 00001: val_loss improved from inf to 4.99406, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/001.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.08118, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/001.h5\n",
      "382/382 [==============================] - 13652s 36s/step - loss: 5.2447 - accuracy: 0.0588 - macro_f1score: 4.6773e-04 - weighted_f1score: 1.3505e-05 - val_loss: 4.9941 - val_accuracy: 0.0812 - val_macro_f1score: 4.0884e-04 - val_weighted_f1score: 9.4721e-06\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 2/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.8699 - accuracy: 0.0889 - macro_f1score: 0.0026 - weighted_f1score: 7.7978e-05\n",
      "Epoch 00002: val_loss improved from 4.99406 to 4.65867, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/002.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.08118 to 0.10258, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/002.h5\n",
      "382/382 [==============================] - 600s 2s/step - loss: 4.8699 - accuracy: 0.0889 - macro_f1score: 0.0026 - weighted_f1score: 7.7978e-05 - val_loss: 4.6587 - val_accuracy: 0.1026 - val_macro_f1score: 0.0040 - val_weighted_f1score: 1.1392e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 3/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.6650 - accuracy: 0.1069 - macro_f1score: 0.0047 - weighted_f1score: 1.3427e-04\n",
      "Epoch 00003: val_loss improved from 4.65867 to 4.44330, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/003.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.10258 to 0.13010, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/003.h5\n",
      "382/382 [==============================] - 602s 2s/step - loss: 4.6650 - accuracy: 0.1069 - macro_f1score: 0.0047 - weighted_f1score: 1.3427e-04 - val_loss: 4.4433 - val_accuracy: 0.1301 - val_macro_f1score: 0.0061 - val_weighted_f1score: 1.7159e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 4/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.5036 - accuracy: 0.1203 - macro_f1score: 0.0061 - weighted_f1score: 1.7789e-04\n",
      "Epoch 00004: val_loss improved from 4.44330 to 4.27229, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/004.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.13010 to 0.14776, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/004.h5\n",
      "382/382 [==============================] - 601s 2s/step - loss: 4.5036 - accuracy: 0.1203 - macro_f1score: 0.0061 - weighted_f1score: 1.7789e-04 - val_loss: 4.2723 - val_accuracy: 0.1478 - val_macro_f1score: 0.0075 - val_weighted_f1score: 2.1324e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 5/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.3408 - accuracy: 0.1386 - macro_f1score: 0.0074 - weighted_f1score: 2.0795e-04\n",
      "Epoch 00005: val_loss improved from 4.27229 to 4.05557, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/005.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.14776 to 0.18580, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/005.h5\n",
      "382/382 [==============================] - 600s 2s/step - loss: 4.3408 - accuracy: 0.1386 - macro_f1score: 0.0074 - weighted_f1score: 2.0795e-04 - val_loss: 4.0556 - val_accuracy: 0.1858 - val_macro_f1score: 0.0089 - val_weighted_f1score: 2.4802e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 6/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 4.1580 - accuracy: 0.1623 - macro_f1score: 0.0088 - weighted_f1score: 2.4625e-04\n",
      "Epoch 00006: val_loss improved from 4.05557 to 3.89276, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/006.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.18580 to 0.20143, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/006.h5\n",
      "382/382 [==============================] - 601s 2s/step - loss: 4.1580 - accuracy: 0.1623 - macro_f1score: 0.0088 - weighted_f1score: 2.4625e-04 - val_loss: 3.8928 - val_accuracy: 0.2014 - val_macro_f1score: 0.0109 - val_weighted_f1score: 2.9574e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 7/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.9878 - accuracy: 0.1826 - macro_f1score: 0.0102 - weighted_f1score: 2.8189e-04\n",
      "Epoch 00007: val_loss improved from 3.89276 to 3.67976, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/007.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.20143 to 0.23573, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/007.h5\n",
      "382/382 [==============================] - 612s 2s/step - loss: 3.9878 - accuracy: 0.1826 - macro_f1score: 0.0102 - weighted_f1score: 2.8189e-04 - val_loss: 3.6798 - val_accuracy: 0.2357 - val_macro_f1score: 0.0134 - val_weighted_f1score: 3.4704e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 8/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.8208 - accuracy: 0.2065 - macro_f1score: 0.0120 - weighted_f1score: 3.1690e-04\n",
      "Epoch 00008: val_loss improved from 3.67976 to 3.51841, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/008.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.23573 to 0.26053, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/008.h5\n",
      "382/382 [==============================] - 606s 2s/step - loss: 3.8208 - accuracy: 0.2065 - macro_f1score: 0.0120 - weighted_f1score: 3.1690e-04 - val_loss: 3.5184 - val_accuracy: 0.2605 - val_macro_f1score: 0.0171 - val_weighted_f1score: 4.1723e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 9/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.6373 - accuracy: 0.2311 - macro_f1score: 0.0144 - weighted_f1score: 3.6343e-04\n",
      "Epoch 00009: val_loss improved from 3.51841 to 3.32199, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/009.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.26053 to 0.29586, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/009.h5\n",
      "382/382 [==============================] - 606s 2s/step - loss: 3.6373 - accuracy: 0.2311 - macro_f1score: 0.0144 - weighted_f1score: 3.6343e-04 - val_loss: 3.3220 - val_accuracy: 0.2959 - val_macro_f1score: 0.0203 - val_weighted_f1score: 4.6885e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 10/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.4564 - accuracy: 0.2581 - macro_f1score: 0.0175 - weighted_f1score: 4.1964e-04\n",
      "Epoch 00010: val_loss improved from 3.32199 to 3.15955, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/010.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.29586 to 0.31556, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/010.h5\n",
      "382/382 [==============================] - 600s 2s/step - loss: 3.4564 - accuracy: 0.2581 - macro_f1score: 0.0175 - weighted_f1score: 4.1964e-04 - val_loss: 3.1595 - val_accuracy: 0.3156 - val_macro_f1score: 0.0258 - val_weighted_f1score: 5.9048e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 11/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.2980 - accuracy: 0.2853 - macro_f1score: 0.0208 - weighted_f1score: 4.8680e-04\n",
      "Epoch 00011: val_loss improved from 3.15955 to 3.02119, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/011.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.31556 to 0.34613, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/011.h5\n",
      "382/382 [==============================] - 606s 2s/step - loss: 3.2980 - accuracy: 0.2853 - macro_f1score: 0.0208 - weighted_f1score: 4.8680e-04 - val_loss: 3.0212 - val_accuracy: 0.3461 - val_macro_f1score: 0.0295 - val_weighted_f1score: 6.6500e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 12/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 3.1347 - accuracy: 0.3110 - macro_f1score: 0.0248 - weighted_f1score: 5.6563e-04\n",
      "Epoch 00012: val_loss improved from 3.02119 to 2.90691, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/012.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.34613 to 0.36209, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/012.h5\n",
      "382/382 [==============================] - 612s 2s/step - loss: 3.1347 - accuracy: 0.3110 - macro_f1score: 0.0248 - weighted_f1score: 5.6563e-04 - val_loss: 2.9069 - val_accuracy: 0.3621 - val_macro_f1score: 0.0324 - val_weighted_f1score: 7.2170e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 13/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.9783 - accuracy: 0.3394 - macro_f1score: 0.0296 - weighted_f1score: 6.5712e-04\n",
      "Epoch 00013: val_loss improved from 2.90691 to 2.80823, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/013.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.36209 to 0.38961, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/013.h5\n",
      "382/382 [==============================] - 608s 2s/step - loss: 2.9783 - accuracy: 0.3394 - macro_f1score: 0.0296 - weighted_f1score: 6.5712e-04 - val_loss: 2.8082 - val_accuracy: 0.3896 - val_macro_f1score: 0.0388 - val_weighted_f1score: 8.2810e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 14/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.8577 - accuracy: 0.3579 - macro_f1score: 0.0334 - weighted_f1score: 7.2019e-04\n",
      "Epoch 00014: val_loss improved from 2.80823 to 2.71348, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/014.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.38961 to 0.40693, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/014.h5\n",
      "382/382 [==============================] - 606s 2s/step - loss: 2.8577 - accuracy: 0.3579 - macro_f1score: 0.0334 - weighted_f1score: 7.2019e-04 - val_loss: 2.7135 - val_accuracy: 0.4069 - val_macro_f1score: 0.0461 - val_weighted_f1score: 9.5306e-04\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 15/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.7273 - accuracy: 0.3777 - macro_f1score: 0.0384 - weighted_f1score: 8.0354e-04\n",
      "Epoch 00015: val_loss improved from 2.71348 to 2.62415, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/015.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.40693 to 0.42663, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/015.h5\n",
      "382/382 [==============================] - 601s 2s/step - loss: 2.7273 - accuracy: 0.3777 - macro_f1score: 0.0384 - weighted_f1score: 8.0354e-04 - val_loss: 2.6241 - val_accuracy: 0.4266 - val_macro_f1score: 0.0496 - val_weighted_f1score: 0.0010\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 16/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.6064 - accuracy: 0.4070 - macro_f1score: 0.0434 - weighted_f1score: 9.0319e-04\n",
      "Epoch 00016: val_loss improved from 2.62415 to 2.50593, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/016.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.42663 to 0.44531, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/016.h5\n",
      "382/382 [==============================] - 600s 2s/step - loss: 2.6064 - accuracy: 0.4070 - macro_f1score: 0.0434 - weighted_f1score: 9.0319e-04 - val_loss: 2.5059 - val_accuracy: 0.4453 - val_macro_f1score: 0.0535 - val_weighted_f1score: 0.0011\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 17/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.4972 - accuracy: 0.4261 - macro_f1score: 0.0483 - weighted_f1score: 9.9188e-04\n",
      "Epoch 00017: val_loss improved from 2.50593 to 2.44850, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/017.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.44531 to 0.45550, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/017.h5\n",
      "382/382 [==============================] - 603s 2s/step - loss: 2.4972 - accuracy: 0.4261 - macro_f1score: 0.0483 - weighted_f1score: 9.9188e-04 - val_loss: 2.4485 - val_accuracy: 0.4555 - val_macro_f1score: 0.0577 - val_weighted_f1score: 0.0012\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 18/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.3890 - accuracy: 0.4449 - macro_f1score: 0.0533 - weighted_f1score: 0.0011\n",
      "Epoch 00018: val_loss improved from 2.44850 to 2.37294, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/018.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.45550 to 0.47181, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/018.h5\n",
      "382/382 [==============================] - 608s 2s/step - loss: 2.3890 - accuracy: 0.4449 - macro_f1score: 0.0533 - weighted_f1score: 0.0011 - val_loss: 2.3729 - val_accuracy: 0.4718 - val_macro_f1score: 0.0626 - val_weighted_f1score: 0.0012\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 19/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.2880 - accuracy: 0.4654 - macro_f1score: 0.0573 - weighted_f1score: 0.0012\n",
      "Epoch 00019: val_loss improved from 2.37294 to 2.29519, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/019.h5\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.47181 to 0.48947, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/019.h5\n",
      "382/382 [==============================] - 607s 2s/step - loss: 2.2880 - accuracy: 0.4654 - macro_f1score: 0.0573 - weighted_f1score: 0.0012 - val_loss: 2.2952 - val_accuracy: 0.4895 - val_macro_f1score: 0.0657 - val_weighted_f1score: 0.0013\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 20/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.1807 - accuracy: 0.4875 - macro_f1score: 0.0636 - weighted_f1score: 0.0013\n",
      "Epoch 00020: val_loss improved from 2.29519 to 2.26843, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/020.h5\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.48947 to 0.49796, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/020.h5\n",
      "382/382 [==============================] - 605s 2s/step - loss: 2.1807 - accuracy: 0.4875 - macro_f1score: 0.0636 - weighted_f1score: 0.0013 - val_loss: 2.2684 - val_accuracy: 0.4980 - val_macro_f1score: 0.0697 - val_weighted_f1score: 0.0014\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 21/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.0919 - accuracy: 0.5023 - macro_f1score: 0.0667 - weighted_f1score: 0.0013\n",
      "Epoch 00021: val_loss improved from 2.26843 to 2.21526, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/021.h5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.49796 to 0.51427, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/021.h5\n",
      "382/382 [==============================] - 603s 2s/step - loss: 2.0919 - accuracy: 0.5023 - macro_f1score: 0.0667 - weighted_f1score: 0.0013 - val_loss: 2.2153 - val_accuracy: 0.5143 - val_macro_f1score: 0.0736 - val_weighted_f1score: 0.0015\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 22/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 2.0114 - accuracy: 0.5204 - macro_f1score: 0.0711 - weighted_f1score: 0.0014\n",
      "Epoch 00022: val_loss improved from 2.21526 to 2.16323, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/022.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.51427\n",
      "382/382 [==============================] - 597s 2s/step - loss: 2.0114 - accuracy: 0.5204 - macro_f1score: 0.0711 - weighted_f1score: 0.0014 - val_loss: 2.1632 - val_accuracy: 0.5132 - val_macro_f1score: 0.0771 - val_weighted_f1score: 0.0015\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 23/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.9246 - accuracy: 0.5366 - macro_f1score: 0.0762 - weighted_f1score: 0.0015\n",
      "Epoch 00023: val_loss improved from 2.16323 to 2.10006, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/023.h5\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.51427 to 0.51732, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/023.h5\n",
      "382/382 [==============================] - 603s 2s/step - loss: 1.9246 - accuracy: 0.5366 - macro_f1score: 0.0762 - weighted_f1score: 0.0015 - val_loss: 2.1001 - val_accuracy: 0.5173 - val_macro_f1score: 0.0778 - val_weighted_f1score: 0.0015\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 24/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.8510 - accuracy: 0.5546 - macro_f1score: 0.0808 - weighted_f1score: 0.0016\n",
      "Epoch 00024: val_loss improved from 2.10006 to 2.08358, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/024.h5\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.51732 to 0.53261, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/024.h5\n",
      "382/382 [==============================] - 604s 2s/step - loss: 1.8510 - accuracy: 0.5546 - macro_f1score: 0.0808 - weighted_f1score: 0.0016 - val_loss: 2.0836 - val_accuracy: 0.5326 - val_macro_f1score: 0.0830 - val_weighted_f1score: 0.0016\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 25/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.7608 - accuracy: 0.5694 - macro_f1score: 0.0849 - weighted_f1score: 0.0017\n",
      "Epoch 00025: val_loss improved from 2.08358 to 2.05812, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/025.h5\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.53261 to 0.54688, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/025.h5\n",
      "382/382 [==============================] - 614s 2s/step - loss: 1.7608 - accuracy: 0.5694 - macro_f1score: 0.0849 - weighted_f1score: 0.0017 - val_loss: 2.0581 - val_accuracy: 0.5469 - val_macro_f1score: 0.0854 - val_weighted_f1score: 0.0017\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 26/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.6832 - accuracy: 0.5844 - macro_f1score: 0.0893 - weighted_f1score: 0.0017\n",
      "Epoch 00026: val_loss improved from 2.05812 to 2.01820, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/026.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.54688\n",
      "382/382 [==============================] - 602s 2s/step - loss: 1.6832 - accuracy: 0.5844 - macro_f1score: 0.0893 - weighted_f1score: 0.0017 - val_loss: 2.0182 - val_accuracy: 0.5465 - val_macro_f1score: 0.0885 - val_weighted_f1score: 0.0017\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 27/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.6280 - accuracy: 0.5967 - macro_f1score: 0.0931 - weighted_f1score: 0.0018\n",
      "Epoch 00027: val_loss improved from 2.01820 to 1.98520, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/027.h5\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.54688 to 0.55673, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/027.h5\n",
      "382/382 [==============================] - 599s 2s/step - loss: 1.6280 - accuracy: 0.5967 - macro_f1score: 0.0931 - weighted_f1score: 0.0018 - val_loss: 1.9852 - val_accuracy: 0.5567 - val_macro_f1score: 0.0897 - val_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 28/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.5606 - accuracy: 0.6119 - macro_f1score: 0.0971 - weighted_f1score: 0.0019\n",
      "Epoch 00028: val_loss improved from 1.98520 to 1.96358, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/028.h5\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.55673 to 0.56522, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/028.h5\n",
      "382/382 [==============================] - 599s 2s/step - loss: 1.5606 - accuracy: 0.6119 - macro_f1score: 0.0971 - weighted_f1score: 0.0019 - val_loss: 1.9636 - val_accuracy: 0.5652 - val_macro_f1score: 0.0915 - val_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 29/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.4680 - accuracy: 0.6318 - macro_f1score: 0.1015 - weighted_f1score: 0.0019\n",
      "Epoch 00029: val_loss improved from 1.96358 to 1.94948, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/029.h5\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.56522 to 0.56590, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/029.h5\n",
      "382/382 [==============================] - 599s 2s/step - loss: 1.4680 - accuracy: 0.6318 - macro_f1score: 0.1015 - weighted_f1score: 0.0019 - val_loss: 1.9495 - val_accuracy: 0.5659 - val_macro_f1score: 0.0941 - val_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 30/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.4342 - accuracy: 0.6374 - macro_f1score: 0.1036 - weighted_f1score: 0.0020\n",
      "Epoch 00030: val_loss improved from 1.94948 to 1.91914, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/030.h5\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.56590 to 0.56861, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/030.h5\n",
      "382/382 [==============================] - 598s 2s/step - loss: 1.4342 - accuracy: 0.6374 - macro_f1score: 0.1036 - weighted_f1score: 0.0020 - val_loss: 1.9191 - val_accuracy: 0.5686 - val_macro_f1score: 0.0968 - val_weighted_f1score: 0.0018\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 31/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.3641 - accuracy: 0.6511 - macro_f1score: 0.1082 - weighted_f1score: 0.0021\n",
      "Epoch 00031: val_loss improved from 1.91914 to 1.90206, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/031.h5\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.56861 to 0.58050, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/031.h5\n",
      "382/382 [==============================] - 596s 2s/step - loss: 1.3641 - accuracy: 0.6511 - macro_f1score: 0.1082 - weighted_f1score: 0.0021 - val_loss: 1.9021 - val_accuracy: 0.5805 - val_macro_f1score: 0.0997 - val_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 32/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.2789 - accuracy: 0.6711 - macro_f1score: 0.1141 - weighted_f1score: 0.0022\n",
      "Epoch 00032: val_loss improved from 1.90206 to 1.87515, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/032.h5\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.58050 to 0.58899, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/032.h5\n",
      "382/382 [==============================] - 597s 2s/step - loss: 1.2789 - accuracy: 0.6711 - macro_f1score: 0.1141 - weighted_f1score: 0.0022 - val_loss: 1.8751 - val_accuracy: 0.5890 - val_macro_f1score: 0.1013 - val_weighted_f1score: 0.0019\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 33/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.2467 - accuracy: 0.6794 - macro_f1score: 0.1159 - weighted_f1score: 0.0022\n",
      "Epoch 00033: val_loss improved from 1.87515 to 1.86651, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/033.h5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.58899\n",
      "382/382 [==============================] - 592s 2s/step - loss: 1.2467 - accuracy: 0.6794 - macro_f1score: 0.1159 - weighted_f1score: 0.0022 - val_loss: 1.8665 - val_accuracy: 0.5815 - val_macro_f1score: 0.1013 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 34/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.1876 - accuracy: 0.6902 - macro_f1score: 0.1198 - weighted_f1score: 0.0023\n",
      "Epoch 00034: val_loss improved from 1.86651 to 1.85310, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/034.h5\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.58899\n",
      "382/382 [==============================] - 592s 2s/step - loss: 1.1876 - accuracy: 0.6902 - macro_f1score: 0.1198 - weighted_f1score: 0.0023 - val_loss: 1.8531 - val_accuracy: 0.5883 - val_macro_f1score: 0.1030 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 35/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.1309 - accuracy: 0.7023 - macro_f1score: 0.1236 - weighted_f1score: 0.0023\n",
      "Epoch 00035: val_loss improved from 1.85310 to 1.83810, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/035.h5\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.58899 to 0.59341, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/035.h5\n",
      "382/382 [==============================] - 605s 2s/step - loss: 1.1309 - accuracy: 0.7023 - macro_f1score: 0.1236 - weighted_f1score: 0.0023 - val_loss: 1.8381 - val_accuracy: 0.5934 - val_macro_f1score: 0.1058 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 36/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.0805 - accuracy: 0.7171 - macro_f1score: 0.1266 - weighted_f1score: 0.0024\n",
      "Epoch 00036: val_loss did not improve from 1.83810\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59341\n",
      "382/382 [==============================] - 597s 2s/step - loss: 1.0805 - accuracy: 0.7171 - macro_f1score: 0.1266 - weighted_f1score: 0.0024 - val_loss: 1.8400 - val_accuracy: 0.5927 - val_macro_f1score: 0.1049 - val_weighted_f1score: 0.0020\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 37/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 1.0404 - accuracy: 0.7248 - macro_f1score: 0.1292 - weighted_f1score: 0.0024\n",
      "Epoch 00037: val_loss improved from 1.83810 to 1.83644, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/037.h5\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.59341 to 0.60224, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/037.h5\n",
      "382/382 [==============================] - 602s 2s/step - loss: 1.0404 - accuracy: 0.7248 - macro_f1score: 0.1292 - weighted_f1score: 0.0024 - val_loss: 1.8364 - val_accuracy: 0.6022 - val_macro_f1score: 0.1071 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 38/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.9759 - accuracy: 0.7401 - macro_f1score: 0.1332 - weighted_f1score: 0.0025\n",
      "Epoch 00038: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.60224\n",
      "382/382 [==============================] - 592s 2s/step - loss: 0.9759 - accuracy: 0.7401 - macro_f1score: 0.1332 - weighted_f1score: 0.0025 - val_loss: 1.8366 - val_accuracy: 0.5995 - val_macro_f1score: 0.1085 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 39/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.9258 - accuracy: 0.7516 - macro_f1score: 0.1366 - weighted_f1score: 0.0026\n",
      "Epoch 00039: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.60224\n",
      "382/382 [==============================] - 590s 2s/step - loss: 0.9258 - accuracy: 0.7516 - macro_f1score: 0.1366 - weighted_f1score: 0.0026 - val_loss: 1.8526 - val_accuracy: 0.6009 - val_macro_f1score: 0.1118 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 40/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.8937 - accuracy: 0.7560 - macro_f1score: 0.1389 - weighted_f1score: 0.0026\n",
      "Epoch 00040: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00040: val_accuracy improved from 0.60224 to 0.60666, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/040.h5\n",
      "382/382 [==============================] - 591s 2s/step - loss: 0.8937 - accuracy: 0.7560 - macro_f1score: 0.1389 - weighted_f1score: 0.0026 - val_loss: 1.8656 - val_accuracy: 0.6067 - val_macro_f1score: 0.1129 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 41/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.8545 - accuracy: 0.7693 - macro_f1score: 0.1419 - weighted_f1score: 0.0027\n",
      "Epoch 00041: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.60666\n",
      "382/382 [==============================] - 589s 2s/step - loss: 0.8545 - accuracy: 0.7693 - macro_f1score: 0.1419 - weighted_f1score: 0.0027 - val_loss: 1.8521 - val_accuracy: 0.6063 - val_macro_f1score: 0.1115 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 42/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.8061 - accuracy: 0.7783 - macro_f1score: 0.1450 - weighted_f1score: 0.0027\n",
      "Epoch 00042: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.60666 to 0.61005, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/042.h5\n",
      "382/382 [==============================] - 593s 2s/step - loss: 0.8061 - accuracy: 0.7783 - macro_f1score: 0.1450 - weighted_f1score: 0.0027 - val_loss: 1.8761 - val_accuracy: 0.6101 - val_macro_f1score: 0.1109 - val_weighted_f1score: 0.0021\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 43/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7644 - accuracy: 0.7917 - macro_f1score: 0.1485 - weighted_f1score: 0.0028\n",
      "Epoch 00043: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.61005 to 0.61107, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/043.h5\n",
      "382/382 [==============================] - 593s 2s/step - loss: 0.7644 - accuracy: 0.7917 - macro_f1score: 0.1485 - weighted_f1score: 0.0028 - val_loss: 1.8700 - val_accuracy: 0.6111 - val_macro_f1score: 0.1133 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 44/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.7244 - accuracy: 0.8002 - macro_f1score: 0.1510 - weighted_f1score: 0.0028\n",
      "Epoch 00044: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.61107 to 0.61583, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/044.h5\n",
      "382/382 [==============================] - 592s 2s/step - loss: 0.7244 - accuracy: 0.8002 - macro_f1score: 0.1510 - weighted_f1score: 0.0028 - val_loss: 1.8540 - val_accuracy: 0.6158 - val_macro_f1score: 0.1150 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 45/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6715 - accuracy: 0.8140 - macro_f1score: 0.1556 - weighted_f1score: 0.0029\n",
      "Epoch 00045: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.61583\n",
      "382/382 [==============================] - 588s 2s/step - loss: 0.6715 - accuracy: 0.8140 - macro_f1score: 0.1556 - weighted_f1score: 0.0029 - val_loss: 1.8600 - val_accuracy: 0.6124 - val_macro_f1score: 0.1137 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 46/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6524 - accuracy: 0.8201 - macro_f1score: 0.1579 - weighted_f1score: 0.0029\n",
      "Epoch 00046: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.61583 to 0.61651, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/046.h5\n",
      "382/382 [==============================] - 589s 2s/step - loss: 0.6524 - accuracy: 0.8201 - macro_f1score: 0.1579 - weighted_f1score: 0.0029 - val_loss: 1.8554 - val_accuracy: 0.6165 - val_macro_f1score: 0.1140 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 47/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.6312 - accuracy: 0.8213 - macro_f1score: 0.1590 - weighted_f1score: 0.0030\n",
      "Epoch 00047: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.61651\n",
      "382/382 [==============================] - 587s 2s/step - loss: 0.6312 - accuracy: 0.8213 - macro_f1score: 0.1590 - weighted_f1score: 0.0030 - val_loss: 1.8568 - val_accuracy: 0.6158 - val_macro_f1score: 0.1171 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 48/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.5994 - accuracy: 0.8323 - macro_f1score: 0.1609 - weighted_f1score: 0.0030\n",
      "Epoch 00048: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.61651\n",
      "382/382 [==============================] - 593s 2s/step - loss: 0.5994 - accuracy: 0.8323 - macro_f1score: 0.1609 - weighted_f1score: 0.0030 - val_loss: 1.9097 - val_accuracy: 0.6073 - val_macro_f1score: 0.1166 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 49/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.5542 - accuracy: 0.8403 - macro_f1score: 0.1647 - weighted_f1score: 0.0031\n",
      "Epoch 00049: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.61651 to 0.61821, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/049.h5\n",
      "382/382 [==============================] - 594s 2s/step - loss: 0.5542 - accuracy: 0.8403 - macro_f1score: 0.1647 - weighted_f1score: 0.0031 - val_loss: 1.9076 - val_accuracy: 0.6182 - val_macro_f1score: 0.1166 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.001\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 50/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.8413 - macro_f1score: 0.1648 - weighted_f1score: 0.0031\n",
      "Epoch 00050: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.61821\n",
      "382/382 [==============================] - 589s 2s/step - loss: 0.5544 - accuracy: 0.8413 - macro_f1score: 0.1648 - weighted_f1score: 0.0031 - val_loss: 1.9145 - val_accuracy: 0.6162 - val_macro_f1score: 0.1163 - val_weighted_f1score: 0.0022\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 51/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.9228 - macro_f1score: 0.1863 - weighted_f1score: 0.0034\n",
      "Epoch 00051: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00051: val_accuracy improved from 0.61821 to 0.62364, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/051.h5\n",
      "382/382 [==============================] - 592s 2s/step - loss: 0.2927 - accuracy: 0.9228 - macro_f1score: 0.1863 - weighted_f1score: 0.0034 - val_loss: 1.8974 - val_accuracy: 0.6236 - val_macro_f1score: 0.1199 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 52/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.2533 - accuracy: 0.9348 - macro_f1score: 0.1899 - weighted_f1score: 0.0035\n",
      "Epoch 00052: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.62364 to 0.62534, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/052.h5\n",
      "382/382 [==============================] - 595s 2s/step - loss: 0.2533 - accuracy: 0.9348 - macro_f1score: 0.1899 - weighted_f1score: 0.0035 - val_loss: 1.8988 - val_accuracy: 0.6253 - val_macro_f1score: 0.1202 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 53/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.9395 - macro_f1score: 0.1909 - weighted_f1score: 0.0035\n",
      "Epoch 00053: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.62534\n",
      "382/382 [==============================] - 589s 2s/step - loss: 0.2376 - accuracy: 0.9395 - macro_f1score: 0.1909 - weighted_f1score: 0.0035 - val_loss: 1.8993 - val_accuracy: 0.6213 - val_macro_f1score: 0.1209 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 54/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9432 - macro_f1score: 0.1936 - weighted_f1score: 0.0036\n",
      "Epoch 00054: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.62534\n",
      "382/382 [==============================] - 586s 2s/step - loss: 0.2235 - accuracy: 0.9432 - macro_f1score: 0.1936 - weighted_f1score: 0.0036 - val_loss: 1.9166 - val_accuracy: 0.6247 - val_macro_f1score: 0.1218 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 55/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.9453 - macro_f1score: 0.1937 - weighted_f1score: 0.0036\n",
      "Epoch 00055: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.62534\n",
      "382/382 [==============================] - 585s 2s/step - loss: 0.2120 - accuracy: 0.9453 - macro_f1score: 0.1937 - weighted_f1score: 0.0036 - val_loss: 1.9373 - val_accuracy: 0.6230 - val_macro_f1score: 0.1219 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 56/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.9479 - macro_f1score: 0.1950 - weighted_f1score: 0.0036\n",
      "Epoch 00056: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00056: val_accuracy improved from 0.62534 to 0.62738, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Inception_v4/056.h5\n",
      "382/382 [==============================] - 591s 2s/step - loss: 0.2056 - accuracy: 0.9479 - macro_f1score: 0.1950 - weighted_f1score: 0.0036 - val_loss: 1.9325 - val_accuracy: 0.6274 - val_macro_f1score: 0.1204 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 57/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.9528 - macro_f1score: 0.1958 - weighted_f1score: 0.0036\n",
      "Epoch 00057: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 588s 2s/step - loss: 0.1867 - accuracy: 0.9528 - macro_f1score: 0.1958 - weighted_f1score: 0.0036 - val_loss: 1.9433 - val_accuracy: 0.6257 - val_macro_f1score: 0.1202 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 58/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.9550 - macro_f1score: 0.1962 - weighted_f1score: 0.0036\n",
      "Epoch 00058: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 585s 2s/step - loss: 0.1820 - accuracy: 0.9550 - macro_f1score: 0.1962 - weighted_f1score: 0.0036 - val_loss: 1.9506 - val_accuracy: 0.6233 - val_macro_f1score: 0.1198 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 59/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9551 - macro_f1score: 0.1979 - weighted_f1score: 0.0036\n",
      "Epoch 00059: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 584s 2s/step - loss: 0.1779 - accuracy: 0.9551 - macro_f1score: 0.1979 - weighted_f1score: 0.0036 - val_loss: 1.9564 - val_accuracy: 0.6253 - val_macro_f1score: 0.1204 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 60/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9591 - macro_f1score: 0.1978 - weighted_f1score: 0.0036\n",
      "Epoch 00060: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 586s 2s/step - loss: 0.1676 - accuracy: 0.9591 - macro_f1score: 0.1978 - weighted_f1score: 0.0036 - val_loss: 1.9525 - val_accuracy: 0.6230 - val_macro_f1score: 0.1216 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 61/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1625 - accuracy: 0.9591 - macro_f1score: 0.1990 - weighted_f1score: 0.0037\n",
      "Epoch 00061: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 587s 2s/step - loss: 0.1625 - accuracy: 0.9591 - macro_f1score: 0.1990 - weighted_f1score: 0.0037 - val_loss: 1.9609 - val_accuracy: 0.6202 - val_macro_f1score: 0.1209 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 62/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9638 - macro_f1score: 0.1991 - weighted_f1score: 0.0037\n",
      "Epoch 00062: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 585s 2s/step - loss: 0.1527 - accuracy: 0.9638 - macro_f1score: 0.1991 - weighted_f1score: 0.0037 - val_loss: 1.9840 - val_accuracy: 0.6213 - val_macro_f1score: 0.1202 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 63/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9648 - macro_f1score: 0.2002 - weighted_f1score: 0.0037\n",
      "Epoch 00063: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 584s 2s/step - loss: 0.1479 - accuracy: 0.9648 - macro_f1score: 0.2002 - weighted_f1score: 0.0037 - val_loss: 1.9821 - val_accuracy: 0.6216 - val_macro_f1score: 0.1213 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 64/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9654 - macro_f1score: 0.2003 - weighted_f1score: 0.0037\n",
      "Epoch 00064: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 585s 2s/step - loss: 0.1400 - accuracy: 0.9654 - macro_f1score: 0.2003 - weighted_f1score: 0.0037 - val_loss: 2.0105 - val_accuracy: 0.6219 - val_macro_f1score: 0.1184 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 65/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.9683 - macro_f1score: 0.2011 - weighted_f1score: 0.0037\n",
      "Epoch 00065: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 585s 2s/step - loss: 0.1357 - accuracy: 0.9683 - macro_f1score: 0.2011 - weighted_f1score: 0.0037 - val_loss: 2.0074 - val_accuracy: 0.6192 - val_macro_f1score: 0.1191 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 66/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9690 - macro_f1score: 0.2016 - weighted_f1score: 0.0037\n",
      "Epoch 00066: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 586s 2s/step - loss: 0.1303 - accuracy: 0.9690 - macro_f1score: 0.2016 - weighted_f1score: 0.0037 - val_loss: 2.0104 - val_accuracy: 0.6247 - val_macro_f1score: 0.1209 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 67/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9710 - macro_f1score: 0.2024 - weighted_f1score: 0.0037\n",
      "Epoch 00067: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 586s 2s/step - loss: 0.1236 - accuracy: 0.9710 - macro_f1score: 0.2024 - weighted_f1score: 0.0037 - val_loss: 2.0010 - val_accuracy: 0.6192 - val_macro_f1score: 0.1175 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 68/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9708 - macro_f1score: 0.2022 - weighted_f1score: 0.0037\n",
      "Epoch 00068: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 586s 2s/step - loss: 0.1235 - accuracy: 0.9708 - macro_f1score: 0.2022 - weighted_f1score: 0.0037 - val_loss: 2.0161 - val_accuracy: 0.6206 - val_macro_f1score: 0.1200 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 69/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9731 - macro_f1score: 0.2035 - weighted_f1score: 0.0037\n",
      "Epoch 00069: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 585s 2s/step - loss: 0.1169 - accuracy: 0.9731 - macro_f1score: 0.2035 - weighted_f1score: 0.0037 - val_loss: 2.0267 - val_accuracy: 0.6209 - val_macro_f1score: 0.1215 - val_weighted_f1score: 0.0023\n",
      "Learning rate:  0.0001\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 70/70\n",
      "382/382 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9737 - macro_f1score: 0.2031 - weighted_f1score: 0.0037\n",
      "Epoch 00070: val_loss did not improve from 1.83644\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.62738\n",
      "382/382 [==============================] - 585s 2s/step - loss: 0.1100 - accuracy: 0.9737 - macro_f1score: 0.2031 - weighted_f1score: 0.0037 - val_loss: 2.0381 - val_accuracy: 0.6213 - val_macro_f1score: 0.1209 - val_weighted_f1score: 0.0023\n"
     ]
    }
   ],
   "source": [
    "######## flow_from_directory\n",
    "history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs , verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jhTx3Gm8-FhB"
   },
   "source": [
    "### 3) Inception-V4 Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56591046,
     "status": "ok",
     "timestamp": 1599370332684,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "bRiw3ebD-FhC",
    "outputId": "106810f1-3bde-4bd1-e60e-3d1cbe82b253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1392s 29s/step - loss: 2.1003 - accuracy: 0.6003 - macro_f1score: 0.1159 - weighted_f1score: 0.0022\n",
      "[Test Loss: 2.1003 /  Test Accuracy: 0.6003 / Test Macro f1: 0.1159 / Test Weighted f1: 0.0022]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. epoch=maximum\n",
    "loss , acc, mf1, wf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n",
    "print('[Test Loss: %.4f /  Test Accuracy: %.4f / Test Macro f1: %.4f / Test Weighted f1: %.4f]\\n' % (loss,acc,mf1,wf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWPdDUWI-FhG"
   },
   "outputs": [],
   "source": [
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "f1=history.history['macro_f1score']\n",
    "val_f1=history.history['val_macro_f1score']\n",
    "epochs=range(1,len(acc)+1)\n",
    "\n",
    "data = np.array([epochs,loss,val_loss,acc,val_acc,f1,val_f1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yzzh0R9ositH"
   },
   "outputs": [],
   "source": [
    "# data save\n",
    "# epochs, loss, val_loss, acc, val_acc, f1, val_f1\n",
    "\n",
    "np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MpHWlUGsitJ"
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'Inception_v4.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-1nKiCnsitM"
   },
   "outputs": [],
   "source": [
    "epochs=data[:,0]\n",
    "loss=data[:,1]\n",
    "val_loss=data[:,2]\n",
    "acc=data[:,3]\n",
    "val_acc=data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56591574,
     "status": "ok",
     "timestamp": 1599370333303,
     "user": {
      "displayName": "이동규",
      "photoUrl": "",
      "userId": "07323071725004325774"
     },
     "user_tz": -540
    },
    "id": "oLhoPhjqsitO",
    "outputId": "3c22c999-f91b-4c8c-977a-f143d9a0c7a4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZzN9f7A8dfbWEZjsqtsoZBkn7RQKHUpkZKaUrQpv26lUrfUjRbdblfddLtpoUUJpQiJrEMhWyrEzTIYu5F1MNvn98f7zDjGObNwZs4y7+fj8X0453y/53vec2a8z+d8vp/P+yPOOYwxxoS/EsEOwBhjTGBYQjfGmAhhCd0YYyKEJXRjjIkQltCNMSZCWEI3xpgIYQk9QonIdyLSO9DHBpOIJIpIx0I471wRuc9z+w4R+T4/x57C69QWkUMiEnWqsRqTG0voIcTznz1ryxSRI1737yjIuZxznZ1znwT62FAkIk+LyDwfj1cRkVQRuSi/53LOjXbOXRuguE74AHLObXbOlXPOZQTi/D5eT0Rkg4isLozzm9BnCT2EeP6zl3POlQM2Azd4PTY66zgRKRm8KEPSZ8DlIlI3x+O3Ab8551YGIaZguBKoBtQTkYuL8oXtbzI0WEIPAyLSXkSSRORvIrID+EhEKorIFBHZLSJ/em7X9HqOdzdCHxH5QUSGeo7dKCKdT/HYuiIyT0QOishMEfmviHzmJ+78xPiSiPzoOd/3IlLFa/+dIrJJRJJF5Fl/749zLgmYDdyZY9ddwKi84sgRcx8R+cHr/jUiskZE9ovI24B47TtPRGZ74tsjIqNFpIJn36dAbWCy5xvWUyJSR0RcVvITkeoiMklE9orIOhG53+vcg0XkCxEZ5XlvVolInL/3wKM38A0w1XPb++dqLCIzPK+1U0QGeh6PEpGBIrLe8zrLRKRWzlg9x+b8O/lRRP4tIsnA4NzeD89zaonI157fQ7KIvC0ipT0xNfE6rpqIpIhI1Tx+XpODJfTwcTZQCTgX6Iv+7j7y3K8NHAHezuX5lwBrgSrAa8BIEZFTOPZzYDFQGRjMyUnUW35ivB24G21ZlgYGAIjIhcBwz/mre17PZxL2+MQ7FhFpCDT3xFvQ9yrrHFWAr4Hn0PdiPdDG+xDgH574GgG10PcE59ydnPgt6zUfLzEWSPI8vwfwiohc5bW/q+eYCsCk3GIWkTM85xjt2W4TkdKefbHATGCa57XOB2Z5nvo4EA9cB5wJ3AOk5PrGHHcJsAE4CxiS2/shet1gCrAJqAPUAMY651I9P2Mvr/PGA7Occ7vzGYfJ4pyzLQQ3IBHo6LndHkgFonM5vjnwp9f9ucB9ntt9gHVe+84AHHB2QY5Fk2E6cIbX/s+Az/L5M/mK8Tmv+/8HTPPcfh79D5+1L8bzHnT0c+4zgAPA5Z77Q4BvTvG9+sFz+y5gkddxgibg+/yc90bgZ1+/Q8/9Op73siSa7DKAWK/9/wA+9tweDMz02nchcCSX97YXsNtz7mhgP9Ddsy/eO64cz1sLdPPxeHasubxPm/P4fWe/H8BlWfH5OO4S9MNPPPeXAj2D+f8vXDdroYeP3c65o1l3ROQMEXnP0yVxAJgHVBD/Iyh2ZN1wzmW1wMoV8NjqwF6vxwC2+As4nzHu8Lqd4hVTde9zO+cOA8n+XssT05fAXZ5vE3cAowoQhy85Y3De90XkLBEZKyJbPef9DG3J50fWe3nQ67FNaMs1S873Jlr891X3Br5wzqV7/k6+4ni3Sy3024Uvue3Lywm/+zzej1rAJudces6TOOd+Qn++9iJyAfoNYtIpxlSsWUIPHznLYj4BNAQucc6diV4QA68+3kKwHajk+XqfpVYux59OjNu9z+15zcp5POcToCdwDRALTD7NOHLGIJz4876C/l6aeM7bK8c5cytlug19L2O9HqsNbM0jppN4rgdcBfQSkR2i11l6ANd5uo22APX8PH0LcJ6Pxw97/vX+XZ+d45icP19u78cWoHYuH0ifeI6/Exjv3Xgx+WcJPXzFon3B+0SkEjCosF/QObcJ/To82HMx6zLghkKKcTzQRUTaevqCXyTvv9f5wD7gfY73z55OHN8CjUXkJk8ieoQTk1oscAjYLyI1gCdzPH8nfhKpc24LsAD4h4hEi0hT4F60VVtQdwL/Qz+0mnu2Bmj3UDzad32OiPQXkTIiEisil3ieOwJ4SUTqi2oqIpWd9l9vRT8kokTkHnwnfm+5vR+L0Q/IV0UkxvMze1+P+Azojib1UafwHhgsoYezN4GywB5gEXrBqyjcgfaHJgMvA+OAY36OPeUYnXOrgIfQi5rbgT/RBJXbcxyaDM7lxKRwSnE45/YAtwCvoj9vfeBHr0NeAFqi/dXfohdQvf0DeE5E9onIAB8vEY/2VW8DJgCDnHMz8xNbDr2Bd5xzO7w34F2gt6db5xr0w3cH8AfQwfPcN4AvgO/RaxAj0fcK4H40KScDjdEPoNz4fT+cjr2/Ae1O2Yz+Lm/12r8FWI628OcX/C0wcPwihDGnRETGAWucc4X+DcFENhH5ENjmnHsu2LGEK0vopkBEJ6zsBTYC1wITgcuccz8HNTAT1kSkDrACaOGc2xjcaMKXdbmYgjobHb52CHgL6GfJ3JwOEXkJWAn8y5L56bEWujHGRAhroRtjTIQIWkGdKlWquDp16gTr5Y0xJiwtW7Zsj3POZ52bPBO658pzF2CXc+6kMqSeyRbD0FoQKUAf59zyvM5bp04dli5dmtdhxhhjvIjIJn/78tPl8jHQKZf9ndHxufXRolHDCxKcMcaYwMgzoTvn5qHD1PzpBoxyahFaI+OcQAVojDEmfwJxUbQGJxbpSeLEAkPZRKSviCwVkaW7d1tlTGOMCaQivSjqnHsfrbNBXFzcSeMl09LSSEpK4uhRq8sTyqKjo6lZsyalSpUKdijGGC+BSOhbObECXU1OoWIcQFJSErGxsdSpUwf/ay+YYHLOkZycTFJSEnXr5lzxzRgTTIHocpmEpwa1iFwK7HfObT+VEx09epTKlStbMg9hIkLlypXtW5QxISg/wxbHoCvmVBGRJLT0aCkA59y76PqF1wHr0GGLd59OQJbMQ5/9jowJTXkmdOdcfB77HVrm1Bhjij3nYM8e2LxZt9274dixE7cbboCLLw78awdtpmgoSk5O5uqrrwZgx44dREVFUbWqTshavHgxpUuX9vvcpUuXMmrUKN56661cX+Pyyy9nwYK8ykrnX//+/fnyyy/ZsmULJUpYJQdjTtf+/fDHH7BlC6SkwJEjuqWkaHLetg22b9d/9+2DEiV0i4oCEdi1C/Lqkaxe3RJ6oatcuTIrVqwAYPDgwZQrV44BA46vS5Cenk7Jkr7fsri4OOLi4vJ8jUAm88zMTCZMmECtWrVISEigQ4cOeT/JmGIkJQWWLdPke/Dg8e3QoZNbzVu2wP/+pwnZn+hoTcbnnAPNmkHFitoiz8yEjAz9t1o1qF1bt1q14Kyz9HmlS0OZMlCqlCb+wmAJPQ99+vQhOjqan3/+mTZt2nDbbbfx6KOPcvToUcqWLctHH31Ew4YNmTt3LkOHDmXKlCkMHjyYzZs3s2HDBjZv3kz//v155JFHAChXrhyHDh1i7ty5DB48mCpVqrBy5UpatWrFZ599hogwdepUHn/8cWJiYmjTpg0bNmxgypQpJ8U2d+5cGjduzK233sqYMWOyE/rOnTt58MEH2bBhAwDDhw/n8ssvZ9SoUQwdOhQRoWnTpnz66adF90YaE2CpqbB6Nez1THvMKhy7bx8sXAg//ADLl0Na2snPLVNGk2yZMse3GjWga1do0EC32rUhJgbKltUtOlrvh/IlpJBN6P37g6exHDDNm8Obbxb8eUlJSSxYsICoqCgOHDjA/PnzKVmyJDNnzmTgwIF89dVXJz1nzZo1zJkzh4MHD9KwYUP69et30rjtn3/+mVWrVlG9enXatGnDjz/+SFxcHA888ADz5s2jbt26xMf7v4QxZswY4uPj6datGwMHDiQtLY1SpUrxyCOP0K5dOyZMmEBGRgaHDh1i1apVvPzyyyxYsIAqVaqwd29uk3+NCQ7ntFsjKUm3gwf1sazt0CH45Rdtdf/2myZ1X8qU0S6NJ56ANm2gXj2IjdWtXDnw80U77EXojxVYt9xyC1FRUQDs37+f3r1788cffyAipPn6+Aeuv/56ypQpQ5kyZahWrRo7d+6kZs2aJxzTunXr7MeaN29OYmIi5cqVo169etljvOPj43n//fdPOn9qaipTp07ljTfeIDY2lksuuYTp06fTpUsXZs+ezahRuqRmVFQU5cuXZ9SoUdxyyy1UqVIFgEqVKgXmzTHmFDmnXRwJCTBvHvz0k15E9Jeks1SoAC1bwqOPQqtW2v2RRURb002aaFIvbkI2oZ9KS7qwxMTEZN/++9//TocOHZgwYQKJiYm0b9/e53PKeP01RUVFkZ6efkrH+DN9+nT27dtHkyZNAEhJSaFs2bJ06dIl3+cwprA5p10iSUmwcePxbcMGWLoUdu7U4846C9q2hZtugpo1j2/ly2uSztqyukZCudsjmEI2oYeq/fv3U6OGlqr5+OOPA37+hg0bsmHDBhITE6lTpw7jxo3zedyYMWMYMWJEdpfM4cOHqVu3LikpKVx99dUMHz6c/v37Z3e5XHXVVXTv3p3HH3+cypUrs3fvXmulm4DZvx9+/VW7SVesgHXrYOtW3XKO+IiNhbp1oWNHaNcOrrxS+6wtSZ8+S+gF9NRTT9G7d29efvllrr/++oCfv2zZsrzzzjt06tSJmJgYLvYxtiklJYVp06bx7rvvZj8WExND27ZtmTx5MsOGDaNv376MHDmSqKgohg8fzmWXXcazzz5Lu3btiIqKokWLFoXygWQiX2Ym/P67XnT84QdYsEBb3FmqVIELLtA+7Btv1BZ1jRqaxOvVg0qVLHkXlqCtKRoXF+dyLnDx+++/06hRo6DEE0oOHTpEuXLlcM7x0EMPUb9+fR577LFgh3UC+10VP8nJMGgQjBlzfGRJVldJq1Y66KBZM+3TtoRdeERkmXPO5xhpa6GHoA8++IBPPvmE1NRUWrRowQMPPBDskEwxlpEBI0bAwIHatRIfD1dfDVdcoS1uS96hwxJ6CHrsscdCrkVuiqdFi+Chh3Q8d7t28J//6AgSE5osoRtjfNq8WS9YVq2q3Sy33mqt8VBnCd0Y49PMmTrL8vvvoXHjYEdj8sOqORljfEpI0Nb5hRcGOxKTX5bQjTE+JSRol4t1s4QPS+heOnTowPTp00947M0336Rfv35+n9O+fXuyhl9ed9117Nu376RjBg8ezNChQ3N97YkTJ7J69ers+88//zwzZ84sSPi56t+/PzVq1CAzMzNg5zSRa9Mm3dq1C3YkpiAsoXuJj49n7NixJzw2duzYXAtkeZs6dSoVKlQ4pdfOmdBffPFFOnbseErnyilnmV1j8pL1Z2IJPbxYQvfSo0cPvv32W1I91YESExPZtm0bV1xxBf369SMuLo7GjRszaNAgn8+vU6cOe/bsAWDIkCE0aNCAtm3bsnbt2uxjPvjgAy6++GKaNWvGzTffTEpKCgsWLGDSpEk8+eSTNG/enPXr19OnTx/Gjx8PwKxZs2jRogVNmjThnnvu4dixY9mvN2jQIFq2bEmTJk1Ys2aNz7iyyuz269ePMWPGZD++c+dOunfvTrNmzWjWrFl2rfZRo0bRtGlTmjVrxp133nma76oJR/Pm6YzOiy4KdiSmIEJ3lEsQ6udWqlSJ1q1b891339GtWzfGjh1Lz549ERGGDBlCpUqVyMjI4Oqrr+bXX3+ladOmPs+zbNkyxo4dy4oVK0hPT6dly5a0atUKgJtuuon7778fgOeee46RI0fy8MMP07VrV7p06UKPHj1OONfRo0fp06cPs2bNokGDBtx1113ZdVoAqlSpwvLly3nnnXcYOnQoI0aMOCkeK7NrCiohQScO2SJY4cV+XTl4d7t4d7d88cUXtGzZkhYtWrBq1aoTukdymj9/Pt27d+eMM87gzDPPpGvXrtn7Vq5cyRVXXEGTJk0YPXo0q1atyjWetWvXUrduXRo0aABA7969mTdvXvb+m266CYBWrVqRmJh40vOzyuzeeOONnHnmmdlldgFmz56dfX0gq8zu7NmzrcxuMbdtmxbXuvLKYEdiCip0W+hBqp/brVs3HnvsMZYvX05KSgqtWrVi48aNDB06lCVLllCxYkX69OnD0bwWDfSjT58+TJw4kWbNmvHxxx8zd+7c04o3qwSvv/K7VmbXFJT1n4cva6HnUK5cOTp06MA999yT3To/cOAAMTExlC9fnp07d/Ldd9/leo4rr7ySiRMncuTIEQ4ePMjkyZOz9x08eJBzzjmHtLQ0Ro8enf14bGwsBw8ePOlcDRs2JDExkXXr1gHw6aef0q4A/9OyyuwmJiaSmJjIxo0bmTFjxglldgEyMjLYv38/V111FV9++SXJyckA1uVSDCUkwJlnag+lCS+W0H2Ij4/nl19+yU7ozZo1o0WLFlxwwQXcfvvttGnTJtfnt2zZkltvvZVmzZrRuXPnE0rgvvTSS1xyySW0adOGCy64IPvx2267jX/961+0aNGC9evXZz8eHR3NRx99xC233EKTJk0oUaIEDz74YL5+jqwyu95lfnOW2Z0zZw5NmjShVatWrF69msaNG2eX2W3WrBmPP/54vl7LRI6EBK2g6Fmky4QRK59rTon9riLTzp1w9tnwz3/CU08FOxrjS27lc62FbozJlnW93frPw5MldGNMtoQEiInRRZhN+Am5hB6sLiCTf/Y7ilwJCXD55VCqVLAjMacipBJ6dHQ0ycnJljBCmHOO5ORkoqOjgx2KCbDkZFi50rpbwllIjUOvWbMmSUlJ7N69O9ihmFxER0dTs2bNYIdhAmz+fP3XEnr4CqmEXqpUKerWrRvsMIyJaOnpMGUKjB4NO3bAoUO67doF0dHgNcrWhJmQSujGmMKzebMu9jxypE7vP+ccaNQIatfWC6Hlymn9Fs/kYxOGLKEbE+E2boRnn4Vx48A56NwZhg+H666DkpYBIor9Oo2JUMnJMGQIvP22Ju4BA6BfP6hTJ9iRmcJiCd2YMHf4MKxaBfv2Hd8SE+Gdd+DgQbjnHhg8GGrUCHakprBZQjcmDG3bphc2J02CmTPBs+bJCa6/XqfwN25c9PGZ4LCEbkwYWb1au02ypujXrav3O3SAKlWgfHmoUEG3mJjgxmqKXr4Suoh0AoYBUcAI59yrOfbXBj4BKniOedo5NzXAsRpTbGVmwrBh8MwzEBurfePdusGFF4JIsKMzoSLPhC4iUcB/gWuAJGCJiExyznkv2fMc8IVzbriIXAhMBeoUQrzGFDubN0OfPjBnDnTpAh98oBURjckpP1P/WwPrnHMbnHOpwFigW45jHHCm53Z5YFvgQjSmeNq1S1viTZrAkiU6hnzSJEvmxr/8dLnUALZ43U8CLslxzGDgexF5GIgBOvo6kYj0BfoC1K5du6CxGlMsLF6sQw3HjYPUVOjUSUes2CRqk5dAFeeKBz52ztUErgM+FZGTzu2ce985F+eci6tatWqAXtqYyLB6tc7UvOQSmDAB+vaF33+H776zZG7yJz8t9K1ALa/7NT2PebsX6ATgnFsoItFAFWBXIII0JpKlp8Prr8OgQTr9/q23oHdvXdfTmILITwt9CVBfROqKSGngNmBSjmM2A1cDiEgjIBqwkonG5GHNGl2/8+mnddz4qlXw8MOWzM2pyTOhO+fSgb8C04Hf0dEsq0TkRRHp6jnsCeB+EfkFGAP0cVbU3Bi/EhPhscegeXP44w8YMwbGj4ezzgp2ZCac5WscumdM+dQcjz3vdXs10CawoRkTeRYv1u6V8eOhRAmIj4fXXrORKyYwbKaoMUVg3Tp48EGYNUu7U554QrtWatXK+7nG5JcldGMKUUYG/Oc/MHAglC6trfP779fZnsYEmiV0YwrJ2rVa6XDBAr3g+d57VvHQFC5L6MYEyIED2ke+aBEsXAizZ0PZsjBqFPTqZTVXTOGzhG7MaVq8GJ58UhdZdk4T94UXwt13w9//rku9GVMULKEbc4q2bdPqh6NG6SiVQYPg8suhdWstY2tMUbOEbkwBpabC0KHwyiuQlqaTggYOtAudJvgsoRtTAJs2Qc+e2s3Svbsm9nr1gh2VMcoSujH59O23cOedOhRx/Hi4+eZgR2TMiQJVbdGYiJWerl0qXbpA7dqwbJklcxOarIVujB/792uNlXffhV9+gfvu00qIZcsGOzJjfLOEbowX53T44YgR2q1y5IiuGPT551p3xZhQZgndGI8DB6BfP03eZ54Jd90F994LcXE2KciEB0voxgDLl8Ott8KGDfDCCzBgAJxxRrCjMqZgLKGbYs05LZ715JNQtSrMnavLwBkTjmyUiym2Nm7UkSuPPgrXXqsXPi2Zm3BmCd0UO0ePwosvar2VefNg2DCYNAkqVw52ZMacHutyMcXKtGm6sMS6dTrj8403rKStiRzWQjfFws8/w1/+Ap0769JvM2bAuHGWzE1ksYRuItq6dTp+vGVLWLpUa6/8+it07BjsyIwJPOtyMRHp55/h7be1tG3p0vDsszqSxcramkhmCd1EjGPH4KuvNJEvXKjjyPv2heees0UmTPFgCd1EhCVLoFs32L4dzj8f/v1v6NMHKlQIdmTGFB1L6CbsLV4M11yjww6nTdPbJezqkCmGLKGbsPbTTzopqEoVmDNHy9saU1xZO8aErUWLtDWeNWXfkrkp7iyhm7A0b562zKtV02Req1awIzIm+Cyhm7CSmqpDEDt0gLPP1mRes2awozImNFhCN2Hj11+hdWt45RXo3VtHtlgyN+Y4S+gm5G3dCi+/rAtNbN8O33wDH35ok4SMyclGuZiQk56uy8BNmwbffQe//aaP33wzDB+uF0GNMSezhG5CyqFDWqM8IQFKlYK2beGf/4ROnaBp02BHZwLmwAH9ZVetqr9oExCW0E3IOHgQrrsOFiyAd96BXr0gNjbYURVjqan6ybplC+zapdvu3Vocp1Ur7QNr2hSio3Xpp6QkWLUKVq6Ew4d1CFK1apq0Y2JgxQqtybBwIfz+uz4HoGLF48fWqgXnnqtjUM89V4/Ztu349uefWsch65jataFuXZ1VVlgLv6ana2W3hAQtz9mxo16RD0Hist7UIhYXF+eWLl0alNc2oefAAU3mixbpIs09ewY7omIgJUVbx94tZOe0stnHH8OYMbBnz/F9MTGanA8dOv54yZJQv75e6DhwIO/XrFgRLr0ULrtMZ4Pt3n38g2LHDv3w2LJFk2hOVatqLYft2zUGb2eeCfXqwXnnQfXqcOSIthAOHtRjjx7Vc6al6b85b6enazznnXd8K1kSZs3Sbf/+E1+vaVOdBNGihf7cf/55fDt2LPfXSkvTSnHdu+fr15STiCxzzsX52mctdBN0Bw5ol8rixTB2LPToEeyIQoBzsGaNXkzYvBkaNoTGjaFRIyhbVhPDmjXacly6FDZt0pZydLTuP+MMHajfqdPJdRB274YhQ/RrUHq6Jsrq1XXbvFlb2KVLa3GcO++EJk2Ot7KzYtuyRYcZLV0Kq1frONKLLtIYGzfWBLtnz/GEfeCA7q9fP++WdEaGJvdNm/TYGjW0RVy69PHX37dP92/apGsJrl+vK3yvXAkzZ+rPHxt7fKtUSRN0qVL6b1TU8Q+zkiX1Pdq5U8+RkHD8A6N2bbjlFk3eHTro+zNjBnz/vS5Gm5p6PO6yZfUDp2xZPaf3lvU6pUrp+1hI3UzWQjdBtWMH3HgjLFumC07cdFOwIyoizkFiIvzxh7b+slqT+/fD8uXwww+QnKzHihzvnhDR7oZdu7SFDVCunLYo09K0ZXrkiCbQlBR9/KGH4O67NYm8+aZelDh8WKuX1a6treusLo0zzoA77oBbb9UkWBw5px9Ghw/re+3vA+jwYf1AqVhRt+joIgkvtxZ6vhK6iHQChgFRwAjn3Ks+jukJDAYc8Itz7vbczmkJ3cyZo4tPHDig3Sw33hjsiAIkJUVnPC1Zoskgq2UWFaUJYMUKXZE659f4LOedp1eDr7hCt7p1daWOrP7pNWvgrLPg4ou1H7tBg5Nb4ampMGGCtiJ//FETdbly+kHQrRv84x/a2jdh57QSuohEAf8DrgGSgCVAvHNutdcx9YEvgKucc3+KSDXn3K7czmsJvfjKzNR88vzzmou+/FK/jYekY8f0q8POnZpos/ppY2P1Bzl4EPbu1W3hQpg6VT+pjh71fb6YGO1/bd5ct0aN9Gu6d/dAVtdCoGSt9rFzJzzzDLRpE9jzmyJ1un3orYF1zrkNnpONBboBq72OuR/4r3PuT4C8krkpvnbvhrvu0jHm8fHw/vvacAw5hw7BBx/omnXbtp28PzZWv3JnZp74eIMG8MADeoX3yis1OWddCEtL077loq7t26IFjBxZtK9pgiI/Cb0GsMXrfhJwSY5jGgCIyI9ot8xg59y0nCcSkb5AX4DaVhqvWMnM1IETTz6puXL4cM17hTXSLE8ZGdrtMXeutlzLltUtOlq7Jd59V1vd7dtr4BdfrBfMNmzQC3Dbtmlyzuo/rVhRv2acf/7Jr1W6dOBb3cb4EKhRLiWB+kB7oCYwT0SaOOf2eR/knHsfeB+0yyVAr21C3MqV0K+fXudr21aTecC7WH79VWsCXHopXHWV9lfntGULTJyow9DmzdMhZgBlymjXircbbtDuicsuO/5Yy5a6GROi8pPQtwLexUlreh7zlgT85JxLAzaKyP/QBL8kIFGasJSaCoMGaa9F+fL6rb9PnwD2OKSlaRL/z380QWepWVOH2/XurV0j48drP/iCBbq/Xj0dTtOhg27Vq+tXiGPHdISIiLa4jQk3zrlcNzTpbwDqAqWBX4DGOY7pBHziuV0F7aKpnNt5W7Vq5Uzk2rDBuYsvdg6cu/tu53bvDuDJU1Ode/NN52rU0BeoU8e5115zbutW58aNc+6665wrUUL3iei/TZs6N2SIc3/8EcBAjCl6wFLnJ6/m2UJ3zqWLyF+B6Wj/+IfOuVUi8qLnxJM8+64VkdVABvCkcy45oL/lmtAAABW1SURBVJ88JmxMnKjDnp2Dr74K8NjyOXPg4Yd1CF/79jo55vrrj3ex9Oyp2/btOtPxyBGt6nXBBQEMwpjQZBOLTMCkpsLf/qZzV+Li4IsvdAh1QCQlwYAB2nVSp46+SNeuQbyqakxw2NR/U+jWr4fbbtOZ4I8+qpMRy5TJxxOzaofs2qWt6aNH9d/kZD1p1rZ5s07OGTwYnnpKR6QYY05gCd2ctrFjoW9f7fX4+ut81hw6fBhGj9YJL1kFz3OqXFkn8Vx6qZZevPvuADb5jYk8ltDNKTt8WFvjI0fC5Zfr9P1zz83jSZs3w7BhuuTQvn3QrJnOLrroouPjwLOKHNmSRMYUiCV0c0o2bdJrkatXw8CB8MILWrLEr6QkXQx0xAjtZrn5ZvjrX3UauvWDGxMQltBNgf32m1ZlPXwYpk/XyqKAzr7cuFEHmmcVpEpJgbfegvfe07He996rnwC1auX6GsaYgrOEbgokIUGL9ZUrp6W6mzTx7Fi/Xsuu/vTTyU+KitL+72ef1REqxphCYQnd5NtXX2nOrldPi2vVro12n3zyiY4NL1lShxNWrHh8hZbMTF1o4bzzgh2+MRHPErrJk3Pw73/rMPDLLoPJkz1rH/z5Jzz4oA44b9cOPv3UulKMCaIiruNpws3Ro1p/5YkndDjizJmeZL5okY5Q+fprLW4+a5Ylc2OCzBK68WvrVi3pPWoUvPiiLkRRNtrpsMMrrtAulgUL4OmnfVc3NMYUKetyMT4tXKg1WA4d0pXMbrwRXTLt3nu1M71bN/joI6tKaEwIsRa6OcnXX2tV2TPOgEUJx7ix5lJd8CEuTitv/etfmuUtmRsTUqyFbnSm5rBhULo02w7FUmZdLN9WiqFd7AZKXvqrjlgBnQY6Z452txhjQo4l9OIsNVXn7r/7Lq51a9b+eRbb1x2kQfmdnFf5ICWq1ILHH9eWeVycJnSb1WlMyLKEXlzt2gU9esD8+WQ+9TQP7nmZDz6M4p57dFJnCfvLMCbs2H/b4mjZMr3iuWsXe9/+nO5fxDNvHjz3nI5msUa4MeHJLooWF5mZMHUqdO6s3SeZmcx/9QcaDIpn2TKd7PnSS5bMjQlnltAj3dGjOs2zQQMtj/jLL6Q//wLP3/AzV/ZvRY0a2mC/665gB2qMOV3W5RLJkpN1vPiPP2qZ2iFDOHxtdzp1Lc0PP8D//R+8/rqWIDfGhD9L6JFq40btXklM1Fort9xCWhr06KqTO0ePhttvD3aQxphAsoQeiZYu1e6VtDSYMQOuuILMTLjnHq2S+MEHlsyNiUTWhx5ppk6F9u11Gbcff8yeBPTUU/DZZ/Dyy3DffcEN0RhTOCyhRwrnYOhQuOEGvQC6cCE0agTow6+/riu+DRwY5DiNMYXGEnokOHJEh6k8+aSOL58/H845B9C1mJ98Enr21Nn9NizRmMhlCT3cJSVpjdvPPtOB5F98ATExgK43cd998Je/aAncEvbbNiai2UXRcJWRAWPH6soThw9rFcRu3bJ3jxunC1N06KCFEcuUCV6oxpiiYW22cJOZqdn6oougVy84+2xdPcgrmX/9ta792aYNTJqk10eNMZHPEno4+f57Xfbtttu0/+TLL2H5cmjcOPuQyZPh1luhdWv49tvs3hdjTDFgCT1cfPihThRKTYUxY+DXX7VaolfH+Bdf6DXRFi3gu+8gNjaI8Rpjipz1oYeD11+HAQP06uZXX/lsdo8cCX37wuWXw5QpUL58EOI0xgSVtdBDmXPw7LOazG+5RTvEfSTzN97Q0SzXXgvTp1syN6a4soQeqjIzdSbQK69oth4zBkqXPuEQ52DQIB3o0qMHfPONrgNqjCmeLKGHoowMuPdeeOcdnRX0/vsQFXXCIc7p6nAvvqg1WsaOPSnfG2OKGUvooSYjQweQf/yxNr//+c+TpndmZGh/+ZtvQv/+MGLESfneGFMM2UXRUJKerlP4x4zRKlrPPnvSIWlpesjYsfD3v8MLL9h0fmOMylcLXUQ6ichaEVknIk/nctzNIuJEJC5wIRYTaWla03bMGHj1VZ/J/OhR7SsfO1Yb7rb+pzHGW54tdBGJAv4LXAMkAUtEZJJzbnWO42KBR4GfCiPQiJaSosn8m290iOLjj590iHM6YWjSJPjvf3W1IWOM8ZafFnprYJ1zboNzLhUYC3TzcdxLwD+BowGML/Lt3Kn1yydP1kztI5mDXhedNEmXB7VkbozxJT8JvQawxet+kuexbCLSEqjlnPs2txOJSF8RWSoiS3fv3l3gYCPO6tVw6aWwapVW0PKTqdev16GJHTvCI48UcYzGmLBx2qNcRKQE8AbwRF7HOufed87FOefiqlaterovHd5mz9ZpnUeOQEICdO3q87CMDLj7bh3F8uGHVgLXGONfftLDVqCW1/2anseyxAIXAXNFJBG4FJhkF0ZzMX8+dOoENWvCTz9BnP+36s039fC33oJatfweZowx+Rq2uASoLyJ10UR+G5C9xLBzbj9QJeu+iMwFBjjnlgY21AiRnKwXQM89F374ASpU8HvoqlU62KVbNx2qaIwxuckzoTvn0kXkr8B0IAr40Dm3SkReBJY65yYVdpARwzmdxr9zp675mUsyT0uD3r21YuJ779nwRGNM3vI1scg5NxWYmuOx5/0c2/70w4pQ776rKwu9/jq0auX3sLQ0iI+HZctg/Hg466wijNEYE7ZspmhR+e03eOwx7Tvv39/vYampOt584kStonjzzUUYozEmrFlCLwopKbrKUIUK8MknfoeqHDumVXInT9aLoA8/XMRxGmPCmiX0wnbkiHaGr16tS8hVq+bzsKNHtTU+darNBDXGnBpL6IVp0ybo3h1WrIChQ+Gaa3weduiQLh03Y4ZeAO3bt4jjNMZEBEvohWX2bOjZUysoTp4M11/v87C9e3XX4sU6cejuu4s4TmNMxLB5h4HmnF7NvOYaHZ6yZInfZL5tG7RrB8uX62gWS+bGmNNhCT3QPv9cC6907w6LFkH9+j4PW78e2raFxETtN+/evWjDNMZEHutyCaSdO7V61qWXwrhxfpcRSkzUZJ6Wpj0zF19ctGEaYyKTJfRAevhhvcL54Yd+k3lGBvTqpSMZFy6ECy8s4hiNMRHLEnqgfPUVfPklvPIKNGrk97BXX4Uff4RPP7VkbowJLHHOBeWF4+Li3NKlEVK/KzkZGjeGGjW037xUKZ+HLVmiFXNvvllXmrP6LMaYghKRZc45nyVarYUeCI89pkl9+nS/yfzwYbjjDjjnHBg+3JK5MSbwLKGfrilTtP/k73+HZs38Hvb447BuHcyaBRUrFmF8xphiw4Ytno6EBK3R0rSpFi73Y9IkXRN0wADo0KEI4zPGFCuW0E/V7NnQuTPUrg3TpkGZMj4P27gR+vSB5s3hpZeKNkRjTPFiCf1UzJihsz/POw/mzNGOcR+OHoUePSAzU2eC+sn5xhgTENaHXlDTpsGNN0LDhjBzJuSy2PVf/6rT+idP1txvjDGFyVroBbFmjSbzRo20yyWXZD5iBIwcqV3rXboUYYzGmGLLEnpBDBig/SbTpkHlyn4PW7ZMW+fXXAMvvFCE8RljijXrcsmv77+Hb7+F117LdZHPvXt14lC1alqny08FAGOMCThL6PmRnq4DyevV0+JbfjgH996rZXF/+AGqVCnCGI0xxZ4l9PwYMQJWrcpzqMrbbx9f3Ll16yKMzxhjsFouedu/X2uaN2oEc+f6nbO/fDlcdhlce61OJLKp/caYwpBbLRe7KJqXIUNgzx7497/9ZumDB+HWW3XQy0cfWTI3xgSHdbnkZsMGGDYMeveGli19HuIc9Ounh86ZY/3mxpjgsRa6P2lpcN99Wj1xyBC/h338MYweDYMGwZVXFl14xhiTk7XQ/RkwQJvco0ZB9eo+D1m9Wsebd+iQa20uY4wpEtZC9+Wjj+Ctt7TO+Z13+jwkJQV69oSYGG2h23hzY0ywWQs9p59+ggcfhKuv1klEfjz6qLbQp03zW5vLGGOKlLXQvW3fDjfdpEvJjRsHJX1/3n3+uQ5Nf+YZHaZojDGhwFroWdLTtdbtvn2wcKHfWi1//AEPPABt2lidFmNMaLGEnmX4cFiwQDvEmzb1eciRIzrevHRpXeTZTwPeGGOCwlIS6MSh55/XfvP4eJ+HOAd9+8LPP2t981q1ijhGY4zJg/Whgy7wfPCgTiLyM83z9dfhs890GTmrb26MCUWW0FesgPfeg4cegsaNfR4ybRr87W/axW7jzY0xoap4J3TntBxu5coweLDPQ/73P7jtNrjoIp0VanVajDGhKl8JXUQ6ichaEVknIk/72P+4iKwWkV9FZJaInBv4UAvBuHEwf75O7a9Y8aTd+/dDt246+/+bb3QSkTHGhKo8E7qIRAH/BToDFwLxInJhjsN+BuKcc02B8YD/GTmh4vBhePJJaNFCV6XIISMDbr8d1q3TMuh16hR9iMYYUxD5aaG3BtY55zY451KBsUA37wOcc3Occymeu4uAmoENM8BSUjSJJyXBf/7jc97+U0/B1Km6u127IMRojDEFlJ+EXgPY4nU/yfOYP/cC3/naISJ9RWSpiCzdvXt3/qMMpPXr4fLL4Ysv4JVXdIZQDiNG6KpDDz+sVQCMMSYcBHQcuoj0AuIAn21a59z7wPugKxYF8rXzZcoU6NULSpTQBZ87dz7pkLlztb75tddqUjfGmHCRnxb6VsB7Gk1Nz2MnEJGOwLNAV+fcscCEF0Avvgg33KALPS9b5jOZr18PN98M55+faykXY4wJSflJ6EuA+iJSV0RKA7cBk7wPEJEWwHtoMt8V+DBP09y5ugJFr17w449Qt+5Jh+zZc3zC0OTJUKFC0YZojDGnK882qHMuXUT+CkwHooAPnXOrRORFYKlzbhLwL6Ac8KXoQO3NzrmuhRh3/jkHAwdqBcX334eyZU86JDlZZ/0nJuokovPPL/owjTHmdOWrU8E5NxWYmuOx571udwxwXIEzZYpWT/STzPfuhY4dYe1amDTJRrQYY8JXZPcSZ2bqXP369aFPn5N2//knXHONLlTxzTdW29wYE94iO6GPGQO//ab/lip1wq59+zSBr1wJEyZAp05BitEYYwIkchN6aqqWxG3eXBf/zLHrxhvhl1/g66/huuuCFKMxxgRQ5Cb0kSNhwwYdb17i+GAe53SyUEKClsO1UrjGmEgRmdUWU1K0cHnbtieNN3/tNfjoI22833FHkOIzxphCEHkt9IwM6N9fF3weN+6Eerdffw1PP63lcP1UyzXGmLAVWQk9JUWb3RMnanWtK67I3rVsmc4ruvRS+PBDq2tujIk8kZPQ9+zRqf0//aRLyT3ySPau1at1V9Wqmut9DEc3xpiwFxkJff167SvfskWLl990U/auRYt0FEuZMloO96yzghinMcYUovBP6Dt26MXP1FSYNUtL43pMm6bFts45B2bM8FnCxRhjIkZ4j3LJzIS77tK14ubMOSGZjxmj3SwNGvitx2WMMRElvBP6669r0/vNN6FpUwDS0nQEyx136NoVc+daN4sxpngI3y6XJUu0iuLNN8P99wOwYgXcfbf+26sXfPABREcHOU5jjCki4dlCP3BAB5NXrw4ffEBqmjB4MFx8sQ4/nzABPv3UkrkxpngJvxa6c7pG3KZNkJDAtiMVuaEjLF+u3SzDhkHlysEO0hhjil74JfRRo+Dzz+Gll1hTuQ1/uUxrmn/9NXTvHuzgjDEmeMIvoZ9/PvTqxcL2z9Clja77mZAALVsGOzBjjAmu8Evobdow5c829LxWV5WbNg3OOy/YQRljTPCF3UXRUaO0lvmFF+r4ckvmxhijwi6hn3eeThiaOxeqVQt2NMYYEzrCrsulTRvdjDHGnCjsWujGGGN8s4RujDERwhK6McZECEvoxhgTISyhG2NMhLCEbowxEcISujHGRAhL6MYYEyHEORecFxbZDWzysasKsKeIwzldFnPRCLeYwy1esJiLyunEfK5zrqqvHUFL6P6IyFLnXFyw4ygIi7lohFvM4RYvWMxFpbBiti4XY4yJEJbQjTEmQoRiQn8/2AGcAou5aIRbzOEWL1jMRaVQYg65PnRjjDGnJhRb6MYYY06BJXRjjIkQIZXQRaSTiKwVkXUi8nSw4/FFRD4UkV0istLrsUoiMkNE/vD8WzGYMXoTkVoiMkdEVovIKhF51PN4KMccLSKLReQXT8wveB6vKyI/ef4+xolI6WDHmpOIRInIzyIyxXM/pGMWkUQR+U1EVojIUs9jofy3UUFExovIGhH5XUQuC/F4G3re26ztgIj0L6yYQyahi0gU8F+gM3AhEC8iFwY3Kp8+BjrleOxpYJZzrj4wy3M/VKQDTzjnLgQuBR7yvK+hHPMx4CrnXDOgOdBJRC4F/gn82zl3PvAncG8QY/TnUeB3r/vhEHMH51xzr3HRofy3MQyY5py7AGiGvtchG69zbq3nvW0OtAJSgAkUVszOuZDYgMuA6V73nwGeCXZcfmKtA6z0ur8WOMdz+xxgbbBjzCX2b4BrwiVm4AxgOXAJOrOupK+/l1DYgJqe/5xXAVMACYOYE4EqOR4Lyb8NoDywEc9gjlCP10f81wI/FmbMIdNCB2oAW7zuJ3keCwdnOee2e27vAM4KZjD+iEgdoAXwEyEes6frYgWwC5gBrAf2OefSPYeE4t/Hm8BTQKbnfmVCP2YHfC8iy0Skr+exUP3bqAvsBj7ydGuNEJEYQjfenG4DxnhuF0rMoZTQI4LTj9yQGwsqIuWAr4D+zrkD3vtCMWbnXIbTr6k1gdbABUEOKVci0gXY5ZxbFuxYCqitc64l2tX5kIhc6b0zxP42SgItgeHOuRbAYXJ0VYRYvNk81066Al/m3BfImEMpoW8Fanndr+l5LBzsFJFzADz/7gpyPCcQkVJoMh/tnPva83BIx5zFObcPmIN2V1QQkZKeXaH299EG6CoiicBYtNtlGKEdM865rZ5/d6F9u60J3b+NJCDJOfeT5/54NMGHarzeOgPLnXM7PfcLJeZQSuhLgPqeUQGl0a8nk4IcU35NAnp7bvdG+6lDgogIMBL43Tn3hteuUI65qohU8Nwui/b5/44m9h6ew0IqZufcM865ms65Oujf7mzn3B2EcMwiEiMisVm30T7elYTo34ZzbgewRUQaeh66GlhNiMabQzzHu1ugsGIO9oWCHBcNrgP+h/aXPhvsePzEOAbYDqShLYZ70b7SWcAfwEygUrDj9Iq3Lfp17ldghWe7LsRjbgr87Il5JfC85/F6wGJgHfrVtUywY/UTf3tgSqjH7IntF8+2Kuv/XIj/bTQHlnr+NiYCFUM5Xk/MMUAyUN7rsUKJ2ab+G2NMhAilLhdjjDGnwRK6McZECEvoxhgTISyhG2NMhLCEbowxEcISujHGRAhL6MYYEyH+H3VAE76wMapiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs[1:],acc[1:],'b',label='Training Acc')\n",
    "plt.plot(epochs[1:],val_acc[1:],'r',label='Validation Acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n",
    "plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nX-JWFT-6kX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0z6BwcAulnw"
   },
   "outputs": [],
   "source": [
    "# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(os.path.join(dir,'model_output',number,'Inception_v4','022.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"weighted_f1score\":weighted_f1score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWlrnY9EuDG-"
   },
   "outputs": [],
   "source": [
    "# 2. epoch=?\n",
    "loss , acc, mf1, wf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n",
    "print('[Test Loss: %.4f /  Test Accuracy: %.4f / Test Macro f1: %.4f / Test Weighted f1: %.4f]\\n' % (loss,acc,mf1,wf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3IawOJT1ydDw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "7.Inception V4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
