{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"12.Xception.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"E-OCKgEwJfTn","colab":{},"executionInfo":{"status":"ok","timestamp":1600128425602,"user_tz":-540,"elapsed":1175,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 참고 : https://sike6054.github.io/blog/paper/fifth-post/"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vwVmRuFcUBkT"},"source":["# [Xception]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"N0MMz6DhUBkW"},"source":["*KU LeeDongGyu*"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ywk25Fr79dWe"},"source":["## Contents\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KSON5xiR9dWf"},"source":["1. Data Preprocessing\n","```\n","1) Data Import\n","2) Data Augmentation\n","```\n","2. Support Functions & Almost Original Xception\n","```\n","1) Support Functions\n","2) Almost Original Xception\n","3) Xception Evaluate\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"U01q4o40UBkY"},"source":["### Install Packages\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XjdygsS_UBke"},"source":["### Module"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"o1tpIlBhXG2i","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600128482039,"user_tz":-540,"elapsed":57564,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"1c029206-e05d-4a78-fc32-054b30d2ec31"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IJdbC2nRXR6h","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600128482040,"user_tz":-540,"elapsed":57542,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"de303079-103d-465a-bbaa-1e9ff80193bc"},"source":["cd /content/drive/My Drive/Colab Notebooks/Paper"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Paper\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"I98omoQ8FF90","colab":{},"executionInfo":{"status":"ok","timestamp":1600128484831,"user_tz":-540,"elapsed":60325,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["from f1score import macro_f1score,weighted_f1score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HKLMWqbuUBkf","colab":{},"executionInfo":{"status":"ok","timestamp":1600128485531,"user_tz":-540,"elapsed":61014,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","from tensorflow.keras import backend as K \n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Concatenate, ZeroPadding2D ,GlobalMaxPooling2D, Reshape , Lambda , Add, Multiply\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, AveragePooling2D , ZeroPadding2D, SeparableConv2D\n","from tensorflow.keras.layers import add\n","from tensorflow.keras.optimizers import Adam, RMSprop , SGD\n","from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler, ModelCheckpoint, CSVLogger, Callback, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l1,l2,l1_l2\n","from tensorflow.keras.models import Model , load_model , Sequential\n","from tensorflow.keras.utils import plot_model , to_categorical, get_file\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cbiFovMgXTax","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600128485533,"user_tz":-540,"elapsed":60993,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"dc0823ff-658e-434f-82d9-feae8765be2c"},"source":["os.getcwd()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/Colab Notebooks/Paper'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AcT0A_iwEzaZ","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1600128485538,"user_tz":-540,"elapsed":60976,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"490c0ddf-7628-4529-b641-84d72c97cce2"},"source":["print(tf.__version__)\n","print(ks.__version__)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2.3.0\n","2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Gr5hMHvmABmG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600128491103,"user_tz":-540,"elapsed":66521,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"5a8b99f9-60be-4547-935b-5e00c90c4822"},"source":["tf.test.gpu_device_name()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Kf057Rw2yigs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":560},"executionInfo":{"status":"ok","timestamp":1600128491105,"user_tz":-540,"elapsed":66501,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"97f343fd-900b-40ad-9b9d-128f978a0586"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 3049649215914751049\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 3580490506980823853\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 8523663058671214039\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15473775744\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 15803976895724421525\n","physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sTXnS6_magkg"},"source":["## 1. Data Preprocessing\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FWigHOuzCRRj"},"source":["### 1) Data Import"]},{"cell_type":"code","metadata":{"id":"BeJ7UtuOEgWY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600128491106,"user_tz":-540,"elapsed":66496,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 바꿔서 살펴 볼 것들\n","# CALTECH, CIFAR100, FER, MIT\n","data_name = 'CALTECH'\n","gan_type = 'No_GAN'\n","number = '1'\n","size = 299 # sizes after cropping\n","super_size = 330 # sizes before cropping \n","input_sizes = (size,size,3)\n","batch_sizes = 32\n","weight_decay = 1e-6\n","epochs = 50"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPnWxfGzLOF6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600128491107,"user_tz":-540,"elapsed":66491,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 참고 : https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras/52897216#52897216\n","# setting the seed number for random number generation for reproducibility.\n","\n","from numpy.random import seed\n","import random\n","\n","\n","if number=='1':\n","    seed_num = 200225\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='2':\n","    seed_num = 727\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='3':\n","    seed_num = 115\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='4':\n","    seed_num = 501\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","elif number=='5':\n","    seed_num = 517\n","    os.environ['PYTHONHASHSEED']=str(seed_num)\n","    random.seed(seed_num)\n","    seed(seed_num)\n","    tf.random.set_seed(seed_num)\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"A4wDCqXKpNBz","colab":{},"executionInfo":{"status":"ok","timestamp":1600128491107,"user_tz":-540,"elapsed":66487,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# data import\n","\n","if data_name=='FER' :\n","    x_train =  np.zeros(28698)\n","    x_valid = np.zeros(3589)\n","    x_test = np.zeros(3588)\n","    classes = 7 \n","    tr_center = [0.50793296, 0.50793296, 0.50793296]\n","elif data_name=='MIT':\n","    x_train = np.zeros(12466)\n","    x_valid = np.zeros(1564)\n","    x_test = np.zeros(1590)\n","    classes = 67 \n","    tr_center = [0.47916578, 0.42029615, 0.36046057]\n","elif data_name=='CALTECH':\n","    x_train = np.zeros(24510)\n","    x_valid = np.zeros(2980)\n","    x_test = np.zeros(3118)\n","    classes = 257\n","    tr_center = [0.51397761, 0.49525248, 0.46555727]\n","elif data_name=='CIFAR100':\n","    x_train = np.zeros(39941)\n","    x_valid = np.zeros(10059)\n","    x_test = np.zeros(10000)\n","    classes = 100\n","    tr_center = [0.53393271, 0.51324147, 0.46450563]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQlStjHWt-jM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600128491108,"user_tz":-540,"elapsed":66484,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["dir = os.path.join(os.getcwd(),data_name,gan_type)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ayj6GUEvpNB4"},"source":["### 2) Data Augmentation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UVHXXOYqpNB4","colab":{},"executionInfo":{"status":"ok","timestamp":1600128491109,"user_tz":-540,"elapsed":66478,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 참고 : https://jkjung-avt.github.io/keras-image-cropping/\n","\n","def random_crop(img, random_crop_size):\n","    # Note: image_data_format is 'channel_last'\n","    assert img.shape[2] == 3 # img.shape[2] 가 3(rgb)이 아니면 assertion error 발생\n","    height, width = img.shape[0], img.shape[1]\n","    dy, dx = random_crop_size\n","    x = np.random.randint(0, width - dx + 1)\n","    y = np.random.randint(0, height - dy + 1)\n","    return img[y:(y+dy), x:(x+dx), :]\n","\n","\n","def crop_generator(batches, crop_length):\n","    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n","    crops from the image batches generated by the original iterator.\n","    \"\"\"\n","    while True:\n","        batch_x, batch_y = next(batches)\n","        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n","        for i in range(batch_x.shape[0]):\n","            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n","        yield (batch_crops, batch_y)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW0KZ6x9EBtf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600128491110,"user_tz":-540,"elapsed":66472,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["from tensorflow.keras.preprocessing.image import img_to_array,load_img\n","import glob\n","\n","# 데이터 전체에 대해 centering 진행함.\n","\n","def read_cal_image(img_path): \n","    x = img_to_array(load_img(img_path)) # x는 채널별 평균값\n","    y = x.shape[0] * x.shape[1]# y는 데이터별 픽셀 수 (비중)\n","\n","    x = 1/255. * x # scaling하고, centering값을 뽑아냄.\n","    x = np.mean(x, axis=(0,1))\n","    \n","    return np.hstack([x,y])\n","\n","def calculate_centered_mean(dataset_path,x_train=x_train):\n","    num = len(x_train)\n","    space = np.empty((num,4))\n","    i=0\n","\n","    for p in glob.glob(os.path.join(dataset_path,'*/*.*')) :\n","        space[i] = read_cal_image(p)\n","        i += 1\n","\n","    ratio = space[:,3] / np.sum(space[:,3])\n","\n","    return np.average(space[:,0:3],axis=0,weights=ratio)\n","\n","\n","# 아래의 함수를 돌려서 나온 결과값을 중심화 값으로 설정.\n","\n","# train_mean = calculate_centered_mean(os.path.join(dir,'data/train')).reshape((1,1,3))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m_6Z9x0vpNB8","colab":{},"executionInfo":{"status":"ok","timestamp":1600128491112,"user_tz":-540,"elapsed":66464,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["datagen_tr = ImageDataGenerator(\n","    rescale=1/255.,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=False,\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=[0.9,1.0],\n","    fill_mode = 'nearest')\n","datagen_val = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","datagen_tes = ImageDataGenerator(rescale=1/255.,featurewise_center=True)\n","\n","# 원래는 이 자리에 fit 매서드를 써야하지만, 그냥 내가 중심화함수를 만들고 적용함. \n","\n","# 중심화 설정\n","datagen_tr.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_val.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB\n","datagen_tes.mean = np.array(tr_center, dtype=np.float32).reshape((1,1,3)) # RGB"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qeao4HympNB9","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1600128556407,"user_tz":-540,"elapsed":131742,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"79d7daf0-8a08-44e3-e7f5-03af4f06ac78"},"source":["train_batches = datagen_tr.flow_from_directory(directory=os.path.join(dir,'data/train'),target_size=(super_size,super_size),batch_size=batch_sizes,class_mode='categorical') # fer : 28698 / mit : 12466 / caltech : 24509 / cifar : 39941\n","train_generator= crop_generator(train_batches, size)\n","valid_generator = datagen_val.flow_from_directory(directory=os.path.join(dir,'data/valid'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3589 / mit : 1564 / caltech : 2980 / cifar : 10059\n","test_generator = datagen_tes.flow_from_directory(directory=os.path.join(dir,'data/test'),target_size=(size,size),batch_size=batch_sizes,class_mode='categorical') # fer : 3588 / mit : 1590 / caltech : 3118 / cifar : 10000"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Found 24509 images belonging to 257 classes.\n","Found 2980 images belonging to 257 classes.\n","Found 3118 images belonging to 257 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"afa9Vvwdw1te"},"source":["## 2. Support Functions & Almost Original Xception\n","---"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iER-OGdBw1tf"},"source":["### 1) Support Functions"]},{"cell_type":"code","metadata":{"id":"XA3sqFv_ZyBS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600128556409,"user_tz":-540,"elapsed":131738,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# def lr_schedule(epoch):\n","#     init_lr = 1e-4\n","#     k = 0.04\n","#     lr = init_lr * np.exp(-k*epoch)\n","#     print('Learning rate: ', lr)\n","#     return lr\n","\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch < 30:\n","        lr = lr\n","    elif epoch < 45:\n","        lr = lr * 0.1\n","    else:\n","        lr = lr * 0.01\n","    print('Learning rate: ', lr)\n","    return lr"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"ggihuV9kvI7D","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600128556412,"user_tz":-540,"elapsed":131735,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["def conv2d_bn(x, filters, kernel_size, padding='same', strides=1, activation='relu', weight_decay=weight_decay):\n","    x = Conv2D(filters, kernel_size, padding=padding, strides=strides, kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n","    x = BatchNormalization()(x)\n","    \n","    if activation:\n","        x = Activation(activation)(x)\n","    \n","    return x"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMVUfgjlDhAw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600128556412,"user_tz":-540,"elapsed":131729,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["def sepconv2d_bn(x, filters, kernel_size, padding='same', strides=1, activation='relu', weight_decay=weight_decay, depth_multiplier=1):\n","    x = SeparableConv2D(filters, kernel_size, padding=padding, strides=strides, depth_multiplier=depth_multiplier, \n","                        depthwise_initializer='he_uniform', pointwise_initializer='he_uniform',\n","                        depthwise_regularizer=l2(weight_decay), pointwise_regularizer=l2(weight_decay))(x)\n","    x = BatchNormalization()(x)\n","    \n","    if activation:\n","        x = Activation(activation)(x)\n","    \n","    return x"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vJixgnY7Z6j7"},"source":["### 2) Almost Original Xception\n"]},{"cell_type":"code","metadata":{"id":"u-VY9odzDmtK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600128556413,"user_tz":-540,"elapsed":131726,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["def Xception(model_input, classes, name = \"Xception\"):\n","    ## Entry flow\n","    x = conv2d_bn(model_input, 32, (3, 3), strides=2) # (299, 299, 3) -> (150, 150, 32)\n","    x = conv2d_bn(x, 64, (3, 3))\n","\n","    for fliters in [128, 256, 728]: # (75, 75, 64) -> (75, 75, 128) -> (38, 38, 256) -> (19, 19, 728)\n","        residual = conv2d_bn(x, fliters, (1, 1), strides=2, activation=None)\n","        \n","        x = Activation(activation='relu')(x)\n","        x = sepconv2d_bn(x, fliters, (3, 3))\n","        x = sepconv2d_bn(x, fliters, (3, 3), activation=None)\n","        x = MaxPooling2D((3, 3), padding='same', strides=2)(x)\n","        \n","        x = Add()([x, residual])\n","        \n","        \n","    ## Middle flow\n","    for i in range(8): # (19, 19, 728)\n","        residual = x\n","        \n","        x = Activation(activation='relu')(x)\n","        x = sepconv2d_bn(x, 728, (3, 3))\n","        x = sepconv2d_bn(x, 728, (3, 3))\n","        x = sepconv2d_bn(x, 728, (3, 3), activation=None)\n","        \n","        x = Add()([x, residual])\n","        \n","        \n","    ## Exit flow\n","    residual = conv2d_bn(x, 1024, (1, 1), strides=2, activation=None) # (19, 19, 728) -> (10, 10, 1024)\n","        \n","    x = Activation(activation='relu')(x)\n","    x = sepconv2d_bn(x, 728, (3, 3))\n","    x = sepconv2d_bn(x, 1024, (3, 3), activation=None) # (19, 19, 728) -> (19, 19, 1024)\n","    x = MaxPooling2D((3, 3), padding='same', strides=2)(x) # (19, 19, 1024) -> (10, 10, 1024)\n","    \n","    x = Add()([x, residual])\n","    \n","    x = sepconv2d_bn(x, 1536, (3, 3))\n","    x = sepconv2d_bn(x, 2048, (3, 3))\n","\n","    x = GlobalAveragePooling2D()(x)\n","    \n","    ## Optinal fully-connected layers\n","    '''\n","    x = Dense(4096)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(activation='relu')(x)\n","    \n","    x = Dense(4096)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(activation='relu')(x)\n","    '''\n","    \n","    x = Dropout(0.5)(x)\n","    \n","    model_output = Dense(classes, activation='softmax')(x)\n","\n","    model = Model(model_input, model_output, name=name)\n","    \n","    return model"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5YOrZ2rhneyq","colab":{},"executionInfo":{"status":"ok","timestamp":1600128557838,"user_tz":-540,"elapsed":133146,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["model_input = Input(shape=input_sizes)\n","model = Xception(model_input, classes=classes, name='Xception')"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0HuelUizNJWz","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600128557839,"user_tz":-540,"elapsed":133132,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"d933b39c-2a2a-43ec-a131-4e046f6f71cc"},"source":["model.summary()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Model: \"Xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 150, 150, 32) 896         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 150, 150, 32) 128         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 150, 150, 32) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 150, 150, 64) 18496       activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 150, 150, 64) 256         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 150, 150, 64) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 150, 150, 64) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","separable_conv2d (SeparableConv (None, 150, 150, 128 8896        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 150, 150, 128 512         separable_conv2d[0][0]           \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 150, 150, 128 0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","separable_conv2d_1 (SeparableCo (None, 150, 150, 128 17664       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 150, 150, 128 512         separable_conv2d_1[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 75, 75, 128)  8320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 75, 75, 128)  0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 75, 75, 128)  512         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 75, 75, 128)  0           max_pooling2d[0][0]              \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 75, 75, 128)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","separable_conv2d_2 (SeparableCo (None, 75, 75, 256)  34176       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 75, 75, 256)  1024        separable_conv2d_2[0][0]         \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 75, 75, 256)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","separable_conv2d_3 (SeparableCo (None, 75, 75, 256)  68096       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 75, 75, 256)  1024        separable_conv2d_3[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 38, 38, 256)  33024       add[0][0]                        \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 38, 38, 256)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 38, 38, 256)  1024        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 38, 38, 256)  0           max_pooling2d_1[0][0]            \n","                                                                 batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 38, 38, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","separable_conv2d_4 (SeparableCo (None, 38, 38, 728)  189400      activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 38, 38, 728)  2912        separable_conv2d_4[0][0]         \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 38, 38, 728)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","separable_conv2d_5 (SeparableCo (None, 38, 38, 728)  537264      activation_7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 38, 38, 728)  2912        separable_conv2d_5[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 19, 19, 728)  187096      add_1[0][0]                      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 19, 19, 728)  0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 19, 19, 728)  2912        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 19, 19, 728)  0           max_pooling2d_2[0][0]            \n","                                                                 batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 19, 19, 728)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","separable_conv2d_6 (SeparableCo (None, 19, 19, 728)  537264      activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_6[0][0]         \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 19, 19, 728)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_7 (SeparableCo (None, 19, 19, 728)  537264      activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_7[0][0]         \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 19, 19, 728)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_8 (SeparableCo (None, 19, 19, 728)  537264      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_8[0][0]         \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 19, 19, 728)  0           batch_normalization_13[0][0]     \n","                                                                 add_2[0][0]                      \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 19, 19, 728)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","separable_conv2d_9 (SeparableCo (None, 19, 19, 728)  537264      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_9[0][0]         \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 19, 19, 728)  0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_10 (SeparableC (None, 19, 19, 728)  537264      activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_10[0][0]        \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 19, 19, 728)  0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_11 (SeparableC (None, 19, 19, 728)  537264      activation_13[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_11[0][0]        \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 19, 19, 728)  0           batch_normalization_16[0][0]     \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 19, 19, 728)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","separable_conv2d_12 (SeparableC (None, 19, 19, 728)  537264      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_12[0][0]        \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 19, 19, 728)  0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_13 (SeparableC (None, 19, 19, 728)  537264      activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_13[0][0]        \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 19, 19, 728)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_14 (SeparableC (None, 19, 19, 728)  537264      activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_14[0][0]        \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 19, 19, 728)  0           batch_normalization_19[0][0]     \n","                                                                 add_4[0][0]                      \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 19, 19, 728)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","separable_conv2d_15 (SeparableC (None, 19, 19, 728)  537264      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_15[0][0]        \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 19, 19, 728)  0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_16 (SeparableC (None, 19, 19, 728)  537264      activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_16[0][0]        \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 19, 19, 728)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_17 (SeparableC (None, 19, 19, 728)  537264      activation_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_17[0][0]        \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 19, 19, 728)  0           batch_normalization_22[0][0]     \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 19, 19, 728)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","separable_conv2d_18 (SeparableC (None, 19, 19, 728)  537264      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_18[0][0]        \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 19, 19, 728)  0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_19 (SeparableC (None, 19, 19, 728)  537264      activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_19[0][0]        \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 19, 19, 728)  0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_20 (SeparableC (None, 19, 19, 728)  537264      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_20[0][0]        \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 19, 19, 728)  0           batch_normalization_25[0][0]     \n","                                                                 add_6[0][0]                      \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 19, 19, 728)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","separable_conv2d_21 (SeparableC (None, 19, 19, 728)  537264      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_21[0][0]        \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 19, 19, 728)  0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_22 (SeparableC (None, 19, 19, 728)  537264      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_22[0][0]        \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 19, 19, 728)  0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_23 (SeparableC (None, 19, 19, 728)  537264      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_23[0][0]        \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 19, 19, 728)  0           batch_normalization_28[0][0]     \n","                                                                 add_7[0][0]                      \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 19, 19, 728)  0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","separable_conv2d_24 (SeparableC (None, 19, 19, 728)  537264      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_24[0][0]        \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 19, 19, 728)  0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_25 (SeparableC (None, 19, 19, 728)  537264      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_25[0][0]        \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 19, 19, 728)  0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_26 (SeparableC (None, 19, 19, 728)  537264      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_26[0][0]        \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 19, 19, 728)  0           batch_normalization_31[0][0]     \n","                                                                 add_8[0][0]                      \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 19, 19, 728)  0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","separable_conv2d_27 (SeparableC (None, 19, 19, 728)  537264      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_27[0][0]        \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 19, 19, 728)  0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_28 (SeparableC (None, 19, 19, 728)  537264      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_28[0][0]        \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 19, 19, 728)  0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_29 (SeparableC (None, 19, 19, 728)  537264      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_29[0][0]        \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 19, 19, 728)  0           batch_normalization_34[0][0]     \n","                                                                 add_9[0][0]                      \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 19, 19, 728)  0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","separable_conv2d_30 (SeparableC (None, 19, 19, 728)  537264      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_30[0][0]        \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 19, 19, 728)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_31 (SeparableC (None, 19, 19, 1024) 753048      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 19, 19, 1024) 4096        separable_conv2d_31[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 10, 10, 1024) 746496      add_10[0][0]                     \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 10, 10, 1024) 0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 10, 10, 1024) 4096        conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 10, 10, 1024) 0           max_pooling2d_3[0][0]            \n","                                                                 batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_32 (SeparableC (None, 10, 10, 1536) 1583616     add_11[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 10, 10, 1536) 6144        separable_conv2d_32[0][0]        \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 10, 10, 1536) 0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","separable_conv2d_33 (SeparableC (None, 10, 10, 2048) 3161600     activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 10, 10, 2048) 8192        separable_conv2d_33[0][0]        \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 10, 10, 2048) 0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 2048)         0           activation_35[0][0]              \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 257)          526593      dropout[0][0]                    \n","==================================================================================================\n","Total params: 21,415,337\n","Trainable params: 21,360,809\n","Non-trainable params: 54,528\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yNCT3g8eE6vT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600128558435,"user_tz":-540,"elapsed":133720,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 폴더 생성\n","\n","os.makedirs(os.path.join(dir,'model_output',number,model.name), exist_ok=True)\n","os.makedirs(os.path.join(dir,'train_valid_output',number), exist_ok=True)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0hcwfHt4efG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600128559629,"user_tz":-540,"elapsed":134909,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# AdamW 시작 / AdamWR은 epoch을 500번은 돌려야 될 것 같아 힘듦.\n","# 참고 : https://github.com/OverLordGoldDragon/keras-adamw\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Paper')\n","import utils\n","import optimizers_v2\n","from utils import get_weight_decays, fill_dict_in_order\n","from utils import reset_seeds, K_eval\n","from optimizers_v2 import AdamW, NadamW, SGDW"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QoWLeggG6dBf","colab":{},"executionInfo":{"status":"ok","timestamp":1600128559630,"user_tz":-540,"elapsed":134903,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["optimizer = AdamW(model=model, use_cosine_annealing=False, total_iterations = len(x_train) // batch_sizes , eta_min = 1e-2)\n","#optimizer = Adam()\n","filepath =  os.path.join(dir,'model_output',number,model.name,'{epoch:03d}.h5')\n","\n","callbacks_list = [ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min'),\n","                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_weights_only=False, save_best_only=True, mode='max'),\n","                  #ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,min_lr=1e-5),\n","                  LearningRateScheduler(lr_schedule,verbose=1)\n","                  ]\n","                  \n","model.compile(optimizer, loss = 'categorical_crossentropy', metrics=['accuracy',macro_f1score,weighted_f1score])"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H9pnv0cw6dBm","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600174988928,"user_tz":-540,"elapsed":46564181,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"d17a3788-21cf-44c2-cdb1-4e44f1451067"},"source":["######## flow_from_directory\n","history = model.fit(train_generator, steps_per_epoch=int(len(x_train)/batch_sizes),  validation_data = valid_generator, epochs=epochs, verbose=1 , callbacks = callbacks_list , validation_steps=int(len(x_valid)/batch_sizes))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Learning rate:  0.001\n","\n","Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 1/50\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for conv2d/kernel:0\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for conv2d_1/kernel:0\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for conv2d_2/kernel:0\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for conv2d_3/kernel:0\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for conv2d_4/kernel:0\n","0.0(L1), 3.615507621182657e-08(L2) weight decay set for conv2d_5/kernel:0\n","765/765 [==============================] - ETA: 0s - loss: 5.1754 - accuracy: 0.0745 - macro_f1score: 5.7095e-04 - weighted_f1score: 2.3732e-05 \n","Epoch 00001: val_loss improved from inf to 7.97049, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/001.h5\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.06620, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/001.h5\n","765/765 [==============================] - 13304s 17s/step - loss: 5.1754 - accuracy: 0.0745 - macro_f1score: 5.7095e-04 - weighted_f1score: 2.3732e-05 - val_loss: 7.9705 - val_accuracy: 0.0662 - val_macro_f1score: 0.0013 - val_weighted_f1score: 5.6961e-05\n","Learning rate:  0.001\n","\n","Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 2/50\n","765/765 [==============================] - ETA: 0s - loss: 4.5609 - accuracy: 0.1256 - macro_f1score: 0.0036 - weighted_f1score: 1.5677e-04\n","Epoch 00002: val_loss improved from 7.97049 to 4.78923, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/002.h5\n","\n","Epoch 00002: val_accuracy improved from 0.06620 to 0.10719, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/002.h5\n","765/765 [==============================] - 657s 859ms/step - loss: 4.5609 - accuracy: 0.1256 - macro_f1score: 0.0036 - weighted_f1score: 1.5677e-04 - val_loss: 4.7892 - val_accuracy: 0.1072 - val_macro_f1score: 0.0027 - val_weighted_f1score: 1.1910e-04\n","Learning rate:  0.001\n","\n","Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 3/50\n","765/765 [==============================] - ETA: 0s - loss: 4.0882 - accuracy: 0.1798 - macro_f1score: 0.0065 - weighted_f1score: 2.7259e-04\n","Epoch 00003: val_loss improved from 4.78923 to 4.49678, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/003.h5\n","\n","Epoch 00003: val_accuracy improved from 0.10719 to 0.16297, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/003.h5\n","765/765 [==============================] - 664s 869ms/step - loss: 4.0882 - accuracy: 0.1798 - macro_f1score: 0.0065 - weighted_f1score: 2.7259e-04 - val_loss: 4.4968 - val_accuracy: 0.1630 - val_macro_f1score: 0.0068 - val_weighted_f1score: 2.8538e-04\n","Learning rate:  0.001\n","\n","Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 4/50\n","765/765 [==============================] - ETA: 0s - loss: 3.6223 - accuracy: 0.2441 - macro_f1score: 0.0103 - weighted_f1score: 4.0754e-04\n","Epoch 00004: val_loss improved from 4.49678 to 3.99582, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/004.h5\n","\n","Epoch 00004: val_accuracy improved from 0.16297 to 0.23824, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/004.h5\n","765/765 [==============================] - 656s 857ms/step - loss: 3.6223 - accuracy: 0.2441 - macro_f1score: 0.0103 - weighted_f1score: 4.0754e-04 - val_loss: 3.9958 - val_accuracy: 0.2382 - val_macro_f1score: 0.0107 - val_weighted_f1score: 4.0817e-04\n","Learning rate:  0.001\n","\n","Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 5/50\n","765/765 [==============================] - ETA: 0s - loss: 3.1831 - accuracy: 0.3125 - macro_f1score: 0.0159 - weighted_f1score: 6.0073e-04\n","Epoch 00005: val_loss improved from 3.99582 to 3.38916, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/005.h5\n","\n","Epoch 00005: val_accuracy improved from 0.23824 to 0.31284, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/005.h5\n","765/765 [==============================] - 650s 850ms/step - loss: 3.1831 - accuracy: 0.3125 - macro_f1score: 0.0159 - weighted_f1score: 6.0073e-04 - val_loss: 3.3892 - val_accuracy: 0.3128 - val_macro_f1score: 0.0201 - val_weighted_f1score: 7.6461e-04\n","Learning rate:  0.001\n","\n","Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 6/50\n","765/765 [==============================] - ETA: 0s - loss: 2.8142 - accuracy: 0.3771 - macro_f1score: 0.0225 - weighted_f1score: 8.3093e-04\n","Epoch 00006: val_loss improved from 3.38916 to 2.97784, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/006.h5\n","\n","Epoch 00006: val_accuracy improved from 0.31284 to 0.37567, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/006.h5\n","765/765 [==============================] - 650s 850ms/step - loss: 2.8142 - accuracy: 0.3771 - macro_f1score: 0.0225 - weighted_f1score: 8.3093e-04 - val_loss: 2.9778 - val_accuracy: 0.3757 - val_macro_f1score: 0.0283 - val_weighted_f1score: 0.0010\n","Learning rate:  0.001\n","\n","Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 7/50\n","765/765 [==============================] - ETA: 0s - loss: 2.5345 - accuracy: 0.4331 - macro_f1score: 0.0287 - weighted_f1score: 0.0010\n","Epoch 00007: val_loss improved from 2.97784 to 2.87177, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/007.h5\n","\n","Epoch 00007: val_accuracy improved from 0.37567 to 0.39449, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/007.h5\n","765/765 [==============================] - 662s 865ms/step - loss: 2.5345 - accuracy: 0.4331 - macro_f1score: 0.0287 - weighted_f1score: 0.0010 - val_loss: 2.8718 - val_accuracy: 0.3945 - val_macro_f1score: 0.0301 - val_weighted_f1score: 0.0011\n","Learning rate:  0.001\n","\n","Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 8/50\n","765/765 [==============================] - ETA: 0s - loss: 2.2853 - accuracy: 0.4853 - macro_f1score: 0.0349 - weighted_f1score: 0.0013\n","Epoch 00008: val_loss improved from 2.87177 to 2.67501, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/008.h5\n","\n","Epoch 00008: val_accuracy improved from 0.39449 to 0.43011, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/008.h5\n","765/765 [==============================] - 662s 865ms/step - loss: 2.2853 - accuracy: 0.4853 - macro_f1score: 0.0349 - weighted_f1score: 0.0013 - val_loss: 2.6750 - val_accuracy: 0.4301 - val_macro_f1score: 0.0327 - val_weighted_f1score: 0.0012\n","Learning rate:  0.001\n","\n","Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 9/50\n","765/765 [==============================] - ETA: 0s - loss: 2.0837 - accuracy: 0.5217 - macro_f1score: 0.0411 - weighted_f1score: 0.0014\n","Epoch 00009: val_loss did not improve from 2.67501\n","\n","Epoch 00009: val_accuracy improved from 0.43011 to 0.43683, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/009.h5\n","765/765 [==============================] - 651s 851ms/step - loss: 2.0837 - accuracy: 0.5217 - macro_f1score: 0.0411 - weighted_f1score: 0.0014 - val_loss: 2.7148 - val_accuracy: 0.4368 - val_macro_f1score: 0.0368 - val_weighted_f1score: 0.0013\n","Learning rate:  0.001\n","\n","Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 10/50\n","765/765 [==============================] - ETA: 0s - loss: 1.9077 - accuracy: 0.5580 - macro_f1score: 0.0463 - weighted_f1score: 0.0016\n","Epoch 00010: val_loss did not improve from 2.67501\n","\n","Epoch 00010: val_accuracy did not improve from 0.43683\n","765/765 [==============================] - 649s 848ms/step - loss: 1.9077 - accuracy: 0.5580 - macro_f1score: 0.0463 - weighted_f1score: 0.0016 - val_loss: 2.8805 - val_accuracy: 0.4083 - val_macro_f1score: 0.0329 - val_weighted_f1score: 0.0012\n","Learning rate:  0.001\n","\n","Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 11/50\n","765/765 [==============================] - ETA: 0s - loss: 1.7426 - accuracy: 0.5918 - macro_f1score: 0.0513 - weighted_f1score: 0.0018\n","Epoch 00011: val_loss improved from 2.67501 to 2.30074, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/011.h5\n","\n","Epoch 00011: val_accuracy improved from 0.43683 to 0.53226, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/011.h5\n","765/765 [==============================] - 666s 870ms/step - loss: 1.7426 - accuracy: 0.5918 - macro_f1score: 0.0513 - weighted_f1score: 0.0018 - val_loss: 2.3007 - val_accuracy: 0.5323 - val_macro_f1score: 0.0478 - val_weighted_f1score: 0.0017\n","Learning rate:  0.001\n","\n","Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 12/50\n","765/765 [==============================] - ETA: 0s - loss: 1.5956 - accuracy: 0.6195 - macro_f1score: 0.0556 - weighted_f1score: 0.0019\n","Epoch 00012: val_loss did not improve from 2.30074\n","\n","Epoch 00012: val_accuracy did not improve from 0.53226\n","765/765 [==============================] - 658s 860ms/step - loss: 1.5956 - accuracy: 0.6195 - macro_f1score: 0.0556 - weighted_f1score: 0.0019 - val_loss: 2.6312 - val_accuracy: 0.5007 - val_macro_f1score: 0.0477 - val_weighted_f1score: 0.0017\n","Learning rate:  0.001\n","\n","Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 13/50\n","765/765 [==============================] - ETA: 0s - loss: 1.4648 - accuracy: 0.6511 - macro_f1score: 0.0596 - weighted_f1score: 0.0021\n","Epoch 00013: val_loss did not improve from 2.30074\n","\n","Epoch 00013: val_accuracy did not improve from 0.53226\n","765/765 [==============================] - 658s 860ms/step - loss: 1.4648 - accuracy: 0.6511 - macro_f1score: 0.0596 - weighted_f1score: 0.0021 - val_loss: 2.3440 - val_accuracy: 0.5302 - val_macro_f1score: 0.0493 - val_weighted_f1score: 0.0017\n","Learning rate:  0.001\n","\n","Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 14/50\n","765/765 [==============================] - ETA: 0s - loss: 1.3557 - accuracy: 0.6742 - macro_f1score: 0.0638 - weighted_f1score: 0.0022\n","Epoch 00014: val_loss did not improve from 2.30074\n","\n","Epoch 00014: val_accuracy did not improve from 0.53226\n","765/765 [==============================] - 669s 875ms/step - loss: 1.3557 - accuracy: 0.6742 - macro_f1score: 0.0638 - weighted_f1score: 0.0022 - val_loss: 2.5319 - val_accuracy: 0.5087 - val_macro_f1score: 0.0505 - val_weighted_f1score: 0.0018\n","Learning rate:  0.001\n","\n","Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 15/50\n","765/765 [==============================] - ETA: 0s - loss: 1.2445 - accuracy: 0.6974 - macro_f1score: 0.0675 - weighted_f1score: 0.0023\n","Epoch 00015: val_loss improved from 2.30074 to 2.26352, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/015.h5\n","\n","Epoch 00015: val_accuracy did not improve from 0.53226\n","765/765 [==============================] - 663s 867ms/step - loss: 1.2445 - accuracy: 0.6974 - macro_f1score: 0.0675 - weighted_f1score: 0.0023 - val_loss: 2.2635 - val_accuracy: 0.5282 - val_macro_f1score: 0.0480 - val_weighted_f1score: 0.0017\n","Learning rate:  0.001\n","\n","Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 16/50\n","765/765 [==============================] - ETA: 0s - loss: 1.1298 - accuracy: 0.7241 - macro_f1score: 0.0718 - weighted_f1score: 0.0025\n","Epoch 00016: val_loss did not improve from 2.26352\n","\n","Epoch 00016: val_accuracy did not improve from 0.53226\n","765/765 [==============================] - 655s 856ms/step - loss: 1.1298 - accuracy: 0.7241 - macro_f1score: 0.0718 - weighted_f1score: 0.0025 - val_loss: 2.7876 - val_accuracy: 0.5255 - val_macro_f1score: 0.0521 - val_weighted_f1score: 0.0018\n","Learning rate:  0.001\n","\n","Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 17/50\n","765/765 [==============================] - ETA: 0s - loss: 1.0384 - accuracy: 0.7472 - macro_f1score: 0.0748 - weighted_f1score: 0.0026\n","Epoch 00017: val_loss did not improve from 2.26352\n","\n","Epoch 00017: val_accuracy did not improve from 0.53226\n","765/765 [==============================] - 661s 864ms/step - loss: 1.0384 - accuracy: 0.7472 - macro_f1score: 0.0748 - weighted_f1score: 0.0026 - val_loss: 2.9266 - val_accuracy: 0.5155 - val_macro_f1score: 0.0503 - val_weighted_f1score: 0.0018\n","Learning rate:  0.001\n","\n","Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 18/50\n","765/765 [==============================] - ETA: 0s - loss: 0.9643 - accuracy: 0.7683 - macro_f1score: 0.0780 - weighted_f1score: 0.0027\n","Epoch 00018: val_loss did not improve from 2.26352\n","\n","Epoch 00018: val_accuracy improved from 0.53226 to 0.55578, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/018.h5\n","765/765 [==============================] - 668s 873ms/step - loss: 0.9643 - accuracy: 0.7683 - macro_f1score: 0.0780 - weighted_f1score: 0.0027 - val_loss: 2.4109 - val_accuracy: 0.5558 - val_macro_f1score: 0.0566 - val_weighted_f1score: 0.0020\n","Learning rate:  0.001\n","\n","Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 19/50\n","765/765 [==============================] - ETA: 0s - loss: 0.8834 - accuracy: 0.7838 - macro_f1score: 0.0807 - weighted_f1score: 0.0028\n","Epoch 00019: val_loss did not improve from 2.26352\n","\n","Epoch 00019: val_accuracy improved from 0.55578 to 0.56754, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/019.h5\n","765/765 [==============================] - 658s 860ms/step - loss: 0.8834 - accuracy: 0.7838 - macro_f1score: 0.0807 - weighted_f1score: 0.0028 - val_loss: 2.3439 - val_accuracy: 0.5675 - val_macro_f1score: 0.0582 - val_weighted_f1score: 0.0020\n","Learning rate:  0.001\n","\n","Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 20/50\n","765/765 [==============================] - ETA: 0s - loss: 0.8063 - accuracy: 0.8039 - macro_f1score: 0.0842 - weighted_f1score: 0.0029\n","Epoch 00020: val_loss did not improve from 2.26352\n","\n","Epoch 00020: val_accuracy improved from 0.56754 to 0.56956, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/020.h5\n","765/765 [==============================] - 656s 858ms/step - loss: 0.8063 - accuracy: 0.8039 - macro_f1score: 0.0842 - weighted_f1score: 0.0029 - val_loss: 2.2790 - val_accuracy: 0.5696 - val_macro_f1score: 0.0575 - val_weighted_f1score: 0.0020\n","Learning rate:  0.001\n","\n","Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 21/50\n","765/765 [==============================] - ETA: 0s - loss: 0.7542 - accuracy: 0.8196 - macro_f1score: 0.0861 - weighted_f1score: 0.0029\n","Epoch 00021: val_loss did not improve from 2.26352\n","\n","Epoch 00021: val_accuracy did not improve from 0.56956\n","765/765 [==============================] - 672s 879ms/step - loss: 0.7542 - accuracy: 0.8196 - macro_f1score: 0.0861 - weighted_f1score: 0.0029 - val_loss: 2.3591 - val_accuracy: 0.5531 - val_macro_f1score: 0.0569 - val_weighted_f1score: 0.0020\n","Learning rate:  0.001\n","\n","Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 22/50\n","765/765 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.8367 - macro_f1score: 0.0888 - weighted_f1score: 0.0030\n","Epoch 00022: val_loss did not improve from 2.26352\n","\n","Epoch 00022: val_accuracy improved from 0.56956 to 0.57292, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/022.h5\n","765/765 [==============================] - 647s 846ms/step - loss: 0.6891 - accuracy: 0.8367 - macro_f1score: 0.0888 - weighted_f1score: 0.0030 - val_loss: 2.3425 - val_accuracy: 0.5729 - val_macro_f1score: 0.0584 - val_weighted_f1score: 0.0021\n","Learning rate:  0.001\n","\n","Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 23/50\n","765/765 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.8508 - macro_f1score: 0.0911 - weighted_f1score: 0.0031\n","Epoch 00023: val_loss did not improve from 2.26352\n","\n","Epoch 00023: val_accuracy did not improve from 0.57292\n","765/765 [==============================] - 660s 863ms/step - loss: 0.6375 - accuracy: 0.8508 - macro_f1score: 0.0911 - weighted_f1score: 0.0031 - val_loss: 2.4952 - val_accuracy: 0.5632 - val_macro_f1score: 0.0593 - val_weighted_f1score: 0.0021\n","Learning rate:  0.001\n","\n","Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 24/50\n","765/765 [==============================] - ETA: 0s - loss: 0.6087 - accuracy: 0.8610 - macro_f1score: 0.0927 - weighted_f1score: 0.0032\n","Epoch 00024: val_loss did not improve from 2.26352\n","\n","Epoch 00024: val_accuracy did not improve from 0.57292\n","765/765 [==============================] - 664s 868ms/step - loss: 0.6087 - accuracy: 0.8610 - macro_f1score: 0.0927 - weighted_f1score: 0.0032 - val_loss: 2.7252 - val_accuracy: 0.5662 - val_macro_f1score: 0.0603 - val_weighted_f1score: 0.0021\n","Learning rate:  0.001\n","\n","Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 25/50\n","765/765 [==============================] - ETA: 0s - loss: 0.5565 - accuracy: 0.8733 - macro_f1score: 0.0946 - weighted_f1score: 0.0032\n","Epoch 00025: val_loss did not improve from 2.26352\n","\n","Epoch 00025: val_accuracy improved from 0.57292 to 0.57460, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/025.h5\n","765/765 [==============================] - 658s 860ms/step - loss: 0.5565 - accuracy: 0.8733 - macro_f1score: 0.0946 - weighted_f1score: 0.0032 - val_loss: 2.7430 - val_accuracy: 0.5746 - val_macro_f1score: 0.0614 - val_weighted_f1score: 0.0021\n","Learning rate:  0.001\n","\n","Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 26/50\n","765/765 [==============================] - ETA: 0s - loss: 0.5320 - accuracy: 0.8809 - macro_f1score: 0.0962 - weighted_f1score: 0.0033\n","Epoch 00026: val_loss did not improve from 2.26352\n","\n","Epoch 00026: val_accuracy did not improve from 0.57460\n","765/765 [==============================] - 657s 859ms/step - loss: 0.5320 - accuracy: 0.8809 - macro_f1score: 0.0962 - weighted_f1score: 0.0033 - val_loss: 2.6293 - val_accuracy: 0.5709 - val_macro_f1score: 0.0614 - val_weighted_f1score: 0.0021\n","Learning rate:  0.001\n","\n","Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 27/50\n","765/765 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.8875 - macro_f1score: 0.0969 - weighted_f1score: 0.0033\n","Epoch 00027: val_loss did not improve from 2.26352\n","\n","Epoch 00027: val_accuracy improved from 0.57460 to 0.58636, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/027.h5\n","765/765 [==============================] - 630s 824ms/step - loss: 0.5078 - accuracy: 0.8875 - macro_f1score: 0.0969 - weighted_f1score: 0.0033 - val_loss: 2.6551 - val_accuracy: 0.5864 - val_macro_f1score: 0.0621 - val_weighted_f1score: 0.0022\n","Learning rate:  0.001\n","\n","Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 28/50\n","765/765 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.8943 - macro_f1score: 0.0978 - weighted_f1score: 0.0033\n","Epoch 00028: val_loss did not improve from 2.26352\n","\n","Epoch 00028: val_accuracy improved from 0.58636 to 0.58871, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/028.h5\n","765/765 [==============================] - 637s 833ms/step - loss: 0.4948 - accuracy: 0.8943 - macro_f1score: 0.0978 - weighted_f1score: 0.0033 - val_loss: 2.5731 - val_accuracy: 0.5887 - val_macro_f1score: 0.0622 - val_weighted_f1score: 0.0022\n","Learning rate:  0.001\n","\n","Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 29/50\n","765/765 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.9061 - macro_f1score: 0.1002 - weighted_f1score: 0.0034\n","Epoch 00029: val_loss did not improve from 2.26352\n","\n","Epoch 00029: val_accuracy improved from 0.58871 to 0.59677, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/029.h5\n","765/765 [==============================] - 675s 882ms/step - loss: 0.4612 - accuracy: 0.9061 - macro_f1score: 0.1002 - weighted_f1score: 0.0034 - val_loss: 2.5727 - val_accuracy: 0.5968 - val_macro_f1score: 0.0639 - val_weighted_f1score: 0.0022\n","Learning rate:  0.001\n","\n","Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n","Epoch 30/50\n","765/765 [==============================] - ETA: 0s - loss: 0.4483 - accuracy: 0.9078 - macro_f1score: 0.1005 - weighted_f1score: 0.0034\n","Epoch 00030: val_loss did not improve from 2.26352\n","\n","Epoch 00030: val_accuracy did not improve from 0.59677\n","765/765 [==============================] - 694s 907ms/step - loss: 0.4483 - accuracy: 0.9078 - macro_f1score: 0.1005 - weighted_f1score: 0.0034 - val_loss: 2.5948 - val_accuracy: 0.5927 - val_macro_f1score: 0.0632 - val_weighted_f1score: 0.0022\n","Learning rate:  0.0001\n","\n","Epoch 00031: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 31/50\n","765/765 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.9523 - macro_f1score: 0.1065 - weighted_f1score: 0.0036\n","Epoch 00031: val_loss improved from 2.26352 to 2.00880, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/031.h5\n","\n","Epoch 00031: val_accuracy improved from 0.59677 to 0.65255, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/031.h5\n","765/765 [==============================] - 693s 905ms/step - loss: 0.3149 - accuracy: 0.9523 - macro_f1score: 0.1065 - weighted_f1score: 0.0036 - val_loss: 2.0088 - val_accuracy: 0.6526 - val_macro_f1score: 0.0703 - val_weighted_f1score: 0.0024\n","Learning rate:  0.0001\n","\n","Epoch 00032: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 32/50\n","765/765 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.9687 - macro_f1score: 0.1093 - weighted_f1score: 0.0037\n","Epoch 00032: val_loss improved from 2.00880 to 2.00654, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/032.h5\n","\n","Epoch 00032: val_accuracy improved from 0.65255 to 0.65793, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/032.h5\n","765/765 [==============================] - 700s 915ms/step - loss: 0.2552 - accuracy: 0.9687 - macro_f1score: 0.1093 - weighted_f1score: 0.0037 - val_loss: 2.0065 - val_accuracy: 0.6579 - val_macro_f1score: 0.0702 - val_weighted_f1score: 0.0024\n","Learning rate:  0.0001\n","\n","Epoch 00033: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 33/50\n","765/765 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.9755 - macro_f1score: 0.1102 - weighted_f1score: 0.0038\n","Epoch 00033: val_loss did not improve from 2.00654\n","\n","Epoch 00033: val_accuracy did not improve from 0.65793\n","765/765 [==============================] - 699s 914ms/step - loss: 0.2329 - accuracy: 0.9755 - macro_f1score: 0.1102 - weighted_f1score: 0.0038 - val_loss: 2.0126 - val_accuracy: 0.6559 - val_macro_f1score: 0.0708 - val_weighted_f1score: 0.0025\n","Learning rate:  0.0001\n","\n","Epoch 00034: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 34/50\n","765/765 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.9782 - macro_f1score: 0.1107 - weighted_f1score: 0.0038\n","Epoch 00034: val_loss did not improve from 2.00654\n","\n","Epoch 00034: val_accuracy did not improve from 0.65793\n","765/765 [==============================] - 696s 910ms/step - loss: 0.2256 - accuracy: 0.9782 - macro_f1score: 0.1107 - weighted_f1score: 0.0038 - val_loss: 2.0239 - val_accuracy: 0.6546 - val_macro_f1score: 0.0705 - val_weighted_f1score: 0.0024\n","Learning rate:  0.0001\n","\n","Epoch 00035: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 35/50\n","765/765 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9802 - macro_f1score: 0.1114 - weighted_f1score: 0.0038\n","Epoch 00035: val_loss did not improve from 2.00654\n","\n","Epoch 00035: val_accuracy did not improve from 0.65793\n","765/765 [==============================] - 700s 915ms/step - loss: 0.2161 - accuracy: 0.9802 - macro_f1score: 0.1114 - weighted_f1score: 0.0038 - val_loss: 2.0597 - val_accuracy: 0.6549 - val_macro_f1score: 0.0702 - val_weighted_f1score: 0.0024\n","Learning rate:  0.0001\n","\n","Epoch 00036: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 36/50\n","765/765 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.9845 - macro_f1score: 0.1123 - weighted_f1score: 0.0038\n","Epoch 00036: val_loss did not improve from 2.00654\n","\n","Epoch 00036: val_accuracy improved from 0.65793 to 0.65995, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/036.h5\n","765/765 [==============================] - 691s 903ms/step - loss: 0.2050 - accuracy: 0.9845 - macro_f1score: 0.1123 - weighted_f1score: 0.0038 - val_loss: 2.0642 - val_accuracy: 0.6599 - val_macro_f1score: 0.0701 - val_weighted_f1score: 0.0025\n","Learning rate:  0.0001\n","\n","Epoch 00037: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 37/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1997 - accuracy: 0.9851 - macro_f1score: 0.1120 - weighted_f1score: 0.0038\n","Epoch 00037: val_loss did not improve from 2.00654\n","\n","Epoch 00037: val_accuracy improved from 0.65995 to 0.66163, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/037.h5\n","765/765 [==============================] - 684s 894ms/step - loss: 0.1997 - accuracy: 0.9851 - macro_f1score: 0.1120 - weighted_f1score: 0.0038 - val_loss: 2.0873 - val_accuracy: 0.6616 - val_macro_f1score: 0.0716 - val_weighted_f1score: 0.0025\n","Learning rate:  0.0001\n","\n","Epoch 00038: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 38/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9862 - macro_f1score: 0.1122 - weighted_f1score: 0.0038\n","Epoch 00038: val_loss did not improve from 2.00654\n","\n","Epoch 00038: val_accuracy did not improve from 0.66163\n","765/765 [==============================] - 696s 910ms/step - loss: 0.1950 - accuracy: 0.9862 - macro_f1score: 0.1122 - weighted_f1score: 0.0038 - val_loss: 2.0990 - val_accuracy: 0.6593 - val_macro_f1score: 0.0709 - val_weighted_f1score: 0.0025\n","Learning rate:  0.0001\n","\n","Epoch 00039: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 39/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9852 - macro_f1score: 0.1123 - weighted_f1score: 0.0038\n","Epoch 00039: val_loss did not improve from 2.00654\n","\n","Epoch 00039: val_accuracy did not improve from 0.66163\n","765/765 [==============================] - 708s 925ms/step - loss: 0.1928 - accuracy: 0.9852 - macro_f1score: 0.1123 - weighted_f1score: 0.0038 - val_loss: 2.0908 - val_accuracy: 0.6613 - val_macro_f1score: 0.0702 - val_weighted_f1score: 0.0025\n","Learning rate:  0.0001\n","\n","Epoch 00040: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 40/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.9889 - macro_f1score: 0.1128 - weighted_f1score: 0.0038\n","Epoch 00040: val_loss did not improve from 2.00654\n","\n","Epoch 00040: val_accuracy did not improve from 0.66163\n","765/765 [==============================] - 701s 917ms/step - loss: 0.1846 - accuracy: 0.9889 - macro_f1score: 0.1128 - weighted_f1score: 0.0038 - val_loss: 2.0995 - val_accuracy: 0.6610 - val_macro_f1score: 0.0715 - val_weighted_f1score: 0.0025\n","Learning rate:  0.0001\n","\n","Epoch 00041: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 41/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9889 - macro_f1score: 0.1125 - weighted_f1score: 0.0038\n","Epoch 00041: val_loss did not improve from 2.00654\n","\n","Epoch 00041: val_accuracy did not improve from 0.66163\n","765/765 [==============================] - 702s 918ms/step - loss: 0.1823 - accuracy: 0.9889 - macro_f1score: 0.1125 - weighted_f1score: 0.0038 - val_loss: 2.1286 - val_accuracy: 0.6583 - val_macro_f1score: 0.0709 - val_weighted_f1score: 0.0025\n","Learning rate:  0.0001\n","\n","Epoch 00042: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 42/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.9895 - macro_f1score: 0.1124 - weighted_f1score: 0.0038\n","Epoch 00042: val_loss did not improve from 2.00654\n","\n","Epoch 00042: val_accuracy did not improve from 0.66163\n","765/765 [==============================] - 700s 915ms/step - loss: 0.1797 - accuracy: 0.9895 - macro_f1score: 0.1124 - weighted_f1score: 0.0038 - val_loss: 2.0936 - val_accuracy: 0.6579 - val_macro_f1score: 0.0708 - val_weighted_f1score: 0.0025\n","Learning rate:  0.0001\n","\n","Epoch 00043: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 43/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9902 - macro_f1score: 0.1130 - weighted_f1score: 0.0038\n","Epoch 00043: val_loss did not improve from 2.00654\n","\n","Epoch 00043: val_accuracy improved from 0.66163 to 0.66230, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/043.h5\n","765/765 [==============================] - 700s 915ms/step - loss: 0.1767 - accuracy: 0.9902 - macro_f1score: 0.1130 - weighted_f1score: 0.0038 - val_loss: 2.1125 - val_accuracy: 0.6623 - val_macro_f1score: 0.0728 - val_weighted_f1score: 0.0025\n","Learning rate:  0.0001\n","\n","Epoch 00044: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 44/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.9906 - macro_f1score: 0.1127 - weighted_f1score: 0.0038\n","Epoch 00044: val_loss did not improve from 2.00654\n","\n","Epoch 00044: val_accuracy improved from 0.66230 to 0.66263, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/044.h5\n","765/765 [==============================] - 714s 933ms/step - loss: 0.1762 - accuracy: 0.9906 - macro_f1score: 0.1127 - weighted_f1score: 0.0038 - val_loss: 2.1149 - val_accuracy: 0.6626 - val_macro_f1score: 0.0716 - val_weighted_f1score: 0.0025\n","Learning rate:  0.0001\n","\n","Epoch 00045: LearningRateScheduler reducing learning rate to 0.0001.\n","Epoch 45/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9905 - macro_f1score: 0.1133 - weighted_f1score: 0.0038\n","Epoch 00045: val_loss did not improve from 2.00654\n","\n","Epoch 00045: val_accuracy did not improve from 0.66263\n","765/765 [==============================] - 709s 927ms/step - loss: 0.1742 - accuracy: 0.9905 - macro_f1score: 0.1133 - weighted_f1score: 0.0038 - val_loss: 2.1079 - val_accuracy: 0.6606 - val_macro_f1score: 0.0723 - val_weighted_f1score: 0.0025\n","Learning rate:  1e-05\n","\n","Epoch 00046: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 46/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9917 - macro_f1score: 0.1134 - weighted_f1score: 0.0038\n","Epoch 00046: val_loss did not improve from 2.00654\n","\n","Epoch 00046: val_accuracy did not improve from 0.66263\n","765/765 [==============================] - 696s 910ms/step - loss: 0.1700 - accuracy: 0.9917 - macro_f1score: 0.1134 - weighted_f1score: 0.0038 - val_loss: 2.1038 - val_accuracy: 0.6616 - val_macro_f1score: 0.0720 - val_weighted_f1score: 0.0025\n","Learning rate:  1e-05\n","\n","Epoch 00047: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 47/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9919 - macro_f1score: 0.1131 - weighted_f1score: 0.0039\n","Epoch 00047: val_loss did not improve from 2.00654\n","\n","Epoch 00047: val_accuracy improved from 0.66263 to 0.66566, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/047.h5\n","765/765 [==============================] - 680s 889ms/step - loss: 0.1689 - accuracy: 0.9919 - macro_f1score: 0.1131 - weighted_f1score: 0.0039 - val_loss: 2.0955 - val_accuracy: 0.6657 - val_macro_f1score: 0.0717 - val_weighted_f1score: 0.0025\n","Learning rate:  1e-05\n","\n","Epoch 00048: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 48/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9929 - macro_f1score: 0.1131 - weighted_f1score: 0.0039\n","Epoch 00048: val_loss did not improve from 2.00654\n","\n","Epoch 00048: val_accuracy improved from 0.66566 to 0.66767, saving model to /content/drive/My Drive/Colab Notebooks/Paper/CALTECH/No_GAN/model_output/1/Xception/048.h5\n","765/765 [==============================] - 698s 912ms/step - loss: 0.1676 - accuracy: 0.9929 - macro_f1score: 0.1131 - weighted_f1score: 0.0039 - val_loss: 2.0877 - val_accuracy: 0.6677 - val_macro_f1score: 0.0713 - val_weighted_f1score: 0.0025\n","Learning rate:  1e-05\n","\n","Epoch 00049: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 49/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9921 - macro_f1score: 0.1133 - weighted_f1score: 0.0038\n","Epoch 00049: val_loss did not improve from 2.00654\n","\n","Epoch 00049: val_accuracy did not improve from 0.66767\n","765/765 [==============================] - 693s 906ms/step - loss: 0.1681 - accuracy: 0.9921 - macro_f1score: 0.1133 - weighted_f1score: 0.0038 - val_loss: 2.0926 - val_accuracy: 0.6657 - val_macro_f1score: 0.0718 - val_weighted_f1score: 0.0025\n","Learning rate:  1e-05\n","\n","Epoch 00050: LearningRateScheduler reducing learning rate to 1e-05.\n","Epoch 50/50\n","765/765 [==============================] - ETA: 0s - loss: 0.1649 - accuracy: 0.9927 - macro_f1score: 0.1133 - weighted_f1score: 0.0039\n","Epoch 00050: val_loss did not improve from 2.00654\n","\n","Epoch 00050: val_accuracy did not improve from 0.66767\n","765/765 [==============================] - 690s 902ms/step - loss: 0.1649 - accuracy: 0.9927 - macro_f1score: 0.1133 - weighted_f1score: 0.0039 - val_loss: 2.0926 - val_accuracy: 0.6677 - val_macro_f1score: 0.0715 - val_weighted_f1score: 0.0025\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bRiw3ebD-FhC","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1600176341411,"user_tz":-540,"elapsed":47916645,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"d9ec589e-05d5-407e-940a-ca168db8ad91"},"source":["# 1. epoch=maximum\n","loss , acc, mf1, wf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Accuracy: %.4f / Test Macro f1: %.4f / Test Weighted f1: %.4f]\\n' % (loss,acc,mf1,wf1))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["97/97 [==============================] - 1331s 14s/step - loss: 2.1280 - accuracy: 0.6643 - macro_f1score: 0.0721 - weighted_f1score: 0.0025\n","[Test Loss: 2.1280 /  Test Accuracy: 0.6643 / Test Macro f1: 0.0721 / Test Weighted f1: 0.0025]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zWPdDUWI-FhG","colab":{},"executionInfo":{"status":"ok","timestamp":1600176341417,"user_tz":-540,"elapsed":47916644,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","f1=history.history['macro_f1score']\n","val_f1=history.history['val_macro_f1score']\n","epochs=range(1,len(acc)+1)\n","\n","data = np.array([epochs,loss,val_loss,acc,val_acc,f1,val_f1]).T"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jhTx3Gm8-FhB"},"source":["### 3) Xception Evaluate\n"]},{"cell_type":"code","metadata":{"id":"yp2_HCXHyihu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600176341888,"user_tz":-540,"elapsed":47917108,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# data save\n","# epochs, loss, val_loss, acc, val_acc, f1, val_f1\n","\n","np.savetxt(os.path.join(dir,'train_valid_output',number,model.name+'.txt'),data)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"PpEXLWpmyihx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600176341891,"user_tz":-540,"elapsed":47917106,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# data import\n","data = np.loadtxt(os.path.join(dir,'train_valid_output',number,'Xception.txt'))"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1UoLe1oyihz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600176341893,"user_tz":-540,"elapsed":47917105,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["epochs=data[:,0]\n","loss=data[:,1]\n","val_loss=data[:,2]\n","acc=data[:,3]\n","val_acc=data[:,4]"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ITeu5vTyih3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"status":"ok","timestamp":1600176342419,"user_tz":-540,"elapsed":47917574,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"1b40b9fb-7b11-44da-ed41-2909fdeaf10a"},"source":["plt.plot(epochs[1:],acc[1:],'b',label='Training Acc')\n","plt.plot(epochs[1:],val_acc[1:],'r',label='Validation Acc')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs[10:],loss[10:],'b',label='Training Loss')\n","plt.plot(epochs[10:],val_loss[10:],'r',label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()"],"execution_count":33,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"_RmXQw95FFrY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600176342422,"user_tz":-540,"elapsed":47917569,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":[""],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-opNS8oXFHdB","colab":{},"executionInfo":{"status":"ok","timestamp":1600176342424,"user_tz":-540,"elapsed":47917566,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 이 아래는 내가 인위적으로 살펴보고 싶은 epoch에 대해서 결과값 출력 / Xception"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H-38Ov61FHdE","colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"status":"error","timestamp":1600176361073,"user_tz":-540,"elapsed":47936204,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}},"outputId":"e2729fd9-05f7-43ac-c3fc-5a9dca72cac2"},"source":["model=load_model(os.path.join(dir,'model_output',number,'Xception','022.h5'),custom_objects={\"macro_f1score\": macro_f1score,\"weighted_f1score\":weighted_f1score})"],"execution_count":35,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-0e9bdb7ab620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model_output'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Xception'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'022.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"macro_f1score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmacro_f1score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"weighted_f1score\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mweighted_f1score\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    180\u001b[0m     if (h5py is not None and (\n\u001b[1;32m    181\u001b[0m         isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 182\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    192\u001b[0m       \u001b[0;31m# Compile model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m       model.compile(**saving_utils.compile_args_from_training_config(\n\u001b[0;32m--> 194\u001b[0;31m           training_config, custom_objects))\n\u001b[0m\u001b[1;32m    195\u001b[0m       \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtry_build_compiled_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mcompile_args_from_training_config\u001b[0;34m(training_config, custom_objects)\u001b[0m\n\u001b[1;32m    209\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0moptimizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;31m# Recover losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       printable_module_name='optimizer')\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 347\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m   \u001b[0mcls_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unknown optimizer: AdamW"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hxpCFriTFHdG","colab":{},"executionInfo":{"status":"aborted","timestamp":1600176358625,"user_tz":-540,"elapsed":47933753,"user":{"displayName":"이동규","photoUrl":"","userId":"16331884730664529787"}}},"source":["# 2. epoch=?\n","loss , acc, mf1, wf1 = model.evaluate(test_generator,steps=int(len(x_test)/batch_sizes))\n","print('[Test Loss: %.4f /  Test Accuracy: %.4f / Test Macro f1: %.4f / Test Weighted f1: %.4f]\\n' % (loss,acc,mf1,wf1))"],"execution_count":null,"outputs":[]}]}